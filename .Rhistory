check_model(model)
install.packages("see")
# defining a model
model <- lm(mpg ~ wt + am + gear + vs * cyl, data = mtcars)
# checking model assumptions
check_model(model)
install.packages("qqplotr")
# defining a model
model <- lm(mpg ~ wt + am + gear + vs * cyl, data = mtcars)
# checking model assumptions
check_model(model)
install.packages(c("actuar", "autoplotly", "autostsm", "berryFunctions", "BGVAR", "bitops", "bookdown", "boot", "brio", "broom", "callr", "class", "cli", "clue", "cluster", "colorspace", "curl", "dbplyr", "dbscan", "DEoptim", "DescTools", "devtools", "diptest", "doBy", "dplyr", "DT", "ecm", "editData", "ellipsis", "esquisse", "exactRankTests", "formatR", "gamlss", "gh", "giscoR", "greybox", "GWmodel", "haven", "highr", "HLMdiag", "httpuv", "inum", "jquerylib", "KernSmooth", "knitr", "Lahman", "later", "lattice", "lwgeom", "magick", "mapsf", "MASS", "MASSExtra", "Matching", "Matrix", "mgcv", "mlr3misc", "modeltime", "muhaz", "multcomp", "nnet", "nycflights13", "odbc", "openssl", "parallelly", "pcaPP", "peopleanalyticsdata", "pillar", "pkgload", "processx", "R.cache", "raster", "rbibutils", "RcppArmadillo", "RcppParallel", "recipes", "remotes", "reprex", "reticulate", "rgl", "rlang", "Rmpfr", "RPostgres", "rsconnect", "RSQLite", "servr", "sfsmisc", "smcfcs", "spatial", "spatialreg", "spatstat", "spatstat.core", "spatstat.geom", "spdep", "splancs", "survival", "tibble", "tidymodels", "tidyselect", "tidyverse", "torch", "tsibble", "tune", "V8", "vctrs", "viridis", "viridisLite", "WDI", "withr", "WriteXLS", "xgboost"))
install.packages(c("actuar", "autoplotly", "autostsm", "berryFunctions", "BGVAR", "bitops", "bookdown", "boot", "brio", "broom", "callr", "class", "cli", "clue", "cluster", "colorspace", "curl", "dbplyr", "dbscan", "DEoptim", "DescTools", "devtools", "diptest", "doBy", "dplyr", "DT", "ecm", "editData", "ellipsis", "esquisse", "exactRankTests", "formatR", "gamlss", "gh", "giscoR", "greybox", "GWmodel", "haven", "highr", "HLMdiag", "httpuv", "inum", "jquerylib", "KernSmooth", "knitr", "Lahman", "later", "lattice", "lwgeom", "magick", "mapsf", "MASS", "MASSExtra", "Matching", "Matrix", "mgcv", "mlr3misc", "modeltime", "muhaz", "multcomp", "nnet", "nycflights13", "odbc", "openssl", "parallelly", "pcaPP", "peopleanalyticsdata", "pillar", "pkgload", "processx", "R.cache", "raster", "rbibutils", "RcppArmadillo", "RcppParallel", "recipes", "remotes", "reprex", "reticulate", "rgl", "rlang", "Rmpfr", "RPostgres", "rsconnect", "RSQLite", "servr", "sfsmisc", "smcfcs", "spatial", "spatialreg", "spatstat", "spatstat.core", "spatstat.geom", "spdep", "splancs", "survival", "tibble", "tidymodels", "tidyselect", "tidyverse", "torch", "tsibble", "tune", "V8", "vctrs", "viridis", "viridisLite", "WDI", "withr", "WriteXLS", "xgboost"))
library(reticulate)
miniconda_update()
py_install("scipy")
conda_python()
conda_version()
py_available()
py_config()
py_install("plotly")
repl_python()
install.packages(c("actuar", "Amelia", "autostsm", "BiocManager", "BMA", "brolgar", "bslib", "cachem", "caret", "corrplot", "cubature", "DataEditR", "dendextend", "DEoptim", "DEoptimR", "diagonals", "diptest", "dplyr", "e1071", "ecm", "effectsize", "eurostat", "fable", "fansi", "fields", "formatR", "greybox", "gt", "GWmodel", "h2o", "hms", "htmlTable", "httpuv", "inline", "insight", "ivreg", "jqr", "ks", "lamW", "leafem", "leafpop", "lme4", "Matrix", "parsnip", "performance", "pillar", "plot3D", "RcppArmadillo", "RcppParallel", "readstata13", "Rfast", "rhandsontable", "rmapshaper", "rmarkdown", "rsample", "rsconnect", "rversions", "sandwich", "sass", "see", "shape", "spdep", "statmod", "stochvol", "stringi", "systemfonts", "tibble", "tidycensus", "tigris", "viridis", "xaringan", "xfun"))
library(reticulate)
repl_python()
install.packages("tidyverse") install.packages("lubridate") install.packages("readxl") install.packages("highcharter") install.packages("tidyquant") install.packages("timetk") install.packages("tibbletime") install.packages("quantmod") install.packages("PerformanceAnalytics") install.packages("scales")
install.packages("tidyverse") , install.packages("lubridate") , install.packages("readxl") install.packages("highcharter") install.packages("tidyquant") install.packages("timetk") install.packages("tibbletime") install.packages("quantmod") install.packages("PerformanceAnalytics") install.packages("scales")
install.packages("tidyverse");  install.packages("lubridate");  install.packages("readxl"); install.packages("highcharter"); install.packages("tidyquant"); install.packages("timetk"); install.packages("tibbletime"); install.packages("quantmod"); install.packages("PerformanceAnalytics"); install.packages("scales")
library(tidyverse); library(lubridate); library(readxl); library(highcharter); library(tidyquant)
library(timetk); library(tibbletime); library(quantmod); library(PerformanceAnalytics); library(scales)
symbols <- c("SPY","EFA", "IJS", "EEM","AGG")
prices < getSymbols(symbols,src = 'yahoo', from = "2009-12-31", to = "2020-12-31", auto.assign = TRUE, warnings = FALSE) %>% map(~Ad(get(.))) %>% reduce(merge) %>% `colnames<-`(symbols)
View(AGG)
View(EEM)
View(SPY)
prices < getSymbols(symbols,src = 'yahoo', from = "2012-12-31", to = "2017-12-31", auto.assign = TRUE, warnings = FALSE) %>% map(~Ad(get(.))) %>% reduce(merge) %>% `colnames<-`(symbols)
prices < getSymbols(symbols,src = 'yahoo', from = "2009-12-31", to = "2020-12-31", auto.assign = TRUE, warnings = FALSE) %>% map(~Ad(get(.))) %>% reduce(merge) %>% `colnames<-`(symbols)
prices < reduce(merge) %>% `colnames<-`(symbols)
View(EEM)
View(AGG)
plot.xts(AGG$AGG.Adjusted)
install.packages(c("ade4", "Amelia", "autostsm", "bayesplot", "bayestestR", "BiocManager", "BMA", "broom", "corrplot", "DescTools", "devtools", "e1071", "fansi", "feasts", "finalfit", "forecast", "formatR", "ggdist", "ggplot2", "ggsignif", "greybox", "gtools", "GWmodel", "hts", "inline", "ks", "lamW", "manipulateWidget", "mapview", "Matrix", "matrixcalc", "matrixStats", "mgcv", "modeltime", "MSwM", "MTS", "mvtnorm", "np", "openxlsx", "optimx", "pander", "parallelly", "parameters", "plot3D", "plotly", "progressr", "proxy", "quantreg", "rbibutils", "RcppArmadillo", "Rdpack", "readstata13", "remotes", "rmarkdown", "robustbase", "rversions", "seasonal", "sf", "skedastic", "smcfcs", "spacetime", "spatstat.core", "spatstat.geom", "spatstat.utils", "spdep", "stars", "stochvol", "tensorflow", "testthat", "tfplot", "tinytex", "tmap", "torch", "units", "vdiffr", "xfun", "zip"))
install.packages(c("actuar", "colorspace", "fields", "glmnet", "Matrix", "mgcv", "spam"))
setwd("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy")
library(readxl)
#
panelx <- read_excel("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy/CAPM_EMP_UK.xls",col_types = c("numeric","numeric","numeric","numeric"),na = 'NA')
#
library(plm)
install.packages("plm")
install.packages("tidyverse")
library(readxl)
#
panelx <- read_excel("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy/CAPM_EMP_UK.xls",col_types = c("numeric","numeric","numeric","numeric"),na = 'NA')
#
library(plm)
data = pdata.frame(panelx, index=c("firm_ident", "year"))
pdim(data)
#
pooled = plm(return~beta, model="pooling", data=data)
summary(pooled)
#
fixed = plm(return~beta, model="within", data=data)
summary(fixed)
#
random = plm(return~beta, model="random", data=data)
summary(random)
#
phtest(fixed, random)
library(readxl)
#
panel <- read_excel("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy/CAPM_EMP_UK.xls",col_types = c("numeric","numeric","numeric","numeric"),na = 'NA')
#
library(plm)
data = pdata.frame(panel, index=c("firm_ident", "year"))
pdim(data)
summary(data[c("return","beta")])
# Pool
pooled = plm(return~beta, model="pooling", data=data)
summary(pooled)
# Efectos fijos
fixed = plm(return~beta, model="within", data=data)
summary(fixed)
# Efectos aleatorios
random = plm(return~beta, model="random", data=data)
summary(random)
# Test de Hausman
phtest(fixed, random)
reticulate::repl_python()
reticulate::repl_python()
reticulate::repl_python()
library(readxl)
#
panel <- read_excel("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy/CAPM_EMP_UK.xls",col_types = c("numeric","numeric","numeric","numeric"),na = 'NA')
head(panel)
#
library(plm)
data = pdata.frame(panel, index=c("firm_ident", "year"))
pdim(data)
summary(data[c("return","beta")])
# Pool MCO
pooled = plm(return~beta, model="pooling", data=data)
summary(pooled)
# Modelo de efectos fijos
fixed = plm(return~beta, model="within", data=data)
summary(fixed)
# Modelo de efectos aleatorios
random = plm(return~beta, model="random", data=data)
summary(random)
# Test de Hausman
phtest(fixed, random)
reticulate::repl_python()
?scatter
?plot
#
library(tidyverse)
CONS_USA <- read_csv("CONS_USA.csv")
#
# Método R tradicional
#
ts_CONS_USA <- ts(CONS_USA[,2:3], start=c(1959), end = c(2015))
head(ts_CONS_USA)
CY_USA %>%
ggplot(aes(x = Y, y = C)) +
geom_point() +
ylab("Consumo privado ($ million)") + xlab("Renta disponible ($ million)")
#
library(tidyverse)
CONS_USA <- read_csv("CONS_USA.csv")
#
# Método R tradicional
#
ts_CONS_USA <- ts(CONS_USA[,2:3], start=c(1959), end = c(2015))
head(ts_CONS_USA)
CONS_USA %>%
ggplot(aes(x = Y, y = C)) +
geom_point() +
ylab("Consumo privado ($ million)") + xlab("Renta disponible ($ million)")
#
C <- ts_CONS_USA[,"C"]
Y <- ts_CONS_USA[,"Y"]
plot(Y, C, type = "p",)
#
KEYNES_model <- lm (C ~ Y)
summary(KEYNES_model)
plot(KEYNES_model)
KEYNES_model <- lm (C ~ Y, data = ts_CONS_USA)
summary(KEYNES_model)
install.packages(c("DataEditR", "Rcpp", "sf", "spatstat.geom"))
setwd("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy")
#
library(tidyverse)
library(lubridate)
library(scales)
#
stock_data<-read_csv("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy/sp500_45.csv")
# filter
MSFT <- stock_data %>% filter(ticker == "MSFT")
# select
p_MSFT <-MSFT %>% select(ref.date,price.close) %>% rename(date=ref.date)
#
SP500<-read_csv("sp500_index.csv")
#
p_SP500 <- SP500 %>% select(ref.date,price.close) %>% rename(date=ref.date)
# join
data_daily <- inner_join(p_SP500,p_MSFT,by="date") %>% rename(p_SP500=price.close.x,p_MSFT=price.close.y)
# filter: de ("31/12/1997","DMY") a ("31/12/2018","DMY")
data_daily <- data_daily %>% filter(date>="1997-12-31" & date<="2018-12-31")
# mutate
data_daily <- data_daily %>% mutate(year = year(date),month=month(date))
#
data_daily<- data_daily %>% mutate(lnp_MSFT=log(p_MSFT),lnp_SP500=log(p_SP500))
p1<-ggplot(data=data_daily,aes(x=date)) +
geom_line(aes(y = p_MSFT), size = 0.5)+
scale_y_continuous(expand = c(0.01,0.01),limits = c(0,120), breaks = seq(0,120,20)) +
scale_x_date(breaks = as.Date(c("1998-01-01","2002-01-01","2006-01-01","2010-01-01","2014-01-01","2018-01-01")),
limits = as.Date(c("1998-01-01","2018-12-31")), labels = date_format("1%b%Y"),
minor_breaks = "1 year") +
labs(y = "Microsoft stock price (US dollars)",x= "Date (day)")
p1
p2<-ggplot(data=data_daily,aes(x=date)) +
geom_line(aes(y = p_SP500), size = 0.5)+
scale_y_continuous(limits = c(500,3000), breaks = seq(500,3000,500)) +
scale_x_date(breaks = as.Date(c("1998-01-01","2002-01-01","2006-01-01","2010-01-01","2014-01-01","2018-01-01")),
limits = as.Date(c("1998-01-01","2018-12-31")), labels = date_format("1%b%Y"),
minor_breaks = "1 year") +
labs(y = "S&P 500 stock market index",x= "Date (day)")
p2
#
data_daily <- data_daily %>%
mutate(l.p_MSFT=lag(p_MSFT),l.p_SP500=lag(p_SP500)) %>%
mutate(d.p_MSFT=p_MSFT-l.p_MSFT,d.p_SP500=p_SP500-l.p_SP500)
data_daily <- data_daily %>% mutate(PctRetMSFT=(d.p_MSFT/l.p_MSFT)*100, PctRetSP500=(d.p_SP500/l.p_SP500)*100)
p3 <- ggplot(data_daily, aes(x=PctRetSP500,y=PctRetMSFT)) +
geom_point() +
stat_smooth(method=lm) +
labs(x="S&P500 index daily returns (percent)",y="Microsoft stock daily returns (percent)")
p3
#   Regresión MCO
#
reg <- lm(PctRetMSFT ~ PctRetSP500, data=data_daily)
summary(reg)
#
reticulate::repl_python()
#
library(tidyverse)
library(lubridate)
library(scales)
#
stock_data<-read_csv("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy/sp500_45.csv")
# filter
MSFT <- stock_data %>% filter(ticker == "MSFT")
# select
p_MSFT <-MSFT %>% select(ref.date,price.close) %>% rename(date=ref.date)
#
SP500<-read_csv("sp500_index.csv")
#
p_SP500 <- SP500 %>% select(ref.date,price.close) %>% rename(date=ref.date)
# join
data_daily <- inner_join(p_SP500,p_MSFT,by="date") %>% rename(p_SP500=price.close.x,p_MSFT=price.close.y)
# filter: de ("31/12/1997","DMY") a ("31/12/2018","DMY")
data_daily <- data_daily %>% filter(date>="1997-12-31" & date<="2018-12-31")
# mutate
data_daily <- data_daily %>% mutate(year = year(date),month=month(date))
#
data_daily<- data_daily %>% mutate(lnp_MSFT=log(p_MSFT),lnp_SP500=log(p_SP500))
p1<-ggplot(data=data_daily,aes(x=date)) +
geom_line(aes(y = p_MSFT), size = 0.5)+
scale_y_continuous(expand = c(0.01,0.01),limits = c(0,120), breaks = seq(0,120,20)) +
scale_x_date(breaks = as.Date(c("1998-01-01","2002-01-01","2006-01-01","2010-01-01","2014-01-01","2018-01-01")),
limits = as.Date(c("1998-01-01","2018-12-31")), labels = date_format("1%b%Y"),
minor_breaks = "1 year") +
labs(y = "Microsoft stock price (US dollars)",x= "Date (day)")
p1
p2<-ggplot(data=data_daily,aes(x=date)) +
geom_line(aes(y = p_SP500), size = 0.5)+
scale_y_continuous(limits = c(500,3000), breaks = seq(500,3000,500)) +
scale_x_date(breaks = as.Date(c("1998-01-01","2002-01-01","2006-01-01","2010-01-01","2014-01-01","2018-01-01")),
limits = as.Date(c("1998-01-01","2018-12-31")), labels = date_format("1%b%Y"),
minor_breaks = "1 year") +
labs(y = "S&P 500 stock market index",x= "Date (day)")
p2
#
data_daily <- data_daily %>%
mutate(l.p_MSFT=lag(p_MSFT),l.p_SP500=lag(p_SP500)) %>%
mutate(d.p_MSFT=p_MSFT-l.p_MSFT,d.p_SP500=p_SP500-l.p_SP500)
data_daily <- data_daily %>% mutate(PctRetMSFT=(d.p_MSFT/l.p_MSFT)*100, PctRetSP500=(d.p_SP500/l.p_SP500)*100)
p3 <- ggplot(data_daily, aes(x=PctRetSP500,y=PctRetMSFT)) +
geom_point() +
stat_smooth(method=lm) +
labs(x="Rendimiento diario del índice S&P500 (%)",y="Rendimiento diario de Microsoft (%)")
p3
#   Regresión MCO
#
reg <- lm(PctRetMSFT ~ PctRetSP500, data=data_daily)
summary(reg)
#
library(tidyverse)
library(lubridate)
library(scales)
#
stock_data<-read_csv("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy/sp500_45.csv")
# filter
MSFT <- stock_data %>% filter(ticker == "MSFT")
# select
p_MSFT <-MSFT %>% select(ref.date,price.close) %>% rename(date=ref.date)
#
SP500<-read_csv("sp500_index.csv")
#
p_SP500 <- SP500 %>% select(ref.date,price.close) %>% rename(date=ref.date)
# join
data_daily <- inner_join(p_SP500,p_MSFT,by="date") %>% rename(p_SP500=price.close.x,p_MSFT=price.close.y)
# filter: de ("31/12/1997","DMY") a ("31/12/2018","DMY")
data_daily <- data_daily %>% filter(date>="1997-12-31" & date<="2018-12-31")
# mutate
data_daily <- data_daily %>% mutate(year = year(date),month=month(date))
#
data_daily<- data_daily %>% mutate(lnp_MSFT=log(p_MSFT),lnp_SP500=log(p_SP500))
p1<-ggplot(data=data_daily,aes(x=date)) +
geom_line(aes(y = p_MSFT), size = 0.5)+
scale_y_continuous(expand = c(0.01,0.01),limits = c(0,120), breaks = seq(0,120,20)) +
scale_x_date(breaks = as.Date(c("1998-01-01","2002-01-01","2006-01-01","2010-01-01","2014-01-01","2018-01-01")),
limits = as.Date(c("1998-01-01","2018-12-31")), labels = date_format("1%b%Y"),
minor_breaks = "1 year") +
labs(y = "Precio de las acciones de Microsoft (US $)",x= "Date (day)")
p1
p2<-ggplot(data=data_daily,aes(x=date)) +
geom_line(aes(y = p_SP500), size = 0.5)+
scale_y_continuous(limits = c(500,3000), breaks = seq(500,3000,500)) +
scale_x_date(breaks = as.Date(c("1998-01-01","2002-01-01","2006-01-01","2010-01-01","2014-01-01","2018-01-01")),
limits = as.Date(c("1998-01-01","2018-12-31")), labels = date_format("1%b%Y"),
minor_breaks = "1 year") +
labs(y = "Índice S&P 500 del mercado bursátil",x= "Date (day)")
p2
#
data_daily <- data_daily %>%
mutate(l.p_MSFT=lag(p_MSFT),l.p_SP500=lag(p_SP500)) %>%
mutate(d.p_MSFT=p_MSFT-l.p_MSFT,d.p_SP500=p_SP500-l.p_SP500)
data_daily <- data_daily %>% mutate(PctRetMSFT=(d.p_MSFT/l.p_MSFT)*100, PctRetSP500=(d.p_SP500/l.p_SP500)*100)
p3 <- ggplot(data_daily, aes(x=PctRetSP500,y=PctRetMSFT)) +
geom_point() +
stat_smooth(method=lm) +
labs(x="Rendimiento diario del índice S&P500 (%)",y="Rendimiento diario de Microsoft (%)")
p3
#   Regresión MCO
#
reg <- lm(PctRetMSFT ~ PctRetSP500, data=data_daily)
summary(reg)
#
reticulate::repl_python()
#
library(tidyverse)
library(lubridate)
library(scales)
#
stock_data<-read_csv("~/Dropbox/Mi Mac (Mac Pro de Julián)/Documents/GitHub/EcoMetricsRPy/sp500_45.csv")
# filter
MSFT <- stock_data %>% filter(ticker == "MSFT")
# select
p_MSFT <-MSFT %>% select(ref.date,price.close) %>% rename(date=ref.date)
#
SP500<-read_csv("sp500_index.csv")
#
p_SP500 <- SP500 %>% select(ref.date,price.close) %>% rename(date=ref.date)
# join
data_daily <- inner_join(p_SP500,p_MSFT,by="date") %>% rename(p_SP500=price.close.x,p_MSFT=price.close.y)
# filter: de ("31/12/1997","DMY") a ("31/12/2018","DMY")
data_daily <- data_daily %>% filter(date>="1997-12-31" & date<="2018-12-31")
# mutate
data_daily <- data_daily %>% mutate(year = year(date),month=month(date))
#
data_daily<- data_daily %>% mutate(l_MSFT=log(p_MSFT),l_SP500=log(p_SP500))
p1<-ggplot(data=data_daily,aes(x=date)) +
geom_line(aes(y = p_MSFT), size = 0.5)+
scale_y_continuous(expand = c(0.01,0.01),limits = c(0,120), breaks = seq(0,120,20)) +
scale_x_date(breaks = as.Date(c("1998-01-01","2002-01-01","2006-01-01","2010-01-01","2014-01-01","2018-01-01")),
limits = as.Date(c("1998-01-01","2018-12-31")), labels = date_format("1%b%Y"),
minor_breaks = "1 year") +
labs(y = "Precio de las acciones de Microsoft (US $)",x= "Fecha (día)")
p1
p2<-ggplot(data=data_daily,aes(x=date)) +
geom_line(aes(y = p_SP500), size = 0.5)+
scale_y_continuous(limits = c(500,3000), breaks = seq(500,3000,500)) +
scale_x_date(breaks = as.Date(c("1998-01-01","2002-01-01","2006-01-01","2010-01-01","2014-01-01","2018-01-01")),
limits = as.Date(c("1998-01-01","2018-12-31")), labels = date_format("1%b%Y"),
minor_breaks = "1 year") +
labs(y = "Índice S&P 500 del mercado bursátil",x= "Fecha (día)")
p2
#
data_daily <- data_daily %>%
mutate(l.p_MSFT=lag(p_MSFT),l.p_SP500=lag(p_SP500)) %>%
mutate(d.p_MSFT=p_MSFT-l.p_MSFT,d.p_SP500=p_SP500-l.p_SP500)
data_daily <- data_daily %>% mutate(r_MSFT=(d.p_MSFT/l.p_MSFT)*100, r_SP500=(d.p_SP500/l.p_SP500)*100)
p3 <- ggplot(data_daily, aes(r_SP500,y=r_MSFT)) +
geom_point() +
stat_smooth(method=lm) +
labs(x="Rendimiento diario del índice S&P 500 (%)",y="Rendimiento diario de Microsoft (%)")
p3
#   Regresión MCO
#
reg <- lm(r_MSFT ~ r_SP500, data=data_daily)
summary(reg)
#
library(readr)
GAPMINDER <- read_delim("GAPMINDER.csv",
";", escape_double = FALSE, trim_ws = TRUE)
View(GAPMINDER)
library(tidyverse)
gapminder <- read_delim("GAPMINDER.csv", ";", escape_double = FALSE, trim_ws = TRUE)
gapminder
#
library(skimr)
skim(gapminder)
#
# Operaciones básicas del Tidyverse
#
# "Verbos" de dplyr
#
# select
#
gapminder_selected <- select(gapminder, year, country, pop, gdpPercap)
#
# filter
#
gapminder_filtered <- filter(gapminder_selected, year>=1980)
#
# mutate
#
gapminder_mutated <- mutate(gapminder_filtered, GDP=gdpPercap*pop)
#
# group_by
#
gapminder_grouped <- group_by(gapminder_mutated, country)
#
# summarise
#
gapminder_summarised <- summarise(gapminder_grouped, AVG_GDP=mean(GDP))
#
# arrange
#
gapminder_arranged_ascending <- arrange(gapminder_summarised, AVG_GDP)
gapminder_arranged_descending <- arrange(gapminder_summarised, -AVG_GDP)
#
# El operador "tubería" (pipe) (%>%)
#
AVG_GDP <-
gapminder %>%
select(year, country, pop, gdpPercap) %>%
filter(year>=1980) %>%
mutate(GDP=gdpPercap*pop) %>%
group_by(country) %>%
summarise(AVG_GDP=mean(GDP)) %>%
arrange(-AVG_GDP)
#
# Gráficas y EDA
#
# esquisse plots
# Select the 'ggplot2' builder in the Addins menu of RStudio or ...
#
esquisse:::esquisser()
library(tidyverse)
gapminder <- read_delim("GAPMINDER.csv", ";", escape_double = FALSE, trim_ws = TRUE)
gapminder
#
library(skimr)
skim(gapminder)
#
# Operaciones básicas del Tidyverse
#
# "Verbos" de dplyr
#
# select
#
gapminder_selected <- select(gapminder, year, country, pop, gdpPercap)
#
# filter
#
gapminder_filtered <- filter(gapminder_selected, year>=1980)
#
# mutate
#
gapminder_mutated <- mutate(gapminder_filtered, GDP=gdpPercap*pop)
#
# group_by
#
gapminder_grouped <- group_by(gapminder_mutated, country)
#
# summarise
#
gapminder_summarised <- summarise(gapminder_grouped, AVG_GDP=mean(GDP))
#
# arrange
#
gapminder_arranged_ascending <- arrange(gapminder_summarised, AVG_GDP)
gapminder_arranged_descending <- arrange(gapminder_summarised, -AVG_GDP)
#
# El operador "tubería" (pipe) (%>%)
#
AVG_GDP <-
gapminder %>%
select(year, country, pop, gdpPercap) %>%
filter(year>=1980) %>%
mutate(GDP=gdpPercap*pop) %>%
group_by(country) %>%
summarise(AVG_GDP=mean(GDP)) %>%
arrange(-AVG_GDP)
#
# Gráficas y EDA
#
# esquisse plots
# Select the 'ggplot2' builder in the Addins menu of RStudio or ...
#
# esquisse:::esquisser()
#
# GGally technique
library(GGally)
#
gapminder %>% select(-country) %>% ggpairs()
#
# Regression
#
# Simple linear model
#
model_1 <- lm(lifeExp ~ gdpPercap, data=gapminder)
summary(model_1)
#
model_2 <- lm(lifeExp ~ gdpPercap + year, data=gapminder)
summary(model_2)
#
# LRM assumptions
#
library(lindia)
model_2 %>%
gg_diagnose(plot.all=TRUE,boxcox=TRUE)
#
model_3 <- lm(lifeExp ~ log(gdpPercap) + year, data=gapminder)
summary(model_3)
model_3 %>%
gg_diagnose(plot.all=TRUE,boxcox=TRUE)
#
View(gapminder_arranged_descending)
rm(GAPMINDER)
View(gapminder)
View(gapminder_selected)
View(gapminder_filtered)
View(gapminder_mutated)
View(gapminder_grouped)
View(gapminder_summarised)
View(gapminder_arranged_ascending)
View(gapminder_arranged_descending)
View(AVG_GDP)
ggThemeAssist:::ggThemeAssistAddin()
