#
# Modelo A
#
summary(dynlm_A <- dynlm(AH ~ L(AH, 1:2), data = AHORRO_RENTA_ts, start = c(1972,1), end = c(2005,1)))
#
# Modelo B
#
summary(dynlm_B <- dynlm(AH ~ L(Y,0:0) + L(AH, 1:1), data = AHORRO_RENTA_ts, start = c(1972,1), end = c(2005,1)))
#
# Contraste de Cox
#
coxtest(dynlm_A, dynlm_B)
#
#  Contraste J de Davidson y MacKinnon
#
jtest(dynlm_A, dynlm_B)
#
# Modelo anidado
#
summary(dynlm_AB <- dynlm(AH ~ L(AH, 1:2) + L(Y,0:0), data = AHORRO_RENTA_ts, start = c(1972,1), end = c(2005,1)))
#
# Comparación de modelos (librería performance)
#
model_performance(dynlm_A)
model_performance(dynlm_B)
#
compare_performance(dynlm_A, dynlm_B, rank = TRUE)
plot(compare_performance(dynlm_A, dynlm_B, rank = TRUE))
#
test_performance(dynlm_A,dynlm_B)
check_model(dynlm_A)
compare_performance(dynlm_A, dynlm_B, rank = TRUE)
rm(list=ls())
#
# Lectura de datos
#
library(tidyverse)
VENTAS <- read_csv("VENTAS_SUPER.csv")
dim(VENTAS)
VENTAS
summary(VENTAS)
#
# Matriz de diagrama de puntos de las variables
#
library(alr4)
scatterplotMatrix(~ V + P + A, id=list(n=3), smooth=list(span=0.75), data=VENTAS)
#
# Modelo econométrico
#
modelo.ventas.1 <- lm(V ~ P + A, data=VENTAS)
S(modelo.ventas.1)
confint(modelo.ventas.1, level=.95)
plot(allEffects(modelo.ventas.1), grid=TRUE, rug=TRUE)
# Diagnósticos de la regresión
#
# Validación global de las hipótesis del MRL
#
library(gvlma)
gvmodel <- gvlma(modelo.ventas.1)
summary(gvmodel)
plot(gvmodel)
#
Funcionamiento general del modelo
#
library(performance)
model_performance(modelo.ventas.1)
check_model(modelo.ventas.1)
#
Test RESET de Ramsey de especificación funcional
#
library(lmtest)
resettest(modelo.ventas.1, power=2, type="fitted")
resettest(modelo.ventas.1, power=2:3, type="fitted")
#
No linealidad
#
library(car)
residualPlots(modelo.ventas.1) # Gráficos estándar de los residuos
avPlots(modelo.ventas.1) # Added-Variable plots
crPlots(modelo.ventas.1) # Component-plus-Residual plots (partial-residual plots)
ceresPlots(modelo.ventas.1) # CERES (Combining conditional Expectations and RESidual) plots
#
# Heteroscedasticidad (varianza no constante)
#
spreadLevelPlot(modelo.ventas, smooth=list(span=1))
ncvTest(modelo.ventas)
ncvTest(modelo.ventas, var.formula= ~ P + A)
#
# Normalidad y datos atípicos
#
densityPlot(residuals(modelo.ventas.1))
densityPlot(rstudent(modelo.ventas.1))
qqPlot(modelo.ventas.1, id=list(n=3)) # Outliers
outlierTest(modelo.ventas.1) # Outliers
influenceIndexPlot(modelo.ventas.1, id=list(n=3), vars=c("Studentized","hat","Cook")) # Outliers & Leverages
influencePlot(modelo.ventas.1, id=list(n=3)) # Outliers & Leverages
avPlots(modelo.ventas.1, id=list(n=3, method="mahal")) # id=list(n=0) suprime etiquetas
#
#
spreadLevelPlot(modelo.ventas.1, smooth=list(span=1))
ncvTest(modelo.ventas.1)
ncvTest(modelo.ventas.1, var.formula= ~ P + A)
#
Modelo alternativo: re-especificación cuadrática
#
modelo.ventas.2 <- lm(V ~ P + A + I(A^2), data=VENTAS)
S(modelo.ventas.2)
confint(modelo.ventas.2, level=.95)
plot(Effect("P", modelo.ventas.2))
plot(Effect("A", modelo.ventas.2))
#
# Comparación con el modelo básico
#
compareCoefs(modelo.ventas.1, modelo.ventas.2)
anova(modelo.ventas.1, modelo.ventas.2)
ccompare_performance(modelo.ventas.1, modelo.ventas.2, rank = TRUE)
plot(compare_performance(modelo.ventas.1, modelo.ventas.2, rank = TRUE))
test_performance(modelo.ventas.1, modelo.ventas.2)
test_wald(modelo.ventas.1, modelo.ventas.2)
test_bf(modelo.ventas.1, modelo.ventas.2)
test_vuong(modelo.ventas.1, modelo.ventas.2)
#
ompare_performance(modelo.ventas.1, modelo.ventas.2, rank = TRUE)
compare_performance(modelo.ventas.1, modelo.ventas.2, rank = TRUE)
rm(list=ls())
install.packages(c("autostsm", "backports", "BayesFactor", "brio", "BVAR", "conflicted", "coro", "corrplot", "cpp11", "credentials", "crul", "DataEditR", "datamods", "DescTools", "devtools", "digest", "DT", "dtplyr", "Exact", "fabletools", "fda", "finalfit", "flextable", "fs", "gamlss.dist", "gert", "ggdist", "git2r", "gld", "glue", "graphlayouts", "greybox", "igraph", "jqr", "Matrix", "memoise", "mhurdle", "mice", "microbenchmark", "mlr3", "mlr3misc", "odbc", "OECD", "officer", "parallelly", "pkgbuild", "pkgload", "PMCMRplus", "polycor", "pracma", "ragg", "raster", "rbibutils", "Rdpack", "readr", "remotes", "rex", "Rfast", "rgl", "rio", "rJava", "robust", "RPostgres", "rsconnect", "RSQLite", "servr", "sessioninfo", "sf", "slam", "smooth", "sn", "sp", "SpatialEpi", "spatialreg", "spatstat", "spatstat.core", "spatstat.geom", "spatstat.linnet", "spatstat.utils", "spdep", "stars", "stochvol", "stringi", "terra", "testthat", "timetk", "tseries", "tsibble", "TTR", "usethis", "V8", "vroom", "withr", "xgboost", "xml2", "yardstick"))
#
library(tidyverse)
CONS_ESP <- read_csv("CONS_ESP.csv")
#
ts_CONS_ESP <- ts(CONS_ESP[,2:8], start=c(1995), end = c(2017), frequency = 4)
plot(ts_CONS_ESP)
#
C <- ts_CONS_ESP[,"PCR"]
Y <- ts_CONS_ESP[,"HDYR"]
ts.plot(Y, C)
View(ts_CONS_ESP)
View(CONS_ESP)
# Modelo Keynesiano de consumo
#
KEYNES_model <- lm (C ~ Y)
summary(KEYNES_model)
plot(KEYNES_model)
rm(list=ls())
#
library(tidyverse)
library(car)
library(lmtest)
library(quantreg)
# library(MASS)
# library(effects)
# library(RcmdrMisc)
# library(sfsmisc)
# library(sandwich)
# library(dynlm)
# library(moments)
# library(tseries)
#
ATIP <- read_csv("ATIP.csv")
View(ATIP)
summary(ATIP)
# Diagrama de puntos
#
scatterplotMatrix(~ Y + X, id=list(n=3), smooth=list(span=0.7), data=ATIP)
ggplot(ATIP, aes(x=X, y=Y)) + geom_point() + labs(title="Diagrama de puntos", x="X", y="Y")
#
# Modelo de regresión lineal
#
summary(lm_YX <- lm(Y ~ X, data = ATIP))
plot(Y ~ X , data=ATIP)
abline(lm_YX)
#
par(mfrow=c(2,2))
plot(lm_YX)
# ¿Qué pasa si se eliminan las tres observaciones atípicas?
summary(lm_YX_1 <- lm(Y ~ X, data = ATIP))
summary(lm_YX_2 <- lm(Y ~ X, data = ATIP[1:19,]))
compareCoefs(lm_YX_1,lm_YX_2)
plot(Y ~ X , data=ATIP)
abline(lm_YX_1)
abline(lm_YX_2, lty=2)
legend("topleft", c("MCO muestra completa", "MCO muestra recortada"), lty = c(1, 2), bty = "n")
#
# ¿Qué pasa si se eliminan las tres observaciones atípicas?
summary(lm_YX_1 <- lm(Y ~ X, data = ATIP))
summary(lm_YX_2 <- lm(Y ~ X, data = ATIP[1:19,]))
compareCoefs(lm_YX_1,lm_YX_2)
plot(Y ~ X , data=ATIP)
abline(lm_YX_1)
abline(lm_YX_2, lty=2)
legend("topleft", c("Muestra completa", "Muestra recortada"), lty = c(1, 2), bty = "n")
#
# ¿Qué pasa si se eliminan las tres observaciones atípicas?
summary(M_1 <- lm(Y ~ X, data = ATIP))
summary(M_2 <- lm(Y ~ X, data = ATIP[1:19,]))
compareCoefs(M_1,M_2)
plot(Y ~ X , data=ATIP)
abline(M_1)
abline(M_2, lty=2)
legend("topleft", c("Muestra completa (M_1)", "Muestra recortada (M_2)"), lty = c(1, 2), bty = "n")
#
# ¿Qué pasa si se eliminan las tres observaciones atípicas?
summary(M1 <- lm(Y ~ X, data = ATIP))
summary(M2 <- lm(Y ~ X, data = ATIP[1:19,]))
compareCoefs(M1,M2)
plot(Y ~ X , data=ATIP)
abline(M1)
abline(M2, lty=2)
legend("topleft", c("Muestra completa (M1)", "Muestra recortada (M2)"), lty = c(1, 2), bty = "n")
#
plot(Y ~ X , data=ATIP)
abline(M1)
abline(M2, lty=2)
legend("topleft", c("Datos completos (M1)", "Datos recortados (M2)"), lty = c(1, 2), bty = "n")
#
# Distribución de los errores del modelo
#
plot(lm_YX$residuals)
#
hist(lm_YX$residuals, main = "")
box()
#
densityPlot(residuals(lm_YX))
#
qqnorm(residuals(lm_YX))
qqline(residuals(lm_YX))
#
qqPlot(lm_YX, distribution="norm")
#
densityPlot(residuals(lm_YX))
densityPlot(rstudent(lm_YX))
# Contrastes de normalidad
#
r <- resid(lm_YX)
rbar <- mean(r)
sdr <- sd(r)
hist(lm_YX$residuals, col="grey", freq=FALSE, main="Distribución de los residuos", ylab="Density", xlab="residuos")
curve(dnorm(x, rbar, sdr), col=2, add=TRUE, ylab="Density", xlab="r")
#
library(moments)
# Librería moments
skewness(lm_YX$residuals)
kurtosis(lm_YX$residuals)
agostino.test(lm_YX$residuals)
anscombe.test(lm_YX$residuals)
jarque.test(lm_YX$residuals)
library(tseries)
# librería tseries
jarque.bera.test(lm_YX$residuals)
shapiro.test(lm_YX$residuals)
ks.test(lm_YX$residuals, pnorm)
# Detección de observaciones atípicas
#
# Observaciones atípicas en las variables explicativas (leverages <-> apalancamiento)
#
hat <- hatvalues(lm_YX)
hat
which(hat > 2 * mean(hat))
plot(hat)
abline(h = mean(hat), col = 4)
abline(h = 2 * mean(hat), col = 2)
id <- which(hat > 2 * mean(hat))
text(id, hat[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
#
summary(hat)
# Observaciones atípicas en la variable dependiente (outliers)
#
slm_YX <- summary(lm_YX)
# Residuos estandarizados
r <- lm_YX$residuals/slm_YX$sigma
r
densityPlot(r)
which(abs(r) > 2.5)
plot(r)
abline(h = c(0,-2.5, 2.5), col = 4)
id <- which(abs(r) > 2.5)
text(id, r[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
# Residuos estudentizados (internamente)
rs <- rstandard(lm_YX)
rs
densityPlot(rs)
which(abs(rs) > 2)
plot(rs)
abline(h = c(0,-2, 2)*sd(rs), col = 4)
id <- which(abs(r) > 2*sd(rs))
text(id, r[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
# Residuos estudentizados (externamente)
rt <- rstudent(lm_YX)
rt
densityPlot(rt)
qqPlot(lm_YX)
outlierTest(lm_YX)
# Diagnósticos específicos
#
# Observaciones influyentes: cálculo de DFBETAS_i, DFFITS_i, COVRATIO_i, DCOOK_i y h_i ;
# inf -> señala obs. inusuales para al menos una medida
#
influence.measures(lm_YX)
S(influence.measures(lm_YX))
influenceIndexPlot(lm_YX, vars=c("hat", "Studentized","Cook"))
influencePlot(lm_YX, xlab="Hat values")
# Medidas individuales
hat <- hatvalues(lm_YX)
dfbetas <-  dfbetas(lm_YX)
dffits <-  dffits(lm_YX)
dcook <-  cooks.distance(lm_YX)
hat ; dfbetas ; dffits; dcook
#
max(hatvalues(lm_YX))
which.max(hatvalues(lm_YX))
#
max(abs(dffits(lm_YX)))
which.max(abs(dffits(lm_YX)))
#
max(cooks.distance(lm_YX))
which.max(cooks.distance(lm_YX))
#
# Gráficos de variable añadida, buscando casos influyentes
avPlots(lm_YX, id=list(cex=0.60, method="mahal"))
# Regresión cuartilítica
#
S(lm_YX <- lm(Y ~ X, data = ATIP))
S(qr_YX <- rq(Y ~ X, data = ATIP)) # tau=0.5
plot(Y ~ X , data=ATIP)
abline(lm_YX)
abline(qr_YX, lty=2)
legend("topleft", c("Regresi?n MCO", "Regresi?n MDA"), lty = c(1, 2), bty = "n")
#
# rq secuencial
S(qr_YX <- rq(Y ~ X, data = ATIP, tau=seq(0.1,0.9,0.1)))
plot(summary(qr_YX), level=0.95)
# rq discreto
S(qr_YX <- rq(Y ~ X, tau = c(0.25, 0.50, 0.75), data = ATIP))
plot(qr_YX)
#
# Regresión cuartilítica
#
S(lm_YX <- lm(Y ~ X, data = ATIP))
S(qr_YX <- rq(Y ~ X, data = ATIP)) # tau=0.5
plot(Y ~ X , data=ATIP)
abline(lm_YX)
abline(qr_YX, lty=2)
legend("topleft", c("Regresión MCO", "Regresión DAM"), lty = c(1, 2), bty = "n")
#
# rq secuencial
S(qr_YX <- rq(Y ~ X, data = ATIP, tau=seq(0.1,0.9,0.1)))
plot(summary(qr_YX), level=0.95)
# rq discreto
S(qr_YX <- rq(Y ~ X, tau = c(0.25, 0.50, 0.75), data = ATIP))
plot(qr_YX)
#
rm(list=ls())
library(MASS)
?rlm
#
library(tidyverse)
library(car)
library(lmtest)
library(quantreg)
#
ATIP <- read_csv("ATIP.csv")
View(ATIP)
summary(ATIP)
summary(lm_YX <- lm(Y ~ X, data = ATIP))
summary(qr_YX <- rq(Y ~ X, data = ATIP)) # tau=0.5
library(MASS)
summary(rlm_YX <- rlm(Y ~ X, data = ATIP, method="MM"))
abline(lm_YX)
abline(rlm_YX, lty=2)
legend("topleft", c("Regresión MCO", "Regresión MM"), lty = c(1, 2), bty = "n")
plot(Y ~ X , data=ATIP) ; abline(lm_YX)
abline(rlm_YX, lty=2)
legend("topleft", c("Regresión MCO", "Regresión MM"), lty = c(1, 2), bty = "n")
compareCoefs(lm_YX,qr_YX,rlm_YX)
#
library(spData)
data(house, package="spData")
class(house)
summary(house@data)
View(house)
#
library(sf)
library(leaflet)
library(ggplot2)
library(maptools)
library(RColorBrewer)
library(classInt)
library(rgdal)
library(viridis)
#
# Representación de datos espaciales
#
spplot(house, "price", col.regions = rev(magma(10)))
#
# Convirtiendo objeto sp a sf
house_sf <- st_as_sf(house)
class(house_sf)
plot(house_sf[1])
ggplot(house_sf) + geom_sf(aes(fill=price))+ theme_bw()
# Indicadores de asociación espacial (global y local)
#
library(spdep)
library(dplyr)
# Información sobre las coordenadas (longitud y latitud) de los datos
coords <- coordinates(house)
# Matrices de pesos espaciales
# Vecinos más próximos (k=6 mediana de vecinos en la base de datos)
house.6nn <- knearneigh(coords, k=6)
house.6nn.nb <- knn2nb(house.6nn)
# Gráficos de vecinos
#
plot(st_geometry(house_sf))
plot(house.6nn.nb, coords, add=TRUE, col="red")
#
# Cálculo de las matrices de pesos W (estandarizadas por filas)
house.6nn.w <- nb2listw(neighbours=house.6nn.nb, style="W")
Estadísticos de autocorrelación espacial
#
# Global
moran.test(house_sf$price, listw=house.6nn.w)
geary.test(house_sf$price, listw=house.6nn.w)
# Local
LocalI <- as.data.frame(localmoran(house_sf$price, listw=house.6nn.w))
str(LocalI)
moran.plot(house_sf$price, listw=house.6nn.w)
# Clusters locales
house_LocalI_sf <- bind_cols(house_sf,LocalI) #
plot(house_LocalI_sf["Z.Ii"])
#
# Modelos econométricos espaciales
#
library(spatialreg)
form <- formula(log(price) ~ age + log(lotsize) + rooms)
# Modelo lineal (LM) estimado por MCO
model.LS <- lm(formula=form, data=house_sf)
summary(model.LS)
# Modelo con retardo espacial (SLM)
#
# Estimación S2SLS
model.SLM.STSLS <- stsls(formula=form, data=house_sf, listw=house.6nn.w)
summary(model.SLM.STSLS)
# Modelo con errores espaciales (SEM)
#
# Estimación GMM
#
model.SEM.GMM <- GMerrorsar(formula=form, data=house_sf, listw=house.6nn.w)
summary(model.SEM.GMM)
#
# Modelo combinado (SAC -> SLM + SEM)
#
# Estimación GS2SLS
model.SAC.GSTSLS <- gstsls(formula=form, data=house_sf, listw=house.6nn.w)
summary(model.SAC.GSTSLS)
#
help(house, package="spData")
plot(house)
str(house)
#
library(tidyverse)
library(plm)
#
pdata  <-  pdata.frame(panelx, index=c("firm_ident", "year"))
pdim(pdata)
summary(pdata[c("return", "beta")])
load("~/OneDrive - Universidad de Extremadura/2 - DOCENCIA/0 - ECONOMETRÍA/1 - ECONOMETRÍA CON R -PYTHON-JULIA/_GitHub-EconMetricsRPy/CAPM_EMP_UK.RData")
rm(list=ls())
#
library(tidyverse)
library(plm)
#
load("CAPM_EMP_UK.RData")
pdata  <-  pdata.frame(panelx, index=c("firm_ident", "year"))
pdim(pdata)
summary(pdata[c("return", "beta")])
View(pdata)
class(panelx)
class(pdata)
# Pool (mezcla) de datos (sin efectos individuales)
#
ef_0 <-  plm(return~beta, model="pooling", data=pdata)
summary(ef_0)
#
# Modelo de efectos fijos
#
ef_f <-  plm(return~beta, model="within", data=pdata)
summary(ef_f)
pFtest(ef_f,ef_0) # Contraste de significación de los efectos fijos
#
# Modelo de efecto aleatorios
#
ef_a <-  plm(return~beta, model="random", data=pdata)
summary(ef_a)
plmtest(ef_a, effect = "individual", type = "bp")
# Test de Hausman (efectos fijos versus efectos aleatorios)
phtest(ef_f, ef_a)
#
library(tidyverse)
library(plm)
#
data( "EmplUK", package="plm" )
help( "EmplUK", package="plm" )
#
EmplUK.pdata <-  pdata.frame(EmplUK,index=c( "firm", "year"))
pdim(EmplUK.pdata)
#
dem_empl.GMM.1 <-pgmm(log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1) + log(capital) + lag(log(output), 0:1) | lag(log(emp), 2:99),data=EmplUK.pdata, effect="twoways", model="twosteps")
summary(dem_empl.GMM.1, robust = FALSE )
#
dem_empl.GMM.2 <-pgmm(log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1) + log(capital) + lag(log(output), 0:1) | lag(log(emp), 2:99) + lag(log(wage), 2:99) + lag(log(capital), 1:99) + lag(log(output), 2:99),data=EmplUK.pdata, effect="twoways", model="onestep", transformation="ld")
summary(dem_empl.GMM.2, robust = FALSE )
#
rm(list=ls())
