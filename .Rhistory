compareCoefs(lm_YX_1,lm_YX_2)
plot(Y ~ X , data=ATIP)
abline(lm_YX_1)
abline(lm_YX_2, lty=2)
legend("topleft", c("Muestra completa", "Muestra recortada"), lty = c(1, 2), bty = "n")
#
# ¿Qué pasa si se eliminan las tres observaciones atípicas?
summary(M_1 <- lm(Y ~ X, data = ATIP))
summary(M_2 <- lm(Y ~ X, data = ATIP[1:19,]))
compareCoefs(M_1,M_2)
plot(Y ~ X , data=ATIP)
abline(M_1)
abline(M_2, lty=2)
legend("topleft", c("Muestra completa (M_1)", "Muestra recortada (M_2)"), lty = c(1, 2), bty = "n")
#
# ¿Qué pasa si se eliminan las tres observaciones atípicas?
summary(M1 <- lm(Y ~ X, data = ATIP))
summary(M2 <- lm(Y ~ X, data = ATIP[1:19,]))
compareCoefs(M1,M2)
plot(Y ~ X , data=ATIP)
abline(M1)
abline(M2, lty=2)
legend("topleft", c("Muestra completa (M1)", "Muestra recortada (M2)"), lty = c(1, 2), bty = "n")
#
plot(Y ~ X , data=ATIP)
abline(M1)
abline(M2, lty=2)
legend("topleft", c("Datos completos (M1)", "Datos recortados (M2)"), lty = c(1, 2), bty = "n")
#
# Distribución de los errores del modelo
#
plot(lm_YX$residuals)
#
hist(lm_YX$residuals, main = "")
box()
#
densityPlot(residuals(lm_YX))
#
qqnorm(residuals(lm_YX))
qqline(residuals(lm_YX))
#
qqPlot(lm_YX, distribution="norm")
#
densityPlot(residuals(lm_YX))
densityPlot(rstudent(lm_YX))
# Contrastes de normalidad
#
r <- resid(lm_YX)
rbar <- mean(r)
sdr <- sd(r)
hist(lm_YX$residuals, col="grey", freq=FALSE, main="Distribución de los residuos", ylab="Density", xlab="residuos")
curve(dnorm(x, rbar, sdr), col=2, add=TRUE, ylab="Density", xlab="r")
#
library(moments)
# Librería moments
skewness(lm_YX$residuals)
kurtosis(lm_YX$residuals)
agostino.test(lm_YX$residuals)
anscombe.test(lm_YX$residuals)
jarque.test(lm_YX$residuals)
library(tseries)
# librería tseries
jarque.bera.test(lm_YX$residuals)
shapiro.test(lm_YX$residuals)
ks.test(lm_YX$residuals, pnorm)
# Detección de observaciones atípicas
#
# Observaciones atípicas en las variables explicativas (leverages <-> apalancamiento)
#
hat <- hatvalues(lm_YX)
hat
which(hat > 2 * mean(hat))
plot(hat)
abline(h = mean(hat), col = 4)
abline(h = 2 * mean(hat), col = 2)
id <- which(hat > 2 * mean(hat))
text(id, hat[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
#
summary(hat)
# Observaciones atípicas en la variable dependiente (outliers)
#
slm_YX <- summary(lm_YX)
# Residuos estandarizados
r <- lm_YX$residuals/slm_YX$sigma
r
densityPlot(r)
which(abs(r) > 2.5)
plot(r)
abline(h = c(0,-2.5, 2.5), col = 4)
id <- which(abs(r) > 2.5)
text(id, r[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
# Residuos estudentizados (internamente)
rs <- rstandard(lm_YX)
rs
densityPlot(rs)
which(abs(rs) > 2)
plot(rs)
abline(h = c(0,-2, 2)*sd(rs), col = 4)
id <- which(abs(r) > 2*sd(rs))
text(id, r[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
# Residuos estudentizados (externamente)
rt <- rstudent(lm_YX)
rt
densityPlot(rt)
qqPlot(lm_YX)
outlierTest(lm_YX)
# Diagnósticos específicos
#
# Observaciones influyentes: cálculo de DFBETAS_i, DFFITS_i, COVRATIO_i, DCOOK_i y h_i ;
# inf -> señala obs. inusuales para al menos una medida
#
influence.measures(lm_YX)
S(influence.measures(lm_YX))
influenceIndexPlot(lm_YX, vars=c("hat", "Studentized","Cook"))
influencePlot(lm_YX, xlab="Hat values")
# Medidas individuales
hat <- hatvalues(lm_YX)
dfbetas <-  dfbetas(lm_YX)
dffits <-  dffits(lm_YX)
dcook <-  cooks.distance(lm_YX)
hat ; dfbetas ; dffits; dcook
#
max(hatvalues(lm_YX))
which.max(hatvalues(lm_YX))
#
max(abs(dffits(lm_YX)))
which.max(abs(dffits(lm_YX)))
#
max(cooks.distance(lm_YX))
which.max(cooks.distance(lm_YX))
#
# Gráficos de variable añadida, buscando casos influyentes
avPlots(lm_YX, id=list(cex=0.60, method="mahal"))
# Regresión cuartilítica
#
S(lm_YX <- lm(Y ~ X, data = ATIP))
S(qr_YX <- rq(Y ~ X, data = ATIP)) # tau=0.5
plot(Y ~ X , data=ATIP)
abline(lm_YX)
abline(qr_YX, lty=2)
legend("topleft", c("Regresi?n MCO", "Regresi?n MDA"), lty = c(1, 2), bty = "n")
#
# rq secuencial
S(qr_YX <- rq(Y ~ X, data = ATIP, tau=seq(0.1,0.9,0.1)))
plot(summary(qr_YX), level=0.95)
# rq discreto
S(qr_YX <- rq(Y ~ X, tau = c(0.25, 0.50, 0.75), data = ATIP))
plot(qr_YX)
#
# Regresión cuartilítica
#
S(lm_YX <- lm(Y ~ X, data = ATIP))
S(qr_YX <- rq(Y ~ X, data = ATIP)) # tau=0.5
plot(Y ~ X , data=ATIP)
abline(lm_YX)
abline(qr_YX, lty=2)
legend("topleft", c("Regresión MCO", "Regresión DAM"), lty = c(1, 2), bty = "n")
#
# rq secuencial
S(qr_YX <- rq(Y ~ X, data = ATIP, tau=seq(0.1,0.9,0.1)))
plot(summary(qr_YX), level=0.95)
# rq discreto
S(qr_YX <- rq(Y ~ X, tau = c(0.25, 0.50, 0.75), data = ATIP))
plot(qr_YX)
#
rm(list=ls())
library(MASS)
?rlm
#
library(tidyverse)
library(car)
library(lmtest)
library(quantreg)
#
ATIP <- read_csv("ATIP.csv")
View(ATIP)
summary(ATIP)
summary(lm_YX <- lm(Y ~ X, data = ATIP))
summary(qr_YX <- rq(Y ~ X, data = ATIP)) # tau=0.5
library(MASS)
summary(rlm_YX <- rlm(Y ~ X, data = ATIP, method="MM"))
abline(lm_YX)
abline(rlm_YX, lty=2)
legend("topleft", c("Regresión MCO", "Regresión MM"), lty = c(1, 2), bty = "n")
plot(Y ~ X , data=ATIP) ; abline(lm_YX)
abline(rlm_YX, lty=2)
legend("topleft", c("Regresión MCO", "Regresión MM"), lty = c(1, 2), bty = "n")
compareCoefs(lm_YX,qr_YX,rlm_YX)
#
library(spData)
data(house, package="spData")
class(house)
summary(house@data)
View(house)
#
library(sf)
library(leaflet)
library(ggplot2)
library(maptools)
library(RColorBrewer)
library(classInt)
library(rgdal)
library(viridis)
#
# Representación de datos espaciales
#
spplot(house, "price", col.regions = rev(magma(10)))
#
# Convirtiendo objeto sp a sf
house_sf <- st_as_sf(house)
class(house_sf)
plot(house_sf[1])
ggplot(house_sf) + geom_sf(aes(fill=price))+ theme_bw()
# Indicadores de asociación espacial (global y local)
#
library(spdep)
library(dplyr)
# Información sobre las coordenadas (longitud y latitud) de los datos
coords <- coordinates(house)
# Matrices de pesos espaciales
# Vecinos más próximos (k=6 mediana de vecinos en la base de datos)
house.6nn <- knearneigh(coords, k=6)
house.6nn.nb <- knn2nb(house.6nn)
# Gráficos de vecinos
#
plot(st_geometry(house_sf))
plot(house.6nn.nb, coords, add=TRUE, col="red")
#
# Cálculo de las matrices de pesos W (estandarizadas por filas)
house.6nn.w <- nb2listw(neighbours=house.6nn.nb, style="W")
Estadísticos de autocorrelación espacial
#
# Global
moran.test(house_sf$price, listw=house.6nn.w)
geary.test(house_sf$price, listw=house.6nn.w)
# Local
LocalI <- as.data.frame(localmoran(house_sf$price, listw=house.6nn.w))
str(LocalI)
moran.plot(house_sf$price, listw=house.6nn.w)
# Clusters locales
house_LocalI_sf <- bind_cols(house_sf,LocalI) #
plot(house_LocalI_sf["Z.Ii"])
#
# Modelos econométricos espaciales
#
library(spatialreg)
form <- formula(log(price) ~ age + log(lotsize) + rooms)
# Modelo lineal (LM) estimado por MCO
model.LS <- lm(formula=form, data=house_sf)
summary(model.LS)
# Modelo con retardo espacial (SLM)
#
# Estimación S2SLS
model.SLM.STSLS <- stsls(formula=form, data=house_sf, listw=house.6nn.w)
summary(model.SLM.STSLS)
# Modelo con errores espaciales (SEM)
#
# Estimación GMM
#
model.SEM.GMM <- GMerrorsar(formula=form, data=house_sf, listw=house.6nn.w)
summary(model.SEM.GMM)
#
# Modelo combinado (SAC -> SLM + SEM)
#
# Estimación GS2SLS
model.SAC.GSTSLS <- gstsls(formula=form, data=house_sf, listw=house.6nn.w)
summary(model.SAC.GSTSLS)
#
help(house, package="spData")
plot(house)
str(house)
#
library(tidyverse)
library(plm)
#
pdata  <-  pdata.frame(panelx, index=c("firm_ident", "year"))
pdim(pdata)
summary(pdata[c("return", "beta")])
load("~/OneDrive - Universidad de Extremadura/2 - DOCENCIA/0 - ECONOMETRÍA/1 - ECONOMETRÍA CON R -PYTHON-JULIA/_GitHub-EconMetricsRPy/CAPM_EMP_UK.RData")
rm(list=ls())
#
library(tidyverse)
library(plm)
#
load("CAPM_EMP_UK.RData")
pdata  <-  pdata.frame(panelx, index=c("firm_ident", "year"))
pdim(pdata)
summary(pdata[c("return", "beta")])
View(pdata)
class(panelx)
class(pdata)
# Pool (mezcla) de datos (sin efectos individuales)
#
ef_0 <-  plm(return~beta, model="pooling", data=pdata)
summary(ef_0)
#
# Modelo de efectos fijos
#
ef_f <-  plm(return~beta, model="within", data=pdata)
summary(ef_f)
pFtest(ef_f,ef_0) # Contraste de significación de los efectos fijos
#
# Modelo de efecto aleatorios
#
ef_a <-  plm(return~beta, model="random", data=pdata)
summary(ef_a)
plmtest(ef_a, effect = "individual", type = "bp")
# Test de Hausman (efectos fijos versus efectos aleatorios)
phtest(ef_f, ef_a)
#
library(tidyverse)
library(plm)
#
data( "EmplUK", package="plm" )
help( "EmplUK", package="plm" )
#
EmplUK.pdata <-  pdata.frame(EmplUK,index=c( "firm", "year"))
pdim(EmplUK.pdata)
#
dem_empl.GMM.1 <-pgmm(log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1) + log(capital) + lag(log(output), 0:1) | lag(log(emp), 2:99),data=EmplUK.pdata, effect="twoways", model="twosteps")
summary(dem_empl.GMM.1, robust = FALSE )
#
dem_empl.GMM.2 <-pgmm(log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1) + log(capital) + lag(log(output), 0:1) | lag(log(emp), 2:99) + lag(log(wage), 2:99) + lag(log(capital), 1:99) + lag(log(output), 2:99),data=EmplUK.pdata, effect="twoways", model="onestep", transformation="ld")
summary(dem_empl.GMM.2, robust = FALSE )
#
rm(list=ls())
# Para obtener una visión general de las tendencias segmentadas pueden consultarse las siguientes notas:
# https://robjhyndman.com/hyndsight/piecewise-linear-trends/
# Las regresiones segmentadas permiten modelizar los cambios en la pendiente de una serie o, de forma más general,
# pueden usarse para capturar el cambio estructural en una regresión.
#
library(tidyverse)
library(plotly)
library(dplyr)
# Lectura de datos: y = Total Construction Spending (TTLCON) [ https://fred.stlouisfed.org/series/TTLCON) ]
df <- read_csv("TTLCON_USA.csv") %>% setNames(c("date","y"))
head(df)
tail(df)
class(df)
str(df)
View(df)
# Gráfica de los datos
plot_ly(data = df) %>% add_lines(x = ~ date, y = ~ y)
# Construcción de tendencias
df <- df %>%
mutate(seg1 = 1:nrow(df),
seg2 = pmax(0, seg1 - min(seg1[seg1[which(date > as.Date("2007-08-01"))]])),
seg3 = pmax(0, seg1 - min(seg1[seg1[which(date > as.Date("2011-01-01"))]])))
head(df)
tail(df)
View(df)
# Modelo con tendencia simple
md1 <- lm(y ~ seg1, data = df)
summary(md1)
# Modelo con tendencias sementadas (con pivote conocido)
md2 <- lm(y ~ seg1 + seg2 + seg3, data = df)
summary(md2)
df$yhat1 <- predict(md1)
df$yhat2 <- predict(md2)
# Gráfica de los datos con las tendencias ajustadas por los dos modelos
plot_ly(data = df) %>%
add_markers(x = ~ date,
y = ~ y,
marker = list(
opacity = 0.6,
color = "#90e0ef",
size = 8),
name = "Gasto en construcción") %>%
add_lines(x = ~ date,
y = ~ yhat1,
line = list(color = "red",
dash = "dash",
width = 4),
name = "Tendencia simple") %>%
add_lines(x = ~ date,
y = ~ yhat2,
line = list(color = "#fca311",
dash = "dot",
width = 6),
name = "Tendencia segmentada") %>%
layout(title = "Gasto total en construcción en USA",
font = list(color = "black"),
yaxis = list(title = "Millones de dólares"),
xaxis = list(title = "Fuente: U.S. Census Bureau, Total Construction Spending, extraído de FRED (fred.stlouisfed.org)"),
margin = list(t = 50, b = 80),
legend = list(x = 0.05, y = 0.95))
#
View(df)
rm(list=ls())
# Para obtener una visión general de las tendencias segmentadas pueden consultarse las siguientes notas:
# https://robjhyndman.com/hyndsight/piecewise-linear-trends/
# Las regresiones segmentadas permiten modelizar los cambios en la pendiente de una serie o, de forma más general,
# pueden usarse para capturar el cambio estructural en una regresión.
#
library(tidyverse)
library(plotly)
# Lectura de datos: y = Total Construction Spending (TTLCON) [ https://fred.stlouisfed.org/series/TTLCON) ]
TCS <- read_csv("TTLCON_USA.csv") %>% setNames(c("date","y"))
head(TCS)
tail(TCS)
class(TCS)
str(TCS)
# Gráfica de los datos
plot_ly(data = TCS) %>% add_lines(x = ~ date, y = ~ y)
# Construcción de tendencias
TCS <- TCS %>%
mutate(seg1 = 1:nrow(TCS),
seg2 = pmax(0, seg1 - min(seg1[seg1[which(date > as.Date("2007-08-01"))]])),
seg3 = pmax(0, seg1 - min(seg1[seg1[which(date > as.Date("2011-01-01"))]])))
# Modelo con tendencia simple
mod1 <- lm(y ~ seg1, data = TCS)
summary(mod1)
# Modelo con tendencias sementadas (con pivote conocido)
mod2 <- lm(y ~ seg1 + seg2 + seg3, data = TCS)
summary(m0d2)
TCS$yhat1 <- predict(mod1)
TCS$yhat2 <- predict(mod2)
# Gráfica de los datos con las tendencias ajustadas por los dos modelos
plot_ly(data = TCS) %>%
add_markers(x = ~ date,
y = ~ y,
marker = list(
opacity = 0.6,
color = "#90e0ef",
size = 8),
name = "Gasto en construcción") %>%
add_lines(x = ~ date,
y = ~ yhat1,
line = list(color = "red",
dash = "dash",
width = 4),
name = "Tendencia simple") %>%
add_lines(x = ~ date,
y = ~ yhat2,
line = list(color = "#fca311",
dash = "dot",
width = 6),
name = "Tendencia segmentada") %>%
layout(title = "Gasto total en construcción en USA",
font = list(color = "black"),
yaxis = list(title = "Millones de dólares"),
xaxis = list(title = "Fuente: U.S. Census Bureau, Total Construction Spending, extraído de FRED (fred.stlouisfed.org)"),
margin = list(t = 50, b = 80),
legend = list(x = 0.05, y = 0.95))
#
library(alr4)
#
help(segreg)
head(segreg)
tail(segreg)
#
plot(C ~ Temp, segreg, xlab="Temperatura media del mes (ºF)", ylab="Consumo de electricidad (KWH/día)")
#
lin.reg <- lm(C ~ Temp, data=segreg)
summary(segm.reg)
#
plot(C ~ Temp, segreg, xlab="Temperatura media (ºF)", ylab="Consumo de electricidad (KWH/día)")
x <- (0:90)
lines(x, predict(lin.reg, data.frame(Temp=x)))
#
lin.reg <- lm(C ~ Temp, data=segreg)
summary(lin.reg)
#
plot(C ~ Temp, segreg, xlab="Temperatura media (ºF)", ylab="Consumo de electricidad (KWH/día)")
x <- (0:90)
lines(x, predict(lin.reg, data.frame(Temp=x)))
#
# Modelo no lineal con tendencia segmentada
segm.reg <- nls(C ~ th0 + th1 * (pmax(0, Temp - gamma)), data=segreg, start=list(th0=70, th1=.5, gamma=40))
summary(segm.reg)
#
plot(C ~ Temp, segreg, xlab="Temperatura media (ºF)", ylab="Consumo de electricidad (KWH/día)")
x <- (0:90)
lines(x, predict(segm.reg, data.frame(Temp=x)))
# Bootstrapping del modelo
segm.reg.boot <- Boot(segm.reg, R=999)
summary(segm.reg.boot)
confint(segm.reg.boot)
hist(segm.reg.boot, layout=c(1, 3))
#
rm(list=ls())
#
library(alr4)
#
help(segreg)
head(segreg)
tail(segreg)
#
plot(C ~ Temp, segreg, xlab="Temperatura media del mes (ºF)", ylab="Consumo de electricidad (KWH/día)")
#
# Modelo lineal con tendencia simple
lin.reg <- lm(C ~ Temp, data=segreg)
summary(lin.reg)
#
plot(C ~ Temp, segreg, xlab="Temperatura media (ºF)", ylab="Consumo de electricidad (KWH/día)")
x <- (0:90)
lines(x, predict(lin.reg, data.frame(Temp=x)))
# Modelo no lineal con tendencia segmentada
segm.reg <- nls(C ~ th0 + th1 * (pmax(0, Temp - gamma)), data=segreg, start=list(th0=70, th1=.5, gamma=40))
summary(segm.reg)
#
plot(C ~ Temp, segreg, xlab="Temperatura media (ºF)", ylab="Consumo de electricidad (KWH/día)")
x <- (0:90)
lines(x, predict(segm.reg, data.frame(Temp=x)))
# Bootstrapping del modelo
segm.reg.boot <- Boot(segm.reg, R=999)
summary(segm.reg.boot)
confint(segm.reg.boot)
hist(segm.reg.boot, layout=c(1, 3))
#
rm(list = ls())
help(house, package="spData")
