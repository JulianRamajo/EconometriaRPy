r <- lm_YX$residuals/slm_YX$sigma
r
densityPlot(r)
which(abs(r) > 2.5)
plot(r)
abline(h = c(0,-2.5, 2.5), col = 4)
id <- which(abs(r) > 2.5)
text(id, r[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
# Residuos estudentizados (internamente)
rs <- rstandard(lm_YX)
rs
densityPlot(rs)
which(abs(rs) > 2)
plot(r)
abline(h = c(0,-2, 2)*sd(rs), col = 4)
id <- which(abs(r) > 2*sd(rs))
text(id, r[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
# Residuos estudentizados (externamente)
rt <- rstudent(lm_YX)
rt
densityPlot(rs)
outlierTest(lm_YX)
#
rs <- rstandard(lm_YX)
rs
densityPlot(rs)
which(abs(rs) > 2)
plot(rs)
abline(h = c(0,-2, 2)*sd(rs), col = 4)
id <- which(abs(r) > 2*sd(rs))
text(id, r[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
# Residuos estudentizados (externamente)
rt <- rstudent(lm_YX)
rt
densityPlot(rt)
outlierTest(lm_YX)
spreadLevelPlot(lm_YX)
qqPlot(lm_YX)
#
influence.measures(lm_YX)
S(influence.measures(lm_YX))
influencePlot(lm_YX, xlab="Hat values")
influenceIndexPlot(lm_YX, vars=c("hat", "Studentized","Cook"))
# Medidas individuales
hat <- hatvalues(lm_YX)
dfbetas <-  dfbetas(lm_YX)
dffits <-  dffits(lm_YX)
dcook <-  cooks.distance(lm_YX)
hat ; dfbetas ; dffits; dcook
#
# Gráficos de variable añadida, buscando casos influyentes
avPlots(lm_YX, id=list(cex=0.60, method="mahal"))
# Chequeo de no linealidad: gráficos de componente+residuo
crPlots(lm_YX, smooth=list(span=0.7))
#
# Regresión cuartilítica
#
S(qr_YX <- rq(Y ~ X, data = ATIP))
qr_YX <- rq(Y ~ X, tau = c(0.25, 0.50, 0.75), data = ATIP)
sqr_YX <- summary(qr_YX)
sqr_YX
plot(sqr_YX)
#
S(qr_YX <- rq(Y ~ X, data = ATIP)) # tau=0.5
S(qr_YX <- rq(Y ~ X, data = ATIP, tau=seq(0.1,0.9,0.1))
)
S(qr_YX <- rq(Y ~ X, data = ATIP, tau=seq(0.1,0.9,0.1)))
plot(summary(qr_YX), level=0.95)
qr_YX <- rq(Y ~ X, tau = c(0.25, 0.50, 0.75), data = ATIP)
sqr_YX <- summary(qr_YX)
sqr_YX
plot(sqr_YX)
S(qr_YX <- rq(Y ~ X, tau = c(0.25, 0.50, 0.75), data = ATIP))
plot(sqr_YX)
plot(Y ~ X , data=ATIP)
abline(lm_YX)
abline(qr_YX, lty=2)
legend("topleft", c("Regresión MCO", "Regresión MDA"), lty = c(1, 2), bty = "n")
#
# Regresión cuartilítica
#
S(lm_YX <- lm(Y ~ X, data = ATIP))
S(qr_YX <- rq(Y ~ X, data = ATIP)) # tau=0.5
plot(Y ~ X , data=ATIP)
abline(lm_YX)
abline(qr_YX, lty=2)
legend("topleft", c("Regresión MCO", "Regresión MDA"), lty = c(1, 2), bty = "n")
#
# rq secuencial
S(qr_YX <- rq(Y ~ X, data = ATIP, tau=seq(0.1,0.9,0.1)))
plot(summary(qr_YX), level=0.95)
# rq discreto
S(qr_YX <- rq(Y ~ X, tau = c(0.25, 0.50, 0.75), data = ATIP))
plot(sqr_YX)
#
rt <- rstudent(lm_YX)
rt
densityPlot(rt)
qqPlot(lm_YX)
spreadLevelPlot(lm_YX)
outlierTest(lm_YX)
hat <- hatvalues(lm_YX)
hat
which(hat > 2 * mean(hat))
plot(hat)
abline(h = mean(hat), col = 4)
abline(h = 2 * mean(hat), col = 2)
id <- which(hat > 2 * mean(hat))
text(id, hat[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)
#
max(hatvalues(lm_YX))
which.max(hatvalues(lm_YX))
hat <- hatvalues(lm_YX)
dfbetas <-  dfbetas(lm_YX)
dffits <-  dffits(lm_YX)
dcook <-  cooks.distance(lm_YX)
hat ; dfbetas ; dffits; dcook
#
max(hatvalues(lm_YX))
which.max(hatvalues(lm_YX))
#
max(cooks.distance(lm_YX))
which.max(cooks.distance(lm_YX))
#
max(abs(dffits(lm_YX)))
which.max(abs(dffits(lm_YX)))
influence.measures(lm_YX)
S(influence.measures(lm_YX))
influencePlot(lm_YX, xlab="Hat values")
influenceIndexPlot(lm_YX, vars=c("hat", "Studentized","Cook"))
library(tseries)
skewness(lm_YX$residuals)
kurtosis(lm_YX$residuals)
jarque.test(lm_YX$residuals)
agostino.test(lm_YX$residuals)
anscombe.test(lm_YX$residuals)
jarque.bera.test(r)
shapiro.test(r)
jarque.bera.test(lm_YX$residuals)
shapiro.test(lm_YX$residuals)
plot(lm_YX$residuals)
hist(lm_YX$residuals, main = "")
box()
hist(lm_YX$residuals, col="grey", freq=FALSE, main="Distribución de los residuos", ylab="Density", xlab="residuos")
curve(dnorm(x, rbar, sdr), col=2, add=TRUE, ylab="Density", xlab="r")
# Contrastes de normalidad
r <- resid(lm_YX)
rbar <- mean(r)
sdr <- sd(r)
hist(lm_YX$residuals, col="grey", freq=FALSE, main="Distribución de los residuos", ylab="Density", xlab="residuos")
curve(dnorm(x, rbar, sdr), col=2, add=TRUE, ylab="Density", xlab="r")
plot(lm_YX$residuals)
hist(lm_YX$residuals, main = "")
box()
densityPlot(residuals(lm_YX))
qqnorm(residuals(lm_YX))
qqPlot(lm_YX, distribution="norm")
plot(lm_YX$residuals)
hist(lm_YX$residuals, main = "")
box()
densityPlot(residuals(lm_YX))
qqnorm(residuals(lm_YX))
qqPlot(lm_YX, distribution="norm")
#
r <- resid(lm_YX)
rbar <- mean(r)
sdr <- sd(r)
hist(lm_YX$residuals, col="grey", freq=FALSE, main="Distribución de los residuos", ylab="Density", xlab="residuos")
curve(dnorm(x, rbar, sdr), col=2, add=TRUE, ylab="Density", xlab="r")
# Contrastes de normalidad
#
r <- resid(lm_YX)
rbar <- mean(r)
sdr <- sd(r)
hist(lm_YX$residuals, col="grey", freq=FALSE, main="Distribución de los residuos", ylab="Density", xlab="residuos")
curve(dnorm(x, rbar, sdr), col=2, add=TRUE, ylab="Density", xlab="r")
#
# Librería moments
skewness(lm_YX$residuals)
kurtosis(lm_YX$residuals)
agostino.test(lm_YX$residuals)
anscombe.test(lm_YX$residuals)
jarque.test(lm_YX$residuals)
# librería tseries
jarque.bera.test(lm_YX$residuals)
shapiro.test(lm_YX$residuals)
install.packages(c("openxlsx", "quantreg", "R6"))
library(readr)
library(car)
library(MASS)
library(effects)
library(tidyverse)
library(RcmdrMisc)
library(sfsmisc)
library(quantreg)
library(lmtest)
library(sandwich)
library(dynlm)
library(moments)
library(tseries)
#
ATIP <- read_csv("ATIP.csv")
View(ATIP)
summary(ATIP)
#
# Diagrama de puntos
#
scatterplotMatrix(~ Y + X, id=list(n=3), smooth=list(span=0.7), data=ATIP)
ggplot(ATIP, aes(x=X, y=Y)) + geom_point() + labs(title="Diagrama de puntos", x="X", y="Y")
#
# Modelo de regresión lineal
#
S(lm_YX <- lm(Y ~ X, data = ATIP))
plot(Y ~ X , data=ATIP)
abline(lm_YX)
plot(lm_YX, which = 1:6)
# Distribución de los errores del modelo
#
plot(lm_YX$residuals)
hist(lm_YX$residuals, main = "")
box()
densityPlot(residuals(lm_YX))
qqnorm(residuals(lm_YX))
qqPlot(lm_YX, distribution="norm")
qqline(residuals(lm_YX))
qqnorm(residuals(lm_YX))
qqline(residuals(lm_YX))
# Contrastes de normalidad
#
r <- resid(lm_YX)
rbar <- mean(r)
sdr <- sd(r)
hist(lm_YX$residuals, col="grey", freq=FALSE, main="Distribución de los residuos", ylab="Density", xlab="residuos")
curve(dnorm(x, rbar, sdr), col=2, add=TRUE, ylab="Density", xlab="r")
#
Librería moments
skewness(lm_YX$residuals)
kurtosis(lm_YX$residuals)
agostino.test(lm_YX$residuals)
anscombe.test(lm_YX$residuals)
jarque.test(lm_YX$residuals)
# Librería moments
skewness(lm_YX$residuals)
kurtosis(lm_YX$residuals)
agostino.test(lm_YX$residuals)
anscombe.test(lm_YX$residuals)
jarque.test(lm_YX$residuals)
# librería tseries
jarque.bera.test(lm_YX$residuals)
shapiro.test(lm_YX$residuals)
ks.test(lm_YX$residuals)
ks.test(lm_YX$residuals, pnorm)
?ks.test
library(readr)
library(dynlm)
library(car)
library(lmtest)
#
AHORRO_RENTA <- read_csv("AHORRO_RENTA.csv")
AHORRO_RENTA_ts <- ts(AHORRO_RENTA[,2:3], start=c(1970), end = c(2005))
plot(TIPOS_ESP_ts)
#
AH <- AHORRO_RENTA_ts[,"AH"]
Y <- AHORRO_RENTA_ts[,"Y"]
plot(AHORRO_RENTA_ts)
# Modelo A
S(dynlm_AH <- dynlm(AH ~ L(AH, 1:2)))
#
# Modelo A
S(dynlm_A <- dynlm(AH ~ L(AH, 1:2)))
#
# Modelo B
#
S(dynlm_B <- dynlm(AH ~ L(AH, 1:1) + L(Y, 0:0)))
#
rm(dynlm_AH)
# Modelo anidado
S(dynlm_AB <- dynlm(AH ~ L(AH, 1:2) + + L(Y, 0:0)))
# Cox test in both directions
coxtest(dynlm_A, dynlm_B)
#  jtest() and encomptest().
jtest(dynlm_A, dynlm_B)
encomptest(dynlm_A, dynlm_B)
## the encompassing test is essentially
waldtest(dynlm_A, dynlm_B, dynlm_AB)
#
# Modelo A
S(dynlm_A <- dynlm(AH ~ L(AH, 1:2)))
#
# Modelo B
#
S(dynlm_B <- dynlm(AH ~ L(AH, 1:1) + L(Y, 0:0)))
#
# Modelo anidado
S(dynlm_AB <- dynlm(AH ~ L(AH, 1:2)  + L(Y, 0:0)))
# Contraste de Cox
coxtest(dynlm_A, dynlm_B)
#  Contraste J de Davidson y MacKinnon
jtest(dynlm_A, dynlm_B)
#
anova(dynlm_A,dynlm_B,dynlm_AB)
#
encomptest(dynlm_A, dynlm_B)
# Modelo anidado
S(dynlm_AB <- dynlm(AH ~ L(AH, 1:2)  + L(Y, 0:0)))
#
library(readr)
library(dynlm)
library(car)
library(lmtest)
#
AHORRO_RENTA <- read_csv("AHORRO_RENTA.csv")
AHORRO_RENTA_ts <- ts(AHORRO_RENTA[,2:3], start=c(1970), end = c(2005))
plot(AHORRO_RENTA_ts)
#
AH <- AHORRO_RENTA_ts[,"AH"]
Y <- AHORRO_RENTA_ts[,"Y"]
#
# Modelo A
S(dynlm_A <- dynlm(AH ~ L(AH, 1:2)))
#
# Modelo B
#
S(dynlm_B <- dynlm(AH ~ L(AH, 1:1) + L(Y, 0:0)))
#
# Contraste de Cox
#
coxtest(dynlm_A, dynlm_B)
#
#  Contraste J de Davidson y MacKinnon
#
jtest(dynlm_A, dynlm_B)
Modelo anidado
#
S(dynlm_AB <- dynlm(AH ~ L(AH, 1:2)  + L(Y, 0:0)))
#
encomptest(dynlm(AH ~ L(AH, 1:2)), dynlm(AH ~ L(AH, 1:1) + L(Y, 0:0)), data = AHORRO_RENTA_ts)
#
encomptest(AH ~ L(AH, 1:2), AH ~ L(AH, 1:1) + L(Y, 0:0), data = AHORRO_RENTA_ts)
#
encomptest(dynlm(AH ~ L(AH, 1:2)), dynlm(AH ~ L(AH, 1:1) + L(Y, 0:0)), data = AHORRO_RENTA_ts[3:36,])
#
ncomptest(dynlm(AH ~ L(AH, 1:2)), dynlm(AH ~ L(AH, 1:1) + L(Y, 0:0)), data = AHORRO_RENTA_ts[4:36,])
encomptest(dynlm(AH ~ L(AH, 1:2)), dynlm(AH ~ L(AH, 1:1) + L(Y, 0:0)), data = AHORRO_RENTA_ts[4:36,])
encomptest(dynlm(AH ~ L(AH, 1:2)), dynlm(AH ~ L(AH, 1:1) + L(Y, 0:0)), data = AHORRO_RENTA_ts[5:36,])
library(spData)
data(house, package="spData")
class(house)
summary(house@data)
#
View(house)
#
library(sf)
library(leaflet)
library(ggplot2)
library(maptools)
library(RColorBrewer)
library(classInt)
library(rgdal)
library(viridis)
# Representación de datos espaciales
#
# Convirtiendo objeto sp a sf
house_sf <- st_as_sf(house)
class(house_sf)
plot(house_sf[1])
ggplot(house_sf) + geom_sf(aes(fill=price))+ theme_bw()
spplot(house, "price", col.regions = rev(magma(10)))
# leaflet(house_sf)
leaflet(house_sf)
# Indicadores de asociación espacial (global y local)
#
library(spdep)
library(dplyr)
# Información sobre las coordenadas (longitud y latitud) de los datos
coords <- coordinates(house)
# Matrices de pesos espaciales
# Vecinos más próximos (k=6 mediana de vecinos en la base de datos)
house.6nn <- knearneigh(coords, k=6)
house.6nn.nb <- knn2nb(house.6nn)
Gráficos de vecinos
#
plot(st_geometry(house_sf))
plot(house.6nn.nb, coords, add=TRUE, col="red")
house.6nn.w <- nb2listw(neighbours=house.6nn.nb, style="W")
# Estadísticos de autocorrelación espacial
#
# Global
moran.test(house_sf$price, listw=house.6nn.w)
geary.test(house_sf$price, listw=house.6nn.w)
# Local
LocalI <- as.data.frame(localmoran(house_sf$price, listw=house.6nn.w))
str(LocalI)
moran.plot(house_sf$price, listw=house.6nn.w)
# Clusters locales
house_LocalI_sf <- bind_cols(house_sf,LocalI) #
plot(house_LocalI_sf["Z.Ii"])
# Modelos econométricos espaciales
#
library(spatialreg)
form <- formula(log(price) ~ age + log(lotsize) + rooms)
Modelo lineal (LM) estimado por MCO
model.LS <- lm(formula=form, data=house_sf)
summary(model.LS)
Modelo con retardo espacial (SLM)
#
# Estimación S2SLS
model.SLM.STSLS <- stsls(formula=form, data=house_sf, listw=house.6nn.w)
summary(model.SLM.STSLS)
Estimación GMM
model.SEM.GMM <- GMerrorsar(formula=form, data=house_sf, listw=house.6nn.w)
summary(model.SEM.GMM)
Estimación GS2SLS
model.SAC.GSTSLS <- gstsls(formula=form, data=house_sf, listw=house.6nn.w)
summary(model.SAC.GSTSLS)
```
library(readr)
library(alr4)
#
CURV_APR <- read_csv("CURV_APR.csv")
CURV_APR_ts <- ts(CURV_APR, start=c(1), end = c(60), frequency = 1)
plot(CURV_APR_ts)
#
curv.apr.dat <- cbind(CURV_APR_ts,lag(CURV_APR_ts[,2],-1))
curv.apr <- data.frame(curv.apr.dat)
names(curv.apr) <- c("T", "X", "LX")
summary(curv.apr)
#
reg_nl <- nls(T~c1*(X^(c2+1)-LX^(c2+1)), data=curv.apr, start=list(c1=10, c2=-0.5))
summary(reg_nl)
coef(reg_nl)
gamma <- coef(reg_nl)[[1]]
delta <- coef(reg_nl)[[2]]
#
curve(gamma*x^delta, from=0, to=100, xlab="Unidades producidas", ylab="Costes medios" )
#
et.seed(10131985)
reg_nl.boot <- Boot(reg_nl, R=999)
summary(reg_nl.boot)
confint(reg_nl.boot)
hist(reg_nl.boot, layout=c(1, 2))
complete.cases(curv.apr)
library(readr)
library(alr4)
#
CURV_APR <- read_csv("CURV_APR.csv")
CURV_APR_ts <- ts(CURV_APR, start=c(1), end = c(60), frequency = 1)
plot(CURV_APR_ts)
#
curv.apr.dat <- cbind(CURV_APR_ts,lag(CURV_APR_ts[,2],-1))
curv.apr <- data.frame(curv.apr.dat)
names(curv.apr) <- c("T", "X", "LX")
summary(curv.apr)
#
reg_nl <- nls(T~c1*(X^(c2+1)-LX^(c2+1)), data=curv.apr, start=list(c1=10, c2=-0.5))
summary(reg_nl)
coef(reg_nl)
gamma <- coef(reg_nl)[[1]]
delta <- coef(reg_nl)[[2]]
#
curve(gamma*x^delta, from=0, to=100, xlab="Unidades producidas", ylab="Costes medios" )
#
library(readr)
library(alr4)
#
DEM_CARNE <- read_csv("DEM_CARNE.csv")
DEM_CARNE
attach(DEM_CARNE)
#
# Gr?ficas
#
plot(Q ~ P, xlab="P", ylab="Q")
plot(Q ~ Y, xlab="Y", ylab="Q")
scatter3D(x = P, y = Y, z = Q,
pch = 16, cex = 1.5, xlab = "Precio", ylab = "Renta",
zlab = "Gasto  per c?pita", clab = c("Renta"),
main = "Demanda familiar de carne", ticktype = "detailed")
#
# Regresi?n no lineal
#
nonlin_mod <- nls(Q ~  c1 + c2*P + c3*(Y^c4), start = list(c1=5, c2=-0.5, c3=0.001, c4=3))
summary(nonlin_mod)
#
set.seed(10131985)
reg_nl.boot <- Boot(nonlin_mod, R=999)
summary(reg_nl.boot)
confint(reg_nl.boot)
hist(reg_nl.boot, layout=c(2, 2))
#
library(readr)
DEM_CARNE <- read_csv("DEM_CARNE.csv")
DEM_CARNE
attach(DEM_CARNE)
#
# Método R estándar
#
# Gráficas
#
plot(Q ~ P, xlab="P", ylab="Q")
plot(Q ~ Y, xlab="Y", ylab="Q")
#
# Regresiones
#
lin_model <- lm(Q ~ P + Y)
summary(lin_model)
library(coefplot)
coefplot(lin_model)
log_model <- lm(log(Q) ~ log(P) + log(Y))
summary(log_model)
coefplot(log_model)
multiplot(lin_model,log_model)
?fortify
