---
title: "PROGRAMACIÓN CONJUNTA EN R Y PYTHON CON RETICULATE"
author:
  name: Julián Ramajo, ramajo@unex.es
  affiliation: GRADO EN ESTADÍSTICA | ECONOMETRIA (502243)
subtitle: 'Interoperabilidad entre R y Python usando RStudio'
output:
  html_document:
    theme: journal
    highlight: haddock
    toc: yes
    toc_depth: 2
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Justificación

En este documento se demuestra cómo los ficheros **R Markdown** (con extensión _Rmd_) o **Quarto** (con extensión _qmd_) son un buen entorno para codificar un proyecto simultáneamente en los dos lenguajes de programación más usados en _Ciencia de Datos_, **R** y **Python**, permitiendo programar algunos elementos del proyecto en cada lenguaje y manipular objetos creados en un lenguaje usando el otro, y viceversa.

Esto puede ser útil por varias razones:

1.  Permite codificar en la _lengua nativa en estadística_ (**R**) pero añadiendo características que podrían existir sólo en la _segunda lengua_ (**Python**); o al contrario. Obviamente cuando uso la palabra _lengua_ me refiero a _lenguaje de programación_.
2.  Permite colaborar directamente con otro colega que sea un experto programador en el otro lenguaje (**equipos multi-lenguaje**).
3.  Da la oportunidad de trabajar en ambos lenguajes de programación y de adquirir fluidez en ellos, intentando alcanzar a largo plazo el _bilingüismo_.

# ¿Qué se necesita?

Para que la interacción R-Python funcione correctametne se necesita lo siguiente:

1.  **R** y **Python** instalados en el ordenador.
2.  El entorno de ejecución (IDE) **RStudio** también instalado.
3.  Las **librerías** `rmarkdown`/`quarto` y `reticulate` instaladas en R.

En nuestro caso, trabajaremos en el IDE de RStudio escribiendo en un documento R Markdown o Quarto, moviéndonos entre trozos de código que están escritos en R o en Python. En esta aplicación haré una demostración con un par de ejemplos sencillos.

# Primer ejemplo

Se puede configurar un documento **R Markdown**/**Quarto** y codificar en los dos idiomas diferentes. Primero hay que cargar la librería `reticulate` en el entorno R.

```{r}
library(reticulate)
```

Ahora, cuando se quiera escribir código en Python, se debe envolver con los habituales signos de puntuación, pero etiquetarlo como un trozo de código python usando `{python}`; y cuando se quiera escribir código en R debe usarse `{r}`.

En nuestro primer ejemplo, vamos a suponer que se va a estimar con Python un modelo de regresión con un conjunto de datos sobre las calificaciones finales de las pruebas de los estudiantes de Grado en el último curso en función de sus resultados pasados en los tres años anteriores. 

Debajo se ejecuta Python dentro de este código para estimar el modelo:

```{python}
# Librerías
import pandas as pd
import statsmodels.formula.api as smf

# Datos
ugtests = pd.read_csv("DG_SCORES.csv")

# Modelo
model = smf.ols(formula = "Final ~ Yr3 + Yr2 + Yr1", data = ugtests)

# Estimación y resultados
fitted_model = model.fit()
model_summary = fitted_model.summary()
print(model_summary)
```

En este momento tienes que dejar este trabajo debido a algo más urgente y se lo pasas a otro colega que sólo programa en R para hacer algunas comprobaciones sobre el funcionamiento del modelo.

Pues bien, el nuevo programador puede acceder a todos los objetos Python que se han creado anteriormente usando el prefijo `py$` en el entorno R. Así, si escribe un cógigo R como el que sigue puede acceder a los parámetros del modelo de regresión: 

```{r}
py$fitted_model$params
```

o a los primeros _residuos_ (errores estimados) del mismo, junto con unas estadístias básicas y un histograma:

```{r}
head(py$fitted_model$resid)
summary(py$fitted_model$resid)
hist(py$fitted_model$resid)
```

Además, se pueden hacer fácilmente algunos diagnósticos del modelo estimado:

```{r}
library(car)
densityPlot(py$fitted_model$resid)
qqnorm(py$fitted_model$resid)
qqPlot(py$fitted_model$resid)
```

# Segundo ejemplo

Supongamos ahora que se han estado analizando algunos datos en Python y se ha creado un `dataframe` de **pandas** con todos ellos.  Vamos a descargar los datos (https://www.kaggle.com/datasets/annavictoria/speed-dating-experiment) y a echarles un vistazo:

```{python}
# Librería
import pandas as pd

# Datos
speed_dating = pd.read_csv("FIRST_DATE.csv")
print(speed_dating.head())
```

Supongamos que has ejecutado un _modelo de regresión logística simple_ en Python para intentar relacionar la variable decisión, `dec`, con otras variables del fichero.

```{python}
# Librerías
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf

# Datos
speed_dating = pd.read_csv("FIRST_DATE.csv")

# Modelo
model = smf.glm(formula = "dec ~ agediff + samerace + attr + intel + prob", 
                data = speed_dating, 
                family = sm.families.Binomial())
                
# Estimación y resultados
promotion_model = model.fit()
print(promotion_model.summary())
```

Sin embargo, te das cuenta de que estos datos son en realidad jerárquicos ya que el mismo `iid` individual puede tener múltiples fechas, así que es necesario estimar un _modelo de regresión logística de efectos mixtos_, ¡pero no puedes encontrar ninguna librería en Python que lo haga! Esto no es un problema, pues le mandas el _script_ a un colega para que lo estime en R, dónde sí existe una librería específica para estimar este tipo de modelos jerárquicos:

```{r}
# Librería
library(lme4)

# Datos
speed_dating <- py$speed_dating

# Modelo
iid_intercept_model <- lme4:::glmer(dec ~ agediff + samerace + attr + intel + 
                                      prob + (1 | iid), data = speed_dating, 
                                    family = "binomial")
# Resultados
summary(iid_intercept_model)
coefficients <- coef(iid_intercept_model)$iid
```

Ahora se pueden recuperar los resultados en Python y echar un vistazo a las estimaciones de los coeficientes, por ejemplo. Para acceder a los objetos de R en Python se utiliza el prefijo `r.`.

```{python}
coefs = r.coefficients
print(coefs.head())
```

# Tercer ejemplo

En esta última aplicación veremos cómo usar R y Python juntos pasando un conjunto de datos desde R a los paquetes de *machine learning* (ML) de Python, haciendo algunas visualizaciones en Python, pasando de nuevo a R, y finalmente de nuevo a un archivo externo de Python.

```{r, message=FALSE, include = TRUE, echo=TRUE, eval=TRUE}
# Librerías R
library(reticulate)
library(tidyverse)
library(tidymodels)
library(caret)
library(magrittr)
library(plotly)
library(data.table)
# Librerías Python
pandas <- import("pandas")
numpy <- import("numpy")
sns <- import('seaborn')
plt <- import('matplotlib.pyplot')
skl_model_selection <- import("sklearn.model_selection")
skl <- import("sklearn")
skl_ensemble <- import("sklearn.ensemble")
skl_pipeline <- import("sklearn.pipeline")
skl_metrics <- import("sklearn.metrics")
skl_externals <- import("sklearn.externals")
skl_lm <- import("sklearn.linear_model")
```

El primer paso es `preparar y manipular´ de los datos para ponerlos en el formato adecuado. Vamos a hacer primero una regresión y luego se intentará predecir la variable temperatura, *TTBS_mins*, en función de otras variables recogidas en el estudio.

En primer lugar se leen los datos y se dividen las variables en predictores (características) y variable predicha:

```{r, include = TRUE, echo=TRUE, eval=TRUE}
ttbs <- read_csv("TTBS.csv")
X <- ttbs[,1:3]
Y <- data.frame(ttbs[,4])
```

El siguiente paso es la conversión de objetos de R hacia Python. El comando a utilizar es `_r_to_py()`, que se usa para convertir el conjunto de datos, o un objeto de R, en un marco de datos asociado Python `panda`, en un array de `numpy`, etc.

```{r, include = TRUE, echo=TRUE, eval=TRUE}
py_ttbs <- r_to_py(ttbs)
py_X <- r_to_py(X)
py_Y <- r_to_py(Y)
py_ttbs$head() 
py_ttbs$dtypes
py_ttbs$describe()
py_len(py_ttbs)
```

Ahora se usará la función *train_test_split* de la librería `scikit-learn` al objeto de dividir los datos en dos subconjuntos (*splits*), el de entrenamiento y el de prueba, para utilizarlos con `sklearn` más adelante:

```{r, include = TRUE, echo=TRUE, eval=TRUE}
split <- skl_model_selection$train_test_split(X, Y, test_size=0.75)
```

Esto devolverá una lista de elementos, ya que así es como se mantiene como una tupla en Python. Python permite esta asignación múltiple, pero R no tiene esa capacidad, así que hay que indexar los subconjuntos de datos relevantes almacenados en *split* en objetos distintos de R:

```{r py_convert_splits, include = TRUE, echo=TRUE, eval=TRUE}
py_X_train <- r_to_py(split[[2]])
py_X_test <- r_to_py(split[[1]])
py_Y_train <- r_to_py(split[[4]])
py_Y_test <- r_to_py(split[[3]])
```

A continuación se procede al ajuste de un modelo de regresión usando la librería ML de Python `scikit-learn`. A diferencia de R, `scikit-learn` requiere que se inicialice el objeto `modelo` antes de ajustarlo. El código siguiente muestra el proceso:

```{r fit_ml_model, include = TRUE, echo=TRUE, eval=TRUE}
sk_lm_model <- skl_lm$LinearRegression() 
model <- sk_lm_model$fit(py_X_train, py_Y_train)
r_squared <- model$score(py_X_test, py_Y_test)
r_squared
```

Para acceder a los resultados del modelo utilizamos el siguiente código, que nos devolverá la constante (`intercept`) y los coeficientes estimados:

```{r fit_access_metrics, include = TRUE, echo=TRUE, eval=TRUE}
model_intercept <- model$intercept_
model_coef <- model$coef_
print(model_intercept)
print(model_coef)
```

A continuación se realizán predicciones con el modelo. Para ello, se utiliza el conjunto de datos de prueba que creamos al usar la función de división de `scikit-learn`. Esto nos permitirá validar el ajuste del modelo estimado:

```{r, include = TRUE, echo=TRUE, eval=TRUE}
model_predict <- model$predict(py_X_test)
model_results <- data.frame(Predicted_Temp=model_predict, 
                            py_to_r(py_Y_test),
                            py_to_r(py_Y_test) - model_predict)
colnames(model_results) <- c("Predicted", "Actual", "Residual")
```

El modelo predicho se ha convertido en un objeto de R. Puesto que *py_Y_test* estaba en un formato nativo de Python, se ha necesitado el uso de la función de conversión inversa `py_to_r()` para convertirlo de nuevo en un objeto con el que R pueda trabajar. Si se intentara usarlo directamente sin la conversión, se obtendría un error de excepción.

El *model_results* crea un marco de datos y luego se ha usado la función R *colnames()* para cambiar los nombres de las columnas en el marco de datos.

Para visualizar el ajuste del modelo con la librería `seaborn`, se convierte el objeto `model_results` a un formato de Python (un marco de datos `pandas`) para permitir que `seaborn` interactúe con las columnas y filas del data.frame de R. 

```{r, include = TRUE, echo=TRUE, eval=TRUE}
py_mod_results <- r_to_py(model_results)
py_mod_results$dtypes
```

Finalmente, se pasan estos datos a `seaborn` para hacer alguna gráfica:

```{r, include = TRUE, echo=TRUE, eval=TRUE}
sns$lineplot(data=py_mod_results, x="Actual", y="Predicted")
plt$show()
```

El gráfico devuelto es un gráfico de Python, es decir, se abre en Python y por tanto no se puede integrar en el libro de R Markdown. Por este motivo se creará el mismo gráfico en R, y los haremos en dos versiones una estática y otra dinámica:

```{r, include = TRUE, echo=TRUE, eval=TRUE}
plot <- model_results %>% 
  ggplot(aes(x=Actual, 
             y=Predicted)) + geom_point(color="blue") +
  geom_smooth(method = 'lm', formula = "y ~ x") 
plot
plotly::ggplotly(plot)
```
