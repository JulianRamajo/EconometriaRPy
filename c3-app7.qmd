---
engine: knitr
excerpt: ""
draft: false
format: 
  html:
    theme: simplex
    self-contained: true
    max-width: 1920px
    code-fold: show
    code-tools: true
    highlight-style: atom-one-dark
    code-block-bg: "#282c34"
---

```{css, echo = FALSE}
.justify { text-align: justify !important }
```

::: justify
# Aplicación 3.7: Autocorrelación y regresiones dinámicas (modelos ARDL y VAR) {.unnumbered}

## Caso univariante (especificación ARDL): Tipos de interés en España en la década de 1980 {.unnumbered}

En esta primera aplicación se estimará un modelo de regresión uniecuacional para explicar los tipos de interés de largo plazo vigentes en la economía española en década de los ochenta del siglo pasado, se analizará la correlación serial de los residuos de dicho modelo, y se propondrán soluciones al problema detectado de autocorrelación en los errores.
:::

### Código R {.unnumbered}

```{r}
#| include: true
#| warning: false
#| message: false

# Lectura de librerías
library(tidyverse)
library(dynlm)
library(car)
library(lmtest)
library(sandwich)
library(orcutt)
# Lectura de datos
TIPOS_INT_ESP <- read_delim("data/TIPOS_INT_ESP.csv", delim = ";")
str(TIPOS_INT_ESP)
# Gráfica de las series temporales
ggplot(TIPOS_INT_ESP,aes(date,R3M)) +
  geom_line(color="blue") +
  geom_line(aes(date,RD),color="orange") +
  geom_line(aes(date,RL),color="green") +
  xlab("") + ylab("Tipos de interés")
# Asignación del formato trimestral
TIPOS_ESP_ts <- ts(TIPOS_INT_ESP[,2:4], start=c(1982,1), end = c(1990,3), frequency = 4)
plot(TIPOS_ESP_ts)
# Modelo de regresión estático
summary(lm_KM <- lm(RL ~ R3M + RD, data=TIPOS_ESP_ts))
# Librería dynlm (especificación ARDL(0,0,0))
summary(dynlm_KM_0 <- dynlm(RL ~ R3M + RD, data=TIPOS_ESP_ts)) 
# Contrastes de correlación en los errores (autocorrelación)
# Errores estimados del modelo
resid <-residuals(dynlm_KM_0)
plot(resid)
abline(h=0, lty=2)
# Correlograma de los residuos
corr <- acf(resid)
corr$acf[2:10]
# Test de Durbin-Watson
dwtest(dynlm_KM_0, alternative = "two.sided")
dwtest(dynlm_KM_0, alternative = "greater")
# Test de Breusch-Godfrey
bgtest(dynlm_KM_0, order=1, type="Chisq", fill=0)
# Corrección de la autocorrelación:
# MCO corregidos: errores estándar robustos, HAC (Newey-West)
summary(dynlm_KM_0 <- dynlm(RL ~ R3M + RD, data=TIPOS_ESP_ts), 
        vcov.=vcovHAC(dynlm_KM_0))
# Mínimos cuadrados generalizados (MCG): errores AR(1)
cochrane.orcutt(dynlm_KM_0)
# Modelo dinámico ARDL(1,1,1) 
summary(dynlm_KM_1 <- dynlm(RL ~ L(RL, 1:1) + L(R3M, 0:1) + L(RD, 0:1), 
                            data=TIPOS_ESP_ts))
# Comparación de modelos
compareCoefs(dynlm_KM_0,dynlm_KM_1)
# Estimación de efectos parciales
# Efectos a corto y largo plazo
library(nlWaldTest)
# Modelo estático (c.p=l.p)
nlConfint(dynlm_KM_0, c("b[2]","b[3]"))
nlWaldtest(dynlm_KM_0, "b[2]")
nlWaldtest(dynlm_KM_0, "b[3]")
# Modelo dinámico
# Corto plazo
nlConfint(dynlm_KM_1, c("b[3]","b[5]"))
nlWaldtest(dynlm_KM_1, "b[3]")
nlWaldtest(dynlm_KM_1, "b[5]")
# Largo plazo
nlConfint(dynlm_KM_1, c("(b[3]+b[4])/(1-b[2])","(b[5]+b[6])/(1-b[2])"))
nlWaldtest(dynlm_KM_1, "(b[3]+b[4])/(1-b[2])")
nlWaldtest(dynlm_KM_1, "(b[5]+b[6])/(1-b[2])")
```

### Código Python {.unnumbered}

```{python}
#| include: true
#| warning: false
#| message: false

# Lectura de librerías
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import statsmodels.formula.api as smf
import statsmodels.stats.api as sms
from statsmodels.graphics import tsaplots
import statsmodels.stats.diagnostic as smsdiag
from statsmodels.compat import lzip
# Lectura de datos y asignación del índice temporal
TIPOS_INT_ESP = pd.read_csv("data/TIPOS_INT_ESP.csv", sep=";", 
parse_dates=['date'], index_col='date')
TIPOS_INT_ESP.info()
# Gráfica de las series temporales
plt.figure(1)
fig, ax = plt.subplots()
TIPOS_INT_ESP.plot(ax=ax)
plt.legend(['R3M','RD','RL']); plt.xlabel(''); plt.ylabel('Tipos de interés')
plt.show()
# Asignación del formato trimestral
TIPOS_ESP_ts = pd.read_csv("data/TIPOS_INT_ESP.csv", sep=";").iloc[:,1:]
date = pd.date_range(start = '1982', periods = len(TIPOS_ESP_ts.index), freq = 'QS')
TIPOS_ESP_ts.index = date
TIPOS_ESP_ts.info()
TIPOS_ESP_ts.index
plt.figure(2)
fig, ax = plt.subplots(3, 1, sharex = True)
ax[0].plot(TIPOS_ESP_ts.R3M)
ax[0].set_ylabel('R3M')
ax[1].plot(TIPOS_ESP_ts.RD)
ax[1].set_ylabel('RD')
ax[2].plot(TIPOS_ESP_ts.RL)
ax[2].set_ylabel('RL')
plt.show()
# Modelo de regresión estático
model = smf.ols(formula = "RL ~ R3M + RD", data = TIPOS_ESP_ts)
lm_KM = model.fit()
print(lm_KM.summary())
# Contrastes de correlación en los errores (autocorrelación)
# Errores estimados (residuos)
residuos = lm_KM.resid
plt.figure(3)
plt.plot(residuos, label='Residuos')
plt.xlabel('Date')
plt.legend()
plt.show()
# Correlograma de los residuos
r = sm.tsa.stattools.acf(residuos, nlags=9, fft=True)
plt.figure(4)
fig, ax = plt.subplots()
tsaplots.plot_acf(residuos, lags=15, alpha=0.05, zero=False, 
vlines_kwargs={"colors":'black'}, color='black', title='', ax=ax)
plt.show()
print(r)
# Test de Durbin-Watson
sms.durbin_watson(residuos).round(5)
# Test de Breusch-Godfrey
name = ['LM statistic', 'Chi^2 p-val', 'F statistic', 'F p-val']
BG_test = smsdiag.acorr_breusch_godfrey(lm_KM,1)
lzip(name, BG_test)
# Corrección de la autocorrelación:
# MCO corregidos: errores estándar robustos
# Corrección de la matriz de covarianzas: estimador de Newey-West 
# (si maxlags=0 -> HAC=HC1)
lm_KM_HAC = smf.ols(formula = "RL ~ R3M + RD", data = TIPOS_ESP_ts).fit(cov_type='HAC', cov_kwds={'maxlags':6,'use_correction':True})
print(lm_KM_HAC.summary())
# Modelo de regresión dinámico 
# Especificación ARDL(1,1,1) 
model = smf.ols(formula = "RL ~ RL.shift(1) + R3M + R3M.shift(1) + RD + RD.shift(1)", 
data = TIPOS_ESP_ts)
lm_KM_dyn = model.fit()
print(lm_KM_dyn.summary())
b = lm_KM_dyn.params[1:]
# Multiplicadores de corto plazo
b[1].round(3) ; b[3].round(3)
# Multiplicadores de largo plazo
b_lr_R3M = (b[1]+b[2])/(1-b[0])
b_lr_R3M.round(3)
b_lr_RD = (b[3]+b[4])/(1-b[0])
b_lr_RD.round(3)
# Contrastes
H_0_b1 = '(R3M = 0)'
W_test = lm_KM_dyn.wald_test(H_0_b1, use_f = False)
W_test
H_0_b3 = '(RD = 0)'
W_test = lm_KM_dyn.wald_test(H_0_b3, use_f = False)
W_test
```

::: justify
## Caso multivariante (especificación VAR): Evolución temporal de los tipos de cambio {.unnumbered}

En esta segunda aplicación se estimará un modelo vectorial autorregresivo para explicar la evolución en el tiempo de los tipos de cambio de tres de las principales monedas al nivel mundial.
:::

### Código R {.unnumbered}

```{r}
#| include: true
#| warning: false
#| message: false

# Lectura de librerías
library(tidyverse)
library(imputeTS)
library(FinTS)
library(vars)
library(rmgarch)
# Lectura de datos
# Descarga de los datos de tipos de cambio EURUSD, USDJPY y GBPUSD
# de la página https://finance.yahoo.com/currencies
library(tseries)
EURUSD <- get.hist.quote("EURUSD=X", start = "2003-12-01", end = "2023-12-31")
USDJPY <- get.hist.quote("JPY=X", start = "2003-12-01", end = "2023-12-31")
GBPUSD <- get.hist.quote("GBPUSD=X", start = "2003-12-01", end = "2023-12-31")
XRATES_0 <- merge(EURUSD$Close, USDJPY$Close, GBPUSD$Close)
class(XRATES_0)
autoplot(XRATES_0) + facet_free()
# Missing data (NAs)
statsNA(EURUSD$Close)
ggplot_na_distribution(EURUSD$Close)
statsNA(USDJPY$Close)
ggplot_na_distribution(USDJPY$Close)
statsNA(GBPUSD$Close)
ggplot_na_distribution(GBPUSD$Close)
# Reemplazar NAs por valores interpolados linealmente
# (la opción na.spline usa splines cúbicos para la interpolación)
EurUsd <- na.approx(EURUSD$Close)
UsdJpy <- na.approx(USDJPY$Close)
GbpUsd <- na.approx(GBPUSD$Close)
XRATES <- merge(EurUsd, UsdJpy, GbpUsd)
autoplot(XRATES) + facet_free()
# Se guardan los datos para el análisis en Python
# write.zoo(XRATES, "TIPOS_CAMB.CSV", index.name = "Date")
# Cambios porcentuales diarios (aproximación dif-log)
rEurUsd <- 100 * diff(log(EurUsd))
autoplot(rEurUsd)
rUsdJpy <- 100 * diff(log(UsdJpy))
autoplot(rUsdJpy)
rGbpUsd <- 100 * diff(log(GbpUsd))
autoplot(rGbpUsd)
# Agrupación de los datos en una matriz para el análisis VAR
VAR_data <- as.matrix(cbind(rEurUsd,rUsdJpy,rGbpUsd))
class(VAR_data)
plot.ts(VAR_data)
# Modelo VAR para las variables rEurUsd, rUsdJpy y rGbpUsd
# Librería vars (https://cran.r-project.org/web/packages/vars/)
# Elección del retardo óptimo (type = c("const", "trend", "both", "none"))
VARselect(VAR_data,lag.max = 5, type = "const")
# Estimación del modelo VAR(2)
VAR2 <-  VAR(VAR_data, p=2)
summary(VAR2)
# Análisis de causalidad de Granger
causality(VAR2, cause = c("rGbpUsd","rUsdJpy"))$Granger
causality(VAR2, cause = c("rEurUsd","rUsdJpy"))$Granger
causality(VAR2, cause = c("rEurUsd","rGbpUsd"))$Granger
# Funciones de respuesta al impulso (IRFs)
irf_VAR2 <- irf(VAR2, n.ahead = 5)
plot(irf_VAR2)
# Funciones de descomposición de la varianza (FEVDs)
fevd_VAR2 <- fevd(VAR2, n.ahead = 5)
plot(fevd_VAR2)
# ANEXO: Modelo VAR con estructura GARCH multivariante (MGARCH))
# Librería rmgarch (https://cran.r-project.org/web/packages/rmgarch/)
# Contraste ARCH para los residuos del modelo VAR(2)
ArchTest(VAR2$varresult$rEurUsd$residuals , lags = 1)
ArchTest(VAR2$varresult$rGbpUsd$residuals , lags = 1)
ArchTest(VAR2$varresult$rUsdJpy$residuals , lags = 1)
# Modelo VAR con correlación condicional (GARCH-Copula model)
VAR_GARCH_spec  <-  ugarchspec(
variance.model = list (garchOrder =c(1,1), model = "sGARCH") )
Multi_spec  <-  multispec ( replicate (3 , VAR_GARCH_spec) )
Copula_GARCH_spec  <-  cgarchspec (Multi_spec, VAR = TRUE, lag = 2)
VAR_GARCH_fit <-  cgarchfit ( Copula_GARCH_spec , data = VAR_data )
show(VAR_GARCH_fit)
# Correlaciones condicionales entre los residuos estandarizados
VAR_GARCH_fit@mfit$Rt
```

### Código Python {.unnumbered}

```{python}
#| include: true
#| warning: false
#| message: false

# Lectura de librerías
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.tsa.api as smt
# Lectura de datos
XRATES = pd.read_csv("data/TIPOS_CAMB.csv", delimiter = ' ', index_col = 0)
def LogDiff(x):
    x_diff = 100*np.log(x/x.shift(1))
    x_diff = x_diff.dropna()
    return x_diff
VAR_data = pd.DataFrame({'rEurUsd':LogDiff(XRATES['EurUsd']),
                     'rUsdJpy':LogDiff(XRATES['UsdJpy']),
                     'rGbpUsd':LogDiff(XRATES['GbpUsd'])})
# Modelo VAR 
model = smt.VAR(VAR_data)
res = model.select_order(maxlags=5)
print(res.summary())
res = model.fit(maxlags=2)
print(res.summary())
# Funciones de respuesta al impulso y de descomposición de la varianza
irf = res.irf(5)
plt.figure(5)
fig = irf.plot()
plt.show()
fevd = res.fevd(5)
plt.figure(6)
fig = fevd.plot()
plt.show()
```
