---
title: "Variable dependiente discreta: modelos Logit y Probit"
author: "Julián Ramajo"
date: "1/9/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R script

```{r}
# Lectura de librerías
library(tidyverse)
library(AER)
library(alr4)
library(margins)
# Lectura de datos
PREST_HIP <- read_csv("PREST_HIP.csv")
summary(PREST_HIP)
# Modelo logit
modelo_logit <- glm(Y ~ FI + MARG + YLD + PTS + MAT + BA + BS + FTB + CB + MC + SE + MOB + NW + LA + STL, data=PREST_HIP, family=binomial(link="logit"))
summary(modelo_logit)
# Modelo probit
modelo_probit <- glm(Y ~ FI + MARG + YLD + PTS + MAT + BA + BS + FTB + CB + MC + SE + MOB + NW + LA + STL, data=PREST_HIP, family=binomial(link="probit"))
summary(modelo_probit)
# Significación de las características personales
linearHypothesis ( modelo_logit , c("BA = 0", "BS = 0","FTB = 0","CB = 0","MC = 0","SE = 0","MOB = 0","NW = 0","LA = 0","STL = 0"))
# Modelos logit restringidos
modelo_logit_1 <- glm(Y ~ FI + MARG + YLD + PTS + MAT, data=PREST_HIP, family=binomial(link="logit"))
summary(modelo_logit_1)
linearHypothesis ( modelo_logit_1, c("PTS = 0", "MAT = 0"))
#
modelo_logit_2 <- glm(Y ~ FI + MARG + YLD, data=PREST_HIP, family=binomial(link="logit"))
summary(modelo_logit_2)
coeftest(modelo_logit_2, vcov. = vcovHC, type = "HC1") # Matriz de convarianzas robusta
#
# Ajuste del modelo: pseudoR2
#
pseudoR2 <- 1 - (modelo_logit_2$deviance) / (modelo_logit_2$null.deviance)
pseudoR2
# Fórmula equivalente
modelo_logit_0 <- glm(Y ~ 1, data=PREST_HIP, family=binomial(link="logit"))
1 - logLik(modelo_logit_2)[1]/logLik(modelo_logit_0)[1]
# ANOVA
Anova(modelo_logit_2)
# Tabla de éxito-fracaso (confusion matrix)
table(true=PREST_HIP$Y, predicted=round(fitted(modelo_logit_2)))
# Formulación alternativa
predicted_probs_logit <- predict(modelo_logit_2, modelo_logit_2$data, type = "response")
tmp_out <- InformationValue::confusionMatrix(modelo_logit_2$y,
                                             predicted_probs_logit, threshold = 0.5)
colnames(tmp_out) <- paste0("Observados ", colnames(tmp_out))
rownames(tmp_out) <- paste0("Predichos ", rownames(tmp_out))
print(tmp_out)
# Precisión global del modelo en términos de predicción
tmp_misclass <- InformationValue::misClassError(PREST_HIP$Y, predicted_probs_logit, 
                                                threshold = 0.5)
print(1 - tmp_misclass)
# Curva ROC (Receiver Operating Characteristics): resume el rendimiento del modelo evaluando el trade-off entre la tasa de verdaderos positivos (sensibilidad) y la tasa de falsos positivos (1-especificidad).
InformationValue::plotROC(PREST_HIP$Y, predicted_probs_logit, Show.labels = TRUE) # AUROC: índice de concordancia (entre 0 y 1)
# Con la librería ROCR
pred_logit  <- ROCR::prediction(predictions = predicted_probs_logit, labels = PREST_HIP$Y)
roc_logit   <- ROCR::performance(pred_logit, measure = "tpr", x.measure = "fpr")
auc_logit <- ROCR::performance(pred_logit, measure = "auc")
auc_logit <- unlist(auc_logit@y.values)
#
ROCR::plot(roc_logit, colorize = TRUE, lwd = 2, main = "Curva ROC \n Modelo Logit")
lines(x = c(0, 1), y = c(0, 1), col = "grey", lty = 2)
text(x = 0.6,  y = 0.3, paste0("AUC = ", round(auc_logit, 4)), cex = 2)
# Gráficas de efectos marginales
# Gráfica conjunta
effs <- Effect(c("FI", "MARG","YLD"), modelo_logit_2)
plot(effs, multiline=TRUE, grid=TRUE, lines=c(1, 2, 3), 
     xlab="FI",main="", rotx=45, roty = 45,
     ylab="Prob[Y=1]", rescale.axis=FALSE, rug=FALSE)
# Gráficas separadas
# Función de probabilidad estimada para la variable FI
# 
plot( Y ~ FI, PREST_HIP, xlab="FI", ylab="Prob", ylim=c(0,1))
FInew <- seq(10, 20, length=78)
lines(FInew, predict(modelo_logit_2, newdata=data.frame(FI=FInew, MARG=rep(mean(PREST_HIP$MARG), 78), YLD=rep(mean(PREST_HIP$YLD), 78)), type="response"), lwd=1.5)
grid(col="gray", lty="solid")
# Función de probabilidad estimada para la variable MARG
plot( Y ~ MARG, PREST_HIP, xlab="MARG", ylab="Prob", ylim=c(0,1))
MARGnew <- seq(-1, 6, length=78)
lines(MARGnew, predict(modelo_logit_2, newdata=data.frame(FI=rep(mean(PREST_HIP$FI), 78), MARG=MARGnew, YLD=rep(mean(PREST_HIP$YLD), 78)), type="response"), lwd=1.5)
grid(col="gray", lty="solid")
# Función de probabilidad estimada para la variable YLD
plot( Y ~ YLD, PREST_HIP, xlab="YLD", ylab="Prob", ylim=c(0,1))
YLDnew <- seq(1, 2.5, length=78)
lines(YLDnew, predict(modelo_logit_2, newdata=data.frame(FI=rep(mean(PREST_HIP$FI), 78), MARG=rep(mean(PREST_HIP$MARG), 78), YLD=YLDnew), type="response"), lwd=1.5)
grid(col="gray", lty="solid")
# Efecto marginal en la media de las variables explicativas
EMM_logit = mfx::logitmfx(formula = modelo_logit_2$formula, data = modelo_logit_2$data, atmean = TRUE)
print(EMM_logit[[1]])
# Efecto marginal promedio
EMP_logit = mfx::logitmfx(formula = modelo_logit_2$formula, data = modelo_logit_2$data, atmean = FALSE)
print(EMP_logit[[1]])
# Forma alternativa del EMP
margins(modelo_logit_2)
```

## Python script

```{python}
# Lectura de librerías
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
import statsmodels.api as sm
# Lectura de datos
PREST_HIP = pd.read_csv("PREST_HIP.csv")
PREST_HIP.describe()
# Modelo logit
modelo_logit = smf.glm("Y ~ 1 + FI + MARG + YLD", data = PREST_HIP, 
family = sm.families.Binomial(link = sm.genmod.families.links.logit())).fit()
print(modelo_logit.summary())
# Formulación alternativa del modelo logit
modelo_logit = smf.logit("Y ~ 1 + FI + MARG + YLD", data = PREST_HIP).fit()
print(modelo_logit.summary())
# Modelo probit
modelo_probit = smf.probit("Y ~ 1 + FI + MARG + YLD", data = PREST_HIP).fit()
print(modelo_probit.summary())
# Tabla de éxito-fracaso
tmp_out_1 = modelo_logit.pred_table(threshold = 0.5)
print(pd.DataFrame(tmp_out_1, columns = ["Predichos 0", "Predichos 1"], index = ["Observados 0", "Observados 1"]))
# Formulación alternativa
from sklearn import metrics
predicted_probs_logit = modelo_logit.predict(exog = PREST_HIP)
tmp_out_2 = metrics.confusion_matrix(modelo_logit.model.endog, 
                                   np.where(predicted_probs_logit >= 0.5, 1, 0))
print(pd.DataFrame(tmp_out_2, 
                   columns = ["Predichos 0", "Predichos 1"],
                   index = ["Observados 0", "Observados 1"]))
# Precisión global del modelo en términos de predicción
tmp_accuracy = metrics.accuracy_score(modelo_logit.model.endog,
                       np.where(predicted_probs_logit >= 0.5, 1, 0))
print(np.round(tmp_accuracy,4)) 
# Curva ROC
# Definición de la curva ROC
def plotROC(fpr, tpr, thresholds): 
  roc_auc = metrics.auc(fpr, tpr)
  fig = plt.figure(figsize = (10, 8))
  plt.plot(fpr, tpr, linestyle = "-", color = "cornflowerblue")
  plt.fill_between(fpr, tpr, 0, color = "cornflowerblue")
  plt.annotate(s = "AUROC: " + str(roc_auc.round(4)), xy = (0.3, 0.3), color = "white", fontsize = 25)
  for i in range(1, len(fpr))[::10]:
    _ = plt.annotate(s = thresholds[i].round(2), xy = (fpr[i], tpr[i]))
  plt.xlabel("1-Specificity (FPR)", color = "cornflowerblue", fontsize = 25)
  plt.ylabel("Sensitivity (TPR)", color = "cornflowerblue", fontsize = 25)
  plt.title("ROC Curve", color = "cornflowerblue", fontsize = 25)
  ax = fig.add_subplot(1, 1, 1) 
  ax.set_facecolor("lightgray")
  plt.grid(True, zorder = 0, color = "white")
  plt.rcParams['axes.axisbelow'] = True
  plt.tight_layout()
  plt.show()
# Gráfica
fpr, tpr, thresholds = metrics.roc_curve(PREST_HIP[["Y"]], 
                                         predicted_probs_logit, pos_label = 1)
plotROC(fpr, tpr, thresholds)
# Efecto marginal en la media de las variables explicativas
EMM_logit = modelo_logit.get_margeff(at = "mean")
print(EMM_logit.summary())
# Efecto marginal promedio
EMP_logit = modelo_logit.get_margeff(at = "overall")
print(EMP_logit.summary())
```
