---
engine: knitr
excerpt: ""
draft: false
format: 
  html:
    theme: simplex
    self-contained: true
    max-width: 1920px
    code-fold: show
    code-tools: true
    highlight-style: atom-one-dark
    code-block-bg: "#282c34"
---

```{css, echo = FALSE}
.justify { text-align: justify !important }
```

::: justify
# Aplicación 3.5 (Regresiones heteroscedásticas): Función de demanda con varianza no constante {.unnumbered}

Empleando datos de corte transversal, en este ejemplo se va a estimar un modelo de demanda para un determinado producto:

$$log(Q_{A,i}) = \beta_1 + \beta_2 log(P_{A,i}) + \beta_3 log(P_{B,i}) + \beta_4 log(P_{C,i}) + \beta_5 log(Y_{i}) + e_{i}$$

donde $Q_{A}$ es la cantidad demandada del bien A analizado por el individuo i-ésimo, $P_{A}$, $P_{B}$ y $P_{C}$ son, respectivamente, los precios de los bienes A, B y C en el mercado, e $Y$ es el nivel de renta.

Una vez chequeada la hipótesis de varianza constante (homoscedasticidad), se plantea la estimación por MCP de la función de demanda bajo la hipótesis de un modelo heteroscedasticidad asociada al logaritmo de la renta del tipo siguiente:

$${σ_i}^2 = e^{α_0 + α_1 log⁡(Y_i)}$$

Esta especificación equivale a suponer que

$${σ_i}^2 = σ^2 (Y_i)^{α_1}$$

donde $$σ^2 = e^{α_0}$$

y de ahí que este tipo de especificación reciba el nombre de **heteroscedasticidad multiplicativa**.

De forma complementaria, compararemos los resultados de MCP con los que se obtienen al estimar la función de demanda por MCO, pero corrigiendo la matriz de covarianzas usando el método de White (MCO-HC).
:::

## Código R {.unnumbered}

```{r}
#| include: true
#| warning: false
#| message: false

# Lectura de librerías
library(tidyverse)
library(car)
library(skedastic)
library(lmtest)
library(sandwich)
# Lectura de datos
DEM_HET <- read_csv("data/DEM_HET.csv")
dim(DEM_HET)
summary(DEM_HET)
# Estimación MCO
modelo_MCO <- lm(log(QA) ~ log(PA) + log(PB) + log(PC)+ log(Y), data = DEM_HET)
summary(modelo_MCO)
# Chequeo de la hipótesis de homoscedasticidad
# Contrastes estándar (automáticos): Z's -> variables explicativas del modelo
# Test de White
white(modelo_MCO)
white(modelo_MCO, interactions=TRUE)
# Test de Glejser
glejser(modelo_MCO)
# Test de Breusch-Pagan
breusch_pagan(modelo_MCO)
# Contrastes específicos: Z's seleccionadas
# Test de Breusch-Pagan (manual)
DEM_HET$resid2 = resid(modelo_MCO)^2
# Análisis gráfico
ggplot(DEM_HET, aes(x = log(Y), y = resid2)) +
    geom_point(color = "blue") +
    geom_smooth(method='lm', formula = y~x, se = TRUE, color = "blue", linetype = "dashed") +
    xlab("Y (log)") + 
    ylab("resid2") +
    theme_minimal()
# Regresión auxiliar
summary(modelo_resid2 <- lm(resid2 ~ log(Y), data=DEM_HET))
N <- nobs(modelo_resid2)
p <- 1 # Número Z's de la regresión auxiliar, sin incluir la constante
sm_resid2 <- summary(modelo_resid2)
R2_m_resid2 <- sm_resid2$r.squared
BP <- N*R2_m_resid2
# Contraste Chi-cuadrado
pval <- 1-pchisq(BP, p)
BP ; pval 
# Test de Breusch-Pagan (automático)
bptest(modelo_MCO, varformula = ~ log(Y), data=DEM_HET) 
# Test de Breusch-Pagan robusto (variante de Koenker)
bptest(modelo_MCO, varformula = ~ log(Y), data=DEM_HET, studentize = FALSE)
# Corrección básica de la heteroscedasticidad: MCO con matriz de covarianzas robusta (MCO-HC)
# Corrección de White (librería sandwich)
coeftest(modelo_MCO, vcov. = vcovHC(modelo_MCO,type="HC1"))
# Otra versión, con idéntico resultado (librería car)
coeftest(modelo_MCO, vcov.=hccm(modelo_MCO, type = "hc1")) 
# Corrección avanzada: mínimos cuadrados ponderados (MCP)
# Regresión auxiliar para el logaritmo de la varianza estimada
summary(modelo_l_resid2 <- lm(log(resid2) ~ log(Y), data=DEM_HET))
# Estimación de la varianza residual (no constante)
sigma2 <- exp(fitted(modelo_l_resid2))
# MCO con ponderaciones: MCP (FGLS)
summary(modelo_MCP <- lm(log(QA) ~ log(PA) + log(PB) + log(PC)+ log(Y), weights = 1/sigma2, data = DEM_HET))
```

## Código Python {.unnumbered}

```{python}
#| include: true
#| warning: false
#| message: false

# Lectura de librerías
import pandas as pd
import numpy as np
import statsmodels.api as sm
import statsmodels.formula.api as smf
import statsmodels.stats.api as sms
import statsmodels.stats as smstats
import statsmodels.stats.diagnostic as smsdiag
import matplotlib.pyplot as plt
import seaborn as sns
# Lectura de datos
DEM_HET = pd.read_csv('data/DEM_HET.csv')
DEM_HET.describe()
# Estimación MCO
modelo1 = smf.ols(formula = "np.log(QA) ~ np.log(PA) + np.log(PB) + np.log(PC) + np.log(Y)", data = DEM_HET)
modelo_MCO = modelo1.fit()
print(modelo_MCO.summary())
# Contrastes de heteroscedasticidad
name = ['LM statistic', 'Chi^2 p-val', 'F statistic', 'F p-val']
# Test de White
W_test = smsdiag.het_white(modelo_MCO.resid, modelo_MCO.model.exog)
print(pd.DataFrame([np.round(W_test, 8)], columns=name))
# Test de Breusch-Pagan
BP_test = smsdiag.het_breuschpagan(modelo_MCO.resid, modelo_MCO.model.exog)
print(pd.DataFrame([np.round(BP_test, 8)], columns=name))
# Estimación MCO-HC
modelo1 = smf.ols(formula = "np.log(QA) ~ np.log(PA) + np.log(PB) + np.log(PC) + np.log(Y)", data = DEM_HET)
# HC1 -> corrige la fórmula de White por grados de libertad
modelo_MCO_HC1 = modelo1.fit(cov_type='HC1')
print(modelo_MCO_HC1.summary())
# HC2 -> corrige la fórmula de White por grados de libertad y tamaño muestral pequeño
modelo_MCO_HC2 = modelo1.fit(cov_type='HC2') 
print(modelo_MCO_HC2.summary())
# Estimación MCP (FGLS)
# Análisis gráfico
DEM_HET['resid2'] = (modelo_MCO.resid)**2
sns.regplot(x=np.log(DEM_HET['Y']), y = DEM_HET['resid2'])
plt.show()
# Regresión auxiliar para el logaritmo de la varianza estimada
reg_aux_resid2 = smf.ols(formula = "np.log(resid2) ~ np.log(Y)", data = DEM_HET)
modelo_l_resid2 = reg_aux_resid2.fit()
print(modelo_l_resid2.summary())
# Estimación de la varianza residual (no constante)
sigma2 = np.exp(modelo_l_resid2.fittedvalues)
w=list(1/sigma2)
# MCO con ponderaciones (FGLS)
modelo2 = smf.wls(formula = "np.log(QA) ~ np.log(PA) + np.log(PB) + np.log(PC) + np.log(Y)", weights = w , data = DEM_HET)
modelo_MCP = modelo2.fit()
print(modelo_MCP.summary())
```
