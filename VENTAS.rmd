---
title: "Ventas en una cadena de supermercados"
author: "J. Ramajo"
date: "`r Sys.Date() # fecha de ejecución del código`"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

<!--this initial code block establishes basic settings--> 
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment="", prompt=TRUE, fig.height=7, fig.width=7)
```

## Datos

Supongamos que somos el gerente de una cadena de 75 supermercados ubicados en distintas ciudades españolas. Las ventas totales en cada tienda dependen básicamente del precio de los productos que se venden en la misma y del gasto en publicidad que se realice en cada ciudad. El objetivo de este ejemplo consiste en determinar el efecto que tendrán sobre las ventas de cada supermercado distintas políticas de precios, así como distintas políticas de gasto en publicidad.

En primer lugar leeremos los datos y los examinaremos:
```{r}
library(readr)
VENTAS <- read_csv("VENTAS.csv")
dim(VENTAS)
VENTAS
summary(VENTAS) 
```

## Gráfica de las variables

Haremos un análisis gráfico a través de una *scatterplot matrix* de las tres variables del modelo, empleando la función `scatterplotMatrix()` en la librería **car**:

```{r}
library("alr4")
scatterplotMatrix(~ V + P + A, id=list(n=3),
                  smooth=list(span=0.7), data=VENTAS)
pairs(~ V + P + A, data=VENTAS)
```


## Modelo econométrico

La ecuación que se ajusta es la siguiente:

$$
V_i = \beta_0 + \beta_1 P_{i} + \beta_2 A_{i} + \varepsilon_i
$$
donde $$ V_i $$ representan los ingresos mensuales por ventas en cada ciudad, $$ P_i $$ es el índice de precios en el supermercado de esa ciudad, y $$ A_i $$ son los gastos mensuales en publicidad para promocionar los productos de la tienda. *V* y *A* se miden en miles de euros, mientras que *P* es un índice ponderado del precio (en euros) de todos los productos que se venden en cada tienda.

```{r}
modelo.ventas <- lm(V ~ P + A, data=VENTAS)
S(modelo.ventas)
plot(allEffects(modelo.ventas), grid=TRUE, rug=TRUE)
confint(modelo.ventas, level=.95)
pred.ventas <- predict(modelo.ventas, newdata=data.frame(P=c(6), A=c(1.9)), se.fit=TRUE, interval="prediction", level=.95)
pred.ventas
```

## Diagnósticos de la regresión

Para comprobar si el modelo estimado ajusta adecuadamente los datos llevaremos a cabo diferentes contrastes de diagnóstico:

### No-linealidad

Gráficos C+R (*Component-plus-Residual*) sobre *P* y *A* para el análisis de la linealidad de las regresiones parciales:

```{r fig.height=4, fig.width=8}
crPlots(modelo.ventas, smooth=list(span=0.7))
```

NOTA: Cuando el tamaño de la muestra es pequeño es mejor tomar un parámetro de suavizado relativamente elevado (el parámetro por defecto es 0.5, pero aquí se ha tomado el valor 0.7).

### Heteroscedasticidad (varianza no constante)

En nuestro caso mediremos si la varianza residual cambia con el nivel de la variable respuesta o de los regresores:
```{r}
spreadLevelPlot(modelo.ventas, smooth=list(span=1))
ncvTest(modelo.ventas)
ncvTest(modelo.ventas, var.formula= ~ P + A)
```

### Datos atípicos

Se realizará un examen de los residuos *estudentizados* para el análisis de outliers:
```{r}
densityPlot(rstudent(modelo.ventas))
qqPlot(modelo.ventas, id=list(n=3))
outlierTest(modelo.ventas)
```

Y, finalmente, un examen conjunto de las observaciones influyentes (residuos grandes y leverages elevados) y del efecto de las mismas sobre los coeficientes estimados para *P* y *A*:

```{r}
influencePlot(modelo.ventas, id=list(n=3))
```
```{r fig.height=4, fig.width=8}
avPlots(modelo.ventas, id=list(n=3, method="mahal")) # id=list(n=0) suprime etiquetas
```

Si se eliminan de la regresión las observaciones atípicas el resultado sería el siguiente:

```{r}
modelo.ventas.2 <- update(modelo.ventas, subset=-c(3,9,38,39))
S(modelo.ventas.2)
compareCoefs(modelo.ventas, modelo.ventas.2)
```
