---
title: "Aplicación 2.1. Valoración de activos en el mercado de valores"
author: "J. Ramajo"
date: '2020'
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

En esta aplicación se aplica el modelo CAPM (Capital Asset Pricing Model) a la empresa americana Mobil. 

## 1. Lectura de datos y análisis exploratorio básico

En primer lugar, se leen los datos y se les da formato de series temporales:

```{r}
library(readr)
CAPM_MOBIL <- read_csv("CAPM_MOBIL.csv")
dim(CAPM_MOBIL)
head(CAPM_MOBIL, n=10)
ts_CAPM_MOBIL <- ts(CAPM_MOBIL, start=c(1978,1), end = c(1987,12), frequency = 12)
plot(ts_CAPM_MOBIL)
```

Estadísticos descriptivos de las variables en el fichero `CAPM_MOBIL`:

```{r}
summary(ts_CAPM_MOBIL)
```

Gráficas e histogramas de la variables:

```{r, fig.width=3, fig.height=3}
ER_MOBIL <- ts_CAPM_MOBIL[,"ER_MOBIL"]
ER_M <- ts_CAPM_MOBIL[,"ER_M"]
ts.plot(ER_MOBIL)
ts.plot(ER_M)
with(CAPM_MOBIL, hist(ER_MOBIL))
with(CAPM_MOBIL, hist(ER_M))
```

## 2. Análisis econométrico básico

Ajuste de un modelo de regresión lineal ( función`lm()` ):

```{r}
CAPM <- lm (ER_MOBIL~ER_M)
summary(CAPM)
```
NOTA: Las funciones `brief()` y `S()`, ambas en el paquete **car** , proporcionan alternativas a las salida estándar de la función `summary` del paquete básico.

```{r}
library(car)
brief(CAPM)
```
# ************
```{r}
S(CAPM)
```

Contrastes de hipótesis e intervalos de confianza:

```{r}
#
# Contrastes de hipótesis
#
# beta1=0 versus beta1≠0
#
# Estadístico t
#
# Método del valor crítico
#
alpha <- 0.05 # nivel de significación
b1 <- coef(CAPM)[[1]] # estimación del parámetro beta1
seb1 <- sqrt(vcov(CAPM)[1,1]) # estimación de la desviación típica de beta1
c <- 0
df <- df.residual(CAPM) # grados de libertad
t <- (b1-c)/seb1 # estadístico t
t
tcr <- qt(1-alpha/2, df) # valor crítico
tcr
#
# Gráfico de la función de densidad t de Student, valor crítico y estadístico t:
#
curve(dt(x, df), -5, 5, ylab=" ", xlab="t")
abline(v=c(-tcr, tcr, t), col=c("red", "red", "blue"), lty=c(2,2,3))
legend("topleft", legend=c("-tcr", "tcr", "t"), col=c("red", "red", "blue"), lty=c(2, 2, 3))
#
# Método del P-valor
#
p <- 2*(1-pt(abs(t), df))
p
#
# Estadístico F
#
H_0 <- "(Intercept)=0"
linearHypothesis(CAPM,H_0,test="F")
#
# beta2=1 versus beta1≠1
#
# Estadístico t
#
# Método del valor crítico
alpha <- 0.05 # nivel de significación
b2 <- coef(CAPM)[[2]] # estimación del parámetro beta1
seb2 <- sqrt(vcov(CAPM)[2,2]) # estimación de la desviación típica de beta1
c <- 1
df <- df.residual(CAPM) # grados de libertada
t <- (b2-c)/seb2 # estadístico t
t
tcr <- qt(1-alpha/2, df) # valor crítico
tcr
#
# Gráfico de la función de densidad t de Student, valor crítico y estadístico t:
#  
curve(dt(x, df), -5, 5, ylab=" ", xlab="t")
abline(v=c(-tcr, tcr, t), col=c("red", "red", "blue"), lty=c(2,2,3))
legend("topleft", legend=c("-tcr", "tcr", "t"), col=c("red", "red", "blue"), lty=c(2, 2, 3))
#
# Método del P-valor
#
p <- 2*(1-pt(abs(t), df))
p
#
# Estadístico F
#
H_0 <- "ER_M=1"
linearHypothesis(CAPM,H_0,test="F")
#
# Contraste conjunto: beta1=0, beta2=1
#
H_0 <- c("(Intercept) = 0", "ER_M = 1")
linearHypothesis(CAPM,H_0,test="F")
#
# Contrastes unilaterales
# 
# beta2≤1 versus beta2>1
#
c <- 1
alpha <- 0.05
t <- (b2-c)/seb2
t
tcr <- qt(1-alpha, df) # alpha no se divide por 2
tcr
curve(dt(x, df), -5, 5, ylab=" ", xlab="t")
abline(v=c(tcr, t), col=c("red", "blue"), lty=c(2, 3))
legend("topleft", legend=c("tcr", "t"),
       col=c("red", "blue"), lty=c(2, 3))
#
p <- 1-pt(t, df)
p
# 
# beta2≥2 versus beta2<2
#
c <- 2
alpha <- 0.05
t <- (b2-c)/seb2
t
tcr <- qt(alpha, df) # alpha no se divide por 2
tcr
curve(dt(x, df), -20, 20, ylab=" ", xlab="t")
abline(v=c(tcr, t), col=c("red", "blue"), lty=c(2, 3))
legend("topleft", legend=c("tcr", "t"),
       col=c("red", "blue"), lty=c(2, 3))
#
p <- pt(t, df)
p
#
# Intervalos de confianza (automáticos)
#
IntConf <- confint(CAPM)
print(IntConf)
#
# Intervalos de confianza (manualmente)
#
alpha <- 0.05
tc <- qt(1-alpha/2, df)
#
inf_b1 <- b1-tc*seb1 # cota inferior
sup_b1 <- b1+tc*seb1 # cota superior
inf_b1 ; sup_b1
#
inf_b2 <- b2-tc*seb2 # cota inferior
sup_b2 <- b2+tc*seb2 # cota superior
inf_b2 ; sup_b2
#
# Ajuste del modelo (R^2) y ANOVA
#
s_CAPM <- summary(CAPM)
print(s_CAPM)
names(s_CAPM)
R2 <- s_CAPM$r.squared
R2
# 
T <- nobs(CAPM)
K <- T-df.residual(CAPM)
T ; K
F_0 <- (R2/(K-1))/((1-R2)/(T-K))
F_0
anova(CAPM)
#
# Intervalo confianza para sigma
#
s2 <- s_CAPM$sigma^2
s2
#
alpha <- 0.05
chisqcr1 <- qchisq(alpha/2, df) 
chisqcr2 <- qchisq(1-alpha/2, df)
chisqcr1 ; chisqcr2
inf_s2 <- (T-K)*s2/chisqcr2 # cota inferior
sup_s2 <- (T-K)*s2/chisqcr1 # cota superior
inf_s2 ; sup_s2
#
s <-  sqrt(s2)
inf_s <- sqrt(inf_s2)
sup_s <- sqrt(sup_s2)
inf_s ; s ; sup_s
```

##  3. Diagnósticos de la regresión

`rstudent()` : residuos estudentizados

`densityPlot()` : estimación de la distribución de los residuos (adaptive kernel density estimator)

```{r fig.height=3, fig.width=3}
densityPlot(rstudent(CAPM))
```

`qqPlot()` : comparación de los residuos estudentizados con una distribution t de Student
```{r fig.height=3,fig.width=3}
qqPlot(CAPM, id=list(n=3))
```

`qqPlot()` : búsqueda de **outliers** en la regresión
```{r}
outlierTest(CAPM)
```

`influenceIndexPlot` : medidas de  influencia
```{r fig.height=4,fig.width=4}
influenceIndexPlot(CAPM, vars=c("hat", "Studentized", "Cook"), 
    id=list(n=3))
```

`crPlots` [Added-variable plots] : búsqueda de observaciones influyentes (para cada variable explicativa)

```{r fig.height=4, fig.width=8}
avPlots(CAPM, 
    id=list(cex=0.75, n=3, method="mahal"))
```

`crPlots` [Component-plus-residual plots] : chequeo de nonlinealidad (para cada variable explicativa)

```{r fig.height=4, fig.width=8}
crPlots(CAPM, smooth=list(span=0.7))
```

`ncvTest` : contraste de varianza no constante (heteroscedasticidad)

```{r}
ncvTest(CAPM)
ncvTest(CAPM, var.formula= ~ ER_M) # con sólo una variable explicativa coincide con el anterior
```
