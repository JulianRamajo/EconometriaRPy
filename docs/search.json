[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Econometría",
    "section": "",
    "text": "PREFACIO\nEl objetivo de este libro de texto en formato eBook es exponer los fundamentos teóricos básicos de la econometría, así como la implementación práctica de los métodos y técnicas más importantes de esta disciplina usando los lenguajes de programación R y Python."
  },
  {
    "objectID": "index.html#requisitos-previos",
    "href": "index.html#requisitos-previos",
    "title": "Econometría",
    "section": "Requisitos previos",
    "text": "Requisitos previos\n\nR, Python y RStudio deben estar instalados localmente (ver Capítulo 0, dedicado a la instalación y configuración del software necesario)."
  },
  {
    "objectID": "index.html#estructura-del-ebook",
    "href": "index.html#estructura-del-ebook",
    "title": "Econometría",
    "section": "Estructura del eBook",
    "text": "Estructura del eBook\n\nCapítulo 0 (Software): Aspectos técnicos.\nCapítulo 1 (Introducción): Conceptos básicos de la econometría.\nCapítulo 2 (Núcleo): El modelo de regresión lineal y sus hipótesis básicas.\nCapítulo 3 (Ampliaciones): Diagnosis, correcciones y extensiones del modelo de regresión lineal."
  },
  {
    "objectID": "index.html#autor",
    "href": "index.html#autor",
    "title": "Econometría",
    "section": "Autor",
    "text": "Autor\nJulián Ramajo es Catedrático de Economía Aplicada (Econometría) en la Universidad de Extremadura. https://sites.google.com/site/julianramajo/"
  },
  {
    "objectID": "index.html#cita-del-libro",
    "href": "index.html#cita-del-libro",
    "title": "Econometría",
    "section": "Cita del libro",
    "text": "Cita del libro\nRamajo, J. (2023) Econometría: Con aplicaciones en R y Python. Edition 2023-11. https://jramajo.quarto.pub/econometriarpy/"
  },
  {
    "objectID": "index.html#página-web",
    "href": "index.html#página-web",
    "title": "Econometría",
    "section": "Página web",
    "text": "Página web\nhttps://sites.google.com/view/econometriarpy/"
  },
  {
    "objectID": "index.html#licencia",
    "href": "index.html#licencia",
    "title": "Econometría",
    "section": "Licencia",
    "text": "Licencia\nEste eBook es de uso libre, con una licencia del tipo Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License."
  },
  {
    "objectID": "p0-aspectos-tecnicos.html",
    "href": "p0-aspectos-tecnicos.html",
    "title": "CAPÍTULO 0: ASPECTOS TÉCNICOS",
    "section": "",
    "text": "En esta sección se explicará cómo instalar y configurar R y Python localmente en un ordenador con el sistema operativo Windows o macOS, así como la instalación y configuración del entorno de ejecución (IDE) RStudio para dichos lenguajes de programación. Aquellos interesados en instalar este software en un sistema Linux-Ubuntu deben consultar (y adaptar) las instrucciones contenidas en la siguiente dirección: https://github.com/Robinlovelace/install-geocomp-ubuntu.\nUna vez realizada la instalación, se realizará una aplicación comparativa de ambos lenguajes, y también se mostrará a través de varios ejemplos cómo la librería reticulate de R permite la interacción entre los lenguajes R y Python en una misma aplicación econométrica."
  },
  {
    "objectID": "p0c1-setup.html#nota-introductoria",
    "href": "p0c1-setup.html#nota-introductoria",
    "title": "Instalación y configuración de R y Python en RStudio",
    "section": "Nota introductoria",
    "text": "Nota introductoria\nEn las distintas aplicaciones del libro se usan los lenguajes de programación R (https://www.r-project.org/) y Python (https://www.python.org), utilizando RStudio (https://www.rstudio.com/) como entorno de ejecución (IDE) de dichos lenguajes.\nTambién pueden emplearse otras opciones alternativas, como JupyterLab (https://jupyter.org/), Visual Studio Code (https://code.visualstudio.com/), Google Colab (https://colab.research.google.com/?hl=es), Amazon SageMaker Studio Lab (https://studiolab.sagemaker.aws/), DataCamp Workspace (https://www.datacamp.com/workspace) o Deepnote Worspace (https://deepnote.com/workspace)."
  },
  {
    "objectID": "p0c1-setup.html#instalación-y-configuración-de-r-en-rstudio",
    "href": "p0c1-setup.html#instalación-y-configuración-de-r-en-rstudio",
    "title": "Instalación y configuración de R y Python en RStudio",
    "section": "Instalación y configuración de R en RStudio",
    "text": "Instalación y configuración de R en RStudio\n\nDescargar e instalar R y RStudio: https://posit.co/download/rstudio-desktop/\n(Windows) Instalar el software Rtools (https://cran.r-project.org/bin/windows/Rtools/) y,\nDesde R, instalar la librería Rcpp:\n\n\ninstall.packages(\"Rcpp\")\n\n\nAbrir RStudio e instalar la colección de librerías tidyverse (https://www.tidyverse.org/), y opcionalmente las librerías shiny y tidymodels:\n\n\n# Librerías básicas para analizar y explorar\ninstall.packages(\"tidyverse\")\n# Librerías complementarias (opcionales)\n# Para comunicar e interactuar\ninstall.packages(\"shiny\")\n# Para modelizar y predecir\ninstall.packages(\"tidymodels\")\n\n\nUna vez instalados R y RStudio, y sus librerías generales básicas, el siguiente paso consiste en instalar las librerías específicas para realizar análisis de tipo estadístico y/o econométrico. Hay una gama muy amplia de paquetes disponibles en R, aunque afortunadamente la mayoría de las librerías más populares, o muy especializadas, están agrupadas en diferentes categorías en CRAN TASK Views (https://cran.r-project.org/web/views/). Para descargarse estos paquetes de macro-librerías, primero debe instalarse la librería ctv, y posteriormente se instalarán los conjuntos de librerías homogéneos:\n\n\ninstall.packages(\"ctv\")\n\n\n# Librerías básica de econometría\nctv::install.views(\"Econometrics\")\n# Librerías complementarias (opcionales)\nctv::install.views(\"TimeSeries\")\nctv::install.views(\"Spatial\")\nctv::install.views(\"SpatioTemporal\")\nctv::install.views(\"MissingData\")\nctv::install.views(\"Robust\")\nctv::install.views(\"Finance\")\n\nEs recomendable instalar sólo los paquetes necesarios para el análisis econométrico “básico”, https://cran.r-project.org/web/views/Econometrics.html. Siempre se pueden instalar paquetes adicionales más adelante; así, la IDE RStudio instalada nos avisará cuándo un script contenga alguna librería no instalada y nos dará la opción de descargarla antes de ejecutar el código.\nNo obstante el comentario anterior, tras la instalación de la macro-librería Econometrics, para la ejecución de todos los scripts de R correspondientes a la aplicaciones econométricas seleccionadas en el libro se necesitan algunas librerías específicas que se detallan a continuación, las cuales pueden instalarse desde el principio, o instalarlas cuando RStudio lo pida a la vista de la líneas de cógigo de R que se intenten ejecutar:\n\ninstall.packages(\"skimr\")\ninstall.packages(\"modelsummary\")\ninstall.packages(\"easystats\")\ninstall.packages(\"effects\")\ninstall.packages(\"marginaleffects\")\ninstall.packages(\"jtools\")\ninstall.packages(\"plotly\")\ninstall.packages(\"ggstatsplot\")\ninstall.packages(\"esquisse\")\ninstall.packages(\"viridis\")\ninstall.packages(\"RColorBrewer\")\ninstall.packages(\"stargazer\")\ninstall.packages(\"huxtable\")\ninstall.packages(\"fpp3\")\ninstall.packages(\"gvlma\")\ninstall.packages(\"alr4\")\ninstall.packages(\"skedastic\")\ninstall.packages(\"nlWaldTest\")\ninstall.packages(\"orcutt\")\ninstall.packages(\"faraway\")\ninstall.packages(\"mctest\")\ninstall.packages(\"ivreg\")\ninstall.packages(\"sampleSelection\")\ninstall.packages(\"geojsonsf\")\ninstall.packages(\"leaflet\")\ninstall.packages(\"sf\")\ninstall.packages(\"mapsf\")\ninstall.packages(\"mapview\")\ninstall.packages(\"tmap\")\ninstall.packages(\"spdep\")\ninstall.packages(\"spatialreg\")\ninstall.packages(\"rgeoda\")\ninstall.packages(\"DataEditR\")\ninstall.packages(\"tidyquant\")\ninstall.packages(\"scales\")\ninstall.packages(\"palmerpenguins\")"
  },
  {
    "objectID": "p0c1-setup.html#instalación-y-configuración-de-python-en-rstudio",
    "href": "p0c1-setup.html#instalación-y-configuración-de-python-en-rstudio",
    "title": "Instalación y configuración de R y Python en RStudio",
    "section": "Instalación y configuración de Python en RStudio",
    "text": "Instalación y configuración de Python en RStudio\nHay varias formas de configurar Python en el ordenador. Los tres métodos más frecuentes son los siguientes:\n\nDistribución estándar: https://www.python.org/\nDistribución Anaconda: https://www.anaconda.com/\nDistribución Miniconda: https://docs.conda.io/en/latest/miniconda.html\n\nTanto la distribución Anaconda como la Miniconda utilizan la librería conda en sus instalaciones de Python, la cual permite descargar e instalar paquetes adicionales de Python. La instalación estándar de Python utiliza pip para descargar e instalar librerías adicionales de Python.\nPara las necesidades de este libro, donde se ejecutarán simultáneamente líneas de código (chunks) en R y Python, hay que disponer en el ordenador de una las distribuciones, Python estándar o Miniconda. Veamos a continuación cómo hacerlo; los detalles pueden encontrarse aquí.\nSi se usa la primera distribución, Python estándar, lo primero que hay que hacer es ir a la página de descargas de la web oficial de Python, https://www.python.org/downloads/, y luego buscar e instalar la versión correspondiente al sistema operativo utilizado.\nA continuación, una vez realizada la instalación, para configurar el entorno de Python en RStudio hay que instalar y ejecutar la librería de R reticulate:\n\ninstall.packages(\"reticulate\")\nlibrary(reticulate)\n\ny luego hay que realizar las acciones siguientes desde RStudio: ir al menú de herramientas (Tools), luego a opciones globales (Global Options), y en el listado de la izquierda (Options) hay que ir a Python y asignar en la casilla del intérprete el directorio donde está instalado el software.\nPor ejemplo, si se tiene instalado Python 3.XX en un ordenador con el sistema operativo Windows o macOS, y se quiere utilizar esa versión, debe utilizarse la siguiente línea de comandos indicando la localización correspondiente a la instalación de Python:\n\nlibrary(reticulate)\nuse_python(\"C:/.../python3.XX\") # En Windows\nuse_python(\"/usr/local/bin/python3.XX\") # En macOS\n\nSi se elige la segunda distribución, Miniconda, lo único que hay que hacer es configurar el entorno de Python en RStudio con la librería de R reticulate. Así, una vez instalada esta última, cuando se ejecuta por primera vez dicho paquete se crea una instalación miniconda adaptada a R llamada R-Miniconda; también se puede instalar miniconda manualmente utilizando el comando install_miniconda().\n\ninstall.packages(\"reticulate\")\nlibrary(reticulate)\ninstall_miniconda()\n\nSea cual sea la opción elegida, Python estándar o Miniconda, para comprobar que existe alguna instalación de Python disponible se pueden usar los siguientes comandos en R:\n\nconda_list()\nconda_version()\npy_config()\n\nSi no aparece ninguna instalación de Python hay que volver a intentar la instalación de Python estándar o la versión Miniconda.\nPara comprobar que el entorno Python se ha creado adecuadamente se puede entrar en la consola de Python y hacer algún cálculo sencillo para ver si la instalación es correcta.\nAsí, desde R, tras cargar la librería reticulate, se debe usar el comando repl_python() y luego, ya en la consola de Python, se pueden teclear por ejemplo los siguientes comandos:\n\nimport numpy as np\na = np.sqrt(2)\nprint(a)\nx = 42*2\nprint(x)\nexit\n\nTambién se pueden ejecutar algunos comandos Python desde R importando la librería correspondiente:\n\nlibrary(reticulate)\nnp &lt;- import(\"numpy\")\nnp$sqrt(2)\n\nO se puede ejecutar un script de Python y mostrar los resultados en RStudio:\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\nx = list(range(1, 11))\ny = np.random.randn(10)\nplt.figure(0)\nplt.plot(x, y,  linestyle = \"--\", color = \"blue\", marker = \"s\", label = \"Línea 1\")\nplt.title(\"Ejemplo de gráfico de líneas\")\nplt.legend(loc = \"upper left\")\nplt.show()\n\n\nInstalación de librerías Python\nEl siguiente paso consiste en instalar las librerías de Python pertinentes en el entorno de Python recién creado.\nSi se usa la versión estándar de Python, se instalarán las librerías a través de pip en el terminal de Windows o macOS:\n\npip install –upgrade nombre-librería # En Windows\npip3 install –upgrade nombre-librería # En macOS\n\nSi se utiliza R-Miniconda a través de reticulate, se pueden instalar las librerías desde RStudio utilizando el comando py_install. Debajo se muestran los comandos necesarios para la instalación de todas las librerías Python necesarias en este libro; si se utilizase la opcíon Python estándar habría que usar el comando pip mostrado anteriormente, instalando una a una todas las librerías sugeridas.\n\nlibrary(reticulate)\n# Librerías básicas\npy_install(\"numpy\", pip = TRUE)\npy_install(\"pandas\", pip = TRUE)\npy_install(\"statsmodels\", pip = TRUE)\npy_install(\"matplotlib\", pip = TRUE)\n# Librerías complementarias\npy_install(\"seaborn\", pip = TRUE)\npy_install(\"plotly\", pip = TRUE)\npy_install(\"plotnine\", pip = TRUE)\npy_install(\"pandas-bokeh\", pip = TRUE)\npy_install(\"scipy\", pip = TRUE)\npy_install(\"scikit-learn\", pip = TRUE)\npy_install(\"linearmodels\", pip = TRUE)\npy_install(\"arch\", pip=TRUE)\npy_install(\"datetime\", pip =  TRUE)\npy_install(\"stargazer\", pip = TRUE)\npy_install(\"xlrd\", pip = TRUE)\npy_install(\"category_encoders\", pip = TRUE)\npy_install(\"palmerpenguins\", pip = TRUE)\npy_install(\"siuba\", pip = TRUE)\npy_install(\"plydata\", pip = TRUE)\npy_install(\"skimpy\", pip = TRUE)\npy_install(\"yfinance\", pip = TRUE)\npy_install(\"geopandas\", pip = TRUE)\npy_install(\"folium\", pip = TRUE)\npy_install(\"leafmap\", pip = TRUE)\npy_install(\"chart_studio\", pip = TRUE)\npy_install(\"pysal\", pip = TRUE)\npy_install(\"pygeoda\", pip = TRUE)"
  },
  {
    "objectID": "p0c2-rpy-comp.html#código-r",
    "href": "p0c2-rpy-comp.html#código-r",
    "title": "R versus Python: Comparación de lenguajes",
    "section": "Código R",
    "text": "Código R\n\n# Ayuda\n?print #help(print)\n#\n# Matrices de datos (data arrays)\n#\n# Crear un vector:\nmy_vec &lt;- c(1, 2, 3, 4, 5, 6, 7, 8)\nstr(my_vec)\n\n num [1:8] 1 2 3 4 5 6 7 8\n\n# Seleccionar los datos de un vector (en R los valores comienzan en el índice 1)\nprint(my_vec[1])\n\n[1] 1\n\n# Rango de valores: en R el índice rango es 1:3 = {1, 2, 3}\nprint(my_vec[1:3])\n\n[1] 1 2 3\n\nprint(my_vec[c(1, 2, 4, 8)])\n\n[1] 1 2 4 8\n\nmy_range &lt;- seq(from = 1, to = 4, by = 1)\nprint(my_range)\n\n[1] 1 2 3 4\n\nprint(my_range[1:4])\n\n[1] 1 2 3 4\n\n# Longitud de la matriz de datos\nprint(length(my_vec))\n\n[1] 8\n\n# Bucles (loops)\nfor(i in 1:length(my_vec)){\n  print(my_vec[i])}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n\n# Seleccionar cada tercer elemento, empezando desde el segundo\nprint(my_vec[seq(2, length(my_vec), 3)])\n\n[1] 2 5 8\n\n# o cada segundo elemento partiendo desde el primero\nprint(my_vec[seq(1, length(my_vec), 2)])\n\n[1] 1 3 5 7\n\n# Suma de vectores\nmy_vec_1 = seq(from = 1, to = 5, by = 1)\nmy_vec_2 = rev(my_vec_1)\ncat(\"vec. 1: \", my_vec_1)\n\nvec. 1:  1 2 3 4 5\n\ncat(\"vec. 2: \", my_vec_2)\n\nvec. 2:  5 4 3 2 1\n\nvec_sum = my_vec_1 + my_vec_2\ncat(\"vec. 1 + 2: \", vec_sum)\n\nvec. 1 + 2:  6 6 6 6 6\n\n# Concatenación de vectores\ncat(\"vec. 1 & 2: \", c(my_vec_1, my_vec_2))\n\nvec. 1 & 2:  1 2 3 4 5 5 4 3 2 1\n\n# Multiplicar los elementos de un vector por una constante\ncat(my_vec_1 * 3)\n\n3 6 9 12 15\n\n# Concatenar un vector varias veces\ncat(rep(my_vec_1, 3))\n\n1 2 3 4 5 1 2 3 4 5 1 2 3 4 5\n\n#\n# Cadenas de caracteres\n#\n# Funciones específicas de R para modificar caracteres\nmy_animal = \"bear\"\nprint(my_animal)\n\n[1] \"bear\"\n\nprint(toupper(my_animal))\n\n[1] \"BEAR\"\n\nmy_sentence = paste(\"I\", \"saw\", \"a\", my_animal)\nprint(my_sentence)\n\n[1] \"I saw a bear\"\n\nprint(paste(\"----\", \"++++\", sep = \"\"))\n\n[1] \"----++++\"\n\n#\n# Variables que contienen diferentes tipos de información \n# (valores enteros, de cadena, booleanos, etc.)\n#\nmy_data &lt;- list(name = \"Joe\",\n                grades = c(8, 7, 9),\n                has_attended = TRUE)\nstr(my_data)\n\nList of 3\n $ name        : chr \"Joe\"\n $ grades      : num [1:3] 8 7 9\n $ has_attended: logi TRUE\n\nstr(my_data[\"name\"])\n\nList of 1\n $ name: chr \"Joe\"\n\nprint(my_data[\"name\"])\n\n$name\n[1] \"Joe\"\n\nstr(my_data[[\"name\"]])\n\n chr \"Joe\"\n\nprint(my_data[[\"name\"]])\n\n[1] \"Joe\"\n\nstr(my_data[\"grades\"])\n\nList of 1\n $ grades: num [1:3] 8 7 9\n\nstr(my_data[\"has_attended\"])\n\nList of 1\n $ has_attended: logi TRUE\n\nprint(my_data[[\"grades\"]])\n\n[1] 8 7 9\n\nprint(my_data$has_attended)\n\n[1] TRUE\n\n# A menudo tenemos más de una observación con diferentes propiedades.\n# Por ejemplo, una base de datos de personas con nombres, identificaciones\n# únicas, direcciones de correo electrónico, valor del indicador si es un \n# nuevo miembro, etc. Y queremos tener una estructura tipo matriz (es decir,\n# una tabla) para albergar esos valores.\nmy_dataset = data.frame(name = c(\"John\", \"Sam\", \"Tim\"),\n                        wage = c(800, 600, 700),\n                        is_employed = c(TRUE, TRUE, FALSE),\n                        stringsAsFactors = FALSE)\nstr(my_dataset)\n\n'data.frame':   3 obs. of  3 variables:\n $ name       : chr  \"John\" \"Sam\" \"Tim\"\n $ wage       : num  800 600 700\n $ is_employed: logi  TRUE TRUE FALSE\n\n# Tener en cuenta que el stringsAsFactors es necesario para que la columna \n# del nombre sea un vector de caracteres en lugar de un factor (un factor \n# es un vector de valores enteros con un conjunto correspondiente de valores \n# de caracteres para utilizar cuando se muestra el factor).\nprint(my_dataset)\n\n  name wage is_employed\n1 John  800        TRUE\n2  Sam  600        TRUE\n3  Tim  700       FALSE\n\nprint(my_dataset[\"name\"])\n\n  name\n1 John\n2  Sam\n3  Tim\n\nprint(my_dataset$is_employed) \n\n[1]  TRUE  TRUE FALSE\n\n# Notar que el uso de $ devuelve un vector, mientras que la especificación \n# de [\"nombre\"] devuelve un data.frame con una columna (como es evidente por \n# el formato de salida).\n#\n# Definición de funciones\n#\n# Definir una función 1 (una funicón simple que compara dos valores)\nmy_compare &lt;- function(x, y){\n  if(x &lt; y){\n    print(\"1st value is smaller\")\n  }else{\n    if(x &gt; y){\n      print(\"1st value is greater\")\n    }else{\n      print(\"Values are equal\")\n    }\n  }\n}\n# Prueba de la función\nmy_compare(1, 1)\n\n[1] \"Values are equal\"\n\nmy_compare(1, 2)\n\n[1] \"1st value is smaller\"\n\nmy_compare(2, 1)\n\n[1] \"1st value is greater\"\n\n# Definir una función 2 (una función de suma personalizada, que incrementa \n# los valores de dos elementos en uno antes de sumarlos)\nmy_sum &lt;- function(x, y){\n  x &lt;- x + 1\n  y &lt;- y + 1\n  return(x + y)\n}\n# Prueba de la función\nprint(my_sum(1, 2))\n\n[1] 5\n\n# Definir una función 3 (resumen de una matriz de datos)\nmy_summary &lt;- function(x){\n  min_val = min(x)\n  max_val = max(x)\n  sum_val = sum(x)\n  avg_val = mean(x)\n  output = list(min = min_val,\n                max = max_val,\n                average = avg_val,\n                sum = sum_val)\n  return(output)\n}\n# Prueba de la función\nmy_results = my_summary(c(-2, 1, 5))\nprint(my_results$min)\n\n[1] -2\n\nprint(my_results[[\"average\"]])\n\n[1] 1.333333\n\nprint(str(my_results))\n\nList of 4\n $ min    : num -2\n $ max    : num 5\n $ average: num 1.33\n $ sum    : num 4\nNULL\n\nprint(my_results)\n\n$min\n[1] -2\n\n$max\n[1] 5\n\n$average\n[1] 1.333333\n\n$sum\n[1] 4\n\n#\n# Listas\n#\nmy_list &lt;- function(a_vec){\n  a_vec[1] &lt;- \"88\"\n  append(a_vec, \"!!!\")\n}\n# Prueba de la función\nold_vec &lt;- c(\"a\", \"b\")\ncat(\"Old: \", old_vec, \"\\n\")\n\nOld:  a b \n\nnew_vec &lt;- my_list(old_vec)\ncat(\"New: \", new_vec, \"\\n\")\n\nNew:  88 b !!! \n\ncat(\"Old: \", old_vec, \"\\n\")\n\nOld:  a b \n\n#\n# Creación de matrices\n#\n# Crearemos una matriz 3X2 con elementos de 1 a 6 por columnas\nx1 &lt;- c(1, 2, 3)\nx2 &lt;- c(4, 5, 6)\nx  &lt;- cbind(x1, x2) # los vectores se combinan como columnas en una matriz\nprint(x) \n\n     x1 x2\n[1,]  1  4\n[2,]  2  5\n[3,]  3  6\n\n# Podemos transponer una matriz usando t(...)\nprint(t(x))\n\n   [,1] [,2] [,3]\nx1    1    2    3\nx2    4    5    6\n\n# Podemos acceder a diferentes elementos de la matriz X\nprint(x[1, ]) # primera fila (para eliminar nombres, usar unname())\n\nx1 x2 \n 1  4 \n\nprint(x[, 1]) # primera columna\n\n[1] 1 2 3\n\nprint(x[1, 1]) # elemento {1,1}\n\nx1 \n 1 \n\nprint(x[3, 2]) # elemento {3,2}\n\nx2 \n 6 \n\n# Multiplicar matrices (X'X en este ejemplo)\nprint(t(x) %*% x)\n\n   x1 x2\nx1 14 32\nx2 32 77\n\n#\n## Clases en R\n#\n# Existen las llamadas clases S3, S4 y Reference en R, aunque su uso \n# depende de cada creador de paquetes. Para algunos tutoriales sobre\n# la creación de clases en R, ver  esta página &lt;http://adv-r.had.co.nz/OO-essentials.html&gt; .\n# Nos limitaremos a un ejemplo sencillo tanto para R como para Python:\n# Una clase tendrá 3 variables: x, y y z;\n# Otra clase tendrá una función para imprimir 'hola';\n# La siguiente clase tendrá una función para duplicar el valor(es) de y;\n# La última clase tendrá una función que incrementa el valor de la variable \n# pasada en 1.\n# En R, para definir una clase se usa setRefClass. El primer argumento es el \n# nombre de la clase, y por convención debe ser el mismo que la variable a la \n# que se asigna el resultado. \n# También se tienen que pasar listas a los argumentos \"fields\" y \"methods\".\nMyClass &lt;- setRefClass(\n  \"MyClass\",\n  fields = list(\n    x = \"ANY\", #any kind of variable type \n    y = \"numeric\", #integer variable type\n    z = \"character\"#char variable type\n  ),\n  methods = list(\n    initialize = function(x = NULL, y = 1:10, z = letters){\n      # Notar los valores por defecto para x, y, and z;\n      # Esta función se usa cuando se crea una instancia de la clase con `$new()`\n      x &lt;&lt;- x\n      y &lt;&lt;- y\n      z &lt;&lt;- z\n      print(\"You initialized MyClass!\")\n    },\n    hello = function(){\n      # Esta función devuelve la palabra 'hello'.\n      return(\"hello\")\n    },\n    doubleY = function(){\n      return(2 * y)\n    },\n    mySum = function(input){\n      return(input + 1)\n    }\n  )\n)\n# Crear una nueva instancia de la clase:\nmy_obj = MyClass$new(x = NULL, y = 1:10, z = c(\"a\", \"b\", \"cd\"))\n\n[1] \"You initialized MyClass!\"\n\nprint(my_obj)\n\nReference class object of class \"MyClass\"\nField \"x\":\nNULL\nField \"y\":\n [1]  1  2  3  4  5  6  7  8  9 10\nField \"z\":\n[1] \"a\"  \"b\"  \"cd\"\n\n# Para acceder a los valores y funciones de los objetos de clase inicializados:\nprint(my_obj$x) \n\nNULL\n\nprint(my_obj$y)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nprint(my_obj$z)\n\n[1] \"a\"  \"b\"  \"cd\"\n\nmy_obj$hello()\n\n[1] \"hello\"\n\nmy_obj$doubleY()\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\nmy_obj$mySum(5)\n\n[1] 6\n\n#\n## Gráficas de datos\n#\n# Figuras simples\nx &lt;- 1:20\ny &lt;- 0.5 * x^2 + 2 * x + 3\n#\nplot(x, y, \n     type = \"l\", lty = 2, col = \"blue\")\npoints(x, y, col = \"blue\", pch = 15)\ntitle(main = \"Ejempl de gráfico\")\nlegend(x = 1, y = 250, \n       legend = c(\"Muestra_de_datos_1\"),\n       lty = 2, pch = 15, col = \"blue\")\n\n\n\n#\nset.seed(123)\nnsample &lt;- 5000\nx_hist &lt;- rnorm(nsample)\nhist(x_hist, breaks = 40, col = \"lightblue\")\n\n\n\n# Múltiples figuras en una gráfica\n# Podemos especificar un diseño de 1 fila y 2 columnas utilizando \n# par(mfrow = c(1, 2))\npar(mfrow = c(1, 2))\nplot(x, y, type = \"l\", col = \"blue\")\nplot(x, rev(y), type = \"l\", col = \"red\")\n\n\n\n# También se pueden representar un número impar de figuras en una gráfica\n# Utilizando la función layout podemos especificar un diseño de matriz de \n# cómo queremos que se posicionen nuestras figuras, donde el número indica \n# el número de parcela  - cuanto más grande sea la matriz, más preciso puede \n# ser nuestro posicionamiento; un 0 indica que no hay que trazar en esa \n# posición.\nmy_matrix = matrix(c(1, 1,\n                     2, 3), nrow = 2, ncol = 2, byrow = TRUE)\nlayout(my_matrix)\nplot(x, y, type = \"l\", col = \"blue\", lwd = 2)\nhist(x_hist, breaks = 40, col = \"lightblue\")\nhist(x_hist, breaks = 40, col = \"lightgreen\")\n#\n# Librería gráfica moderna\n#\nlibrary(ggplot2)\n\n\n\n#\ndata &lt;- data.frame(x, y)\np &lt;- ggplot(data, aes(x = x, y = y))\np &lt;- p + geom_line(col = \"red\") + geom_point(col = \"darkgreen\")\np"
  },
  {
    "objectID": "p0c2-rpy-comp.html#código-python",
    "href": "p0c2-rpy-comp.html#código-python",
    "title": "R versus Python: Comparación de lenguajes",
    "section": "Código Python",
    "text": "Código Python\n\n# Ayuda\nhelp(print)\n\nHelp on built-in function print in module builtins:\n\nprint(...)\n    print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n    \n    Prints the values to a stream, or to sys.stdout by default.\n    Optional keyword arguments:\n    file:  a file-like object (stream); defaults to the current sys.stdout.\n    sep:   string inserted between values, default a space.\n    end:   string appended after the last value, default a newline.\n    flush: whether to forcibly flush the stream.\n\n#\n# Matrices de datos\n#\n# Crear una lista\nmy_vec = [1, 2, 3, 4, 5, 6, 7, 8]\nprint(type(my_vec))\n\n&lt;class 'list'&gt;\n\n# Seleccionar datos (en Python los valores comienzan en el índice 0)\nprint(my_vec[0])\n\n1\n\nprint(my_vec[0:3]) # En Python el rango 0:3 = {0, 1, 2} t, por tanto,\n\n[1, 2, 3]\n\n# no se incluye el último valor\nprint([my_vec[i] for i in [0, 1, 3, 7]])\n\n[1, 2, 4, 8]\n\nmy_range = list(range(1, 5))\nprint(my_range)\n\n[1, 2, 3, 4]\n\nprint(my_range[1:4])\n\n[2, 3, 4]\n\n# Longitud del vector\nprint(len(my_vec))\n\n8\n\n# Bucles\nfor i in range(0, len(my_vec)):\n  print(my_vec[i])\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n# Seleccionar cada tercer elemento, empezando desde el segundo\nprint(my_vec[1::3])\n\n[2, 5, 8]\n\n# o cada segundo elemento partiendo desde el primero\nprint(my_vec[0::2])\n\n[1, 3, 5, 7]\n\n# Suma de vectores\nmy_vec_1 = list(range(1, 6))\nmy_vec_2 = my_vec_1[::-1]\nprint(\"vec. 1: \", my_vec_1)\n\nvec. 1:  [1, 2, 3, 4, 5]\n\nprint(\"vec. 2: \", my_vec_2)\n\nvec. 2:  [5, 4, 3, 2, 1]\n\nvec_sum = [a + b for a, b in zip(my_vec_1, my_vec_2)]\nprint(\"vec. 1 + 2: \", vec_sum)\n\nvec. 1 + 2:  [6, 6, 6, 6, 6]\n\nprint(list(zip(my_vec_1, my_vec_2)))\n\n[(1, 5), (2, 4), (3, 3), (4, 2), (5, 1)]\n\nprint(\"vec. 1 & 2: \", my_vec_1 + my_vec_2)\n\nvec. 1 & 2:  [1, 2, 3, 4, 5, 5, 4, 3, 2, 1]\n\n# Si usamos numpy.array en lugar de una lista, entonces podemos sumar \n# los dos vectores en Python como lo hacemos en R\nimport numpy as np\nmy_vec_1_np = np.array(my_vec_1)\nnp_vec_2_np = np.array(my_vec_2)\nprint(\"vec. 1 + 2: \", my_vec_1_np + np_vec_2_np)\n\nvec. 1 + 2:  [6 6 6 6 6]\n\n# Multiplicar los elementos de un vector por una constante\nprint([x * 3 for x in my_vec_1])\n\n[3, 6, 9, 12, 15]\n\n# Para una lista en Python, el signo * tiene un significado diferente\nprint(my_vec_1 * 3)\n\n[1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n\n# Si utilizamos numpy.array, el funcionamiento es similar al de R\nimport numpy as np\nmy_vec_1_np = np.array(my_vec_1)\nprint(my_vec_1_np * 3)\n\n[ 3  6  9 12 15]\n\n#\n# Cadenas de caracteres\n#\n# Python tiene estos módulos implementados en la propia clase string, \n# por lo que siempre sabremos qué funciones están disponibles utilizando\n# el operador punto . y pulsando Tab en el editor para obtener la lista\n# completa de módulos de una clase concreta\nmy_animal = \"bear\"\nprint(my_animal)\n\nbear\n\nprint(my_animal.upper())\n\nBEAR\n\nmy_sentence = \"I \" + \"saw a \" + my_animal\nprint(my_sentence)\n\nI saw a bear\n\nprint(\"----\" + \"++++\")\n\n----++++\n\n#\n# Variables que contienen diferentes tipos de información \n# (valores enteros, de cadena, booleanos, etc.)\n#\nmy_data = {\"name\": \"Joe\",\n           \"grades\": [8, 7, 9],\n           \"has_attended\": True}\nprint(type(my_data))\n\n&lt;class 'dict'&gt;\n\nprint(my_data)\n\n{'name': 'Joe', 'grades': [8, 7, 9], 'has_attended': True}\n\nprint(type(my_data[\"name\"]))\n\n&lt;class 'str'&gt;\n\nprint(my_data[\"name\"])\n\nJoe\n\nprint(type(my_data[\"grades\"]))\n\n&lt;class 'list'&gt;\n\nprint(type(my_data[\"has_attended\"]))\n\n&lt;class 'bool'&gt;\n\nprint(my_data[\"grades\"])\n\n[8, 7, 9]\n\nprint(my_data[\"has_attended\"])\n\nTrue\n\n# A menudo tenemos más de una observación con diferentes propiedades \n# (por ejemplo,  una base de datos de personas con nombres, \n# identificaciones únicas, direcciones de correo electrónico, valor \n# del indicador si es un nuevo miembro, etc.) y queremos tener una \n# estructura tipo matriz (es decir, una tabla) para albergar esos valores.\nimport pandas as pd\n#\nmy_dataset = {\"name\": [\"John\", \"Sam\", \"Tim\"],\n              \"wage\": [800, 600, 700],\n              \"is_employed\": [True, True, False]}\n#\nmy_dataset = pd.DataFrame(my_dataset, columns = my_dataset.keys())\n# La opción columns = my_dataset.keys() es necesaria para preservar \n# el orden de las columnas\nprint(type(my_dataset))\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\n\nprint(my_dataset)\n\n   name  wage  is_employed\n0  John   800         True\n1   Sam   600         True\n2   Tim   700        False\n\nprint(my_dataset.keys()) \n\nIndex(['name', 'wage', 'is_employed'], dtype='object')\n\nprint(my_dataset[\"name\"])\n\n0    John\n1     Sam\n2     Tim\nName: name, dtype: object\n\nprint(my_dataset[\"is_employed\"])\n\n0     True\n1     True\n2    False\nName: is_employed, dtype: bool\n\n#\n# Definición de funciones\n#\n# Definir una función 1\ndef my_compare(x, y):\n  if x &lt; y:\n    print(\"1st value is smaller\")\n  elif x &gt; y:\n    print(\"1st value is greater\")\n  else:\n    print(\"Values are equal\")\n# Prueba de la función\nmy_compare(1, 1)\n\nValues are equal\n\nmy_compare(1, 2)\n\n1st value is smaller\n\nmy_compare(2, 1)\n\n1st value is greater\n\n# Definir una función 2\ndef my_sum(x, y):\n  x = x + 1\n  y = y + 1\n  return x + y\n# Prueba de la función\nprint(my_sum(1, 2))\n\n5\n\n# Definir una función 3\nimport numpy as np\ndef my_summary(x):\n  min_val = min(x)\n  max_val = max(x)\n  sum_val = sum(x)\n  avg_val = np.mean(x)\n  output = {\"min\": min_val,\n            \"max\": max_val,\n            \"average\": avg_val,\n            \"sum\": sum_val}\n  return output\n# Prueba de la función\nmy_results = my_summary([-2, 1, 5])\nprint(my_results[\"min\"])\n\n-2\n\nprint(my_results[\"average\"])\n\n1.3333333333333333\n\nprint(type(my_results))\n\n&lt;class 'dict'&gt;\n\nprint(my_results)\n\n{'min': -2, 'max': 5, 'average': 1.3333333333333333, 'sum': 4}\n\n#\n# Listas en Python (son mutables)\n#\ndef my_list(a_list):\n  a_list[0] = \"88\"\n  a_list.append(\"!!!\")\n  return a_list\n# Prueba de la función\nold_list = [\"a\", \"b\"]\nprint(\"Old: \" + str(old_list))\n\nOld: ['a', 'b']\n\nnew_list = my_list(old_list)\nprint(\"New: \" + str(new_list))\n\nNew: ['88', 'b', '!!!']\n\nprint(\"Old: \" + str(old_list)) \n\nOld: ['88', 'b', '!!!']\n\n# Los valores originales fueron cambiados en Python, ¡aunque asignamos \n# la salida de la función a una nueva variable!\n# Para no modificar el objeto que estamos pasando, podemos crear una \n# nueva referencia dentro de nuestra función\ndef my_list(a_list):\n  # Crear una nueva referencia\n  # Método 1\n  # b_list = a_list[:]\n  # Método 2\n  b_list = list(a_list)\n  # Modificar los valores\n  b_list[0] = \"88\"\n  b_list.append(\"!!!\")\n  return b_list\n# Prueba de la función\nold_list = [\"a\", \"b\"]\nprint(\"Old: \" + str(old_list))\n\nOld: ['a', 'b']\n\nnew_list = my_list(old_list)\nprint(\"Old: \" + str(old_list))\n\nOld: ['a', 'b']\n\nprint(\"New: \" + str(new_list))\n\nNew: ['88', 'b', '!!!']\n\n# Tener en cuenta que si escribimos b_list = a_list en lugar de \n# b_list = a_list[:] (o en lugar de b_list = list(a_list)), \n# ¡volveremos a modificar la variable original!\n#\n# Creación de matrices\n#\n# Crearemos una matriz 3X2 con elementos de 1 a 6 por columnas\nimport numpy as np\n#\nx1 = [1, 2, 3]\nx2 = [4, 5, 6]\nx_cs = np.column_stack((x1, x2))\nx_vs = np.vstack((x1, x2))\n# Una matriz bidimensional - cada elemento es un par de listas diferentes\nprint(x_cs)\n\n[[1 4]\n [2 5]\n [3 6]]\n\n# Una matriz bidimensional - cada elemento es una lista completa\nprint(x_vs)  \n\n[[1 2 3]\n [4 5 6]]\n\n# Podemos transponer una matriz usando np.transpose(...)\nprint(\"Column-stacked lists:\\n\", x_cs)\n\nColumn-stacked lists:\n [[1 4]\n [2 5]\n [3 6]]\n\nprint(\"Transposed row-stacked lists:\\n\", np.transpose(x_vs))\n\nTransposed row-stacked lists:\n [[1 4]\n [2 5]\n [3 6]]\n\nprint(\"Row-stacked lists:\\n\", x_vs)\n\nRow-stacked lists:\n [[1 2 3]\n [4 5 6]]\n\nprint(\"Transposed column-stacked lists:\\n\", np.transpose(x_cs))\n\nTransposed column-stacked lists:\n [[1 2 3]\n [4 5 6]]\n\n# Podemos acceder a diferentes elementos de la matriz X\nprint(\"Column-stacked lists:\")\n\nColumn-stacked lists:\n\nprint(x_cs[0])  # Primera fila\n\n[1 4]\n\nprint(np.transpose(x_cs)[0])  # Primera columna\n\n[1 2 3]\n\nprint(x_cs[0][0]) # Elemento X_{1,1}\n\n1\n\nprint(x_cs[2][1]) # Elmentos X_{3,2}\n\n6\n\nprint(\"Row-stacked lists:\")\n\nRow-stacked lists:\n\nprint(np.transpose(x_vs)[0])  # Primera fila\n\n[1 4]\n\nprint(x_vs[0])                # Primera columna\n\n[1 2 3]\n\nprint(x_vs[0][0]) # Elemento X_{1,1}\n\n1\n\nprint(x_vs[1][2]) # Elemento X_{3,2}\n\n6\n\n# Multiplicar matrices (X'X en este ejemplo)\nprint(np.dot(np.transpose(x_cs), x_cs))\n\n[[14 32]\n [32 77]]\n\nprint(np.dot(x_vs, np.transpose(x_vs)))\n\n[[14 32]\n [32 77]]\n\n#\n## Clases en Python\n#\n# El __init__ es un método que establece los valores para cualquier \n# parámetro que  necesite ser definido cuando un objeto de esta clase \n# es creado por primera vez.  La parte self.  es una sintaxis que \n# permite acceder a una variable desde cualquier otra parte de la clase.\nimport numpy as np\nimport string\nclass MyClass():\n  def __init__(self, x = None, y = None, z = None):\n    # Este método se usa cuando se crea una instancia de la clase\n    # Especifica los valores por defecto\n    if y is None:\n      y = list(range(1, 11))\n    if z is None:\n      z = string.ascii_lowercase #alphabet letters\n    self.y = y\n    self.x = x\n    self.z = z\n    print(\"You initialized MyClass!\")\n  # Como los métodos de clase no son funciones, necesitan un parámetro `self`\n  def hello(self):\n    return \"hello\"\n  def doubleY(self):\n    return 2 * np.array(self.y)\n  def mySum(self, my_input):\n    return np.array(my_input) + 1\n# Crear una nueva instancia de la clase:\nmy_obj = MyClass(x = None, y = list(range(1, 11)), z = [\"a\", \"b\", \"cd\"])\n\nYou initialized MyClass!\n\n# Para acceder a los valores y funciones de los objetos de clase inicializados\nprint(my_obj)\n\n&lt;__main__.MyClass object at 0x1260b37f0&gt;\n\nprint(my_obj.x)\n\nNone\n\nprint(my_obj.y)\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\nprint(my_obj.z)\n\n['a', 'b', 'cd']\n\nprint(my_obj.hello())\n\nhello\n\nprint(my_obj.doubleY())\n\n[ 2  4  6  8 10 12 14 16 18 20]\n\nprint(my_obj.mySum(5))\n\n6\n\n#\n# Gráficas de datos\n#\n# Gráficas simples\nimport matplotlib.pyplot as plt\nx = list(range(1, 21))\ny = [0.5 * a**2 + 2 * a + 3 for a in x]\nplt.figure(0)\nplt.plot(x, y, \n        linestyle = \"--\", color = \"blue\",\n        marker = \"s\", # squares (cuadrados)\n        label = \"Muestra_de_datos_1\")\nplt.title(\"Ejemplo de gráfica\")\nplt.legend(loc = \"upper left\")\nplt.show()\n\n\n\n#\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(123)\nnsample = 5000\nx_hist = np.random.normal(size = nsample)\nplt.figure(1)\ntmp_hist_ret = plt.hist(x_hist, bins = 40,\n                  color = \"limegreen\", edgecolor = \"black\")\nplt.show()\n\n\n\n# Múltiples figuras\n# Podemos especificar la disposición de 1 fila y 2 columnas utilizando \n# add_subplot(1, 2, c) o add_subplot(12c) donde c es la posición \n# (número entero)  del trazado (c = 1 - trazado en el primer espacio \n# de disposición, c = 2 - trazado en el segundo espacio de disposición).\ny2 = y[::-1]\n_ = plt.figure(2).add_subplot(121)\n_ = plt.plot(x, y, color = \"blue\")\n_ = plt.figure(2).add_subplot(122)\n_ = plt.plot(x, y2, color = \"red\")\nplt.show()\n\n\n\n# Para representar múltiples figuras\n# Utilizando add_subplot(abc) podemos especificar un número par o impar \n# de figuras especificando un diseño de subplot diferente (por ejemplo, \n# el mismo número de filas pero diferentes columnas) para algunas de las \n# parcelas, ¡pero sus posiciones no deben solaparse!\n_ = plt.figure(3).add_subplot(211)\n_ = plt.plot(x, y, color = \"blue\")\n_ = plt.figure(3).add_subplot(223)\ntmp_hist_ret = plt.hist(x_hist, color = \"darkcyan\", \n                  bins = 40, edgecolor = \"black\")\n_ = plt.figure(3).add_subplot(224)\ntmp_hist_ret = plt.hist(x_hist, color = \"limegreen\", \n                  bins = 40, edgecolor = \"black\")\nplt.show()\n\n\n\n#\n# Librerías gráficas avanzadas\n#\nfrom plotnine import *\ndata = pd.DataFrame(data = {\"x\": x, \"y\": y})\np = ggplot(data, aes(x = 'x', y = 'y')) \np = p + geom_line(color = \"red\") + geom_point(color = \"darkgreen\")\nprint(p)\n\n\n\ndel p # Eliminar la variable del entorno Python"
  },
  {
    "objectID": "p0c3-reticulate.html#justificación",
    "href": "p0c3-reticulate.html#justificación",
    "title": "Programación conjunta en R y Python con reticulate",
    "section": "Justificación",
    "text": "Justificación\nEn este apartado se demuestra cómo los ficheros Quarto (con extensión qmd) o R Markdown (con extensión Rmd) son un buen entorno para codificar un proyecto simultáneamente en los dos lenguajes de programación más usados en Data Science, R y Python, permitiendo programar algunos elementos del proyecto en cada lenguaje y manipular objetos creados en un lenguaje usando el otro, y viceversa.\nEsto puede ser útil por varias razones:\n\nPermite codificar en la lengua nativa de la estadística (R) pero añadiendo características que podrían existir sólo en la segunda lengua (Python); o al contrario. Obviamente, cuando se usa la palabra lengua se hace referencia al término lenguaje de programación.\nPermite colaborar directamente con otro colega que sea un experto programador en el otro lenguaje (equipos multi-lenguaje).\nDa la oportunidad de trabajar en ambos lenguajes de programación y de adquirir fluidez en ellos, intentando alcanzar a largo plazo el bilingüismo."
  },
  {
    "objectID": "p0c3-reticulate.html#qué-se-necesita",
    "href": "p0c3-reticulate.html#qué-se-necesita",
    "title": "Programación conjunta en R y Python con reticulate",
    "section": "¿Qué se necesita?",
    "text": "¿Qué se necesita?\nPara que la interacción R-Python funcione correctamente se necesita lo siguiente:\n\nR y Python instalados en el ordenador.\nEl entorno de ejecución (IDE) RStudio también instalado.\nLa librería reticulate instalada en R. Se pueden encontrar todos los detalles de la librería en la página web siguiente: https://rstudio.github.io/reticulate/\n\nTrabajaremos en el IDE de RStudio, escribiendo en un fichero tipo Quarto o R Markdown, moviéndonos entre trozos de código que están escritos en R o en Python.\nA continuación se hará una demostración con tres ejemplos sencillos."
  },
  {
    "objectID": "p0c3-reticulate.html#primer-ejemplo",
    "href": "p0c3-reticulate.html#primer-ejemplo",
    "title": "Programación conjunta en R y Python con reticulate",
    "section": "Primer ejemplo",
    "text": "Primer ejemplo\nA través de este caso se verá fácilmente cómo interactúan R y Python a través de la librería reticulate. Para configurar RStudio y permitir la interacción R-Python simplemente hay que leer la librería para activar ambos lenguajes:\n\nlibrary(reticulate)\n\nCuando se quiera escribir código en Python, se deben envolver las líneas con los habituales signos de puntuación (```), pero etiquetarlo como un trozo de código python usando {python}; y cuando se quiera escribir en R debe usarse {r}.\n\nDesde Python hacia R\n\nEn primer lugar se usa Python para leer y manipular los datos:\n\nimport pandas\nflights = pandas.read_csv(\"data/flights.csv\")\nflights = flights[flights['dest'] == \"ORD\"]\nflights = flights[['carrier', 'dep_delay', 'arr_delay']]\nflights = flights.dropna()\nflights\n\n       carrier  dep_delay  arr_delay\n5           UA       -4.0       12.0\n9           AA       -2.0        8.0\n25          MQ        8.0       32.0\n38          AA       -1.0       14.0\n57          AA       -4.0        4.0\n...        ...        ...        ...\n336645      AA      -12.0      -37.0\n336669      UA       -7.0      -13.0\n336675      MQ       -7.0      -11.0\n336696      B6       -5.0      -23.0\n336709      AA      -13.0      -38.0\n\n[16566 rows x 3 columns]\n\nflights.describe()\n\n          dep_delay     arr_delay\ncount  16566.000000  16566.000000\nmean      13.432814      5.876615\nstd       42.708837     48.008944\nmin      -20.000000    -62.000000\n25%       -5.000000    -20.000000\n50%       -2.000000     -8.000000\n75%       11.000000     13.000000\nmax     1126.000000   1109.000000\n\n\nAhora se usa R para visualizar los datos guardados en Python (en formato Pandas DataFrame):\n\nlibrary(ggplot2)\nggplot(py$flights, aes(carrier, arr_delay)) + geom_point() + geom_jitter()\n\n\n\n\n\nDesde R hacia Python\n\nPrimero se usa R para leer y manipular los datos:\n\nlibrary(tidyverse)\nflights &lt;- read_csv(\"data/flights.csv\") %&gt;%\n  filter(dest == \"ORD\") %&gt;%\n  select(carrier, dep_delay, arr_delay) %&gt;%\n  na.omit()\nhead(flights)\n\n# A tibble: 6 × 3\n  carrier dep_delay arr_delay\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 UA             -4        12\n2 AA             -2         8\n3 MQ              8        32\n4 AA             -1        14\n5 AA             -4         4\n6 UA              9        20\n\ntail(flights)\n\n# A tibble: 6 × 3\n  carrier dep_delay arr_delay\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n1 9E              4        -2\n2 AA            -12       -37\n3 UA             -7       -13\n4 MQ             -7       -11\n5 B6             -5       -23\n6 AA            -13       -38\n\nsummary(flights)\n\n   carrier            dep_delay         arr_delay       \n Length:16566       Min.   : -20.00   Min.   : -62.000  \n Class :character   1st Qu.:  -5.00   1st Qu.: -20.000  \n Mode  :character   Median :  -2.00   Median :  -8.000  \n                    Mean   :  13.43   Mean   :   5.877  \n                    3rd Qu.:  11.00   3rd Qu.:  13.000  \n                    Max.   :1126.00   Max.   :1109.000  \n\n\nY luego se usa Python para visualizar los datos guardados en R (en formato R DataFrame):\n\nfrom plotnine import *\n(ggplot(r.flights, aes(x=\"carrier\", y=\"arr_delay\")) + geom_point() + geom_jitter())\n\n&lt;ggplot: (303830728)&gt;"
  },
  {
    "objectID": "p0c3-reticulate.html#segundo-ejemplo",
    "href": "p0c3-reticulate.html#segundo-ejemplo",
    "title": "Programación conjunta en R y Python con reticulate",
    "section": "Segundo ejemplo",
    "text": "Segundo ejemplo\nEn este ejemplo se va a estimar en Python una regresión con un conjunto de datos sobre las calificaciones finales de Grado de los estudiantes en función de sus resultados en los diferentes años académicos.\n\nDebajo se ejecuta Python dentro de este código para estimar el modelo:\n\n\nimport pandas as pd\nimport statsmodels.formula.api as smf\n# Datos\nugtests = pd.read_csv(\"data/ugtests.csv\")\n# Modelo\nmodel = smf.ols(formula = \"Final ~ Yr3 + Yr2 + Yr1\", data = ugtests)\n# Estimación del modelo y resultados\nfitted_model = model.fit()\nmodel_summary = fitted_model.summary()\nprint(model_summary)\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  Final   R-squared:                       0.530\nModel:                            OLS   Adj. R-squared:                  0.529\nMethod:                 Least Squares   F-statistic:                     365.5\nDate:                Tue, 07 Nov 2023   Prob (F-statistic):          8.22e-159\nTime:                        06:55:28   Log-Likelihood:                -4711.6\nNo. Observations:                 975   AIC:                             9431.\nDf Residuals:                     971   BIC:                             9451.\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     14.1460      5.480      2.581      0.010       3.392      24.900\nYr3            0.8657      0.029     29.710      0.000       0.809       0.923\nYr2            0.4313      0.033     13.267      0.000       0.367       0.495\nYr1            0.0760      0.065      1.163      0.245      -0.052       0.204\n==============================================================================\nOmnibus:                        0.762   Durbin-Watson:                   2.006\nProb(Omnibus):                  0.683   Jarque-Bera (JB):                0.795\nSkew:                           0.067   Prob(JB):                        0.672\nKurtosis:                       2.961   Cond. No.                         858.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nEn este momento has tenido que dejar este trabajo debido a algo más urgente y se lo has pasado a otro colega que sólo programa en R para que él haga algunos diagnósticos del modelo estimado. Pues bien, el nuevo programador puede acceder a todos los objetos Python que se han creado anteriormente dentro de una lista general llamada py en el entorno R.\n\nAsí, si escribe un cógigo R como el que sigue puede acceder a los parámetros del modelo estimado:\n\npy$fitted_model$params\n\n  Intercept         Yr3         Yr2         Yr1 \n14.14598945  0.86568123  0.43128539  0.07602621 \n\n\no ralizar unas estadísticas básicas y un histograma de los residuos (errores estimados del modelo):\n\nsummary(py$fitted_model$resid)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-92.63812 -20.34864   0.00081   0.00000  18.95411  98.48933 \n\nhist(py$fitted_model$resid)\n\n\n\n\nAdemás, puede hacer fácilmente algunos diagnósticos más sofisticados usando la librería car:\n\nlibrary(car)\ndensityPlot(py$fitted_model$resid)\n\n\n\nqqnorm(py$fitted_model$resid)\n\n\n\nqqPlot(py$fitted_model$resid)\n\n\n\n\n280 265 \n281 266 \n\n\n\nTercer ejemplo\nSupongamos ahora que se han estado analizando algunos datos en Python y se ha creado un dataframe de la librería pandas con todos ellos. Vamos a cargar los datos y echarles un vistazo:\n\nimport pandas as pd\nspeed_dating = pd.read_csv(\"data/speed_dating.csv\")\nprint(speed_dating.head())\n\n   iid  gender  match  samerace  race  goal  dec  attr  intel  prob  agediff\n0    1       0      0         0   4.0   2.0    1   6.0    7.0   6.0      6.0\n1    1       0      0         0   4.0   2.0    1   7.0    7.0   5.0      1.0\n2    1       0      1         1   4.0   2.0    1   5.0    9.0   NaN      1.0\n3    1       0      1         0   4.0   2.0    1   7.0    8.0   6.0      2.0\n4    1       0      1         0   4.0   2.0    1   5.0    7.0   6.0      3.0\n\n\nSupongamos que se estima una regresión logística simple en Python para intentar relacionar la variable decisión dec en función de algunas de las otras variables de la base de datos:\n\nimport pandas as pd\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n# Datos\nspeed_dating = pd.read_csv(\"data/speed_dating.csv\")\n# Modelo\nmodel = smf.glm(formula = \"dec ~ agediff + samerace + attr + intel + prob\", \n                data = speed_dating, \n                family = sm.families.Binomial())\n# Estimación del modelo\npromotion_model = model.fit()\n# Resultados\nprint(promotion_model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                    dec   No. Observations:                 7789\nModel:                            GLM   Df Residuals:                     7783\nModel Family:                Binomial   Df Model:                            5\nLink Function:                  Logit   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -4041.5\nDate:                Tue, 07 Nov 2023   Deviance:                       8082.9\nTime:                        06:55:30   Pearson chi2:                 8.04e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.2805\nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -5.8129      0.184    -31.534      0.000      -6.174      -5.452\nagediff       -0.0105      0.009     -1.165      0.244      -0.028       0.007\nsamerace      -0.0934      0.056     -1.677      0.094      -0.203       0.016\nattr           0.6611      0.019     34.111      0.000       0.623       0.699\nintel         -0.0045      0.021     -0.216      0.829      -0.045       0.036\nprob           0.2706      0.015     18.575      0.000       0.242       0.299\n==============================================================================\n\n\nSin embargo, alguien se da cuenta de que estos datos son en realidad jerárquicos ya que el mismo iid individual puede tener múltiples fechas, así que es necesario estimar un modelo de regresión logística de efectos mixtos, ¡pero nadie es capaz de encontrar una librería en Python que lo haga! Sin embargo, para un colega especializado en R es fácil estimar ese tipo de modelos con la librería lme4:\n\nlibrary(lme4)\nspeed_dating &lt;- py$speed_dating\niid_intercept_model &lt;- lme4:::glmer(dec ~ agediff + samerace + attr + intel + prob + (1 | iid), data = speed_dating, family = \"binomial\")\nsummary(iid_intercept_model)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: dec ~ agediff + samerace + attr + intel + prob + (1 | iid)\n   Data: speed_dating\n\n     AIC      BIC   logLik deviance df.resid \n  6420.3   6469.0  -3203.1   6406.3     7782 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-25.6968  -0.3644  -0.0606   0.3608  25.0370 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n iid    (Intercept) 5.18     2.276   \nNumber of obs: 7789, groups:  iid, 541\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -12.88885    0.42149 -30.579  &lt; 2e-16 ***\nagediff      -0.03671    0.01401  -2.621  0.00877 ** \nsamerace      0.20186    0.08140   2.480  0.01314 *  \nattr          1.07895    0.03334  32.361  &lt; 2e-16 ***\nintel         0.31592    0.03473   9.097  &lt; 2e-16 ***\nprob          0.61998    0.02873  21.580  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n         (Intr) agedff samerc attr   intel \nagediff  -0.098                            \nsamerace -0.103 -0.048                     \nattr     -0.646  0.003  0.008              \nintel    -0.641 -0.030  0.055  0.049       \nprob     -0.502 -0.003 -0.025  0.266 -0.008\n\ncoefficients &lt;- coef(iid_intercept_model)$iid\n\nAhora se pueden recuperar los resultados en Python y echar un vistazo a las estimaciones de los coeficientes, por ejemplo. Para acceder a los objetos de R en Python se utiliza el objeto de lista general r.\n\ncoefs = r.coefficients\nprint(coefs.head())\n\n   (Intercept)  agediff  samerace      attr    intel      prob\n1   -10.573307 -0.03671  0.201863  1.078946  0.31592  0.619976\n2   -13.612416 -0.03671  0.201863  1.078946  0.31592  0.619976\n3   -18.188261 -0.03671  0.201863  1.078946  0.31592  0.619976\n4   -14.473331 -0.03671  0.201863  1.078946  0.31592  0.619976\n5   -10.893444 -0.03671  0.201863  1.078946  0.31592  0.619976"
  },
  {
    "objectID": "p1-introduccion.html",
    "href": "p1-introduccion.html",
    "title": "CAPÍTULO 1: CONCEPTOS BÁSICOS",
    "section": "",
    "text": "En este capítulo se hace una presentación de la econometría, exponiéndose sus conceptos básicos, así como sus elementos, principios básicos y usos fundamentales."
  },
  {
    "objectID": "p1c1-teoria.html#definición-de-econometría",
    "href": "p1c1-teoria.html#definición-de-econometría",
    "title": "1  Conceptos básicos de la econometría",
    "section": "1.1 Definición de Econometría",
    "text": "1.1 Definición de Econometría\nDe entre las distintas definiciones que se han hecho de la econometría a lo largo de su historia, a continuación se recogen algunas de ellas, que abarcan todo el período transcurrido desde el nacimiento de la disciplina hasta la actualidad:\n\n“La cuantificación de los modelos teóricos para intentar contrastar la validez empírica de las teorías y un medio para el análisis de políticas” (Frisch, 1933).\n“El análisis cuantitativo de fenómenos económicos reales, basado en el desarrollo simultáneo de la teoría y la observación, relacionados mediante los métodos apropiados de inferencia” (Samuelson, Koopmans y Stone, 1954).\n“La econometría se ocupa de la aplicación de la estadística matemática y de los instrumentos de la estadística inferencial a la medición empírica de las relaciones postuladas por la teoría económica” (Greene, 2012).\n\nDe los enunciados anteriores pueden extraerse varias conclusiones generales, entre las que se pueden destacar:\n\nLa econometría es una rama de la ciencia económica interesada en el análisis cuantitativo de los fenómenos económicos introduciendo, por tanto, contenido empírico en el razonamiento teórico puro.\nSe caracteriza por su interrelación con otras disciplinas. Así, la teoría económica, la estadística y las matemáticas son necesarias, pero no suficientes, para la comprensión de las relaciones cuantitativas que se dan en la vida económica. La consideración de estas tres disciplinas en la econometría es la que da potencia a ésta.\nEstá basada en un enfoque probabilístico y no determinístico.\nLos cuatro componentes básicos del enfoque econométrico son: teoría, datos, técnicas y aplicaciones.\n\nSi, a grandes rasgos, puede señalarse que la ciencia económica se ocupa de estudiar y analizar la realidad económica y que su fin es inferir leyes que expliquen el comportamiento de los fenómenos económicos en lo referente a la satisfacción de las necesidades humanas, el papel de la econometría (su objeto) consiste en contribuir a mejorar el conocimiento de los fenómenos económicos, aprovechando para ello las potencialidades que representan los métodos econométricos en la investigación económica (medios). A través de su uso se podrá tener un conocimiento más profundo y eficaz de la actividad económica, lo que permitirá la realización de análisis estructural, el contraste de determinadas propiedades teóricas, la predicción o la evaluación de políticas (fines)."
  },
  {
    "objectID": "p1c1-teoria.html#los-modelos-económicos",
    "href": "p1c1-teoria.html#los-modelos-económicos",
    "title": "1  Conceptos básicos de la econometría",
    "section": "1.2 Los modelos económicos",
    "text": "1.2 Los modelos económicos\nCualquiera que se inicie en el estudio de la economía encuentra, desde el primer momento, la existencia de relaciones entre las variables económicas. A partir de aquí, el desarrollo de la ciencia económica llevará a la agrupación de tales relaciones para llegar a la formulación de los modelos económicos.\nTodos los modelos económicos, sean macro o microeconómicos, pertenezcan a una empresa, una industria, a la economía nacional o a un mercado, tienen unas características o supuestos básicos comunes:\n\nEl primer supuesto que se realiza sobre el comportamiento de las variables económicas es el de la acción conjunta y simultánea de varias relaciones económicas.\nEn segundo lugar, el modelo, aún reconocido como una simplificación de una realidad más compleja y excesivamente general como para abarcar todos los aspectos de los sistemas reales, recogerá las características más importantes del sector o sistema económico que estudia.\nPor último, debe tenerse en cuenta que el objetivo último del modelo es que mediante el mismo se pueda explicar el sistema económico y predecir sus movimientos futuros e incluso de poder controlarlos.\n\nEn esta primera etapa del trabajo econométrico formularemos la teoría o las hipótesis y especificaremos el modelo matemático de la teoría. Así, por ejemplo, podemos plantear un modelo Keynesiano de consumo como \\(C = f(Y)\\), donde C es el consumo agregado de bienes y servicios e Y la renta disponible, debiéndose cumplir, de acuerdo con la teoría económica, que \\(f’ &gt; 0\\)."
  },
  {
    "objectID": "p1c1-teoria.html#los-modelos-econométricos",
    "href": "p1c1-teoria.html#los-modelos-econométricos",
    "title": "1  Conceptos básicos de la econometría",
    "section": "1.3 Los modelos econométricos",
    "text": "1.3 Los modelos econométricos\nEs habitual que en la formulación de teorías económicas se fijen hipótesis sobre el comportamiento de las variables económicas y sus relaciones deterministas de causalidad. Sin embargo, los modelos económicos ni determinan la forma exacta de la relación funcional entre las variables que intervienen, ni recogen componentes estocásticas propias del comportamiento de los agentes económicos. Así, se dirá que la variable x afecta a la variable y, de modo que y crece al aumentar x, pero sin que se dé la forma funcional o la magnitud de tal relación. Además, se establece que dos unidades económicas con el mismo valor de la variable x darán lugar a la misma observación de la variable y.\nPara resolver tal limitación se han desarrollado los llamados modelos econométricos, basados en los modelos económicos, en los que aparecen de forma explícita la forma funcional entre las las variables del modelo y el componente aleatorio que forma parte del comportamiento heterogéneo de los agentes económicos.\nPor ejemplo, un modelo econométrico para analizar el consumo (C) de un conjunto de personas de un país o región, o de una economía agregada durante cierto período de tiempo, podría venir dado por la forma lineal siguiente:\n\\[C = \\beta_{1} + \\beta_{2}Y + e\\  \\ \\ \\ \\  0 &lt; \\beta_{2} &lt; 1\\]\ndonde Y es la renta agregada total o la renta disponible (libre de impuestos), β1 y β2 son, respectivamente, el consumo autónomo y la propensión marginal a consumir (la ordenada en el origen y la pendiente de la recta de regresión), y e es una variable aleatoria no observable que representa el comportamiento heterogéneo de los consumidores, es decir, la desviación entre el consumo observado y del consumo teórico predicho por el modelo económico.\nPor otra parte, los modelos econométricos son aplicables a sistemas reales concretos, debiendo restringirse la validez de las conclusiones al sistema de referencia espacial y temporal para el que se construye. Así, siguiendo con el ejemplo de la función Keynesiana de consumo, si se estima la regresión propuesta con datos de Estados Unidos entre 1959 y 2015 (ver Aplicación 1.2), las conclusiones a las que se llegue con el modelo empírico resultante sólo serán aplicables a ese país y durante ese período, y no extrapolables a otros países o tramos temporales diferentes.\nPor último, en cuanto al uso final de un modelo econométrico tras la estimación correspondiente, es decir, una vez confrontado el modelo teórico propuesto con un conjunto de datos económicos reales, se puede utilizar el mismo para varios objetivos, que pueden ser los siguientes:\n\nEl análisis estructural: su finalidad es encontrar respuestas a preguntas tales como ¿cuál es el efecto de la reducción del gasto público sobre la demanda privada?, ¿cuánto debería incrementarse la renta disponible para reactivar el consumo en una cierta cantidad?\nLa predicción: por ejemplo, una estimación cuantitativa de la propensión marginal a consumir nos llevará a poder predecir, con niveles adecuados de error, el comportamiento futuro del consumo según los cambios en la política fiscal del gobierno.\nAnálisis de control o evaluación y simulación de políticas. En este caso, las variables explicativas actuarán como variables de control; así, el gobierno puede utilizar un modelo estimado con esta finalidad para saber cómo controlar la variable x para obtener el nivel deseado en la variable y: ¿cuál debe ser el incremento de la renta de las familias, vía reducción de impuestos, para que se incremente el consumo un determinado tanto por ciento?"
  },
  {
    "objectID": "p1c1-teoria.html#elementos-de-un-modelo-econométrico",
    "href": "p1c1-teoria.html#elementos-de-un-modelo-econométrico",
    "title": "1  Conceptos básicos de la econometría",
    "section": "1.4 Elementos de un modelo econométrico",
    "text": "1.4 Elementos de un modelo econométrico\n\n1.4.1 Variables\nEn el sistema económico representado por un modelo existirán un elevado número de variables económicas cuyas relaciones reflejarán su comportamiento. Las variables pueden clasificarse en:\n\nDependientes (explicadas, objetivo, endógenas), que son las determinadas dentro del sistema económico.\nIndependientes (explicativas, control, regresores, predeterminadas o exógenas), que vienen dadas desde fuera del sistema y que, por tanto, son susceptibles de ser controladas (al menos teóricamente).\n\nAunque en un sentido amplio casi todas las variables económicas son endógenas, sin embargo, la finalidad del estudio y la modelización llevada a cabo en el sistema determinarán la clasificación de las variables presentes. Por ejemplo, si estamos haciendo un estudio de la demanda de automóviles la renta de las familias será una variable exógena o predeterminada, mientras que la cantidad de automóviles vendidos cada mes será la variable endógena.\n\n\n1.4.2 Relaciones\nPartimos de un modelo económico que describe un sistema. Las relaciones económicas que interesa investigar darán lugar a los diferentes modelos econométricos que pueden ser uniecuacionales o multiecuacionales.\n\nEn las relaciones uniecuacionales, en cuyo estudio se centrará básicamente este libro, una única variable dependiente queda determinada por el comportamiento de una o más variables explicativas. Por ejemplo, la demanda de un bien depende de su precio y de la renta disponible, es decir, \\(Q = f(P,Y)\\), donde Q es la demanda, P el precio e Y la renta disponible o el gasto total realizado.\nEn las relaciones multiecuacionales un grupo de variables dependientes vendrá explicada, de modo separado, por una serie de variables exógenas. Por ejemplo, podemos considerar como variables dependientes el gasto de las familias en alimentación, y1, y servicios, y2, como función de la renta, x, y la riqueza, z, de las familias, es decir, \\(y_{1} = f(x,z)\\) e \\(y_{2} = g(x,z)\\).\n\nUn caso particular de modelos multiecuacionales son los modelos de ecuaciones simultáneas, en los que dos o más variables endógenas son explicadas simultáneamente por un grupo de variables exógenas o predeterminadas.\nPor ejemplo, consideremos en un mercado las ecuaciones siguientes:\n\n\\(Q = f(P,Y)\\) [ecuación de demanda]\n\\(Q = g(P,Z)\\) [ecuación de oferta]\n\ndonde P y Q son las variables endógenas (precio y cantidad) e Y y Z son variables predeterminadas (renta y precios del año anterior, por ejemplo). En este caso, los valores de equilibrio observados en el mercado (\\(P^{*}\\), \\(Q^{*}\\)) serán el resultado de la interacción simultánea entre las funciones de oferta y demanda, las cuales dependen también de otros factores externos determinados por la teoría económica (\\(Y^{*}\\) y \\(Z^{*}\\)) que afectan a los valores de equilibrio de mercado observados.\nOtro ejemplo de sistema de ecuaciones simultáneas viene dado por el modelo macroeconómico IS, en el cual se especifica no sólo la ecuación de consumo (C), sino también las ecuaciones de inversión (I), importaciones (M), exportaciones (X) y renta agregada (Y) del país:\n\n\\(C = \\alpha_{1} + \\alpha_{2}(Y - T) + e_{1}\\) [ecuación de consumo privado]\n\\(I = \\beta_{1} + \\beta_{2}Y + \\beta_{3}R + e_{2}\\) [ecuación de inversión privada]\n\\(M = \\gamma_{1} + \\gamma_{2}Y + \\gamma_{3}REER + e_{3}\\) [ecuación de importaciones]\n\\(X = \\delta_{1} + \\delta_{2}Y^{*} + \\delta_{3}REER + e_{4}\\) [ecuación de exportaciones]\n\\(Y = C + I + G + (X - M)\\) [ecuación de demanda agregada]\n\ndonde T son los impuestos pagados menos las transferencias recibidas del estado R es el tipo de interés real, REER es el tipo de cambio efectivo real, G es el gasto público y, finalmente, Y* es la renta agregada extranjera (o un indicador del volumen de comercio exterior).\nPor otra parte, si se considera la evolución temporal de las variables en el modelo podemos distinguir los modelos dinámicos frente a los estáticos. Así, por ejemplo, para la función de demanda de uno de los ejemplos anteriores, puede proponerse una especificación estática del tipo, \\(Q_{t}^{d} = \\beta_{1} + \\beta_{2}P_{t} + \\beta_{3}Y_{t} + e_{t}\\), donde todas las variables son contemporáneas, mientras que para la función de oferta podría utilizarse una regresión dinámica, \\(Q_{t}^{s} = \\gamma_{1} + \\gamma_{2}P_{t} + \\gamma_{3}P_{t - 1} + e_{t}\\), en la que aparece la variable precio fechada en distintos momentos del tiempo.\n\n\n1.4.3 Especificación funcional\nEl modelo económico nos dirá que una variable endógena es función de un grupo de variables explicativas, pero no nos indicará cuál es la forma funcional concreta de la relación; además, un modelo económico es determinista en el sentido que las variables explicativas determinan la endógena de forma unívoca. Por ejemplo, según la teoría de la demanda, la cantidad demandada de un producto es función del precio y de la renta disponible: \\(Q = f(P,Y)\\). Esta relación, tal y como está escrita, establece una estructura determinista de la demanda que se observa en el mercado: los consumidores que se enfrenten al mismo precio P, y tengan la misma renta Y, consumirán todos ellos la misma cantidad Q del producto.\nSi se quiere introducir un mayor grado de realidad en el modelo, debe establecerse una relación estocástica del tipo \\(Q = f(P,Y,e)\\), donde e es una variable aleatoria no observable. Más aún, si se supone que la aleatoriedad es aditiva, el modelo se convierte en \\(Q = f(P,Y) + e\\). Aún así, la función \\(f\\) no queda especificada.\nUn modelo econométrico estándar introduce una forma funcional lineal para la función \\(f\\) teórica:\n\\[Q = \\beta_{1} + \\beta_{2}P + \\beta_{3}Y + e\\ \\ \\ \\ \\\\ \\ \\beta_{2} \\leq 0\\ ,\\ \\beta_{3} \\geq 0\\]\nes decir, se considera una relación lineal entre la variable de interés Q y las variables observables P e Y, y se añade una variable aleatoria no observable e.\nLa especificación anterior es lineal en los parámetros \\(\\beta_{1}\\), \\(\\beta_{2}\\) y \\(\\beta_{3}\\), pero también podrían proponerse modelos no lineales, como una función potencial del tipo\n\\[Q = \\alpha P^{\\beta_{2}}Y^{\\beta_{3}}e^{e}\\]\nque, aunque es inicialmente no líneal puede linealizarse tomando logaritmos, para convertirse en el modelo log-lineal\n\\[\\log Q = \\beta_{1} + \\beta_{2}\\log P + \\beta_{3}\\log Y + e\\]\nsiendo \\(\\beta_{1} = \\log\\alpha\\), o también podría plantearse una función intrínsecamente no lineal como la siguiente\n\\[Q = \\beta_{1} + \\beta_{2}P + \\beta_{3}Y^{\\beta_{4}} + e\\]\ndonde, en este caso, los parámetros aparecen en forma no lineal en la relación funcional entre Q e Y.\n\n\n1.4.4 Datos\nLos datos utilizados para la estimación de los modelos econométricos pueden ser de varios tipos:\n\nDatos de series temporales: se corresponden con el valor de un único agente económico (por regla general, una entidad agregada, como una familia, una industria, una región, un país, etc.) en sucesivos momentos de tiempo (años, trimestres, meses, etc.), por ejemplo, el índice de precios de consumo armonizado de la Unión Europea durante un periodo concreto de varios meses. Los valores que toma una variable \\(z\\) en los momentos de tiempo \\(1,2,\\ldots,T\\) se representarán por \\(z_{t}\\), \\(t = 1,2,\\ldots,T\\).\nDatos de sección cruzada (corte transversal): se corresponden con diferentes unidades individuales en un momento dado del tiempo, por ejemplo, el número de parados en un mes determinado en cada una de las 17 comunidades autónomas. Los valores que toma la variable \\(z\\) para las unidades económicas \\(1,2,\\ldots,n\\) se representarán por \\(z_{i}\\), \\(i = 1,2,\\ldots,n\\).\nDatos fusionados de sección cruzada (pool de cortes transversales): se dispone de secciones cruzadas (encuestas, por ejemplo) en dos o varios momentos del tiempo.\nDatos de panel (longitudinales): son una combinación de datos de sección cruzada y de series temporales, y se corresponden con una serie de datos en el tiempo de un grupo de unidades individuales. Los valores de la variable \\(z\\) para las unidades económicas \\(1,2,\\ldots,n\\) en los momentos de tiempo \\(1,2,\\ldots,T\\) se representarán por \\(z_{it}\\), \\(i = 1,2,\\ldots,n\\), \\(t = 1,2,\\ldots,T\\)."
  },
  {
    "objectID": "p1c2-app1a.html#código-r",
    "href": "p1c2-app1a.html#código-r",
    "title": "Aplicación 1.1.a (Gestión y representación gráfica de datos): Gramática básica del tidyverse",
    "section": "Código R",
    "text": "Código R\n\nEn las siguientes páginas web se pueden encontrar los detalles sobre cada cuestión analizada en la aplicación:\n\nDatos ordenados: Tidy Data (https://www.jstatsoft.org/article/view/v059i10)\nGestión de datos y gráficas en R: macro-librería tidyverse (https://www.tidyverse.org/)\n\n\nhttps://tidyr.tidyverse.org/articles/tidy-data.html (datos ordenados)\nhttps://tidyverse.tidyverse.org/articles/paper.html\nhttps://es.r4ds.hadley.nz/12-tidy.html (tidy data)\nhttps://es.r4ds.hadley.nz/09-wrangle.html (data wrangling)\nhttps://education.rstudio.com/blog/2020/07/teaching-the-tidyverse-in-2020-part-1-getting-started/\nhttps://education.rstudio.com/blog/2020/07/teaching-the-tidyverse-in-2020-part-2-data-visualisation/\nhttps://education.rstudio.com/blog/2020/07/teaching-the-tidyverse-in-2020-part-3-data-wrangling-and-tidying/\nhttps://education.rstudio.com/blog/2020/07/teaching-the-tidyverse-in-2020-part-4-when-to-purrr/\n\nSobre los datos utilizados en la aplicación R:\n\nGapminder (https://www.gapminder.org/fw/world-health-chart/): los datos por países se han extraído de la base de datos del Banco Mundial (https://data.worldbank.org/), usando la librería WDI (https://vincentarelbundock.github.io/WDI/index.html).\nNYC_Flights_2013 (https://github.com/tidyverse/nycflights13)\n\n\n\n# Lectura de librerías\nlibrary(tidyverse)\ntidyverse_packages()\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n# Estructura de la macro-librería tidyverse\nlibrary(deepdep)\ndep_tidyverse &lt;- deepdep(\"tidyverse\", depth = 1)\nplot_dependencies(dep_tidyverse, \"circular\")\n\n\n\n# Lectura de datos\n# https://es.r4ds.hadley.nz/11-import.html\ngapminder &lt;- read_csv(\"data/GAPMINDER.csv\")\n# https://es.r4ds.hadley.nz/10-tibble.html\nclass(gapminder)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n# Cambio de nombres de variables\ngapminder &lt;- gapminder %&gt;% \n  rename(year = date, \n         gdpPercap = NY.GDP.PCAP.CD, \n         lifeExp = SP.DYN.LE00.IN, \n         pop = SP.POP.TOTL)\n# Datos iniciales y finales\nhead(gapminder)\n\n# A tibble: 6 × 8\n  iso2c iso3c country  year gdpPercap lifeExp   pop region                   \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                    \n1 AW    ABW   Aruba    1960        NA    64.2 54608 Latin America & Caribbean\n2 AW    ABW   Aruba    1961        NA    64.5 55811 Latin America & Caribbean\n3 AW    ABW   Aruba    1962        NA    64.8 56682 Latin America & Caribbean\n4 AW    ABW   Aruba    1963        NA    65.1 57475 Latin America & Caribbean\n5 AW    ABW   Aruba    1964        NA    65.3 58178 Latin America & Caribbean\n6 AW    ABW   Aruba    1965        NA    65.5 58782 Latin America & Caribbean\n\ntail(gapminder)\n\n# A tibble: 6 × 8\n  iso2c iso3c country   year gdpPercap lifeExp      pop region            \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;             \n1 ZW    ZWE   Zimbabwe  2016     1422.    60.3 14452704 Sub-Saharan Africa\n2 ZW    ZWE   Zimbabwe  2017     1192.    60.7 14751101 Sub-Saharan Africa\n3 ZW    ZWE   Zimbabwe  2018     2269.    61.4 15052184 Sub-Saharan Africa\n4 ZW    ZWE   Zimbabwe  2019     1422.    61.3 15354608 Sub-Saharan Africa\n5 ZW    ZWE   Zimbabwe  2020     1373.    61.1 15669666 Sub-Saharan Africa\n6 ZW    ZWE   Zimbabwe  2021     1774.    59.3 15993524 Sub-Saharan Africa\n\n# Manejo y transformación de datos\n# (https://es.r4ds.hadley.nz/05-transform.html)\n#\n# Librería dplyr (https://dplyr.tidyverse.org/) \n# y 'tuberías' (https://es.r4ds.hadley.nz/18-pipes.html)\n#\n# \"Verbos\" de dplyr \n# select\ngapminder_selected &lt;- select(gapminder, year, country, pop, gdpPercap)\n# filter\ngapminder_filtered &lt;- filter(gapminder_selected, year &gt;= 1980)\n# mutate\ngapminder_mutated &lt;- mutate(gapminder_filtered, GDP = gdpPercap*pop)\n# group_by\ngapminder_grouped &lt;- group_by(gapminder_mutated, country)\n# summarise\ngapminder_summarised &lt;- summarise(gapminder_grouped, AVG_GDP = mean(GDP))\n# arrange\ngapminder_arranged_ascending &lt;- arrange(gapminder_summarised, AVG_GDP)\ngapminder_arranged_ascending\n\n# A tibble: 217 × 2\n   country                           AVG_GDP\n   &lt;chr&gt;                               &lt;dbl&gt;\n 1 Kiribati                        99642313.\n 2 Tonga                          247764480.\n 3 Dominica                       335912659.\n 4 Vanuatu                        416627524.\n 5 St. Vincent and the Grenadines 477704237.\n 6 St. Kitts and Nevis            505233445.\n 7 Grenada                        562186456.\n 8 Guinea-Bissau                  580471717.\n 9 Comoros                        617956234.\n10 Solomon Islands                652451970.\n# ℹ 207 more rows\n\ngapminder_arranged_descending &lt;- arrange(gapminder_summarised, -AVG_GDP)\ngapminder_arranged_descending\n\n# A tibble: 217 × 2\n   country        AVG_GDP\n   &lt;chr&gt;            &lt;dbl&gt;\n 1 United States  1.11e13\n 2 China          4.12e12\n 3 Japan          4.10e12\n 4 Germany        2.48e12\n 5 United Kingdom 1.82e12\n 6 France         1.79e12\n 7 Italy          1.44e12\n 8 Brazil         1.03e12\n 9 India          9.96e11\n10 Canada         9.96e11\n# ℹ 207 more rows\n\n# Operador tubería (pipe) del tidyverse: %&gt;%\nAVG_GDP &lt;- \n  gapminder %&gt;% \n  select(year, country, pop, gdpPercap) %&gt;% \n  filter(year&gt;=1980) %&gt;% \n  mutate(GDP=gdpPercap*pop) %&gt;% \n  group_by(country) %&gt;% \n  summarise(AVG_GDP=mean(GDP)) %&gt;% \n  arrange(-AVG_GDP)\nAVG_GDP\n\n# A tibble: 217 × 2\n   country        AVG_GDP\n   &lt;chr&gt;            &lt;dbl&gt;\n 1 United States  1.11e13\n 2 China          4.12e12\n 3 Japan          4.10e12\n 4 Germany        2.48e12\n 5 United Kingdom 1.82e12\n 6 France         1.79e12\n 7 Italy          1.44e12\n 8 Brazil         1.03e12\n 9 India          9.96e11\n10 Canada         9.96e11\n# ℹ 207 more rows\n\n# Tubería nativa de R: |&gt;\ngapminder |&gt; subset(year==2021) |&gt; head()\n\n# A tibble: 6 × 8\n  iso2c iso3c country               year gdpPercap lifeExp      pop region      \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 AW    ABW   Aruba                 2021    29342.    74.6   106537 Latin Ameri…\n2 AF    AFG   Afghanistan           2021      364.    62.0 40099462 South Asia  \n3 AO    AGO   Angola                2021     1904.    61.6 34503774 Sub-Saharan…\n4 AL    ALB   Albania               2021     6377.    76.5  2811666 Europe & Ce…\n5 AD    AND   Andorra               2021    42072.    NA      79034 Europe & Ce…\n6 AE    ARE   United Arab Emirates  2021    44316.    78.7  9365145 Middle East…\n\n# Familia de operaciones join \n# (https://es.r4ds.hadley.nz/13-relational-data.html)\n#\n# `inner_join(df1, df2)`\n# `left_join(df1, df2)`\n# `right_join(df1, df2)`\n# `full_join(df1, df2)`\n# `semi_join(df1, df2)`\n# `anti_join(df1, df2)`\n#\n# Lectura de datos\nlibrary(nycflights13)\nflights \n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 336,766 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\nplanes\n\n# A tibble: 3,322 × 9\n   tailnum  year type              manufacturer model engines seats speed engine\n   &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;             &lt;chr&gt;        &lt;chr&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; \n 1 N10156   2004 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 2 N102UW   1998 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 3 N103US   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 4 N104UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 5 N10575   2002 Fixed wing multi… EMBRAER      EMB-…       2    55    NA Turbo…\n 6 N105UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 7 N107US   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 8 N108UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n 9 N109UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n10 N110UW   1999 Fixed wing multi… AIRBUS INDU… A320…       2   182    NA Turbo…\n# ℹ 3,312 more rows\n\n# Ejemplo de left_join\nleft_join(flights, planes) %&gt;%\n  select(year, month, day, dep_time, arr_time, \n         carrier, flight, tailnum, type, model)\n\n# A tibble: 336,776 × 10\n    year month   day dep_time arr_time carrier flight tailnum type  model\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;    &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;\n 1  2013     1     1      517      830 UA        1545 N14228  &lt;NA&gt;  &lt;NA&gt; \n 2  2013     1     1      533      850 UA        1714 N24211  &lt;NA&gt;  &lt;NA&gt; \n 3  2013     1     1      542      923 AA        1141 N619AA  &lt;NA&gt;  &lt;NA&gt; \n 4  2013     1     1      544     1004 B6         725 N804JB  &lt;NA&gt;  &lt;NA&gt; \n 5  2013     1     1      554      812 DL         461 N668DN  &lt;NA&gt;  &lt;NA&gt; \n 6  2013     1     1      554      740 UA        1696 N39463  &lt;NA&gt;  &lt;NA&gt; \n 7  2013     1     1      555      913 B6         507 N516JB  &lt;NA&gt;  &lt;NA&gt; \n 8  2013     1     1      557      709 EV        5708 N829AS  &lt;NA&gt;  &lt;NA&gt; \n 9  2013     1     1      557      838 B6          79 N593JB  &lt;NA&gt;  &lt;NA&gt; \n10  2013     1     1      558      753 AA         301 N3ALAA  &lt;NA&gt;  &lt;NA&gt; \n# ℹ 336,766 more rows\n\n# Para evitar errores o malas asignaciones automáticas (tailnum y year) \n# debe usarse el argumento 'by = '\n# Ejemplos de otras operacionesn pueden encontrarse en:\n# https://cran.r-project.org/web/packages/dplyr/vignettes/two-table.html\nleft_join(flights, planes, by = \"tailnum\") %&gt;%\n  select(month, day, dep_time, arr_time, \n         carrier, flight, tailnum, type, model)\n\n# A tibble: 336,776 × 9\n   month   day dep_time arr_time carrier flight tailnum type               model\n   &lt;int&gt; &lt;int&gt;    &lt;int&gt;    &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;              &lt;chr&gt;\n 1     1     1      517      830 UA        1545 N14228  Fixed wing multi … 737-…\n 2     1     1      533      850 UA        1714 N24211  Fixed wing multi … 737-…\n 3     1     1      542      923 AA        1141 N619AA  Fixed wing multi … 757-…\n 4     1     1      544     1004 B6         725 N804JB  Fixed wing multi … A320…\n 5     1     1      554      812 DL         461 N668DN  Fixed wing multi … 757-…\n 6     1     1      554      740 UA        1696 N39463  Fixed wing multi … 737-…\n 7     1     1      555      913 B6         507 N516JB  Fixed wing multi … A320…\n 8     1     1      557      709 EV        5708 N829AS  Fixed wing multi … CL-6…\n 9     1     1      557      838 B6          79 N593JB  Fixed wing multi … A320…\n10     1     1      558      753 AA         301 N3ALAA  &lt;NA&gt;               &lt;NA&gt; \n# ℹ 336,766 more rows\n\n# Gramática de gráficas (ggplot2) [https://ggplot2.tidyverse.org/]\n# (https://es.r4ds.hadley.nz/03-visualize.html)\np  &lt;-  ggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp))\n# Gráfica 0\np0  &lt;-  p + geom_point(alpha = 0.3)\np0\n\n\n\n# Gráfica 0 plus: con ajuste no paramétrico\np0plus &lt;- p0 + geom_smooth(method = \"loess\")\np0plus\n\n\n\n# Gráfica 1: colores por regiones\np1  &lt;-  p + geom_point(aes(size = pop, col = region), alpha = 0.3)\np1\n\n\n\n# Gráfica 2: colores por regiones y tamaño por población\np2  &lt;-  p +\ngeom_point(aes(size = pop, col = region), alpha = 0.3) +\nscale_color_brewer(name = \"Región\", palette = \"Set1\") + # Escala de colores\nscale_size(name = \"Población\", labels = scales::comma) + # Escala de puntos\nscale_x_log10(labels = scales::dollar) + # Esc. logarítmica eje X, unidades $\nlabs(x = \"PIB per capita (log)\", y = \"Experanza de vida al nacer\") + # Títulos\ntheme_minimal() # Tema mínimo (b&w)\np2\n\n\n\n# Gráfica 3: burbujas de Hans-Rosling\nlibrary(viridis)\nlibrary(gganimate)\np3 &lt;- gapminder |&gt;\n    ggplot(aes(x = log(gdpPercap), y = lifeExp, size = pop)) +\n    geom_point(alpha = 0.5, aes(color = region)) +\n    scale_size(range = c(.1, 16), guide = \"none\") +\n    scale_x_continuous(limits = c(2.5, 12.5)) +\n    scale_y_continuous(limits = c(30, 90)) +\n    scale_color_viridis(discrete = TRUE, name = \"Región\", option = \"viridis\") +\n    labs(x = \"RIQUEZA - PIB per capita (log)\",\n                  y = \"SALUD - Esperanza de vida al nacer\") +\n    theme_classic() +\n    geom_text(aes(x = 7.5, y = 60, label = year), size = 14, color = 'lightgrey', family = 'Oswald') +\n    gganimate::transition_states(year, transition_length = 1, state_length = 1) +\n    gganimate::ease_aes('cubic-in-out')\np3\n# Gráfica 4: gráfica animada (cambio de la relación por años)\nlibrary(gganimate)\np4  &lt;-  ggplot(gapminder, aes(gdpPercap, lifeExp, size = pop, colour = country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_x_log10(labels = scales::dollar) +\n  facet_wrap(~region) +\n  labs(title = 'Año: {frame_time}', x = 'PIB per capita (log)', y = 'Experanza de vida') +\n  transition_time(year) +\n  ease_aes('linear')\np4\n\n\n\n# Análisis exploratorio de datos (EDA)\n# (https://es.r4ds.hadley.nz/07-eda.html)\nlibrary(skimr)\nskim(gapminder)\n\n\nData summary\n\n\nName\ngapminder\n\n\nNumber of rows\n13454\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\niso2c\n62\n1\n2\n2\n0\n216\n0\n\n\niso3c\n0\n1\n3\n3\n0\n217\n0\n\n\ncountry\n0\n1\n4\n30\n0\n217\n0\n\n\nregion\n0\n1\n10\n26\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1.00\n1990.50\n17.90\n1960.00\n1975.00\n1990.50\n2006.00\n2021.0\n▇▇▇▇▇\n\n\ngdpPercap\n3108\n0.77\n9200.70\n18094.41\n12.79\n581.77\n2109.08\n8870.14\n234317.1\n▇▁▁▁▁\n\n\nlifeExp\n564\n0.96\n64.71\n11.28\n11.99\n57.65\n67.55\n73.00\n85.5\n▁▁▃▇▇\n\n\npop\n30\n1.00\n24697848.53\n103586682.12\n2646.00\n480456.50\n4180250.00\n13449954.75\n1412360000.0\n▇▁▁▁▁\n\n\n\n\n# Gráficas bivariantes con  GGally  (https://ggobi.github.io/ggally/)\nlibrary(GGally)\ngapminder %&gt;% select(-c(iso2c,iso3c,country,year,region)) %&gt;% ggpairs()\n\n\n\n# Gráficas parciales con línea de regresión\nggplot(data = gapminder, aes(x = log(gdpPercap), y = lifeExp)) + \n    geom_smooth(method = \"lm\", col = \"blue\") + \n    geom_point()\n\n\n\nggplot(data = gapminder, aes(x = year, y = lifeExp)) + \n    geom_smooth(method = \"lm\", col = \"blue\") + \n    geom_point()"
  },
  {
    "objectID": "p1c2-app1a.html#código-python",
    "href": "p1c2-app1a.html#código-python",
    "title": "Aplicación 1.1.a (Gestión y representación gráfica de datos): Gramática básica del tidyverse",
    "section": "Código Python",
    "text": "Código Python\n\nEn las siguientes páginas web se pueden encontrar los detalles sobre cada cuestión analizada en este lenguaje:\n\nGestión a la tidyverse de datos y gráficos en Python:\n\n\nlibrería siuba: https://siuba.readthedocs.io/en/latest/\nlibrería plotnine: https://plotnine.readthedocs.io/en/stable/\n\nSobre los datos utilizados en la aplicación Python:\n\nmtcars (https://cran.r-project.org/web/packages/explore/vignettes/explore_mtcars.html)\n\n\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom siuba import *\nfrom plotnine import *\n# Lectura de datos\nmtcars = pd.read_csv('data/MTCARS.csv')\nmtcars.head()\n\n               model   mpg  cyl   disp   hp  ...   qsec  vs  am  gear  carb\n0          Mazda RX4  21.0    6  160.0  110  ...  16.46   0   1     4     4\n1      Mazda RX4 Wag  21.0    6  160.0  110  ...  17.02   0   1     4     4\n2         Datsun 710  22.8    4  108.0   93  ...  18.61   1   1     4     1\n3     Hornet 4 Drive  21.4    6  258.0  110  ...  19.44   1   0     3     1\n4  Hornet Sportabout  18.7    8  360.0  175  ...  17.02   0   0     3     2\n\n[5 rows x 12 columns]\n\n# Gramática de datos y tuberías (&gt;&gt;) con siuba\n# arrange, group_by\nmtcars_groups = mtcars &gt;&gt; arrange(_.hp) &gt;&gt; group_by(_.cyl)\nmtcars_groups\n\n(grouped data frame)\n                  model   mpg  cyl   disp   hp  ...   qsec  vs  am  gear  carb\n18          Honda Civic  30.4    4   75.7   52  ...  18.52   1   1     4     2\n7             Merc 240D  24.4    4  146.7   62  ...  20.00   1   0     4     2\n19       Toyota Corolla  33.9    4   71.1   65  ...  19.90   1   1     4     1\n17             Fiat 128  32.4    4   78.7   66  ...  19.47   1   1     4     1\n25            Fiat X1-9  27.3    4   79.0   66  ...  18.90   1   1     4     1\n26        Porsche 914-2  26.0    4  120.3   91  ...  16.70   0   1     5     2\n2            Datsun 710  22.8    4  108.0   93  ...  18.61   1   1     4     1\n8              Merc 230  22.8    4  140.8   95  ...  22.90   1   0     4     2\n20        Toyota Corona  21.5    4  120.1   97  ...  20.01   1   0     3     1\n5               Valiant  18.1    6  225.0  105  ...  20.22   1   0     3     1\n31           Volvo 142E  21.4    4  121.0  109  ...  18.60   1   1     4     2\n0             Mazda RX4  21.0    6  160.0  110  ...  16.46   0   1     4     4\n1         Mazda RX4 Wag  21.0    6  160.0  110  ...  17.02   0   1     4     4\n3        Hornet 4 Drive  21.4    6  258.0  110  ...  19.44   1   0     3     1\n27         Lotus Europa  30.4    4   95.1  113  ...  16.90   1   1     5     2\n9              Merc 280  19.2    6  167.6  123  ...  18.30   1   0     4     4\n10            Merc 280C  17.8    6  167.6  123  ...  18.90   1   0     4     4\n21     Dodge Challenger  15.5    8  318.0  150  ...  16.87   0   0     3     2\n22          AMC Javelin  15.2    8  304.0  150  ...  17.30   0   0     3     2\n4     Hornet Sportabout  18.7    8  360.0  175  ...  17.02   0   0     3     2\n24     Pontiac Firebird  19.2    8  400.0  175  ...  17.05   0   0     3     2\n29         Ferrari Dino  19.7    6  145.0  175  ...  15.50   0   1     5     6\n11           Merc 450SE  16.4    8  275.8  180  ...  17.40   0   0     3     3\n12           Merc 450SL  17.3    8  275.8  180  ...  17.60   0   0     3     3\n13          Merc 450SLC  15.2    8  275.8  180  ...  18.00   0   0     3     3\n14   Cadillac Fleetwood  10.4    8  472.0  205  ...  17.98   0   0     3     4\n15  Lincoln Continental  10.4    8  460.0  215  ...  17.82   0   0     3     4\n16    Chrysler Imperial  14.7    8  440.0  230  ...  17.42   0   0     3     4\n6            Duster 360  14.3    8  360.0  245  ...  15.84   0   0     3     4\n23           Camaro Z28  13.3    8  350.0  245  ...  15.41   0   0     3     4\n28       Ford Pantera L  15.8    8  351.0  264  ...  14.50   0   1     5     4\n30        Maserati Bora  15.0    8  301.0  335  ...  14.60   0   1     5     8\n\n[32 rows x 12 columns]\n\n# group_by, filter, summarize, arrange\n# and\n(mtcars &gt;&gt; filter((_.cyl == 4), (_.gear == 5)))\n\n            model   mpg  cyl   disp   hp  drat     wt  qsec  vs  am  gear  carb\n26  Porsche 914-2  26.0    4  120.3   91  4.43  2.140  16.7   0   1     5     2\n27   Lotus Europa  30.4    4   95.1  113  3.77  1.513  16.9   1   1     5     2\n\n# or\n(mtcars &gt;&gt; filter((_.cyl == 4) | (_.gear == 5)))\n\n             model   mpg  cyl   disp   hp  ...   qsec  vs  am  gear  carb\n2       Datsun 710  22.8    4  108.0   93  ...  18.61   1   1     4     1\n7        Merc 240D  24.4    4  146.7   62  ...  20.00   1   0     4     2\n8         Merc 230  22.8    4  140.8   95  ...  22.90   1   0     4     2\n17        Fiat 128  32.4    4   78.7   66  ...  19.47   1   1     4     1\n18     Honda Civic  30.4    4   75.7   52  ...  18.52   1   1     4     2\n19  Toyota Corolla  33.9    4   71.1   65  ...  19.90   1   1     4     1\n20   Toyota Corona  21.5    4  120.1   97  ...  20.01   1   0     3     1\n25       Fiat X1-9  27.3    4   79.0   66  ...  18.90   1   1     4     1\n26   Porsche 914-2  26.0    4  120.3   91  ...  16.70   0   1     5     2\n27    Lotus Europa  30.4    4   95.1  113  ...  16.90   1   1     5     2\n28  Ford Pantera L  15.8    8  351.0  264  ...  14.50   0   1     5     4\n29    Ferrari Dino  19.7    6  145.0  175  ...  15.50   0   1     5     6\n30   Maserati Bora  15.0    8  301.0  335  ...  14.60   0   1     5     8\n31      Volvo 142E  21.4    4  121.0  109  ...  18.60   1   1     4     2\n\n[14 rows x 12 columns]\n\n# grouped filters, count\n(mtcars &gt;&gt; group_by(_.cyl) &gt;&gt; summarize(n = _.cyl.count()))\n\n   cyl   n\n0    4  11\n1    6   7\n2    8  14\n\n(mtcars &gt;&gt; count(_.cyl))\n\n   cyl   n\n0    4  11\n1    6   7\n2    8  14\n\n(mtcars &gt;&gt; count(_.cyl, _.gear, sort = True))\n\n   cyl  gear   n\n0    8     3  12\n1    4     4   8\n2    6     4   4\n3    4     5   2\n4    6     3   2\n5    8     5   2\n6    4     3   1\n7    6     5   1\n\n(mtcars &gt;&gt; count(_.cyl, many_gears = _.gear &gt; 3))\n\n   cyl  many_gears   n\n0    4       False   1\n1    4        True  10\n2    6       False   2\n3    6        True   5\n4    8       False  12\n5    8        True   2\n\n(mtcars &gt;&gt; group_by(_.cyl) &gt;&gt; summarize(n = _.cyl.median()))\n\n   cyl    n\n0    4  4.0\n1    6  6.0\n2    8  8.0\n\n(mtcars &gt;&gt; group_by(_.cyl) &gt;&gt; filter(_.hp &gt; _.hp.median()))\n\n(grouped data frame)\n                  model   mpg  cyl   disp   hp  ...   qsec  vs  am  gear  carb\n2            Datsun 710  22.8    4  108.0   93  ...  18.61   1   1     4     1\n6            Duster 360  14.3    8  360.0  245  ...  15.84   0   0     3     4\n8              Merc 230  22.8    4  140.8   95  ...  22.90   1   0     4     2\n9              Merc 280  19.2    6  167.6  123  ...  18.30   1   0     4     4\n10            Merc 280C  17.8    6  167.6  123  ...  18.90   1   0     4     4\n14   Cadillac Fleetwood  10.4    8  472.0  205  ...  17.98   0   0     3     4\n15  Lincoln Continental  10.4    8  460.0  215  ...  17.82   0   0     3     4\n16    Chrysler Imperial  14.7    8  440.0  230  ...  17.42   0   0     3     4\n20        Toyota Corona  21.5    4  120.1   97  ...  20.01   1   0     3     1\n23           Camaro Z28  13.3    8  350.0  245  ...  15.41   0   0     3     4\n27         Lotus Europa  30.4    4   95.1  113  ...  16.90   1   1     5     2\n28       Ford Pantera L  15.8    8  351.0  264  ...  14.50   0   1     5     4\n29         Ferrari Dino  19.7    6  145.0  175  ...  15.50   0   1     5     6\n30        Maserati Bora  15.0    8  301.0  335  ...  14.60   0   1     5     8\n31           Volvo 142E  21.4    4  121.0  109  ...  18.60   1   1     4     2\n\n[15 rows x 12 columns]\n\n# arrange, group_by, filter\nfrom siuba.dply.vector import row_number\n(mtcars &gt;&gt; arrange(_.hp) &gt;&gt; group_by(_.cyl) &gt;&gt; filter(row_number(_) &lt;= 2))\n\n(grouped data frame)\n               model   mpg  cyl   disp   hp  ...   qsec  vs  am  gear  carb\n0          Mazda RX4  21.0    6  160.0  110  ...  16.46   0   1     4     4\n5            Valiant  18.1    6  225.0  105  ...  20.22   1   0     3     1\n7          Merc 240D  24.4    4  146.7   62  ...  20.00   1   0     4     2\n18       Honda Civic  30.4    4   75.7   52  ...  18.52   1   1     4     2\n21  Dodge Challenger  15.5    8  318.0  150  ...  16.87   0   0     3     2\n22       AMC Javelin  15.2    8  304.0  150  ...  17.30   0   0     3     2\n\n[6 rows x 12 columns]\n\n# lag, led\nfrom siuba.dply.vector import lag # o led\n(mtcars &gt;&gt; arrange(_.hp) &gt;&gt; filter(_.hp - lag(_.hp) &gt; 50))\n\n            model   mpg  cyl   disp   hp  drat    wt  qsec  vs  am  gear  carb\n30  Maserati Bora  15.0    8  301.0  335  3.54  3.57  14.6   0   1     5     8\n\n# arrange, select, rename\nsmall_mtcars = mtcars &gt;&gt; select(_.cyl, _.mpg, _.hp)\nsmall_mtcars\n\n    cyl   mpg   hp\n0     6  21.0  110\n1     6  21.0  110\n2     4  22.8   93\n3     6  21.4  110\n4     8  18.7  175\n5     6  18.1  105\n6     8  14.3  245\n7     4  24.4   62\n8     4  22.8   95\n9     6  19.2  123\n10    6  17.8  123\n11    8  16.4  180\n12    8  17.3  180\n13    8  15.2  180\n14    8  10.4  205\n15    8  10.4  215\n16    8  14.7  230\n17    4  32.4   66\n18    4  30.4   52\n19    4  33.9   65\n20    4  21.5   97\n21    8  15.5  150\n22    8  15.2  150\n23    8  13.3  245\n24    8  19.2  175\n25    4  27.3   66\n26    4  26.0   91\n27    4  30.4  113\n28    8  15.8  264\n29    6  19.7  175\n30    8  15.0  335\n31    4  21.4  109\n\n# ordenar filas con una variable\n(small_mtcars &gt;&gt; arrange(_.hp)) # ascendente\n\n    cyl   mpg   hp\n18    4  30.4   52\n7     4  24.4   62\n19    4  33.9   65\n17    4  32.4   66\n25    4  27.3   66\n26    4  26.0   91\n2     4  22.8   93\n8     4  22.8   95\n20    4  21.5   97\n5     6  18.1  105\n31    4  21.4  109\n0     6  21.0  110\n1     6  21.0  110\n3     6  21.4  110\n27    4  30.4  113\n9     6  19.2  123\n10    6  17.8  123\n21    8  15.5  150\n22    8  15.2  150\n4     8  18.7  175\n24    8  19.2  175\n29    6  19.7  175\n11    8  16.4  180\n12    8  17.3  180\n13    8  15.2  180\n14    8  10.4  205\n15    8  10.4  215\n16    8  14.7  230\n6     8  14.3  245\n23    8  13.3  245\n28    8  15.8  264\n30    8  15.0  335\n\n(small_mtcars &gt;&gt; arrange(-_.hp)) # descendente\n\n    cyl   mpg   hp\n30    8  15.0  335\n28    8  15.8  264\n6     8  14.3  245\n23    8  13.3  245\n16    8  14.7  230\n15    8  10.4  215\n14    8  10.4  205\n11    8  16.4  180\n12    8  17.3  180\n13    8  15.2  180\n4     8  18.7  175\n24    8  19.2  175\n29    6  19.7  175\n21    8  15.5  150\n22    8  15.2  150\n9     6  19.2  123\n10    6  17.8  123\n27    4  30.4  113\n0     6  21.0  110\n1     6  21.0  110\n3     6  21.4  110\n31    4  21.4  109\n5     6  18.1  105\n20    4  21.5   97\n8     4  22.8   95\n2     4  22.8   93\n26    4  26.0   91\n17    4  32.4   66\n25    4  27.3   66\n19    4  33.9   65\n7     4  24.4   62\n18    4  30.4   52\n\n# ordenar filas usando varias varialbes\n(small_mtcars &gt;&gt; arrange(_.cyl, _.mpg))\n\n    cyl   mpg   hp\n31    4  21.4  109\n20    4  21.5   97\n2     4  22.8   93\n8     4  22.8   95\n7     4  24.4   62\n26    4  26.0   91\n25    4  27.3   66\n18    4  30.4   52\n27    4  30.4  113\n17    4  32.4   66\n19    4  33.9   65\n10    6  17.8  123\n5     6  18.1  105\n9     6  19.2  123\n29    6  19.7  175\n0     6  21.0  110\n1     6  21.0  110\n3     6  21.4  110\n14    8  10.4  205\n15    8  10.4  215\n23    8  13.3  245\n6     8  14.3  245\n16    8  14.7  230\n30    8  15.0  335\n13    8  15.2  180\n22    8  15.2  150\n21    8  15.5  150\n28    8  15.8  264\n11    8  16.4  180\n12    8  17.3  180\n4     8  18.7  175\n24    8  19.2  175\n\n# ordenar por hp/cyl (horsepower per cylinder)\n(small_mtcars &gt;&gt; arrange(_.hp / _.cyl))\n\n    cyl   mpg   hp\n18    4  30.4   52\n7     4  24.4   62\n19    4  33.9   65\n17    4  32.4   66\n25    4  27.3   66\n5     6  18.1  105\n0     6  21.0  110\n1     6  21.0  110\n3     6  21.4  110\n21    8  15.5  150\n22    8  15.2  150\n9     6  19.2  123\n10    6  17.8  123\n4     8  18.7  175\n24    8  19.2  175\n11    8  16.4  180\n12    8  17.3  180\n13    8  15.2  180\n26    4  26.0   91\n2     4  22.8   93\n8     4  22.8   95\n20    4  21.5   97\n14    8  10.4  205\n15    8  10.4  215\n31    4  21.4  109\n27    4  30.4  113\n16    8  14.7  230\n29    6  19.7  175\n6     8  14.3  245\n23    8  13.3  245\n28    8  15.8  264\n30    8  15.0  335\n\n# seleccionar variables \n# equivalente: mtcars &gt;&gt; select(1, 2) , mtcars &gt;&gt; select(\"mpg\", \"cyl\")\n(mtcars &gt;&gt; select(_.mpg, _.cyl))\n\n     mpg  cyl\n0   21.0    6\n1   21.0    6\n2   22.8    4\n3   21.4    6\n4   18.7    8\n5   18.1    6\n6   14.3    8\n7   24.4    4\n8   22.8    4\n9   19.2    6\n10  17.8    6\n11  16.4    8\n12  17.3    8\n13  15.2    8\n14  10.4    8\n15  10.4    8\n16  14.7    8\n17  32.4    4\n18  30.4    4\n19  33.9    4\n20  21.5    4\n21  15.5    8\n22  15.2    8\n23  13.3    8\n24  19.2    8\n25  27.3    4\n26  26.0    4\n27  30.4    4\n28  15.8    8\n29  19.7    6\n30  15.0    8\n31  21.4    4\n\n# excluir columnas\n(mtcars &gt;&gt; select(-_.mpg, -_.cyl))\n\n                  model   disp   hp  drat     wt   qsec  vs  am  gear  carb\n0             Mazda RX4  160.0  110  3.90  2.620  16.46   0   1     4     4\n1         Mazda RX4 Wag  160.0  110  3.90  2.875  17.02   0   1     4     4\n2            Datsun 710  108.0   93  3.85  2.320  18.61   1   1     4     1\n3        Hornet 4 Drive  258.0  110  3.08  3.215  19.44   1   0     3     1\n4     Hornet Sportabout  360.0  175  3.15  3.440  17.02   0   0     3     2\n5               Valiant  225.0  105  2.76  3.460  20.22   1   0     3     1\n6            Duster 360  360.0  245  3.21  3.570  15.84   0   0     3     4\n7             Merc 240D  146.7   62  3.69  3.190  20.00   1   0     4     2\n8              Merc 230  140.8   95  3.92  3.150  22.90   1   0     4     2\n9              Merc 280  167.6  123  3.92  3.440  18.30   1   0     4     4\n10            Merc 280C  167.6  123  3.92  3.440  18.90   1   0     4     4\n11           Merc 450SE  275.8  180  3.07  4.070  17.40   0   0     3     3\n12           Merc 450SL  275.8  180  3.07  3.730  17.60   0   0     3     3\n13          Merc 450SLC  275.8  180  3.07  3.780  18.00   0   0     3     3\n14   Cadillac Fleetwood  472.0  205  2.93  5.250  17.98   0   0     3     4\n15  Lincoln Continental  460.0  215  3.00  5.424  17.82   0   0     3     4\n16    Chrysler Imperial  440.0  230  3.23  5.345  17.42   0   0     3     4\n17             Fiat 128   78.7   66  4.08  2.200  19.47   1   1     4     1\n18          Honda Civic   75.7   52  4.93  1.615  18.52   1   1     4     2\n19       Toyota Corolla   71.1   65  4.22  1.835  19.90   1   1     4     1\n20        Toyota Corona  120.1   97  3.70  2.465  20.01   1   0     3     1\n21     Dodge Challenger  318.0  150  2.76  3.520  16.87   0   0     3     2\n22          AMC Javelin  304.0  150  3.15  3.435  17.30   0   0     3     2\n23           Camaro Z28  350.0  245  3.73  3.840  15.41   0   0     3     4\n24     Pontiac Firebird  400.0  175  3.08  3.845  17.05   0   0     3     2\n25            Fiat X1-9   79.0   66  4.08  1.935  18.90   1   1     4     1\n26        Porsche 914-2  120.3   91  4.43  2.140  16.70   0   1     5     2\n27         Lotus Europa   95.1  113  3.77  1.513  16.90   1   1     5     2\n28       Ford Pantera L  351.0  264  4.22  3.170  14.50   0   1     5     4\n29         Ferrari Dino  145.0  175  3.62  2.770  15.50   0   1     5     6\n30        Maserati Bora  301.0  335  3.54  3.570  14.60   0   1     5     8\n31           Volvo 142E  121.0  109  4.11  2.780  18.60   1   1     4     2\n\n(mtcars &gt;&gt; select(-_.model))\n\n     mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n0   21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n1   21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n2   22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n3   21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n4   18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2\n5   18.1    6  225.0  105  2.76  3.460  20.22   1   0     3     1\n6   14.3    8  360.0  245  3.21  3.570  15.84   0   0     3     4\n7   24.4    4  146.7   62  3.69  3.190  20.00   1   0     4     2\n8   22.8    4  140.8   95  3.92  3.150  22.90   1   0     4     2\n9   19.2    6  167.6  123  3.92  3.440  18.30   1   0     4     4\n10  17.8    6  167.6  123  3.92  3.440  18.90   1   0     4     4\n11  16.4    8  275.8  180  3.07  4.070  17.40   0   0     3     3\n12  17.3    8  275.8  180  3.07  3.730  17.60   0   0     3     3\n13  15.2    8  275.8  180  3.07  3.780  18.00   0   0     3     3\n14  10.4    8  472.0  205  2.93  5.250  17.98   0   0     3     4\n15  10.4    8  460.0  215  3.00  5.424  17.82   0   0     3     4\n16  14.7    8  440.0  230  3.23  5.345  17.42   0   0     3     4\n17  32.4    4   78.7   66  4.08  2.200  19.47   1   1     4     1\n18  30.4    4   75.7   52  4.93  1.615  18.52   1   1     4     2\n19  33.9    4   71.1   65  4.22  1.835  19.90   1   1     4     1\n20  21.5    4  120.1   97  3.70  2.465  20.01   1   0     3     1\n21  15.5    8  318.0  150  2.76  3.520  16.87   0   0     3     2\n22  15.2    8  304.0  150  3.15  3.435  17.30   0   0     3     2\n23  13.3    8  350.0  245  3.73  3.840  15.41   0   0     3     4\n24  19.2    8  400.0  175  3.08  3.845  17.05   0   0     3     2\n25  27.3    4   79.0   66  4.08  1.935  18.90   1   1     4     1\n26  26.0    4  120.3   91  4.43  2.140  16.70   0   1     5     2\n27  30.4    4   95.1  113  3.77  1.513  16.90   1   1     5     2\n28  15.8    8  351.0  264  4.22  3.170  14.50   0   1     5     4\n29  19.7    6  145.0  175  3.62  2.770  15.50   0   1     5     6\n30  15.0    8  301.0  335  3.54  3.570  14.60   0   1     5     8\n31  21.4    4  121.0  109  4.11  2.780  18.60   1   1     4     2\n\n# seleccionar y renombrar\n(mtcars &gt;&gt; select(_.miles_per_gallon == _.mpg, _.number_of_cylinders == _.cyl))\n\n    miles_per_gallon  number_of_cylinders\n0               21.0                    6\n1               21.0                    6\n2               22.8                    4\n3               21.4                    6\n4               18.7                    8\n5               18.1                    6\n6               14.3                    8\n7               24.4                    4\n8               22.8                    4\n9               19.2                    6\n10              17.8                    6\n11              16.4                    8\n12              17.3                    8\n13              15.2                    8\n14              10.4                    8\n15              10.4                    8\n16              14.7                    8\n17              32.4                    4\n18              30.4                    4\n19              33.9                    4\n20              21.5                    4\n21              15.5                    8\n22              15.2                    8\n23              13.3                    8\n24              19.2                    8\n25              27.3                    4\n26              26.0                    4\n27              30.4                    4\n28              15.8                    8\n29              19.7                    6\n30              15.0                    8\n31              21.4                    4\n\n# seleccionar columnas (adjacentes)\n(mtcars &gt;&gt; select(_[\"mpg\": \"hp\"])) # equivalente: mtcars &gt;&gt; select(_[1:3])\n\n     mpg  cyl   disp   hp\n0   21.0    6  160.0  110\n1   21.0    6  160.0  110\n2   22.8    4  108.0   93\n3   21.4    6  258.0  110\n4   18.7    8  360.0  175\n5   18.1    6  225.0  105\n6   14.3    8  360.0  245\n7   24.4    4  146.7   62\n8   22.8    4  140.8   95\n9   19.2    6  167.6  123\n10  17.8    6  167.6  123\n11  16.4    8  275.8  180\n12  17.3    8  275.8  180\n13  15.2    8  275.8  180\n14  10.4    8  472.0  205\n15  10.4    8  460.0  215\n16  14.7    8  440.0  230\n17  32.4    4   78.7   66\n18  30.4    4   75.7   52\n19  33.9    4   71.1   65\n20  21.5    4  120.1   97\n21  15.5    8  318.0  150\n22  15.2    8  304.0  150\n23  13.3    8  350.0  245\n24  19.2    8  400.0  175\n25  27.3    4   79.0   66\n26  26.0    4  120.3   91\n27  30.4    4   95.1  113\n28  15.8    8  351.0  264\n29  19.7    6  145.0  175\n30  15.0    8  301.0  335\n31  21.4    4  121.0  109\n\n# excluir columnas seleccionadas\n(mtcars &gt;&gt; select(-_[\"mpg\": \"hp\"]))\n\n                  model  drat     wt   qsec  vs  am  gear  carb\n0             Mazda RX4  3.90  2.620  16.46   0   1     4     4\n1         Mazda RX4 Wag  3.90  2.875  17.02   0   1     4     4\n2            Datsun 710  3.85  2.320  18.61   1   1     4     1\n3        Hornet 4 Drive  3.08  3.215  19.44   1   0     3     1\n4     Hornet Sportabout  3.15  3.440  17.02   0   0     3     2\n5               Valiant  2.76  3.460  20.22   1   0     3     1\n6            Duster 360  3.21  3.570  15.84   0   0     3     4\n7             Merc 240D  3.69  3.190  20.00   1   0     4     2\n8              Merc 230  3.92  3.150  22.90   1   0     4     2\n9              Merc 280  3.92  3.440  18.30   1   0     4     4\n10            Merc 280C  3.92  3.440  18.90   1   0     4     4\n11           Merc 450SE  3.07  4.070  17.40   0   0     3     3\n12           Merc 450SL  3.07  3.730  17.60   0   0     3     3\n13          Merc 450SLC  3.07  3.780  18.00   0   0     3     3\n14   Cadillac Fleetwood  2.93  5.250  17.98   0   0     3     4\n15  Lincoln Continental  3.00  5.424  17.82   0   0     3     4\n16    Chrysler Imperial  3.23  5.345  17.42   0   0     3     4\n17             Fiat 128  4.08  2.200  19.47   1   1     4     1\n18          Honda Civic  4.93  1.615  18.52   1   1     4     2\n19       Toyota Corolla  4.22  1.835  19.90   1   1     4     1\n20        Toyota Corona  3.70  2.465  20.01   1   0     3     1\n21     Dodge Challenger  2.76  3.520  16.87   0   0     3     2\n22          AMC Javelin  3.15  3.435  17.30   0   0     3     2\n23           Camaro Z28  3.73  3.840  15.41   0   0     3     4\n24     Pontiac Firebird  3.08  3.845  17.05   0   0     3     2\n25            Fiat X1-9  4.08  1.935  18.90   1   1     4     1\n26        Porsche 914-2  4.43  2.140  16.70   0   1     5     2\n27         Lotus Europa  3.77  1.513  16.90   1   1     5     2\n28       Ford Pantera L  4.22  3.170  14.50   0   1     5     4\n29         Ferrari Dino  3.62  2.770  15.50   0   1     5     6\n30        Maserati Bora  3.54  3.570  14.60   0   1     5     8\n31           Volvo 142E  4.11  2.780  18.60   1   1     4     2\n\n# renombrar\nmtcars &gt;&gt; rename(transm = \"am\")\n\n                  model   mpg  cyl   disp   hp  ...   qsec  vs  transm  gear  carb\n0             Mazda RX4  21.0    6  160.0  110  ...  16.46   0       1     4     4\n1         Mazda RX4 Wag  21.0    6  160.0  110  ...  17.02   0       1     4     4\n2            Datsun 710  22.8    4  108.0   93  ...  18.61   1       1     4     1\n3        Hornet 4 Drive  21.4    6  258.0  110  ...  19.44   1       0     3     1\n4     Hornet Sportabout  18.7    8  360.0  175  ...  17.02   0       0     3     2\n5               Valiant  18.1    6  225.0  105  ...  20.22   1       0     3     1\n6            Duster 360  14.3    8  360.0  245  ...  15.84   0       0     3     4\n7             Merc 240D  24.4    4  146.7   62  ...  20.00   1       0     4     2\n8              Merc 230  22.8    4  140.8   95  ...  22.90   1       0     4     2\n9              Merc 280  19.2    6  167.6  123  ...  18.30   1       0     4     4\n10            Merc 280C  17.8    6  167.6  123  ...  18.90   1       0     4     4\n11           Merc 450SE  16.4    8  275.8  180  ...  17.40   0       0     3     3\n12           Merc 450SL  17.3    8  275.8  180  ...  17.60   0       0     3     3\n13          Merc 450SLC  15.2    8  275.8  180  ...  18.00   0       0     3     3\n14   Cadillac Fleetwood  10.4    8  472.0  205  ...  17.98   0       0     3     4\n15  Lincoln Continental  10.4    8  460.0  215  ...  17.82   0       0     3     4\n16    Chrysler Imperial  14.7    8  440.0  230  ...  17.42   0       0     3     4\n17             Fiat 128  32.4    4   78.7   66  ...  19.47   1       1     4     1\n18          Honda Civic  30.4    4   75.7   52  ...  18.52   1       1     4     2\n19       Toyota Corolla  33.9    4   71.1   65  ...  19.90   1       1     4     1\n20        Toyota Corona  21.5    4  120.1   97  ...  20.01   1       0     3     1\n21     Dodge Challenger  15.5    8  318.0  150  ...  16.87   0       0     3     2\n22          AMC Javelin  15.2    8  304.0  150  ...  17.30   0       0     3     2\n23           Camaro Z28  13.3    8  350.0  245  ...  15.41   0       0     3     4\n24     Pontiac Firebird  19.2    8  400.0  175  ...  17.05   0       0     3     2\n25            Fiat X1-9  27.3    4   79.0   66  ...  18.90   1       1     4     1\n26        Porsche 914-2  26.0    4  120.3   91  ...  16.70   0       1     5     2\n27         Lotus Europa  30.4    4   95.1  113  ...  16.90   1       1     5     2\n28       Ford Pantera L  15.8    8  351.0  264  ...  14.50   0       1     5     4\n29         Ferrari Dino  19.7    6  145.0  175  ...  15.50   0       1     5     6\n30        Maserati Bora  15.0    8  301.0  335  ...  14.60   0       1     5     8\n31           Volvo 142E  21.4    4  121.0  109  ...  18.60   1       1     4     2\n\n[32 rows x 12 columns]\n\n# mutate\n# nuevas columnas\n(small_mtcars &gt;&gt; mutate(hp_per_cyl = _.hp / _.cyl))\n\n    cyl   mpg   hp  hp_per_cyl\n0     6  21.0  110   18.333333\n1     6  21.0  110   18.333333\n2     4  22.8   93   23.250000\n3     6  21.4  110   18.333333\n4     8  18.7  175   21.875000\n5     6  18.1  105   17.500000\n6     8  14.3  245   30.625000\n7     4  24.4   62   15.500000\n8     4  22.8   95   23.750000\n9     6  19.2  123   20.500000\n10    6  17.8  123   20.500000\n11    8  16.4  180   22.500000\n12    8  17.3  180   22.500000\n13    8  15.2  180   22.500000\n14    8  10.4  205   25.625000\n15    8  10.4  215   26.875000\n16    8  14.7  230   28.750000\n17    4  32.4   66   16.500000\n18    4  30.4   52   13.000000\n19    4  33.9   65   16.250000\n20    4  21.5   97   24.250000\n21    8  15.5  150   18.750000\n22    8  15.2  150   18.750000\n23    8  13.3  245   30.625000\n24    8  19.2  175   21.875000\n25    4  27.3   66   16.500000\n26    4  26.0   91   22.750000\n27    4  30.4  113   28.250000\n28    8  15.8  264   33.000000\n29    6  19.7  175   29.166667\n30    8  15.0  335   41.875000\n31    4  21.4  109   27.250000\n\n(small_mtcars &gt;&gt; mutate(hp_per_cyl = _.hp / _.cyl,  diff = _.hp_per_cyl - _.hp_per_cyl.shift(1)))\n\n    cyl   mpg   hp  hp_per_cyl       diff\n0     6  21.0  110   18.333333        NaN\n1     6  21.0  110   18.333333   0.000000\n2     4  22.8   93   23.250000   4.916667\n3     6  21.4  110   18.333333  -4.916667\n4     8  18.7  175   21.875000   3.541667\n5     6  18.1  105   17.500000  -4.375000\n6     8  14.3  245   30.625000  13.125000\n7     4  24.4   62   15.500000 -15.125000\n8     4  22.8   95   23.750000   8.250000\n9     6  19.2  123   20.500000  -3.250000\n10    6  17.8  123   20.500000   0.000000\n11    8  16.4  180   22.500000   2.000000\n12    8  17.3  180   22.500000   0.000000\n13    8  15.2  180   22.500000   0.000000\n14    8  10.4  205   25.625000   3.125000\n15    8  10.4  215   26.875000   1.250000\n16    8  14.7  230   28.750000   1.875000\n17    4  32.4   66   16.500000 -12.250000\n18    4  30.4   52   13.000000  -3.500000\n19    4  33.9   65   16.250000   3.250000\n20    4  21.5   97   24.250000   8.000000\n21    8  15.5  150   18.750000  -5.500000\n22    8  15.2  150   18.750000   0.000000\n23    8  13.3  245   30.625000  11.875000\n24    8  19.2  175   21.875000  -8.750000\n25    4  27.3   66   16.500000  -5.375000\n26    4  26.0   91   22.750000   6.250000\n27    4  30.4  113   28.250000   5.500000\n28    8  15.8  264   33.000000   4.750000\n29    6  19.7  175   29.166667  -3.833333\n30    8  15.0  335   41.875000  12.708333\n31    4  21.4  109   27.250000 -14.625000\n\n# mutate, group_by\n(small_mtcars &gt;&gt; group_by(_.cyl) &gt;&gt; mutate(hp_mean = _.hp.mean(), demeaned_hp = _.hp - _.hp_mean))\n\n(grouped data frame)\n    cyl   mpg   hp     hp_mean  demeaned_hp\n0     6  21.0  110  122.285714   -12.285714\n1     6  21.0  110  122.285714   -12.285714\n2     4  22.8   93   82.636364    10.363636\n3     6  21.4  110  122.285714   -12.285714\n4     8  18.7  175  209.214286   -34.214286\n5     6  18.1  105  122.285714   -17.285714\n6     8  14.3  245  209.214286    35.785714\n7     4  24.4   62   82.636364   -20.636364\n8     4  22.8   95   82.636364    12.363636\n9     6  19.2  123  122.285714     0.714286\n10    6  17.8  123  122.285714     0.714286\n11    8  16.4  180  209.214286   -29.214286\n12    8  17.3  180  209.214286   -29.214286\n13    8  15.2  180  209.214286   -29.214286\n14    8  10.4  205  209.214286    -4.214286\n15    8  10.4  215  209.214286     5.785714\n16    8  14.7  230  209.214286    20.785714\n17    4  32.4   66   82.636364   -16.636364\n18    4  30.4   52   82.636364   -30.636364\n19    4  33.9   65   82.636364   -17.636364\n20    4  21.5   97   82.636364    14.363636\n21    8  15.5  150  209.214286   -59.214286\n22    8  15.2  150  209.214286   -59.214286\n23    8  13.3  245  209.214286    35.785714\n24    8  19.2  175  209.214286   -34.214286\n25    4  27.3   66   82.636364   -16.636364\n26    4  26.0   91   82.636364     8.363636\n27    4  30.4  113   82.636364    30.363636\n28    8  15.8  264  209.214286    54.785714\n29    6  19.7  175  122.285714    52.714286\n30    8  15.0  335  209.214286   125.785714\n31    4  21.4  109   82.636364    26.363636\n\n# transmute = mutate + select\n(mtcars &gt;&gt; transmute(_.cyl, _.mpg, hp_per_cyl = _.hp / _.cyl))\n\n    cyl   mpg  hp_per_cyl\n0     6  21.0   18.333333\n1     6  21.0   18.333333\n2     4  22.8   23.250000\n3     6  21.4   18.333333\n4     8  18.7   21.875000\n5     6  18.1   17.500000\n6     8  14.3   30.625000\n7     4  24.4   15.500000\n8     4  22.8   23.750000\n9     6  19.2   20.500000\n10    6  17.8   20.500000\n11    8  16.4   22.500000\n12    8  17.3   22.500000\n13    8  15.2   22.500000\n14    8  10.4   25.625000\n15    8  10.4   26.875000\n16    8  14.7   28.750000\n17    4  32.4   16.500000\n18    4  30.4   13.000000\n19    4  33.9   16.250000\n20    4  21.5   24.250000\n21    8  15.5   18.750000\n22    8  15.2   18.750000\n23    8  13.3   30.625000\n24    8  19.2   21.875000\n25    4  27.3   16.500000\n26    4  26.0   22.750000\n27    4  30.4   28.250000\n28    8  15.8   33.000000\n29    6  19.7   29.166667\n30    8  15.0   41.875000\n31    4  21.4   27.250000\n\n# summarize\n# global\n(mtcars &gt;&gt; summarize(avg_mpg = _.mpg.mean()))\n\n     avg_mpg\n0  20.090625\n\n# por grupos\n(mtcars &gt;&gt; group_by(_.cyl) &gt;&gt; summarize(avg_mpg = _.mpg.mean()))\n\n   cyl    avg_mpg\n0    4  26.663636\n1    6  19.742857\n2    8  15.100000\n\n# filter\nhigh_hp_mtcars = mtcars &gt;&gt; filter(_.hp &gt; _.hp.mean())\nhigh_hp_mtcars\n\n                  model   mpg  cyl   disp   hp  ...   qsec  vs  am  gear  carb\n4     Hornet Sportabout  18.7    8  360.0  175  ...  17.02   0   0     3     2\n6            Duster 360  14.3    8  360.0  245  ...  15.84   0   0     3     4\n11           Merc 450SE  16.4    8  275.8  180  ...  17.40   0   0     3     3\n12           Merc 450SL  17.3    8  275.8  180  ...  17.60   0   0     3     3\n13          Merc 450SLC  15.2    8  275.8  180  ...  18.00   0   0     3     3\n14   Cadillac Fleetwood  10.4    8  472.0  205  ...  17.98   0   0     3     4\n15  Lincoln Continental  10.4    8  460.0  215  ...  17.82   0   0     3     4\n16    Chrysler Imperial  14.7    8  440.0  230  ...  17.42   0   0     3     4\n21     Dodge Challenger  15.5    8  318.0  150  ...  16.87   0   0     3     2\n22          AMC Javelin  15.2    8  304.0  150  ...  17.30   0   0     3     2\n23           Camaro Z28  13.3    8  350.0  245  ...  15.41   0   0     3     4\n24     Pontiac Firebird  19.2    8  400.0  175  ...  17.05   0   0     3     2\n28       Ford Pantera L  15.8    8  351.0  264  ...  14.50   0   1     5     4\n29         Ferrari Dino  19.7    6  145.0  175  ...  15.50   0   1     5     6\n30        Maserati Bora  15.0    8  301.0  335  ...  14.60   0   1     5     8\n\n[15 rows x 12 columns]\n\n(high_hp_mtcars &gt;&gt; mutate(avg_hp = _.hp.mean()))\n\n                  model   mpg  cyl   disp   hp  ...  vs  am  gear  carb      avg_hp\n4     Hornet Sportabout  18.7    8  360.0  175  ...   0   0     3     2  206.933333\n6            Duster 360  14.3    8  360.0  245  ...   0   0     3     4  206.933333\n11           Merc 450SE  16.4    8  275.8  180  ...   0   0     3     3  206.933333\n12           Merc 450SL  17.3    8  275.8  180  ...   0   0     3     3  206.933333\n13          Merc 450SLC  15.2    8  275.8  180  ...   0   0     3     3  206.933333\n14   Cadillac Fleetwood  10.4    8  472.0  205  ...   0   0     3     4  206.933333\n15  Lincoln Continental  10.4    8  460.0  215  ...   0   0     3     4  206.933333\n16    Chrysler Imperial  14.7    8  440.0  230  ...   0   0     3     4  206.933333\n21     Dodge Challenger  15.5    8  318.0  150  ...   0   0     3     2  206.933333\n22          AMC Javelin  15.2    8  304.0  150  ...   0   0     3     2  206.933333\n23           Camaro Z28  13.3    8  350.0  245  ...   0   0     3     4  206.933333\n24     Pontiac Firebird  19.2    8  400.0  175  ...   0   0     3     2  206.933333\n28       Ford Pantera L  15.8    8  351.0  264  ...   0   1     5     4  206.933333\n29         Ferrari Dino  19.7    6  145.0  175  ...   0   1     5     6  206.933333\n30        Maserati Bora  15.0    8  301.0  335  ...   0   1     5     8  206.933333\n\n[15 rows x 13 columns]\n\n# joins\ndf1 = pd.DataFrame({'id': [1,2], 'x': ['a', 'b']})\ndf2 = pd.DataFrame({'id': [2,2,3], 'y': ['l', 'm', 'n']})\ndf1\n\n   id  x\n0   1  a\n1   2  b\n\ndf2\n\n   id  y\n0   2  l\n1   2  m\n2   3  n\n\n# inner joins\ndf1 &gt;&gt; inner_join(_, df2, on = \"id\")\n\n   id  x  y\n0   2  b  l\n1   2  b  m\n\ninner_join(df1, df2, on = \"id\")\n\n   id  x  y\n0   2  b  l\n1   2  b  m\n\n# left joins\nleft_join(df1, df2, on = \"id\")\n\n   id  x    y\n0   1  a  NaN\n1   2  b    l\n2   2  b    m\n\n# full join\nfull_join(df1, df2, on = \"id\")\n\n   id    x    y\n0   1    a  NaN\n1   2    b    l\n2   2    b    m\n3   3  NaN    n\n\n# semi join\nsemi_join(df1, df2, on = \"id\")\n\n   id  x\n1   2  b\n\n# Gramática de gráficas con plotnine\n(\n    ggplot(mtcars, aes(x='disp', y='hp'))\n    + geom_point()\n    + labs(x='Cilindrada', y='Potencia')\n)\n\n&lt;ggplot: (330664750)&gt;\n\n\n\n\n(\n    ggplot(mtcars, aes(x='disp', y='hp'))\n    + geom_point()\n    + geom_smooth(method='lm', color = \"blue\")\n    + labs(x='Cilindrada', y='Potencia')\n)\n\n&lt;ggplot: (330674747)&gt;\n\n\n\n\n(\n    ggplot(mtcars, aes(x='disp', y='hp'))\n    + geom_point()\n    + geom_smooth(color = \"blue\")\n    + labs(x='Cilindrada', y='Potencia')\n)\n\n&lt;ggplot: (333380320)&gt;\n\n\n\n\n(ggplot(mtcars, aes('disp', 'hp', color='factor(gear)'))\n + geom_point()\n + stat_smooth(method='lm')\n + facet_wrap('~gear'))\n\n&lt;ggplot: (333411518)&gt;\n\n\n\n\n(\n    ggplot(mtcars, aes(x='disp', y='hp', color='factor(gear)'))\n    + geom_point()\n    + geom_smooth(method='lm')\n    +  labs(x='Cilindrada', y='Potencia')\n)\n\n&lt;ggplot: (335835743)&gt;\n\n\n\n\n(mtcars\n &gt;&gt; ggplot(aes(x = 'wt', y = 'mpg'))\n  + geom_point(aes(color = 'factor(gear)', shape = 'factor(gear)'), size = 3, alpha = 0.8)\n  + theme_minimal()\n  + labs(title = \"Datos mtcars, Motor Trend US magazine (1974)\",\n        x = \"Peso (libras/1000) [US]\",\n        y = \"Millas/galón [US]\",\n        color = \"Número de marchas\",\n        shape = \"Número de marchas\"))\n\n&lt;ggplot: (335886198)&gt;"
  },
  {
    "objectID": "p1c2-app1b.html",
    "href": "p1c2-app1b.html",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "",
    "text": "Código R\nSobre los datos utilizados:"
  },
  {
    "objectID": "p1c2-app1b.html#lectura-de-librerías",
    "href": "p1c2-app1b.html#lectura-de-librerías",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Lectura de librerías",
    "text": "Lectura de librerías\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)   # Datos de la aplicación"
  },
  {
    "objectID": "p1c2-app1b.html#lectura-de-datos",
    "href": "p1c2-app1b.html#lectura-de-datos",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Lectura de datos",
    "text": "Lectura de datos\n\ndata(\"penguins\")\ndf &lt;- penguins\ndf %&gt;%\n  head()\n\n# A tibble: 6 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "p1c2-app1b.html#análisis-exploratorio",
    "href": "p1c2-app1b.html#análisis-exploratorio",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Análisis exploratorio",
    "text": "Análisis exploratorio\nRecuento de casos:\nRecuento de los NAs en cada columna\n\ndf %&gt;%\n  summarize(across(.cols = everything(),\n                   ~sum(is.na(.x)))) %&gt;%\n  pivot_longer(cols = everything())\n\n# A tibble: 8 × 2\n  name              value\n  &lt;chr&gt;             &lt;int&gt;\n1 species               0\n2 island                0\n3 bill_length_mm        2\n4 bill_depth_mm         2\n5 flipper_length_mm     2\n6 body_mass_g           2\n7 sex                  11\n8 year                  0\n\n\nPara eliminar todas las filas con un NA habría que ejecutar el siguiente código\n\n# df &lt;- df %&gt;% na.omit()\n\nNúmero de especies\n\ndf %&gt;%\n  count(species, sort = TRUE)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Gentoo      124\n3 Chinstrap    68\n\n\nNúmero de islas\n\ndf %&gt;%\n  count(island, sort = TRUE)\n\n# A tibble: 3 × 2\n  island        n\n  &lt;fct&gt;     &lt;int&gt;\n1 Biscoe      168\n2 Dream       124\n3 Torgersen    52\n\n\nNúmero de especies en cada isla\n\ndf %&gt;%\n  count(species, island, sort = TRUE)\n\n# A tibble: 5 × 3\n  species   island        n\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;\n1 Gentoo    Biscoe      124\n2 Chinstrap Dream        68\n3 Adelie    Dream        56\n4 Adelie    Torgersen    52\n5 Adelie    Biscoe       44\n\n\nTabla 3x3 de recuento de especies por isla\n\ntable(species = df$species,\n      island = df$island)\n\n           island\nspecies     Biscoe Dream Torgersen\n  Adelie        44    56        52\n  Chinstrap      0    68         0\n  Gentoo       124     0         0\n\n\nTabla 3x3 de proporciones de especies por isla\n\ntable(species = df$species,\n      island = df$island) / nrow(df)\n\n           island\nspecies        Biscoe     Dream Torgersen\n  Adelie    0.1279070 0.1627907 0.1511628\n  Chinstrap 0.0000000 0.1976744 0.0000000\n  Gentoo    0.3604651 0.0000000 0.0000000\n\n\nGráfico de barras de especies\n\ndf %&gt;%\n  count(species, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(species, -n), y = n)) +\n  geom_col(aes(fill = species)) +\n  xlab('species')\n\n\n\n\nDescripción de todas la columnas de la base de datos\n\nsummary(df)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nCálculo de la media de la longitud y la profundidad del pico\n\ndf %&gt;%\n  select(bill_length_mm, bill_depth_mm) %&gt;%\n  summarize(across(.cols = everything(),\n                   ~mean(.x, na.rm = TRUE)))\n\n# A tibble: 1 × 2\n  bill_length_mm bill_depth_mm\n           &lt;dbl&gt;         &lt;dbl&gt;\n1           43.9          17.2\n\n\nCálculo de los cuantiles 25, 50 y 75 para la longitud y profundidad del pico en la Isla Biscoe\n\ndf %&gt;%\n  filter(island == \"Biscoe\") %&gt;%\n  select(bill_length_mm, bill_depth_mm) %&gt;%\n  summarize(length25 = quantile(bill_length_mm, probs = 0.25, na.rm = TRUE),\n            length50 = quantile(bill_length_mm, probs = 0.50, na.rm = TRUE),\n            length75 = quantile(bill_length_mm, probs = 0.75, na.rm = TRUE),\n            depth25 = quantile(bill_depth_mm, probs = 0.25, na.rm = TRUE),\n            depth50 = quantile(bill_depth_mm, probs = 0.50, na.rm = TRUE),\n            depth75 = quantile(bill_depth_mm, probs = 0.75, na.rm = TRUE))\n\n# A tibble: 1 × 6\n  length25 length50 length75 depth25 depth50 depth75\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1       42     45.8     48.7    14.5    15.5      17\n\n\nDiagrama de cajas (boxplot) vertical de la longitud del pico por especie\n\ndf %&gt;%\n  ggplot(aes(x = species, y = bill_length_mm, fill = species)) +\n  geom_boxplot()\n\n\n\n\nBoxplot horizontal\n\ndf %&gt;%\n  ggplot(aes(x = bill_length_mm, y = species, fill = species)) +\n  geom_boxplot()\n\n\n\n\nDensidad estimada de la longitud del pico agrupada por sexo\n\ndf %&gt;%\n  na.omit() %&gt;%\n  ggplot(aes(x = bill_length_mm, fill = sex)) +\n  geom_density(alpha = 0.4)\n\n\n\n\ncon facetas por especie\n\ndf %&gt;%\n  na.omit() %&gt;%\n  ggplot(aes(x = bill_length_mm, fill = sex)) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~species)\n\n\n\n\nDiagrama de dispersión de la masa corporal en relación con la longitud de las aletas\n\ndf %&gt;%\n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point()\n\n\n\n\ncon línea de regresión añadida\n\ndf %&gt;%\n  ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\nDiferenciado por sexo\n\ndf %&gt;%\n  ggplot(aes(x = flipper_length_mm, y = body_mass_g,\n             color = sex)) +\n  geom_point()\n\n\n\n\ncon línea de regresión añadida\n\ndf %&gt;%\n  filter(!is.na(sex)) %&gt;%\n  ggplot(aes(x = flipper_length_mm, y = body_mass_g,\n             color = sex)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\nVariación de la masa corporal media a lo largo de los años por especie\n\ndf %&gt;%\n  group_by(species, year) %&gt;%\n  summarize(N = n(),\n            avg = mean(body_mass_g, na.rm = TRUE),\n            SE = sd(body_mass_g, na.rm = TRUE) / sqrt(N),\n            .groups = \"drop\") %&gt;%\n  ggplot(aes(x = year, y = avg)) +\n  geom_ribbon(aes(ymin = avg - SE, ymax = avg + SE,\n                  fill = species),\n              alpha = 0.3) +\n  geom_line(aes(color = species))"
  },
  {
    "objectID": "p1c2-app1b.html#agrupación---resumen",
    "href": "p1c2-app1b.html#agrupación---resumen",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Agrupación - resumen",
    "text": "Agrupación - resumen\nMedia y desviación estándar de la longitud del pico para cada especie\n\ndf %&gt;%\n  group_by(species) %&gt;%\n  summarize(avg_bill_length = mean(bill_length_mm, na.rm = TRUE),\n            sd_bill_length = sd(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 3 × 3\n  species   avg_bill_length sd_bill_length\n  &lt;fct&gt;               &lt;dbl&gt;          &lt;dbl&gt;\n1 Adelie               38.8           2.66\n2 Chinstrap            48.8           3.34\n3 Gentoo               47.5           3.08\n\n\nMedia y desviación estándar de la longitud del pico de cada especie por sexo\n\ndf %&gt;%\n  filter(!is.na(sex)) %&gt;%\n  group_by(species, sex) %&gt;%\n  summarize(avg_bill_length = mean(bill_length_mm, na.rm = TRUE),\n            sd_bill_length = sd(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 6 × 4\n# Groups:   species [3]\n  species   sex    avg_bill_length sd_bill_length\n  &lt;fct&gt;     &lt;fct&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 Adelie    female            37.3           2.03\n2 Adelie    male              40.4           2.28\n3 Chinstrap female            46.6           3.11\n4 Chinstrap male              51.1           1.56\n5 Gentoo    female            45.6           2.05\n6 Gentoo    male              49.5           2.72"
  },
  {
    "objectID": "p1c2-app1b.html#agrupación---cálculo",
    "href": "p1c2-app1b.html#agrupación---cálculo",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Agrupación - cálculo",
    "text": "Agrupación - cálculo\nAñadir una nueva columna al fichero de datos que muestre la longitud media de las aletas agrupadas por especies\n\ndf &lt;- df %&gt;%\n  group_by(species) %&gt;%\n  mutate(mean_flipper_length = mean(flipper_length_mm, na.rm = TRUE))\n\ndf %&gt;%\n  head()\n\n# A tibble: 6 × 9\n# Groups:   species [1]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 3 more variables: sex &lt;fct&gt;, year &lt;int&gt;, mean_flipper_length &lt;dbl&gt;\n\n\nPuntuación estandarizada (z-score) por especie para la longitud de las aletas\n\ndf &lt;- df %&gt;%\n  group_by(species) %&gt;%\n  mutate(flipper_z = (flipper_length_mm - mean(flipper_length_mm, na.rm = TRUE)) / sd(flipper_length_mm, na.rm = TRUE))\ndf %&gt;%\n  head()\n\n# A tibble: 6 × 10\n# Groups:   species [1]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, mean_flipper_length &lt;dbl&gt;,\n#   flipper_z &lt;dbl&gt;\n\n\nAñadir una columna para la media y la desviación estándar por especie para la longitud del pico\n\ndf &lt;- df %&gt;%\n  group_by(species) %&gt;%\n  mutate(mean_val = mean(bill_length_mm, na.rm = TRUE),\n         sd_val = sd(bill_length_mm, na.rm = TRUE))\n\ndf %&gt;%\n  head()\n\n# A tibble: 6 × 12\n# Groups:   species [1]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 6 more variables: sex &lt;fct&gt;, year &lt;int&gt;, mean_flipper_length &lt;dbl&gt;,\n#   flipper_z &lt;dbl&gt;, mean_val &lt;dbl&gt;, sd_val &lt;dbl&gt;"
  },
  {
    "objectID": "p1c2-app1b.html#comandos-ifelse-case_when",
    "href": "p1c2-app1b.html#comandos-ifelse-case_when",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Comandos ifelse / case_when",
    "text": "Comandos ifelse / case_when\nCrear una nueva columna que codifique las islas como: Biscoe = Isla1 Sueño = Isla2 Torgersen = Isla3\n\ndf &lt;- df %&gt;%\n  mutate(island_code = case_when(island == \"Biscoe\" ~ \"Island1\",\n                                 island == \"Dream\" ~ \"Island2\",\n                                 island == \"Torgersen\" ~ \"Island3\"))\ndf %&gt;%\n  head()\n\n# A tibble: 6 × 13\n# Groups:   species [1]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 7 more variables: sex &lt;fct&gt;, year &lt;int&gt;, mean_flipper_length &lt;dbl&gt;,\n#   flipper_z &lt;dbl&gt;, mean_val &lt;dbl&gt;, sd_val &lt;dbl&gt;, island_code &lt;chr&gt;"
  },
  {
    "objectID": "p1c2-app1b.html#lectura-de-librerías-1",
    "href": "p1c2-app1b.html#lectura-de-librerías-1",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Lectura de librerías",
    "text": "Lectura de librerías\n\nimport numpy as np \nimport pandas as pd                       \nimport matplotlib.pyplot as plt         \nimport seaborn as sns\nfrom palmerpenguins import load_penguins   # Datos de la aplicación"
  },
  {
    "objectID": "p1c2-app1b.html#lectura-de-datos-1",
    "href": "p1c2-app1b.html#lectura-de-datos-1",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Lectura de datos",
    "text": "Lectura de datos\n\ndf = load_penguins()\ndf.head()\n\n  species     island  bill_length_mm  ...  body_mass_g     sex  year\n0  Adelie  Torgersen            39.1  ...       3750.0    male  2007\n1  Adelie  Torgersen            39.5  ...       3800.0  female  2007\n2  Adelie  Torgersen            40.3  ...       3250.0  female  2007\n3  Adelie  Torgersen             NaN  ...          NaN     NaN  2007\n4  Adelie  Torgersen            36.7  ...       3450.0  female  2007\n\n[5 rows x 8 columns]"
  },
  {
    "objectID": "p1c2-app1b.html#análisis-exploratorio-1",
    "href": "p1c2-app1b.html#análisis-exploratorio-1",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Análisis exploratorio",
    "text": "Análisis exploratorio\nRecuento de casos:\nRecuento de los NAs en cada columna\n\ndf.isnull().any()\n\nspecies              False\nisland               False\nbill_length_mm        True\nbill_depth_mm         True\nflipper_length_mm     True\nbody_mass_g           True\nsex                   True\nyear                 False\ndtype: bool\n\nlen(df) - df.count()\n\nspecies               0\nisland                0\nbill_length_mm        2\nbill_depth_mm         2\nflipper_length_mm     2\nbody_mass_g           2\nsex                  11\nyear                  0\ndtype: int64\n\n\nPara eliminar todas las filas con un NA habría que ejecutar el siguiente código\n\n# df = df.dropna()\n\nNúmero de especies\n\ndf['species'].value_counts()\n\nAdelie       152\nGentoo       124\nChinstrap     68\nName: species, dtype: int64\n\n\nNúmero de islas\n\ndf['island'].value_counts()\n\nBiscoe       168\nDream        124\nTorgersen     52\nName: island, dtype: int64\n\n\nNúmero de especies en cada isla\n\ndf[['species', 'island']].value_counts()\n\nspecies    island   \nGentoo     Biscoe       124\nChinstrap  Dream         68\nAdelie     Dream         56\n           Torgersen     52\n           Biscoe        44\ndtype: int64\n\n\nTabla 3x3 de recuento de especies por isla\n\npd.crosstab(df['species'], df['island'])\n\nisland     Biscoe  Dream  Torgersen\nspecies                            \nAdelie         44     56         52\nChinstrap       0     68          0\nGentoo        124      0          0\n\n\nTabla 3x3 de proporciones de especies por isla\n\npd.crosstab(df['species'], df['island']) / len(df)\n\nisland       Biscoe     Dream  Torgersen\nspecies                                 \nAdelie     0.127907  0.162791   0.151163\nChinstrap  0.000000  0.197674   0.000000\nGentoo     0.360465  0.000000   0.000000\n\n\nGráfico de barras de especies\n\nsns.countplot(x = 'species', data = df);\nplt.show()\n\n\n\n\nDescripción de todas la columnas de la base de datos\n\ndf.describe()\n\n       bill_length_mm  bill_depth_mm  ...  body_mass_g         year\ncount      342.000000     342.000000  ...   342.000000   344.000000\nmean        43.921930      17.151170  ...  4201.754386  2008.029070\nstd          5.459584       1.974793  ...   801.954536     0.818356\nmin         32.100000      13.100000  ...  2700.000000  2007.000000\n25%         39.225000      15.600000  ...  3550.000000  2007.000000\n50%         44.450000      17.300000  ...  4050.000000  2008.000000\n75%         48.500000      18.700000  ...  4750.000000  2009.000000\nmax         59.600000      21.500000  ...  6300.000000  2009.000000\n\n[8 rows x 5 columns]\n\n\nCálculo de la media de la longitud y la profundidad del pico\n\ndf[['bill_length_mm', 'bill_depth_mm']].mean()\n\nbill_length_mm    43.92193\nbill_depth_mm     17.15117\ndtype: float64\n\n\nCálculo de los cuantiles 25, 50 y 75 para la longitud y profundidad del pico en la Isla Biscoe\n\ndf.loc[df['island'] == 'Biscoe', ['bill_length_mm', 'bill_depth_mm']].quantile([0.25, 0.5, 0.75])\n\n      bill_length_mm  bill_depth_mm\n0.25            42.0           14.5\n0.50            45.8           15.5\n0.75            48.7           17.0\n\n\nBoxplot vertical de la longitud del pico por especie\n\nsns.boxplot(x = 'species', y = 'bill_length_mm', data = df, orient = 'v', palette = 'rainbow');\nplt.show()\n\n\n\n\nBoxplot horizontal\n\nsns.boxplot(x = 'bill_length_mm', y = 'species', data = df, orient = 'h', palette = 'rainbow');\nplt.show()\n\n\n\n\nDensidad estimada de la longitud del pico agrupada por sexo\n\nsns.displot(x = 'bill_length_mm', \n            data = df,\n            kind = 'kde',\n            hue = 'sex',\n            fill = True);\nplt.show()\n\n\n\n\ncon facetas por especie\n\nsns.displot(x = 'bill_length_mm', \n            data = df,\n            kind = 'kde',\n            hue = 'sex',\n            col = 'species', \n            fill = True);\nplt.show()\n\n\n\n\nDiagrama de dispersión de la masa corporal en relación con la longitud de las aletas\n\nsns.relplot(x = 'flipper_length_mm', y = 'body_mass_g', data = df);\nplt.show()\n\n\n\n\ncon línea de regresión añadida\n\nsns.lmplot(x = 'flipper_length_mm', y = 'body_mass_g', data = df);\nplt.show()\n\n\n\n\nDiferenciado por sexo\n\nsns.relplot(x = 'flipper_length_mm', y = 'body_mass_g', data = df, hue = 'sex');\nplt.show()\n\n\n\n\ny con línea de regresión añadida\n\nsns.lmplot(x = 'flipper_length_mm', y = 'body_mass_g', data = df, hue = 'sex');\nplt.show()\n\n\n\n\nVariación de la masa corporal media a lo largo de los años por especie\n\nsns.relplot(x = 'year', y = 'body_mass_g', kind = 'line',\n           hue = 'species', data = df);\nplt.show()"
  },
  {
    "objectID": "p1c2-app1b.html#agrupación---resumen-1",
    "href": "p1c2-app1b.html#agrupación---resumen-1",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Agrupación - resumen",
    "text": "Agrupación - resumen\nMedia y desviación estándar de la longitud del pico para cada especie\n\nspecies_bill_length = (df\n           .groupby('species')\n           .agg(avg_bill_length = ('bill_length_mm', 'mean'),\n               sd_bill_length = ('bill_length_mm', 'std')).round(1)\n           .reset_index())\nspecies_bill_length\n\n     species  avg_bill_length  sd_bill_length\n0     Adelie             38.8             2.7\n1  Chinstrap             48.8             3.3\n2     Gentoo             47.5             3.1\n\n\nMedia y desviación estándar de la longitud del pico de cada especie por sexo\n\nspecies_bill_length_sex = (df\n           .groupby(['species', 'sex'])\n           .agg(avg_bill_length = ('bill_length_mm', 'mean'),\n               sd_bill_length = ('bill_length_mm', 'std')).round(1)\n           .reset_index())\nspecies_bill_length_sex\n\n     species     sex  avg_bill_length  sd_bill_length\n0     Adelie  female             37.3             2.0\n1     Adelie    male             40.4             2.3\n2  Chinstrap  female             46.6             3.1\n3  Chinstrap    male             51.1             1.6\n4     Gentoo  female             45.6             2.1\n5     Gentoo    male             49.5             2.7"
  },
  {
    "objectID": "p1c2-app1b.html#agrupación---cálculo-1",
    "href": "p1c2-app1b.html#agrupación---cálculo-1",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Agrupación - cálculo",
    "text": "Agrupación - cálculo\nAñadir una nueva columna al fichero de datos que muestre la longitud media de las aletas agrupadas por especies\n\ndf['mean_flipper_length'] = df.groupby('species')['flipper_length_mm'].transform('mean')\ndf.head()\n\n  species     island  bill_length_mm  ...     sex  year  mean_flipper_length\n0  Adelie  Torgersen            39.1  ...    male  2007           189.953642\n1  Adelie  Torgersen            39.5  ...  female  2007           189.953642\n2  Adelie  Torgersen            40.3  ...  female  2007           189.953642\n3  Adelie  Torgersen             NaN  ...     NaN  2007           189.953642\n4  Adelie  Torgersen            36.7  ...  female  2007           189.953642\n\n[5 rows x 9 columns]\n\n\nPuntuación estandarizada (z-score) por especie para la longitud de las aletas\n\ndf['flipper_z'] = df.groupby('species')['flipper_length_mm'].transform(lambda x: (x - x.mean()) / x.std()).round(2)\ndf.head()\n\n  species     island  bill_length_mm  ...  year  mean_flipper_length  flipper_z\n0  Adelie  Torgersen            39.1  ...  2007           189.953642      -1.37\n1  Adelie  Torgersen            39.5  ...  2007           189.953642      -0.60\n2  Adelie  Torgersen            40.3  ...  2007           189.953642       0.77\n3  Adelie  Torgersen             NaN  ...  2007           189.953642        NaN\n4  Adelie  Torgersen            36.7  ...  2007           189.953642       0.47\n\n[5 rows x 10 columns]\n\n\nAñadir una columna para la media y la desviación estándar por especie para la longitud del pico\n\ndf = df.assign(\n    mean_val = df.groupby([\"species\"]).bill_length_mm.transform('mean'),\n    sd_val = df.groupby([\"species\"]).bill_length_mm.transform('std'))\ndf.head()\n\n  species     island  bill_length_mm  ...  flipper_z   mean_val    sd_val\n0  Adelie  Torgersen            39.1  ...      -1.37  38.791391  2.663405\n1  Adelie  Torgersen            39.5  ...      -0.60  38.791391  2.663405\n2  Adelie  Torgersen            40.3  ...       0.77  38.791391  2.663405\n3  Adelie  Torgersen             NaN  ...        NaN  38.791391  2.663405\n4  Adelie  Torgersen            36.7  ...       0.47  38.791391  2.663405\n\n[5 rows x 12 columns]"
  },
  {
    "objectID": "p1c2-app1b.html#comandos-def-where",
    "href": "p1c2-app1b.html#comandos-def-where",
    "title": "Aplicación 1.1.b (Gestión y representación gráfica de datos): Gestión de datos con R y Python",
    "section": "Comandos def / where",
    "text": "Comandos def / where\nCrear una nueva columna que codifique las islas como: Biscoe = Isla1 Sueño = Isla2 Torgersen = Isla3\n\n# def\ndef islad_transform(island):\n if island == 'Biscoe':\n  return 'Island1'\n if island == 'Dream':\n  return 'Island2'\n if island == 'Torgersen':\n  return 'Island3'\ndf[\"island_code\"] = df[\"island\"].map(lambda x: islad_transform(x))\ndf.head()\n\n  species     island  bill_length_mm  ...   mean_val    sd_val  island_code\n0  Adelie  Torgersen            39.1  ...  38.791391  2.663405      Island3\n1  Adelie  Torgersen            39.5  ...  38.791391  2.663405      Island3\n2  Adelie  Torgersen            40.3  ...  38.791391  2.663405      Island3\n3  Adelie  Torgersen             NaN  ...  38.791391  2.663405      Island3\n4  Adelie  Torgersen            36.7  ...  38.791391  2.663405      Island3\n\n[5 rows x 13 columns]\n\n\n\n# numpy\ndf['island_code2'] = np.where(df['island'] == 'Biscoe', 'Island1',\n                        (np.where(df['island'] == 'Dream', 'Island2', 'Island3')))\ndf.head()\n\n  species     island  bill_length_mm  ...    sd_val  island_code  island_code2\n0  Adelie  Torgersen            39.1  ...  2.663405      Island3       Island3\n1  Adelie  Torgersen            39.5  ...  2.663405      Island3       Island3\n2  Adelie  Torgersen            40.3  ...  2.663405      Island3       Island3\n3  Adelie  Torgersen             NaN  ...  2.663405      Island3       Island3\n4  Adelie  Torgersen            36.7  ...  2.663405      Island3       Island3\n\n[5 rows x 14 columns]"
  },
  {
    "objectID": "p1c2-app2a.html#código-r",
    "href": "p1c2-app2a.html#código-r",
    "title": "Aplicación 1.2a (Gestión y representación gráfica de datos financieros): Propiedades estadísticas básicas de los activos bursátiles",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(scales)\n#\n# Descarga de los datos de un activo bursátil desde Yahoo!Finanzas\n#\n# Para acceder a los datos diarios del precio de las acciones \n# se usa el comando tq_get de la librería tidyquant.\n# Solicitaremos los datos del Banco Santander, S.A. (SAN.MC)\n# desde el año 2000 hasta la fecha de realización de esta aplicación:\n# https://es.finance.yahoo.com/quote/SAN.MC?p=SAN.MC&.tsrc=fin-srch\npSAN &lt;- tq_get(\"SAN.MC\",\n  get = \"stock.prices\",\n  from = \"2000-01-01\",\n  to = \"2023-10-31\"\n)\nhead(pSAN)\n\n# A tibble: 6 × 8\n  symbol date        open  high   low close  volume adjusted\n  &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 SAN.MC 2000-01-03  9.95  9.99  9.74  9.85 8797337     2.60\n2 SAN.MC 2000-01-04  9.73  9.78  9.53  9.62 8811013     2.54\n3 SAN.MC 2000-01-05  9.43  9.56  9.30  9.38 9333517     2.48\n4 SAN.MC 2000-01-06  9.38  9.38  9.38  9.38       0     2.48\n5 SAN.MC 2000-01-07  9.45  9.82  9.44  9.80 9603132     2.59\n6 SAN.MC 2000-01-10  9.88  9.88  9.62  9.71 6747710     2.57\n\ntail(pSAN)\n\n# A tibble: 6 × 8\n  symbol date        open  high   low close    volume adjusted\n  &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 SAN.MC 2023-10-23  3.46  3.47  3.39  3.42 178180697     3.34\n2 SAN.MC 2023-10-24  3.44  3.44  3.35  3.38 170601157     3.30\n3 SAN.MC 2023-10-25  3.40  3.50  3.35  3.46  87290373     3.38\n4 SAN.MC 2023-10-26  3.44  3.52  3.41  3.51  32176659     3.43\n5 SAN.MC 2023-10-27  3.55  3.56  3.46  3.48  53188968     3.40\n6 SAN.MC 2023-10-30  3.5   3.58  3.47  3.57  70729714     3.49\n\n# Gráfica de serie temporal: evolución temporal de los precios\npSAN |&gt;\n  ggplot(aes(x = date, y = adjusted)) +\n  geom_line() +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Precio de las acciones del Banco Santander desde el año 2000 (EUR)\"\n  )\n\n\n\n# Cálculo de los rendimientos netos diarios (returns)\nrSAN &lt;- pSAN |&gt;\n  arrange(date) |&gt;\n  mutate(ret = adjusted / lag(adjusted) - 1) |&gt;\n  select(symbol, date, ret)\nhead(rSAN)\n\n# A tibble: 6 × 3\n  symbol date            ret\n  &lt;chr&gt;  &lt;date&gt;        &lt;dbl&gt;\n1 SAN.MC 2000-01-03 NA      \n2 SAN.MC 2000-01-04 -0.0237 \n3 SAN.MC 2000-01-05 -0.0243 \n4 SAN.MC 2000-01-06  0      \n5 SAN.MC 2000-01-07  0.0443 \n6 SAN.MC 2000-01-10 -0.00883\n\ntail(rSAN)\n\n# A tibble: 6 × 3\n  symbol date            ret\n  &lt;chr&gt;  &lt;date&gt;        &lt;dbl&gt;\n1 SAN.MC 2023-10-23 -0.0101 \n2 SAN.MC 2023-10-24 -0.0117 \n3 SAN.MC 2023-10-25  0.0235 \n4 SAN.MC 2023-10-26  0.0144 \n5 SAN.MC 2023-10-27 -0.00854\n6 SAN.MC 2023-10-30  0.0254 \n\n# Eliminación de datos perdidos (missing data)\nrSAN &lt;- rSAN |&gt;\n  drop_na(ret)\n# Evolución temporal de las rentabilidades diarias\nrSAN |&gt;\n  ggplot(aes(x = date, y = ret)) +\n  geom_line() +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Rendimiento diario de las acciones del Banco Santarder\"\n  )\n\n\n\n# Distribución de los rendimientos diarios (detección de asimetrías)\nq5 &lt;- quantile(rSAN |&gt; pull(ret), probs = 0.05)\nq95 &lt;- quantile(rSAN |&gt; pull(ret), probs = 0.95)\nrSAN |&gt;\n  ggplot(aes(x = ret)) +\n  geom_histogram(bins = 100) +\n  geom_vline(aes(xintercept = q5), linetype = \"dashed\") +\n  geom_vline(aes(xintercept = q95), linetype = \"dashed\") +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Distribución de los rendimientos diarios del Banco Santander\"\n  ) +\n  scale_x_continuous(labels = percent)\n\n\n\n# Estadística resumen global\nrSAN |&gt;\n  summarize(across(\n    ret,\n    list(\n      media = mean,\n      desv_típica = sd,\n      mínimo = min,\n      máximo = max\n    )\n  ))\n\n# A tibble: 1 × 4\n  ret_media ret_desv_típica ret_mínimo ret_máximo\n      &lt;dbl&gt;           &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1  0.000291          0.0222     -0.199      0.232\n\n# Estadística resumen por año\nrSAN |&gt;\n  group_by(year = year(date)) |&gt;\n  summarize(across(\n    ret,\n    list(\n      media = mean,\n      desv_típica = sd,\n      mínimo = min,\n      máximo = max\n    ),\n    .names = \"{.fn}\"\n  )) |&gt;\n  print(n = Inf)\n\n# A tibble: 24 × 5\n    year      media desv_típica  mínimo máximo\n   &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1  2000  0.000424      0.0230  -0.0686 0.0909\n 2  2001 -0.000279      0.0252  -0.0988 0.101 \n 3  2002 -0.000757      0.0313  -0.107  0.0943\n 4  2003  0.00176       0.0209  -0.0558 0.0899\n 5  2004  0.000135      0.0115  -0.0442 0.0357\n 6  2005  0.000948      0.00885 -0.0313 0.0356\n 7  2006  0.00113       0.0110  -0.0348 0.0345\n 8  2007  0.000419      0.0132  -0.0440 0.0415\n 9  2008 -0.00200       0.0341  -0.119  0.143 \n10  2009  0.00295       0.0290  -0.0816 0.134 \n11  2010 -0.000833      0.0286  -0.0940 0.232 \n12  2011 -0.000516      0.0239  -0.0833 0.0956\n13  2012  0.000911      0.0241  -0.0732 0.107 \n14  2013  0.000795      0.0164  -0.0570 0.0516\n15  2014  0.000704      0.0141  -0.0403 0.0378\n16  2015 -0.00121       0.0206  -0.141  0.0593\n17  2016  0.000917      0.0278  -0.199  0.0758\n18  2017  0.000698      0.0140  -0.0383 0.0582\n19  2018 -0.00109       0.0137  -0.0543 0.0373\n20  2019  0.0000873     0.0154  -0.0429 0.0429\n21  2020 -0.000491      0.0362  -0.169  0.192 \n22  2021  0.000852      0.0192  -0.0892 0.0687\n23  2022  0.000216      0.0221  -0.0769 0.0725\n24  2023  0.00140       0.0191  -0.0735 0.0573"
  },
  {
    "objectID": "p1c2-app2a.html#código-python",
    "href": "p1c2-app2a.html#código-python",
    "title": "Aplicación 1.2a (Gestión y representación gráfica de datos financieros): Propiedades estadísticas básicas de los activos bursátiles",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom plotnine import *\nfrom datetime import datetime\nfrom mizani.formatters import percent_format\nimport yfinance as yf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n#\n# Descarga de los datos diarios del precio de las acciones del Santander\n#\n# Creación del ticker del Banco Santander\nSAN = yf.Ticker(\"SAN.MC\")\n# Lectura de los datos para el período seleccionado\npSAN = yf.download(\"SAN.MC\", start=\"2000-01-01\", end=\"2023-10-31\")\n\n\n[*********************100%%**********************]  1 of 1 completed\n\nprint(pSAN)\n\n                Open      High       Low     Close  Adj Close     Volume\nDate                                                                    \n2000-01-03  9.953261  9.987881  9.736886  9.849401   2.603298    8797337\n2000-01-04  9.728231  9.780161  9.529166  9.615716   2.541532    8811013\n2000-01-05  9.433961  9.555131  9.304136  9.382031   2.479768    9333517\n2000-01-06  9.382031  9.382031  9.382031  9.382031   2.479768          0\n2000-01-07  9.451271  9.823436  9.442616  9.797471   2.589572    9603132\n...              ...       ...       ...       ...        ...        ...\n2023-10-24  3.441000  3.442500  3.352500  3.381500   3.304766  170601157\n2023-10-25  3.400500  3.501500  3.345000  3.461000   3.382462   87290373\n2023-10-26  3.440000  3.520000  3.405500  3.511000   3.431327   32176659\n2023-10-27  3.545000  3.563000  3.457500  3.481000   3.402008   53188968\n2023-10-30  3.500000  3.576500  3.471500  3.569500   3.488500   70729714\n\n[6123 rows x 6 columns]\n\npSAN = (pSAN.reset_index())\npSAN.head()\n\n        Date      Open      High       Low     Close  Adj Close   Volume\n0 2000-01-03  9.953261  9.987881  9.736886  9.849401   2.603298  8797337\n1 2000-01-04  9.728231  9.780161  9.529166  9.615716   2.541532  8811013\n2 2000-01-05  9.433961  9.555131  9.304136  9.382031   2.479768  9333517\n3 2000-01-06  9.382031  9.382031  9.382031  9.382031   2.479768        0\n4 2000-01-07  9.451271  9.823436  9.442616  9.797471   2.589572  9603132\n\npSAN.tail()\n\n           Date    Open    High     Low   Close  Adj Close     Volume\n6118 2023-10-24  3.4410  3.4425  3.3525  3.3815   3.304766  170601157\n6119 2023-10-25  3.4005  3.5015  3.3450  3.4610   3.382462   87290373\n6120 2023-10-26  3.4400  3.5200  3.4055  3.5110   3.431327   32176659\n6121 2023-10-27  3.5450  3.5630  3.4575  3.4810   3.402008   53188968\n6122 2023-10-30  3.5000  3.5765  3.4715  3.5695   3.488500   70729714\n\n# Gráfica de serie temporal: evolución temporal de los precios\n(\n  ggplot(pSAN, aes(y=\"Adj Close\", x=\"Date\")) \n  + geom_line() \n  + labs(x=\"\", y=\"\", title=\"Precio de las acciones del Banco Santander desde el año 2000 (EUR)\")\n)\n\n&lt;ggplot: (322842294)&gt;\n\n\n\n\n# Cálculo de los rendimientos netos diarios\ndef ret(x):\n    x_change = (x/x.shift(1)-1)\n    return x_change\npSAN['ret'] = ret(pSAN['Adj Close'])\npSAN['ret']\n\n0            NaN\n1      -0.023726\n2      -0.024302\n3       0.000000\n4       0.044280\n          ...   \n6118   -0.011691\n6119    0.023510\n6120    0.014447\n6121   -0.008545\n6122    0.025424\nName: ret, Length: 6123, dtype: float64\n\n# Cálculo alternativo de la rentabilidad diaria\nret2 = (pSAN\n  .sort_values(\"Date\")\n  .assign(ret2 = lambda x: x[\"Adj Close\"].pct_change())\n  .get([\"Date\", \"ret2\"])\n)\nret2.head()\n\n        Date      ret2\n0 2000-01-03       NaN\n1 2000-01-04 -0.023726\n2 2000-01-05 -0.024302\n3 2000-01-06  0.000000\n4 2000-01-07  0.044280\n\n# Eliminación de datos perdidos (missing data)\npSAN = pSAN.dropna()\n# Evolución temporal de las rentabilidades diarias\n(\n  ggplot(pSAN, aes(y=\"ret\", x=\"Date\"))\n + geom_line()\n + labs(x=\"\", y=\"\", title=\"Rendimiento diario de las acciones del Banco Santarder\")\n)\n\n&lt;ggplot: (322911833)&gt;\n\n\n\n\n# Distribución de los rendimientos diarios (detección de asimetrías)\nq5 = pSAN[\"ret\"].quantile(0.05)\nq95 = pSAN[\"ret\"].quantile(0.95)\n(\n  ggplot(pSAN, aes(x=\"ret\"))\n + geom_histogram(bins=100)\n + geom_vline(aes(xintercept=q5), linetype=\"dashed\")\n + geom_vline(aes(xintercept=q95), linetype=\"dashed\")\n + labs(x=None, y=None, title=\"Distribución de los rendimientos diarios del Banco Santander\")\n + scale_x_continuous(labels=percent_format())\n)\n\n&lt;ggplot: (322950631)&gt;\n\n\n\n\n# Estadística resumen global\npSAN[\"ret\"].describe()\n\ncount    6122.000000\nmean        0.000295\nstd         0.022250\nmin        -0.198864\n25%        -0.010764\n50%         0.000000\n75%         0.010888\nmax         0.232166\nName: ret, dtype: float64\n\n# Selección de estadísticos y precisión\nest_res = pSAN['ret'].agg({\n    'media': 'mean',\n    'desv_típica': 'std',\n    'mínimo': 'min',\n    'máximo': 'max'\n})\nest_res.round(4)\n\nmedia          0.0003\ndesv_típica    0.0222\nmínimo        -0.1989\nmáximo         0.2322\nName: ret, dtype: float64\n\n# Estadística resumen por año\npSAN[\"ret\"].groupby(pSAN[\"Date\"].dt.year).describe()\n\n      count      mean       std  ...       50%       75%       max\nDate                             ...                              \n2000  259.0  0.000424  0.022951  ...  0.000000  0.014402  0.090854\n2001  261.0 -0.000279  0.025248  ...  0.000000  0.014374  0.101011\n2002  261.0 -0.000757  0.031266  ...  0.000000  0.015038  0.094340\n2003  261.0  0.001760  0.020850  ...  0.000000  0.011713  0.089888\n2004  262.0  0.000135  0.011547  ...  0.000000  0.006670  0.035714\n2005  260.0  0.000948  0.008852  ...  0.000923  0.005877  0.035646\n2006  255.0  0.001134  0.010973  ...  0.001440  0.008154  0.034546\n2007  255.0  0.000419  0.013181  ...  0.000697  0.008081  0.041507\n2008  254.0 -0.002003  0.034099  ... -0.002576  0.013783  0.143284\n2009  254.0  0.002950  0.028959  ...  0.003462  0.017250  0.133913\n2010  256.0 -0.000833  0.028594  ... -0.000615  0.011564  0.232166\n2011  257.0 -0.000516  0.023928  ... -0.001449  0.012061  0.095599\n2012  256.0  0.000911  0.024094  ...  0.001128  0.012814  0.106749\n2013  255.0  0.000795  0.016403  ...  0.000329  0.010241  0.051650\n2014  255.0  0.000704  0.014124  ...  0.000616  0.009475  0.037773\n2015  256.0 -0.001209  0.020640  ...  0.000304  0.009400  0.059319\n2016  257.0  0.000917  0.027789  ...  0.002039  0.015687  0.075822\n2017  255.0  0.000698  0.014017  ...  0.000866  0.008121  0.058201\n2018  254.0 -0.001001  0.013758  ... -0.001448  0.007173  0.037286\n2019  256.0  0.000087  0.015410  ... -0.001028  0.009087  0.042904\n2020  257.0 -0.000491  0.036154  ... -0.004403  0.019257  0.192221\n2021  256.0  0.000852  0.019230  ...  0.000943  0.012088  0.068725\n2022  257.0  0.000216  0.022138  ... -0.000956  0.013416  0.072488\n2023  213.0  0.001404  0.019096  ...  0.001115  0.014208  0.057257\n\n[24 rows x 8 columns]\n\n# Selección de estadísticos y precisión\npSAN['year'] = pSAN[\"Date\"].dt.year\nest_anual = pSAN.groupby('year').agg({'ret': ['mean', 'std', 'min', 'max']})\nest_anual.round(4)\n\n         ret                        \n        mean     std     min     max\nyear                                \n2000  0.0004  0.0230 -0.0686  0.0909\n2001 -0.0003  0.0252 -0.0988  0.1010\n2002 -0.0008  0.0313 -0.1074  0.0943\n2003  0.0018  0.0209 -0.0558  0.0899\n2004  0.0001  0.0115 -0.0442  0.0357\n2005  0.0009  0.0089 -0.0313  0.0356\n2006  0.0011  0.0110 -0.0348  0.0345\n2007  0.0004  0.0132 -0.0440  0.0415\n2008 -0.0020  0.0341 -0.1194  0.1433\n2009  0.0030  0.0290 -0.0816  0.1339\n2010 -0.0008  0.0286 -0.0940  0.2322\n2011 -0.0005  0.0239 -0.0833  0.0956\n2012  0.0009  0.0241 -0.0732  0.1067\n2013  0.0008  0.0164 -0.0570  0.0516\n2014  0.0007  0.0141 -0.0403  0.0378\n2015 -0.0012  0.0206 -0.1409  0.0593\n2016  0.0009  0.0278 -0.1989  0.0758\n2017  0.0007  0.0140 -0.0383  0.0582\n2018 -0.0010  0.0138 -0.0543  0.0373\n2019  0.0001  0.0154 -0.0429  0.0429\n2020 -0.0005  0.0362 -0.1686  0.1922\n2021  0.0009  0.0192 -0.0892  0.0687\n2022  0.0002  0.0221 -0.0769  0.0725\n2023  0.0014  0.0191 -0.0735  0.0573"
  },
  {
    "objectID": "p1c2-app2b.html#código-r",
    "href": "p1c2-app2b.html#código-r",
    "title": "Aplicación 1.2b (Gestión y representación gráfica de datos financieros): Relaciones entre activos bursátiles",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(scales)\n# Lectura de datos de las 30 mayores empresas del IBEX\n# (https://finance.yahoo.com/quote/%5EIBEX/components?p=%5EIBEX&guccounter=1)\nstock_data &lt;- read_csv(\"data/IBEX_top30.csv\")\nhead(stock_data)\n\n# A tibble: 6 × 10\n  `Unnamed: 0` symbol date        open  high   low close volume adjusted\n         &lt;dbl&gt; &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1            1 RED.MC 2000-01-03  1.52  1.54  1.48  1.49 775472    0.534\n2            2 RED.MC 2000-01-04  1.50  1.50  1.41  1.41 786100    0.506\n3            3 RED.MC 2000-01-05  1.41  1.49  1.40  1.43 702520    0.513\n4            5 RED.MC 2000-01-07  1.48  1.51  1.44  1.5  319884    0.538\n5            6 RED.MC 2000-01-10  1.51  1.52  1.50  1.5  256932    0.538\n6            7 RED.MC 2000-01-11  1.5   1.52  1.5   1.5  290704    0.538\n# ℹ 1 more variable: company_name &lt;chr&gt;\n\ntail(stock_data)\n\n# A tibble: 6 × 10\n  `Unnamed: 0` symbol date        open  high   low close  volume adjusted\n         &lt;dbl&gt; &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1       139424 COL.MC 2023-05-16  5.43  5.58  5.43  5.55 1078400     5.55\n2       139425 COL.MC 2023-05-17  5.59  5.59  5.43  5.51 1142307     5.51\n3       139426 COL.MC 2023-05-18  5.48  5.57  5.41  5.44  770970     5.44\n4       139427 COL.MC 2023-05-19  5.5   5.52  5.43  5.5   923489     5.5 \n5       139428 COL.MC 2023-05-22  5.5   5.54  5.47  5.52  663698     5.52\n6       139429 COL.MC 2023-05-23  5.55  5.68  5.55  5.65 1029332     5.65\n# ℹ 1 more variable: company_name &lt;chr&gt;\n\n# filter\nSAN &lt;- stock_data %&gt;% filter(symbol == \"SAN.MC\")\n# select\np_SAN &lt;- SAN %&gt;% select(date,adjusted)\nhead(p_SAN)\n\n# A tibble: 6 × 2\n  date       adjusted\n  &lt;date&gt;        &lt;dbl&gt;\n1 2000-01-03     2.66\n2 2000-01-04     2.60\n3 2000-01-05     2.54\n4 2000-01-06     2.54\n5 2000-01-07     2.65\n6 2000-01-10     2.63\n\ntail(p_SAN)\n\n# A tibble: 6 × 2\n  date       adjusted\n  &lt;date&gt;        &lt;dbl&gt;\n1 2023-05-16     3.14\n2 2023-05-17     3.16\n3 2023-05-18     3.18\n4 2023-05-19     3.20\n5 2023-05-22     3.23\n6 2023-05-23     3.22\n\n# Lectura de datos del índice IBEX \nIBEX &lt;- read_csv(\"data/IBEX.csv\")\n# select\np_IBEX &lt;- IBEX %&gt;% select(date,adjusted)\nhead(p_IBEX)\n\n# A tibble: 6 × 2\n  date       adjusted\n  &lt;date&gt;        &lt;dbl&gt;\n1 2000-01-03   11610.\n2 2000-01-04   11207.\n3 2000-01-05   10863.\n4 2000-01-07   11102.\n5 2000-01-10   11173.\n6 2000-01-11   11012.\n\ntail(p_IBEX)\n\n# A tibble: 6 × 2\n  date       adjusted\n  &lt;date&gt;        &lt;dbl&gt;\n1 2023-05-16    9191.\n2 2023-05-17    9212.\n3 2023-05-18    9213.\n4 2023-05-19    9252.\n5 2023-05-22    9305 \n6 2023-05-23    9267 \n\n# join\ndata_daily &lt;- inner_join(p_IBEX,p_SAN, by = \"date\") %&gt;% rename(pIBEX = adjusted.x, pSAN = adjusted.y)\n# mutate\ndata_daily &lt;- data_daily %&gt;% mutate(year = year(date), month = month(date))\ndata_daily &lt;- data_daily %&gt;% mutate(l_pSAN = log(pSAN), l_pIBEX = log(pIBEX))\nhead(data_daily)\n\n# A tibble: 6 × 7\n  date        pIBEX  pSAN  year month l_pSAN l_pIBEX\n  &lt;date&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 2000-01-03 11610.  2.66  2000     1  0.980    9.36\n2 2000-01-04 11207.  2.60  2000     1  0.956    9.32\n3 2000-01-05 10863.  2.54  2000     1  0.931    9.29\n4 2000-01-07 11102.  2.65  2000     1  0.974    9.31\n5 2000-01-10 11173.  2.63  2000     1  0.966    9.32\n6 2000-01-11 11012.  2.54  2000     1  0.931    9.31\n\ntail(data_daily)\n\n# A tibble: 6 × 7\n  date       pIBEX  pSAN  year month l_pSAN l_pIBEX\n  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 2023-05-16 9191.  3.14  2023     5   1.14    9.13\n2 2023-05-17 9212.  3.16  2023     5   1.15    9.13\n3 2023-05-18 9213.  3.18  2023     5   1.16    9.13\n4 2023-05-19 9252.  3.20  2023     5   1.16    9.13\n5 2023-05-22 9305   3.23  2023     5   1.17    9.14\n6 2023-05-23 9267   3.22  2023     5   1.17    9.13\n\n# ggplot\np1 &lt;- ggplot(data = data_daily, aes(x = date)) +\n  geom_line(aes(y = pSAN), linewidth = 0.5) +\n  labs(y = \"Precio de las acciones de Banco Santander, S.A.\", x = \"Fecha\")\np1\n\n\n\np2 &lt;- ggplot(data = data_daily,aes(x = date)) +\n  geom_line(aes(y = pIBEX), linewidth = 0.5) +\n  labs(y = \"Indice IBEX 35 (Bolsa de Madrid)\", x = \"Fecha\")\np2\n\n\n\np3 &lt;- ggplot(data_daily, aes(x = l_pIBEX,y = l_pSAN)) + \n               geom_point() +  \n               stat_smooth(method = lm, se=FALSE) +  \n               labs(x = \"Indice IBEX 35 (log)\",y = \"Precio acciones Banco Santander (log)\")\np3"
  },
  {
    "objectID": "p1c2-app2b.html#código-python",
    "href": "p1c2-app2b.html#código-python",
    "title": "Aplicación 1.2b (Gestión y representación gráfica de datos financieros): Relaciones entre activos bursátiles",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom plotnine import *\nfrom datetime import datetime\n# Lectura de datos 30 mayores empresas del IBEX\n# (https://finance.yahoo.com/quote/%5EIBEX/components?p=%5EIBEX&guccounter=1)\nstock_data = pd.read_csv('data/IBEX_top30.csv')\nstock_data.head()\n\n   Unnamed: 0  symbol  ...  adjusted                     company_name\n0           1  RED.MC  ...  0.534056  Red Eléctrica Corporación, S.A.\n1           2  RED.MC  ...  0.506278  Red Eléctrica Corporación, S.A.\n2           3  RED.MC  ...  0.513446  Red Eléctrica Corporación, S.A.\n3           5  RED.MC  ...  0.537640  Red Eléctrica Corporación, S.A.\n4           6  RED.MC  ...  0.537640  Red Eléctrica Corporación, S.A.\n\n[5 rows x 10 columns]\n\nstock_data.tail()\n\n        Unnamed: 0  symbol  ... adjusted                         company_name\n138863      139425  COL.MC  ...    5.505  Inmobiliaria Colonial, SOCIMI, S.A.\n138864      139426  COL.MC  ...    5.440  Inmobiliaria Colonial, SOCIMI, S.A.\n138865      139427  COL.MC  ...    5.500  Inmobiliaria Colonial, SOCIMI, S.A.\n138866      139428  COL.MC  ...    5.520  Inmobiliaria Colonial, SOCIMI, S.A.\n138867      139429  COL.MC  ...    5.650  Inmobiliaria Colonial, SOCIMI, S.A.\n\n[5 rows x 10 columns]\n\n# filter\nSAN = stock_data[stock_data['symbol']=='SAN.MC']\n# select\np_SAN = SAN[['date','adjusted']]\np_SAN['date']=pd.to_datetime(p_SAN['date'])\np_SAN.head()\n\n            date  adjusted\n23629 2000-01-03  2.663743\n23630 2000-01-04  2.600545\n23631 2000-01-05  2.537346\n23632 2000-01-06  2.537346\n23633 2000-01-07  2.649700\n\np_SAN.tail()\n\n            date  adjusted\n29633 2023-05-17    3.1580\n29634 2023-05-18    3.1755\n29635 2023-05-19    3.2000\n29636 2023-05-22    3.2295\n29637 2023-05-23    3.2250\n\n# Lectura de datos del índice IBEX\nIBEX = pd.read_csv('data/IBEX.csv')\np_IBEX = IBEX[['date','adjusted']]\np_IBEX['date']=pd.to_datetime(p_IBEX['date'])\np_IBEX.head()\n\n        date      adjusted\n0 2000-01-03  11609.988281\n1 2000-01-04  11206.587891\n2 2000-01-05  10863.088867\n3 2000-01-07  11102.388672\n4 2000-01-10  11173.288086\n\np_IBEX.tail()\n\n           date     adjusted\n5941 2023-05-17  9211.599609\n5942 2023-05-18  9213.099609\n5943 2023-05-19  9251.500000\n5944 2023-05-22  9305.000000\n5945 2023-05-23  9267.000000\n\n# merge (join)\ndata_daily=pd.merge(p_IBEX,p_SAN,how='inner',on='date').\\\n    rename(columns={'adjusted_x':'pIBEX','adjusted_y':'pSAN'})\n# time\ndata_daily['year'] = data_daily['date'].dt.year\ndata_daily['month'] = data_daily['date'].dt.month\n# mutate\ndata_daily['l_pSAN']=data_daily['pSAN'].map(lambda x:np.log(x))\ndata_daily['l_pIBEX']=data_daily['pIBEX'].map(lambda x:np.log(x))\ndata_daily.head()\n\n        date         pIBEX      pSAN  year  month    l_pSAN   l_pIBEX\n0 2000-01-03  11609.988281  2.663743  2000      1  0.979732  9.359621\n1 2000-01-04  11206.587891  2.600545  2000      1  0.955721  9.324257\n2 2000-01-05  10863.088867  2.537346  2000      1  0.931119  9.293126\n3 2000-01-07  11102.388672  2.649700  2000      1  0.974446  9.314916\n4 2000-01-10  11173.288086  2.626292  2000      1  0.965573  9.321281\n\ndata_daily.tail()\n\n           date        pIBEX    pSAN  year  month    l_pSAN   l_pIBEX\n5940 2023-05-17  9211.599609  3.1580  2023      5  1.149939  9.128219\n5941 2023-05-18  9213.099609  3.1755  2023      5  1.155465  9.128382\n5942 2023-05-19  9251.500000  3.2000  2023      5  1.163151  9.132541\n5943 2023-05-22  9305.000000  3.2295  2023      5  1.172327  9.138307\n5944 2023-05-23  9267.000000  3.2250  2023      5  1.170933  9.134215\n\n# ggplot (Python)\n(ggplot(data_daily) + geom_line(aes('date','pSAN'), size = 0.5) \n+ labs(y = \"Precio de las acciones de Banco Santander, S.A.\",x= \"Date (day)\") + theme_bw())\n\n&lt;ggplot: (318865649)&gt;\n\n\n\n\n(ggplot(data_daily) + geom_line(aes('date','pIBEX'), size = 0.5) + scale_y_continuous(expand = [0.01,0.01]) \n+ labs(y = \"Indice IBEX 35 (Bolsa de Madrid)\",x= \"Date (day)\") + theme_bw())\n\n&lt;ggplot: (321588573)&gt;\n\n\n\n\n(ggplot(data_daily,aes('l_pIBEX','l_pSAN')) + geom_point() + geom_smooth(method='lm',se=False, color = \"blue\") + labs(x=\"Indice IBEX 35 (log)\",y=\"Precio acciones Banco Santander (log)\") + theme_bw())\n\n&lt;ggplot: (321634268)&gt;"
  },
  {
    "objectID": "p1c2-app3a.html#código-r",
    "href": "p1c2-app3a.html#código-r",
    "title": "Aplicación 1.3.a (Gestión y representación gráfica de datos espaciales): Emisiones de CO2 al nivel mundial",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(sf)\nlibrary(geojsonsf)\nlibrary(leaflet)\nlibrary(viridis)\nlibrary(RColorBrewer)\n# Lectura de datos\ndf &lt;- read_csv(\"data/GCPdbase.csv\")\n# Reemplazar \"USA\" por \"United States of America\"\ndf$Country &lt;-\n  ifelse(df$Country == \"USA\", \"United States of America\",\n         df$Country)\n# Eliminar los registros \"Global\" y \"International Transport\" \n# de la lista de países (variable Country)\ndf &lt;- df[!(df$Country %in% c(\"Global\", \"International Transport\")),]\n# Restringir período temporal al conjunto 1970-2021\ndf1 &lt;-\n  df %&gt;% filter(Year &gt;= 1970 & Year &lt;= 2021)\n# Top 10 de emisiones totales medias 1970-2021\ntop_10_emisiones_total &lt;-\n  df1 %&gt;%\n  group_by(Country) %&gt;%\n  summarise(mean_total = mean(Total)) %&gt;%\n  top_n(10, mean_total)\narrange(top_10_emisiones_total, desc(mean_total))\n\n# A tibble: 10 × 2\n   Country                  mean_total\n   &lt;chr&gt;                         &lt;dbl&gt;\n 1 United States of America      5229.\n 2 China                         4602.\n 3 Russia                        1806.\n 4 Japan                         1100.\n 5 India                         1018.\n 6 Germany                        933.\n 7 United Kingdom                 544.\n 8 Canada                         492.\n 9 Ukraine                        448.\n10 France                         411.\n\n# Gráfico de áreas\ndatos_top_10_emisiones_total &lt;- df1 %&gt;%\n  filter(Country %in% top_10_emisiones_total$Country)\nggplot(datos_top_10_emisiones_total, aes(x=Year, y=Total, fill=Country)) +\n    geom_area()\n\n\n\n# Restringir período temporal al año 2021\ndf2 &lt;- df %&gt;% filter(Year == 2021)\n# Top 5 de emisiones totales en 2021 y % sobre el total\ntop5_emisiones_2021 &lt;- df2 %&gt;% \n  select(Country, Total) %&gt;% \n  mutate(Percent = round(Total/sum(Total), digits = 3)) %&gt;% \n  top_n(5, Percent)%&gt;% \n  arrange(desc(Percent)) %&gt;%\n  mutate(Lab_percent = scales::percent(Percent))\ntop5_emisiones_2021\n\n# A tibble: 5 × 4\n  Country                   Total Percent Lab_percent\n  &lt;chr&gt;                     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1 China                    11472.   0.318 31.8%      \n2 United States of America  5007.   0.139 13.9%      \n3 India                     2710.   0.075 7.5%       \n4 Russia                    1756.   0.049 4.9%       \n5 Japan                     1067.   0.03  3.0%       \n\n# Diagrama de sectores\nggplot(top5_emisiones_2021, aes(x = \"\", y = Percent, fill = Country)) +\n    geom_col() + \n    geom_text(aes(label = Lab_percent),\n              position = position_stack(vjust = 0.5)) +\n    coord_polar(theta = \"y\")\n\n\n\n# Top 10 de emisiones per capita medias 1970-2021\ntop_10_emisiones_per_capita &lt;- df1 %&gt;%\n  group_by(Country) %&gt;%\n  summarise(mean_per_capita = mean(`Per Capita`)) %&gt;%\n  top_n(10, mean_per_capita)\narrange(top_10_emisiones_per_capita, desc(mean_per_capita))\n\n# A tibble: 10 × 2\n   Country                   mean_per_capita\n   &lt;chr&gt;                               &lt;dbl&gt;\n 1 Sint Maarten (Dutch part)            52.3\n 2 Qatar                                47.9\n 3 Curaçao                              40.4\n 4 United Arab Emirates                 32.9\n 5 Luxembourg                           25.2\n 6 Brunei Darussalam                    24.3\n 7 Kuwait                               23.5\n 8 Bahrain                              22.8\n 9 United States of America             19.8\n10 Trinidad and Tobago                  19.5\n\n# Gráfico de líneas\ndatos_top_10_emisiones_per_capita &lt;- df1 %&gt;% \n  filter(Country %in% top_10_emisiones_per_capita$Country)\nggplot(datos_top_10_emisiones_per_capita,\n       aes(x=Year, y=`Per Capita`, group=Country, color=Country)) + \n    geom_line()\n\n\n\n# Mapa de distribución mundial de emisiones per capita medias\ndatos_emisiones_per_capita_medias &lt;- df1 %&gt;%\n  group_by(`Country`) %&gt;%\n  summarize(CO2pc = mean(`Per Capita`))\nmap &lt;- geojson_sf(\"data/GCPmap.geojson\")\nclass(map)\n\n[1] \"sf\"         \"data.frame\"\n\nstr(map)\n\nClasses 'sf' and 'data.frame':  177 obs. of  2 variables:\n $ name    : chr  \"Afghanistan\" \"Angola\" \"Albania\" \"United Arab Emirates\" ...\n $ geometry:sfc_GEOMETRY of length 177; first list element: List of 1\n  ..$ : num [1:69, 1:2] 61.2 60.8 60.5 61 60.5 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"POLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n\ndatos_map &lt;- datos_emisiones_per_capita_medias %&gt;% \n    rename(name = Country)\ndatos_geo &lt;- inner_join(map, datos_map, by = \"name\")\nggplot(datos_geo) +\n  geom_sf(aes(fill=CO2pc)) +\n  theme_bw() +\n  labs(title = \"Emisiones de CO2 per capita medias\") +\n  scale_fill_viridis(option=\"magma\")\n\n\n\n# Mapa interactivo\n# Librería leaflet de R: \n# https://rstudio.github.io/leaflet/\n# Paletas de colores según el tipo de variables:\n# palNumeric &lt;- colorNumeric(\"viridis\", domain = shape$vcontinua)\n# palBin &lt;- colorBin(\"magma\", domain = shape$vdiscreta, bins = 4)\n# palQuantile &lt;- colorQuantile(\"Spectral\", domain = shape$numerica, n=4)\n# palFactor &lt;- colorFactor(\"RdBu\", domain = shape$vcategorica)\npalNumeric &lt;- colorNumeric(\"YlGnBu\", domain = datos_geo$CO2pc)\nleaflet(datos_geo) %&gt;% setView(0, 0, zoom = 2) %&gt;% addTiles() %&gt;%\n    addProviderTiles(\"CartoDB.Positron\") %&gt;%\n    addPolygons(color = \"#444444\" ,\n                weight = 1, \n                smoothFactor = 0.5,\n                opacity = 1.0,\n                fillOpacity = 0.7,\n                fillColor = ~palNumeric(datos_geo$CO2pc),   \n                layerId = ~datos_geo$name,                  \n                highlightOptions = highlightOptions(\n                  color = \"white\", weight = 1,\n                  bringToFront = TRUE))"
  },
  {
    "objectID": "p1c2-app3a.html#código-python",
    "href": "p1c2-app3a.html#código-python",
    "title": "Aplicación 1.3.a (Gestión y representación gráfica de datos espaciales): Emisiones de CO2 al nivel mundial",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nimport plotly.graph_objects as go\nimport geopandas as gpd\nimport folium\n# Lectura de datos\ndf = pd.read_csv(\"data/GCPdbase.csv\")\n# Reemplazar \"USA\" por \"United States of America\"\ndf[\"Country\"] = df[\"Country\"].replace(\"USA\", \"United States of America\")\n# Eliminar los registros \"Global\" y \"International Transport\" \n# de la lista de países (variable Country)\ndf = df[~df[\"Country\"].isin([\"Global\", \"International Transport\"])]\n# Restringir período temporal al conjunto 1970-2021\ndf1 = df[(df[\"Year\"] &gt;= 1970) & (df[\"Year\"] &lt;= 2021)]\n# Top 10 de emisiones totales medias por país\ntop_10_emisiones_total = df1.groupby(\"Country\")[\"Total\"].mean().nlargest(10).index\ntop_10_emisiones_total\n\nIndex(['United States of America', 'China', 'Russia', 'Japan', 'India',\n       'Germany', 'United Kingdom', 'Canada', 'Ukraine', 'France'],\n      dtype='object', name='Country')\n\ndatos_top_10_emisiones_total = df1[df1[\"Country\"].isin(top_10_emisiones_total)]\npivot_data_total =datos_top_10_emisiones_total.pivot_table(\n  values=\"Total\",\n  index=\"Year\",\n  columns=\"Country\",\n  aggfunc=\"sum\",\n  fill_value=0)\n# Gráfica de áreas\nfig_area = go.Figure(layout=go.Layout(\n  title=\"Top 10 por emisiones de CO2 totales (1970-2021)\",\n  xaxis_title=\"Años\",\n  yaxis_title=\"CO2\"))\n# Se insertan los datos\nfor country in pivot_data_total.columns:\n    fig_area.add_trace(go.Scatter(x=pivot_data_total.index,\n    y=pivot_data_total[country],\n    name=country,\n    mode=\"none\",\n    stackgroup=\"one\"))\n\n\n                        \n                                            \n\n# Restringir período temporal al año 2021\ndf2 = df[(df[\"Year\"] == 2021)]\n# Top 10 de emisiones totales medias por país\ndf2 = df2[[\"Country\", \"Total\"]]\n# Calculating Percentage\ndf2[\"Percent\"] = (df2[\"Total\"] / df2[\"Total\"].sum())\ntop5_emisiones_2021 = df2.nlargest(5, \"Percent\")\ntop5_emisiones_2021\n\n                        Country         Total   Percent\n10879                     China  11472.369171  0.317776\n60111  United States of America   5007.335889  0.138699\n25567                     India   2709.683625  0.075056\n47327                    Russia   1755.547390  0.048627\n27743                     Japan   1067.398435  0.029566\n\n# Diagrama de sectores\nfig, ax = plt.subplots()\nax.pie(top5_emisiones_2021[\"Percent\"], labels = top5_emisiones_2021[\"Country\"], autopct = '%1.1f%%', normalize=False)\n\n([&lt;matplotlib.patches.Wedge object at 0x129b0d3f0&gt;, &lt;matplotlib.patches.Wedge object at 0x129b58a90&gt;, &lt;matplotlib.patches.Wedge object at 0x129b595a0&gt;, &lt;matplotlib.patches.Wedge object at 0x129b59c90&gt;, &lt;matplotlib.patches.Wedge object at 0x129b5a320&gt;], [Text(0.5958851634949567, 0.9246193118935971, 'China'), Text(-0.8347624034749628, 0.716360055938844, 'United States of America'), Text(-1.099219206463291, 0.04143834145103926, 'India'), Text(-1.0329766146381076, -0.37809960805427256, 'Russia'), Text(-0.9100161313664236, -0.61795682749921, 'Japan')], [Text(0.32502827099724907, 0.5043378064874166, '31.8%'), Text(-0.45532494734997964, 0.3907418486939149, '13.9%'), Text(-0.5995741126163405, 0.022602731700566866, '7.5%'), Text(-0.5634417898026042, -0.20623614984778502, '4.9%'), Text(-0.49637243529077646, -0.3370673604541145, '3.0%')])\n\nplt.show()\n\n\n\n# Top 10 de emisiones per capita medias por país\nemisiones_per_capita_medias = df1.groupby(\"Country\").agg({\"Per Capita\": \"mean\"})\ntop_10_emisiones_per_capita = emisiones_per_capita_medias.nlargest(\n  10, \"Per Capita\").index\ntop_10_emisiones_per_capita\n\nIndex(['Sint Maarten (Dutch part)', 'Qatar', 'Curaçao', 'United Arab Emirates',\n       'Luxembourg', 'Brunei Darussalam', 'Kuwait', 'Bahrain',\n       'United States of America', 'Trinidad and Tobago'],\n      dtype='object', name='Country')\n\n# Gráfica de líneas\ndatos_top_10_emisiones_per_capita = df1[df1[\"Country\"].isin(top_10_emisiones_per_capita)]\npivot_data_per_capita = datos_top_10_emisiones_per_capita.pivot_table(\n  values=\"Per Capita\",\n  index=\"Year\",\n  columns=\"Country\",\n  aggfunc=\"mean\",\n  fill_value=0)\nfig_line = go.Figure(\n  layout=go.Layout(\n    title=\"Top 10 por emisiones de CO2 per capita (1970-2021)\",\n    xaxis_title=\"Años\",\n    yaxis_title=\"CO2pc\"))\nfor country in pivot_data_per_capita.columns:\n    fig_line.add_trace(\n      go.Scatter(x=pivot_data_per_capita.index,\n      y=pivot_data_per_capita[country],\n      name=country, mode=\"lines\"))\n\n\n                        \n                                            \n\n# Mapa de distribución mundial de emisiones per capita medias\ndatos_map = df1.groupby(\"Country\")[\"Per Capita\"].mean().reset_index()\nmap = gpd.read_file(\"data/GCPmap.geojson\")\nmap.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 177 entries, 0 to 176\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   id        177 non-null    object  \n 1   name      177 non-null    object  \n 2   geometry  177 non-null    geometry\ndtypes: geometry(1), object(2)\nmemory usage: 4.3+ KB\n\ndatos_map_2 = datos_map.copy()   \ndatos_map_2 = datos_map_2.rename(columns = {\"Country\": \"name\"})\ndatos_map_2 = datos_map_2.rename(columns = {\"Per Capita\": \"CO2pc\"})\ndatos_geo  = map.merge(datos_map_2, on = 'name', how = 'left')\nfig, ax = plt.subplots(1,1)\ndatos_geo.plot(column=\"CO2pc\",\n           legend=True,\n           cmap='magma',\n           ax=ax)\nplt.title('Emisiones de CO2 per capita medias')\nplt.tight_layout()\nplt.show()\n\n\n\n# Mapa interactivo\n# Libreria folium de Python: \n# https://python-visualization.github.io/folium/\nworld_geo = r'data/GCPmap.geojson'\ndatos_emisiones_per_capita_medias = df1.groupby(\n  \"ISO 3166-1 alpha-3\")[\"Per Capita\"].mean().reset_index()\nmapa_emisiones = folium.Map(location=[0, 0], zoom_start=2)\nfolium.Choropleth(\n    geo_data=world_geo,\n    name=\"choropleth\",\n    data=datos_emisiones_per_capita_medias,\n    columns=[\"ISO 3166-1 alpha-3\", \"Per Capita\"],\n    key_on=\"feature.id\",\n    fill_color=\"YlGnBu\",\n    fill_opacity=0.7,\n    line_opacity=0.2,\n    legend_name=\"Emisiones per capita medias\"\n).add_to(mapa_emisiones)\n\n&lt;folium.features.Choropleth object at 0x12f85fa90&gt;\n\nfolium.LayerControl().add_to(mapa_emisiones)\n\n&lt;folium.map.LayerControl object at 0x1286e8820&gt;\n\nmapa_emisiones\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "p1c2-app3b.html#código-r",
    "href": "p1c2-app3b.html#código-r",
    "title": "Aplicación 1.3b (Gestión y representación gráfica de datos espaciales): Desarrollo humano al nivel mundial",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(viridis)\nlibrary(sf)\nlibrary(geojsonsf)\n# Lectura de datos\ndf &lt;- read_csv(\"data/GDLdbase.csv\")\nstr(df)\n\nspc_tbl_ [58,884 × 37] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ ...1        : num [1:58884] 1 2 3 4 5 6 7 8 9 10 ...\n $ iso_code    : chr [1:58884] \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ country     : chr [1:58884] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ year        : num [1:58884] 1990 1990 1990 1990 1990 ...\n $ GDLCODE     : chr [1:58884] \"AFGr101\" \"AFGr102\" \"AFGr103\" \"AFGr104\" ...\n $ level       : chr [1:58884] \"Subnat\" \"Subnat\" \"Subnat\" \"Subnat\" ...\n $ region      : chr [1:58884] \"Central (Kabul Wardak Kapisa Logar Parwan Panjsher)\" \"Central Highlands (Bamyan Daikundi)\" \"East (Nangarhar Kunar Laghman Nooristan)\" \"North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)\" ...\n $ continent   : chr [1:58884] \"Asia/Pacific\" \"Asia/Pacific\" \"Asia/Pacific\" \"Asia/Pacific\" ...\n $ sgdi        : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ shdi        : num [1:58884] 0.332 0.281 0.287 0.259 0.266 0.213 0.274 0.252 0.273 0.339 ...\n $ shdif       : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ shdim       : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ healthindex : num [1:58884] 0.415 0.375 0.453 0.375 0.404 0.444 0.372 0.369 0.399 0.426 ...\n $ healthindexf: num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ healthindexm: num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ incindex    : num [1:58884] 0.539 0.469 0.472 0.477 0.494 0.487 0.518 0.494 0.497 0.513 ...\n $ incindexf   : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ incindexm   : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ edindex     : num [1:58884] 0.164 0.126 0.11 0.097 0.094 0.045 0.106 0.088 0.102 0.179 ...\n $ edindexf    : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ edindexm    : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ esch        : num [1:58884] 3.5 3.64 2.56 2.73 2.54 ...\n $ eschf       : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ eschm       : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ msch        : num [1:58884] 1.989 0.752 1.175 0.627 0.71 ...\n $ mschf       : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ mschm       : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ lifexp      : num [1:58884] 47 44.4 49.4 44.4 46.3 ...\n $ lifexpf     : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ lifexpm     : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ gnic        : num [1:58884] 3549 2225 2279 2357 2624 ...\n $ gnicf       : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ gnicm       : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ lgnic       : num [1:58884] 8.18 7.71 7.73 7.76 7.87 ...\n $ lgnicf      : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ lgnicm      : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n $ pop         : num [1:58884] NA NA NA NA NA NA NA NA NA NA ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   ...1 = col_double(),\n  ..   iso_code = col_character(),\n  ..   country = col_character(),\n  ..   year = col_double(),\n  ..   GDLCODE = col_character(),\n  ..   level = col_character(),\n  ..   region = col_character(),\n  ..   continent = col_character(),\n  ..   sgdi = col_double(),\n  ..   shdi = col_double(),\n  ..   shdif = col_double(),\n  ..   shdim = col_double(),\n  ..   healthindex = col_double(),\n  ..   healthindexf = col_double(),\n  ..   healthindexm = col_double(),\n  ..   incindex = col_double(),\n  ..   incindexf = col_double(),\n  ..   incindexm = col_double(),\n  ..   edindex = col_double(),\n  ..   edindexf = col_double(),\n  ..   edindexm = col_double(),\n  ..   esch = col_double(),\n  ..   eschf = col_double(),\n  ..   eschm = col_double(),\n  ..   msch = col_double(),\n  ..   mschf = col_double(),\n  ..   mschm = col_double(),\n  ..   lifexp = col_double(),\n  ..   lifexpf = col_double(),\n  ..   lifexpm = col_double(),\n  ..   gnic = col_double(),\n  ..   gnicf = col_double(),\n  ..   gnicm = col_double(),\n  ..   lgnic = col_double(),\n  ..   lgnicf = col_double(),\n  ..   lgnicm = col_double(),\n  ..   pop = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nprint(df)\n\n# A tibble: 58,884 × 37\n    ...1 iso_code country  year GDLCODE level region continent  sgdi  shdi shdif\n   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 AFG      Afghan…  1990 AFGr101 Subn… Centr… Asia/Pac…    NA 0.332    NA\n 2     2 AFG      Afghan…  1990 AFGr102 Subn… Centr… Asia/Pac…    NA 0.281    NA\n 3     3 AFG      Afghan…  1990 AFGr103 Subn… East … Asia/Pac…    NA 0.287    NA\n 4     4 AFG      Afghan…  1990 AFGr104 Subn… North… Asia/Pac…    NA 0.259    NA\n 5     5 AFG      Afghan…  1990 AFGr105 Subn… North… Asia/Pac…    NA 0.266    NA\n 6     6 AFG      Afghan…  1990 AFGr106 Subn… South… Asia/Pac…    NA 0.213    NA\n 7     7 AFG      Afghan…  1990 AFGr107 Subn… South… Asia/Pac…    NA 0.274    NA\n 8     8 AFG      Afghan…  1990 AFGr108 Subn… West … Asia/Pac…    NA 0.252    NA\n 9     9 AFG      Afghan…  1990 AFGt    Nati… Total  Asia/Pac…    NA 0.273    NA\n10    10 AFG      Afghan…  1991 AFGr101 Subn… Centr… Asia/Pac…    NA 0.339    NA\n# ℹ 58,874 more rows\n# ℹ 26 more variables: shdim &lt;dbl&gt;, healthindex &lt;dbl&gt;, healthindexf &lt;dbl&gt;,\n#   healthindexm &lt;dbl&gt;, incindex &lt;dbl&gt;, incindexf &lt;dbl&gt;, incindexm &lt;dbl&gt;,\n#   edindex &lt;dbl&gt;, edindexf &lt;dbl&gt;, edindexm &lt;dbl&gt;, esch &lt;dbl&gt;, eschf &lt;dbl&gt;,\n#   eschm &lt;dbl&gt;, msch &lt;dbl&gt;, mschf &lt;dbl&gt;, mschm &lt;dbl&gt;, lifexp &lt;dbl&gt;,\n#   lifexpf &lt;dbl&gt;, lifexpm &lt;dbl&gt;, gnic &lt;dbl&gt;, gnicf &lt;dbl&gt;, gnicm &lt;dbl&gt;,\n#   lgnic &lt;dbl&gt;, lgnicf &lt;dbl&gt;, lgnicm &lt;dbl&gt;, pop &lt;dbl&gt;\n\nmap &lt;- geojson_sf(\"data/GDLmap.geojson\")\nclass(map)\n\n[1] \"sf\"         \"data.frame\"\n\nstr(map)\n\nClasses 'sf' and 'data.frame':  1745 obs. of  6 variables:\n $ GDLcode : chr  \"AFGr101\" \"AFGr102\" \"AFGr103\" \"AFGr104\" ...\n $ constant: chr  \"World\" \"World\" \"World\" \"World\" ...\n $ iso_code: chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ country : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ region  : chr  \"Central (Kabul Wardak Kapisa Logar Parwan Panjsher)\" \"Central Highlands (Bamyan Daikundi)\" \"East (Nangarhar Kunar Laghman Nooristan)\" \"North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)\" ...\n $ geometry:sfc_MULTIPOLYGON of length 1745; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:289, 1:2] 67.6 67.6 67.6 67.5 67.5 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n\nprint(map)\n\nSimple feature collection with 1745 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -55.98403 xmax: 180 ymax: 83.10833\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   GDLcode constant iso_code     country\n1  AFGr101    World      AFG Afghanistan\n2  AFGr102    World      AFG Afghanistan\n3  AFGr103    World      AFG Afghanistan\n4  AFGr104    World      AFG Afghanistan\n5  AFGr105    World      AFG Afghanistan\n6  AFGr106    World      AFG Afghanistan\n7  AFGr107    World      AFG Afghanistan\n8  AFGr108    World      AFG Afghanistan\n9  AGOr201    World      AGO      Angola\n10 AGOr202    World      AGO      Angola\n                                                region\n1  Central (Kabul Wardak Kapisa Logar Parwan Panjsher)\n2                  Central Highlands (Bamyan Daikundi)\n3             East (Nangarhar Kunar Laghman Nooristan)\n4      North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)\n5        North East (Baghlan Takhar Badakhshan Kunduz)\n6        South (Uruzgan Helmand Zabul Nimroz Kandahar)\n7             South East (Ghazni Paktya Paktika Khost)\n8                      West (Ghor Herat Badghis Farah)\n9                                              Cabinda\n10                                               Zaire\n                         geometry\n1  MULTIPOLYGON (((67.61506 34...\n2  MULTIPOLYGON (((65.23611 33...\n3  MULTIPOLYGON (((69.92137 34...\n4  MULTIPOLYGON (((66.38873 34...\n5  MULTIPOLYGON (((67.39591 35...\n6  MULTIPOLYGON (((60.89944 29...\n7  MULTIPOLYGON (((68.10873 31...\n8  MULTIPOLYGON (((61.12394 31...\n9  MULTIPOLYGON (((12.21127 -5...\n10 MULTIPOLYGON (((13.08792 -7...\n\n# Preparación de datos\n# Eliminación de observaciones nacionales (variable level -&gt; National)\ndf1 &lt;- filter(df, level != 'National')\ndf1\n\n# A tibble: 53,410 × 37\n    ...1 iso_code country  year GDLCODE level region continent  sgdi  shdi shdif\n   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 AFG      Afghan…  1990 AFGr101 Subn… Centr… Asia/Pac…    NA 0.332    NA\n 2     2 AFG      Afghan…  1990 AFGr102 Subn… Centr… Asia/Pac…    NA 0.281    NA\n 3     3 AFG      Afghan…  1990 AFGr103 Subn… East … Asia/Pac…    NA 0.287    NA\n 4     4 AFG      Afghan…  1990 AFGr104 Subn… North… Asia/Pac…    NA 0.259    NA\n 5     5 AFG      Afghan…  1990 AFGr105 Subn… North… Asia/Pac…    NA 0.266    NA\n 6     6 AFG      Afghan…  1990 AFGr106 Subn… South… Asia/Pac…    NA 0.213    NA\n 7     7 AFG      Afghan…  1990 AFGr107 Subn… South… Asia/Pac…    NA 0.274    NA\n 8     8 AFG      Afghan…  1990 AFGr108 Subn… West … Asia/Pac…    NA 0.252    NA\n 9    10 AFG      Afghan…  1991 AFGr101 Subn… Centr… Asia/Pac…    NA 0.339    NA\n10    11 AFG      Afghan…  1991 AFGr102 Subn… Centr… Asia/Pac…    NA 0.288    NA\n# ℹ 53,400 more rows\n# ℹ 26 more variables: shdim &lt;dbl&gt;, healthindex &lt;dbl&gt;, healthindexf &lt;dbl&gt;,\n#   healthindexm &lt;dbl&gt;, incindex &lt;dbl&gt;, incindexf &lt;dbl&gt;, incindexm &lt;dbl&gt;,\n#   edindex &lt;dbl&gt;, edindexf &lt;dbl&gt;, edindexm &lt;dbl&gt;, esch &lt;dbl&gt;, eschf &lt;dbl&gt;,\n#   eschm &lt;dbl&gt;, msch &lt;dbl&gt;, mschf &lt;dbl&gt;, mschm &lt;dbl&gt;, lifexp &lt;dbl&gt;,\n#   lifexpf &lt;dbl&gt;, lifexpm &lt;dbl&gt;, gnic &lt;dbl&gt;, gnicf &lt;dbl&gt;, gnicm &lt;dbl&gt;,\n#   lgnic &lt;dbl&gt;, lgnicf &lt;dbl&gt;, lgnicm &lt;dbl&gt;, pop &lt;dbl&gt;\n\ncolnames(df1)\n\n [1] \"...1\"         \"iso_code\"     \"country\"      \"year\"         \"GDLCODE\"     \n [6] \"level\"        \"region\"       \"continent\"    \"sgdi\"         \"shdi\"        \n[11] \"shdif\"        \"shdim\"        \"healthindex\"  \"healthindexf\" \"healthindexm\"\n[16] \"incindex\"     \"incindexf\"    \"incindexm\"    \"edindex\"      \"edindexf\"    \n[21] \"edindexm\"     \"esch\"         \"eschf\"        \"eschm\"        \"msch\"        \n[26] \"mschf\"        \"mschm\"        \"lifexp\"       \"lifexpf\"      \"lifexpm\"     \n[31] \"gnic\"         \"gnicf\"        \"gnicm\"        \"lgnic\"        \"lgnicf\"      \n[36] \"lgnicm\"       \"pop\"         \n\n# Selección del año de análisis, 2021\ndf1$year &lt;- as.character(df1$year)\ndf2021 &lt;- filter(df1, year == '2021')\nprint(df2021)\n\n# A tibble: 1,786 × 37\n    ...1 iso_code country year  GDLCODE level region continent  sgdi  shdi shdif\n   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   280 AFG      Afghan… 2021  AFGr101 Subn… Centr… Asia/Pac… 0.734 0.55  0.444\n 2   281 AFG      Afghan… 2021  AFGr102 Subn… Centr… Asia/Pac… 0.704 0.472 0.368\n 3   282 AFG      Afghan… 2021  AFGr103 Subn… East … Asia/Pac… 0.583 0.459 0.31 \n 4   283 AFG      Afghan… 2021  AFGr104 Subn… North… Asia/Pac… 0.749 0.497 0.405\n 5   284 AFG      Afghan… 2021  AFGr105 Subn… North… Asia/Pac… 0.667 0.444 0.332\n 6   285 AFG      Afghan… 2021  AFGr106 Subn… South… Asia/Pac… 0.563 0.407 0.269\n 7   286 AFG      Afghan… 2021  AFGr107 Subn… South… Asia/Pac… 0.567 0.476 0.315\n 8   287 AFG      Afghan… 2021  AFGr108 Subn… West … Asia/Pac… 0.692 0.447 0.344\n 9   707 AGO      Angola  2021  AGOr201 Subn… Cabin… Africa    0.938 0.681 0.66 \n10   708 AGO      Angola  2021  AGOr202 Subn… Zaire  Africa    0.892 0.615 0.581\n# ℹ 1,776 more rows\n# ℹ 26 more variables: shdim &lt;dbl&gt;, healthindex &lt;dbl&gt;, healthindexf &lt;dbl&gt;,\n#   healthindexm &lt;dbl&gt;, incindex &lt;dbl&gt;, incindexf &lt;dbl&gt;, incindexm &lt;dbl&gt;,\n#   edindex &lt;dbl&gt;, edindexf &lt;dbl&gt;, edindexm &lt;dbl&gt;, esch &lt;dbl&gt;, eschf &lt;dbl&gt;,\n#   eschm &lt;dbl&gt;, msch &lt;dbl&gt;, mschf &lt;dbl&gt;, mschm &lt;dbl&gt;, lifexp &lt;dbl&gt;,\n#   lifexpf &lt;dbl&gt;, lifexpm &lt;dbl&gt;, gnic &lt;dbl&gt;, gnicf &lt;dbl&gt;, gnicm &lt;dbl&gt;,\n#   lgnic &lt;dbl&gt;, lgnicf &lt;dbl&gt;, lgnicm &lt;dbl&gt;, pop &lt;dbl&gt;\n\nunique(df2021$continent)\n\n[1] \"Asia/Pacific\" \"Africa\"       \"Europe\"       \"America\"     \n\nunique(df2021$country)\n\n  [1] \"Afghanistan\"                  \"Angola\"                      \n  [3] \"Albania\"                      \"Argentina urban\"             \n  [5] \"Armenia\"                      \"Australia\"                   \n  [7] \"Austria\"                      \"Azerbaijan\"                  \n  [9] \"Burundi\"                      \"Belgium\"                     \n [11] \"Benin\"                        \"Burkina Faso\"                \n [13] \"Bangladesh\"                   \"Bulgaria\"                    \n [15] \"Bosnia and Herzegovina\"       \"Belarus\"                     \n [17] \"Belize\"                       \"Bolivia\"                     \n [19] \"Brazil\"                       \"Barbados\"                    \n [21] \"Bhutan\"                       \"Botswana\"                    \n [23] \"Central African Republic CAR\" \"Canada\"                      \n [25] \"Switzerland\"                  \"Chili\"                       \n [27] \"China\"                        \"Cote d'Ivoire\"               \n [29] \"Cameroon\"                     \"Congo Democratic Republic\"   \n [31] \"Congo Brazzaville\"            \"Colombia\"                    \n [33] \"Comoros\"                      \"Cape Verde\"                  \n [35] \"Costa Rica\"                   \"Cuba\"                        \n [37] \"Czech Republic\"               \"Germany\"                     \n [39] \"Djibouti\"                     \"Denmark\"                     \n [41] \"Dominican Republic\"           \"Algeria\"                     \n [43] \"Ecuador\"                      \"Egypt\"                       \n [45] \"Eritrea\"                      \"Spain\"                       \n [47] \"Estonia\"                      \"Ethiopia\"                    \n [49] \"Finland\"                      \"Fiji\"                        \n [51] \"France\"                       \"Gabon\"                       \n [53] \"United Kingdom\"               \"Georgia\"                     \n [55] \"Ghana\"                        \"Guinea\"                      \n [57] \"Gambia\"                       \"Guinea Bissau\"               \n [59] \"Equatorial Guinea\"            \"Greece\"                      \n [61] \"Guatemala\"                    \"Guyana\"                      \n [63] \"Honduras\"                     \"Croatia\"                     \n [65] \"Haiti\"                        \"Hungary\"                     \n [67] \"Indonesia\"                    \"India\"                       \n [69] \"Ireland\"                      \"Iran\"                        \n [71] \"Iraq\"                         \"Italy\"                       \n [73] \"Jamaica\"                      \"Jordan\"                      \n [75] \"Japan\"                        \"Kazakhstan\"                  \n [77] \"Kenya\"                        \"Kyrgyzstan\"                  \n [79] \"Cambodia\"                     \"Kiribati\"                    \n [81] \"South Korea\"                  \"Kuwait\"                      \n [83] \"Lao\"                          \"Lebanon\"                     \n [85] \"Liberia\"                      \"Libya\"                       \n [87] \"Saint Lucia\"                  \"Lesotho\"                     \n [89] \"Lithuania\"                    \"Latvia\"                      \n [91] \"Morocco\"                      \"Moldova\"                     \n [93] \"Madagascar\"                   \"Maldives\"                    \n [95] \"Mexico\"                       \"North Macedonia\"             \n [97] \"Mali\"                         \"Myanmar\"                     \n [99] \"Monte Negro\"                  \"Mongolia\"                    \n[101] \"Mozambique\"                   \"Mauritania\"                  \n[103] \"Mauritius\"                    \"Malawi\"                      \n[105] \"Malaysia\"                     \"Namibia\"                     \n[107] \"Niger\"                        \"Nigeria\"                     \n[109] \"Nicaragua\"                    \"Netherlands\"                 \n[111] \"Norway\"                       \"Nepal\"                       \n[113] \"New Zealand\"                  \"Pakistan\"                    \n[115] \"Panama\"                       \"Peru\"                        \n[117] \"Philippines\"                  \"Papua New Guinea\"            \n[119] \"Poland\"                       \"Portugal\"                    \n[121] \"Paraguay\"                     \"Palestine\"                   \n[123] \"Romania\"                      \"Russian Federation\"          \n[125] \"Rwanda\"                       \"Saudi Arabia\"                \n[127] \"Sudan\"                        \"Senegal\"                     \n[129] \"Sierra Leone\"                 \"El Salvador\"                 \n[131] \"Somalia\"                      \"Serbia\"                      \n[133] \"South Sudan\"                  \"Sao Tome & Principe\"         \n[135] \"Suriname\"                     \"Slovakia\"                    \n[137] \"Slovenia\"                     \"Sweden\"                      \n[139] \"Eswatini\"                     \"Syria\"                       \n[141] \"Chad\"                         \"Togo\"                        \n[143] \"Thailand\"                     \"Tajikistan\"                  \n[145] \"Turkmenistan\"                 \"Timor Leste\"                 \n[147] \"Tonga\"                        \"Trinidad & Tobago\"           \n[149] \"Tunisia\"                      \"Turkey\"                      \n[151] \"Tuvalu\"                       \"Tanzania\"                    \n[153] \"Uganda\"                       \"Ukraine\"                     \n[155] \"Uruguay\"                      \"United States\"               \n[157] \"Uzbekistan\"                   \"Venezuela\"                   \n[159] \"Vietnam\"                      \"Vanuatu\"                     \n[161] \"Samoa\"                        \"Kosovo\"                      \n[163] \"Yemen\"                        \"South Africa\"                \n[165] \"Zambia\"                       \"Zimbabwe\"                    \n\n# Análisis exploratorio básico (EDA)\n# Estadísticos para todo el período\ndf1 %&gt;% \n  select(-c(...1,iso_code, year, country, GDLCODE, level, region,continent)) %&gt;%\n  summary()\n\n      sgdi            shdi            shdif           shdim      \n Min.   :0.369   Min.   :0.1720   Min.   :0.126   Min.   :0.236  \n 1st Qu.:0.881   1st Qu.:0.5150   1st Qu.:0.511   1st Qu.:0.576  \n Median :0.947   Median :0.6610   Median :0.659   Median :0.707  \n Mean   :0.923   Mean   :0.6453   Mean   :0.645   Mean   :0.691  \n 3rd Qu.:0.982   3rd Qu.:0.7760   3rd Qu.:0.788   3rd Qu.:0.805  \n Max.   :1.070   Max.   :0.9890   Max.   :0.974   Max.   :0.996  \n NA's   :17950   NA's   :374      NA's   :17935   NA's   :17947  \n  healthindex       healthindexf    healthindexm      incindex     \n Min.   :-0.1020   Min.   :0.250   Min.   :0.318   Min.   :0.1920  \n 1st Qu.: 0.6540   1st Qu.:0.677   1st Qu.:0.683   1st Qu.:0.5110  \n Median : 0.7760   Median :0.804   Median :0.788   Median :0.6620  \n Mean   : 0.7457   Mean   :0.767   Mean   :0.767   Mean   :0.6524  \n 3rd Qu.: 0.8560   3rd Qu.:0.880   3rd Qu.:0.864   3rd Qu.:0.7850  \n Max.   : 1.0000   Max.   :1.000   Max.   :1.000   Max.   :1.0000  \n NA's   :64        NA's   :17233   NA's   :17233   NA's   :205     \n   incindexf       incindexm        edindex          edindexf    \n Min.   :0.038   Min.   :0.256   Min.   :0.0400   Min.   :0.029  \n 1st Qu.:0.468   1st Qu.:0.571   1st Qu.:0.4180   1st Qu.:0.427  \n Median :0.600   Median :0.731   Median :0.5740   Median :0.610  \n Mean   :0.610   Mean   :0.708   Mean   :0.5662   Mean   :0.590  \n 3rd Qu.:0.752   3rd Qu.:0.839   3rd Qu.:0.7200   3rd Qu.:0.758  \n Max.   :1.000   Max.   :1.000   Max.   :1.0000   Max.   :0.995  \n NA's   :17019   NA's   :17019   NA's   :100      NA's   :17647  \n    edindexm          esch            eschf            eschm       \n Min.   :0.077   Min.   : 0.342   Min.   : 0.867   Min.   : 2.042  \n 1st Qu.:0.494   1st Qu.: 9.613   1st Qu.:10.136   1st Qu.:10.755  \n Median :0.621   Median :11.983   Median :12.780   Median :12.543  \n Mean   :0.617   Mean   :11.733   Mean   :12.441   Mean   :12.450  \n 3rd Qu.:0.754   3rd Qu.:14.266   3rd Qu.:15.150   3rd Qu.:14.505  \n Max.   :0.993   Max.   :18.000   Max.   :18.000   Max.   :18.000  \n NA's   :17659                    NA's   :17475    NA's   :17476   \n      msch            mschf            mschm            lifexp     \n Min.   : 0.137   Min.   : 0.067   Min.   : 0.207   Min.   :13.34  \n 1st Qu.: 4.353   1st Qu.: 4.204   1st Qu.: 5.624   1st Qu.:62.50  \n Median : 7.127   Median : 7.506   Median : 8.111   Median :70.42  \n Mean   : 7.204   Mean   : 7.305   Mean   : 8.113   Mean   :68.47  \n 3rd Qu.:10.020   3rd Qu.:10.373   3rd Qu.:10.742   3rd Qu.:75.61  \n Max.   :15.000   Max.   :14.981   Max.   :14.854   Max.   :85.61  \n NA's   :100      NA's   :17457    NA's   :17468    NA's   :64     \n    lifexpf         lifexpm           gnic              gnicf         \n Min.   :38.78   Min.   :38.17   Min.   :   355.5   Min.   :   128.2  \n 1st Qu.:66.49   1st Qu.:61.92   1st Qu.:  2950.8   1st Qu.:  2216.5  \n Median :74.74   Median :68.71   Median :  7982.1   Median :  5325.3  \n Mean   :72.38   Mean   :67.34   Mean   : 13960.7   Mean   : 11004.4  \n 3rd Qu.:79.69   3rd Qu.:73.64   3rd Qu.: 18059.0   3rd Qu.: 14565.9  \n Max.   :88.29   Max.   :84.53   Max.   :209791.9   Max.   :162951.2  \n NA's   :17233   NA's   :17233   NA's   :205        NA's   :17019     \n     gnicm              lgnic            lgnicf           lgnicm      \n Min.   :   545.9   Min.   : 5.873   Min.   : 4.853   Min.   : 6.302  \n 1st Qu.:  4387.4   1st Qu.: 7.990   1st Qu.: 7.704   1st Qu.: 8.386  \n Median : 12616.0   Median : 8.985   Median : 8.580   Median : 9.443  \n Mean   : 19599.2   Mean   : 8.925   Mean   : 8.641   Mean   : 9.294  \n 3rd Qu.: 25888.4   3rd Qu.: 9.801   3rd Qu.: 9.586   3rd Qu.:10.162  \n Max.   :258567.3   Max.   :12.254   Max.   :12.001   Max.   :12.463  \n NA's   :17019      NA's   :205      NA's   :17019    NA's   :17019   \n      pop       \n Min.   :161.1  \n 1st Qu.:188.4  \n Median :199.0  \n Mean   :256.9  \n 3rd Qu.:280.4  \n Max.   :555.7  \n NA's   :53326  \n\n# Estadísticos para el año 2021\ndf2021 %&gt;%\n  select(-c(...1,iso_code, year, country, GDLCODE, level, region,continent)) %&gt;%\n  summary()\n\n      sgdi             shdi            shdif            shdim       \n Min.   :0.3690   Min.   :0.2320   Min.   :0.1740   Min.   :0.2930  \n 1st Qu.:0.9045   1st Qu.:0.5780   1st Qu.:0.5550   1st Qu.:0.6030  \n Median :0.9620   Median :0.7070   Median :0.6820   Median :0.7240  \n Mean   :0.9406   Mean   :0.6935   Mean   :0.6758   Mean   :0.7125  \n 3rd Qu.:0.9900   3rd Qu.:0.8110   3rd Qu.:0.8080   3rd Qu.:0.8190  \n Max.   :1.0600   Max.   :0.9890   Max.   :0.9740   Max.   :0.9960  \n NA's   :63       NA's   :2        NA's   :63       NA's   :63      \n  healthindex      healthindexf     healthindexm       incindex     \n Min.   :0.4000   Min.   :0.3120   Min.   :0.3900   Min.   :0.2790  \n 1st Qu.:0.6920   1st Qu.:0.6920   1st Qu.:0.6945   1st Qu.:0.5560  \n Median :0.7840   Median :0.7980   Median :0.7770   Median :0.6980  \n Mean   :0.7761   Mean   :0.7799   Mean   :0.7743   Mean   :0.6811  \n 3rd Qu.:0.8600   3rd Qu.:0.8720   3rd Qu.:0.8540   3rd Qu.:0.8110  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n NA's   :2        NA's   :11       NA's   :11                       \n   incindexf        incindexm         edindex          edindexf     \n Min.   :0.0380   Min.   :0.2910   Min.   :0.0610   Min.   :0.0630  \n 1st Qu.:0.4945   1st Qu.:0.5890   1st Qu.:0.4973   1st Qu.:0.4808  \n Median :0.6130   Median :0.7440   Median :0.6620   Median :0.6730  \n Mean   :0.6260   Mean   :0.7164   Mean   :0.6423   Mean   :0.6406  \n 3rd Qu.:0.7740   3rd Qu.:0.8445   3rd Qu.:0.7897   3rd Qu.:0.7983  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :0.9940  \n NA's   :15       NA's   :15                        NA's   :58      \n    edindexm           esch            eschf            eschm       \n Min.   :0.1100   Min.   : 0.369   Min.   : 1.395   Min.   : 3.332  \n 1st Qu.:0.5270   1st Qu.:11.145   1st Qu.:11.085   1st Qu.:11.363  \n Median :0.6630   Median :13.303   Median :13.642   Median :13.187  \n Mean   :0.6555   Mean   :13.052   Mean   :13.261   Mean   :13.065  \n 3rd Qu.:0.7873   3rd Qu.:15.343   3rd Qu.:15.706   3rd Qu.:14.998  \n Max.   :0.9930   Max.   :18.000   Max.   :18.000   Max.   :18.000  \n NA's   :58                        NA's   :36       NA's   :36      \n      msch            mschf            mschm            lifexp     \n Min.   : 0.330   Min.   : 0.136   Min.   : 0.524   Min.   :45.98  \n 1st Qu.: 5.627   1st Qu.: 5.136   1st Qu.: 6.250   1st Qu.:64.98  \n Median : 8.558   Median : 8.521   Median : 8.870   Median :70.99  \n Mean   : 8.393   Mean   : 8.124   Mean   : 8.745   Mean   :70.45  \n 3rd Qu.:11.227   3rd Qu.:11.146   3rd Qu.:11.354   3rd Qu.:75.88  \n Max.   :15.000   Max.   :14.981   Max.   :14.843   Max.   :85.61  \n                  NA's   :53       NA's   :53       NA's   :2      \n    lifexpf         lifexpm           gnic              gnicf         \n Min.   :42.78   Min.   :42.83   Min.   :   632.5   Min.   :   128.2  \n 1st Qu.:67.49   1st Qu.:62.64   1st Qu.:  3960.0   1st Qu.:  2637.6  \n Median :74.38   Median :67.99   Median : 10156.4   Median :  5802.6  \n Mean   :73.19   Mean   :67.83   Mean   : 16411.9   Mean   : 12440.0  \n 3rd Qu.:79.17   3rd Qu.:73.00   3rd Qu.: 21422.5   3rd Qu.: 16763.3  \n Max.   :88.29   Max.   :84.53   Max.   :209791.9   Max.   :162951.2  \n NA's   :11      NA's   :11                         NA's   :15        \n     gnicm              lgnic            lgnicf           lgnicm      \n Min.   :   687.5   Min.   : 6.450   Min.   : 4.853   Min.   : 6.533  \n 1st Qu.:  4939.9   1st Qu.: 8.284   1st Qu.: 7.878   1st Qu.: 8.505  \n Median : 13755.2   Median : 9.226   Median : 8.666   Median : 9.529  \n Mean   : 20564.4   Mean   : 9.116   Mean   : 8.750   Mean   : 9.353  \n 3rd Qu.: 26757.8   3rd Qu.: 9.973   3rd Qu.: 9.727   3rd Qu.:10.194  \n Max.   :258567.3   Max.   :12.254   Max.   :12.001   Max.   :12.463  \n NA's   :15                          NA's   :15       NA's   :15      \n      pop       \n Min.   :161.1  \n 1st Qu.:172.5  \n Median :189.8  \n Mean   :247.1  \n 3rd Qu.:242.4  \n Max.   :549.3  \n NA's   :1779   \n\n# Estadísticos para España en el año 2021\ndf2021 %&gt;%\n  select(-c(...1,iso_code, year, GDLCODE, level, region,continent)) %&gt;%\n  filter(country == 'Spain') %&gt;% \n  summary()\n\n   country               sgdi             shdi            shdif       \n Length:19          Min.   :0.9750   Min.   :0.8530   Min.   :0.8490  \n Class :character   1st Qu.:0.9835   1st Qu.:0.8725   1st Qu.:0.8655  \n Mode  :character   Median :0.9850   Median :0.9000   Median :0.8900  \n                    Mean   :0.9854   Mean   :0.8943   Mean   :0.8863  \n                    3rd Qu.:0.9870   3rd Qu.:0.9110   3rd Qu.:0.9030  \n                    Max.   :0.9960   Max.   :0.9400   Max.   :0.9270  \n                                                                      \n     shdim         healthindex      healthindexf     healthindexm   \n Min.   :0.8560   Min.   :0.9300   Min.   :0.9310   Min.   :0.9290  \n 1st Qu.:0.8775   1st Qu.:0.9570   1st Qu.:0.9660   1st Qu.:0.9510  \n Median :0.9050   Median :0.9680   Median :0.9720   Median :0.9630  \n Mean   :0.8996   Mean   :0.9653   Mean   :0.9696   Mean   :0.9614  \n 3rd Qu.:0.9175   3rd Qu.:0.9750   3rd Qu.:0.9800   3rd Qu.:0.9700  \n Max.   :0.9510   Max.   :0.9970   Max.   :0.9960   Max.   :0.9930  \n                                                                    \n    incindex        incindexf        incindexm         edindex      \n Min.   :0.8490   Min.   :0.8190   Min.   :0.8750   Min.   :0.7610  \n 1st Qu.:0.8635   1st Qu.:0.8335   1st Qu.:0.8900   1st Qu.:0.7975  \n Median :0.8830   Median :0.8520   Median :0.9100   Median :0.8520  \n Mean   :0.8892   Mean   :0.8584   Mean   :0.9159   Mean   :0.8336  \n 3rd Qu.:0.9105   3rd Qu.:0.8790   3rd Qu.:0.9375   3rd Qu.:0.8585  \n Max.   :0.9470   Max.   :0.9150   Max.   :0.9740   Max.   :0.8810  \n                                                                    \n    edindexf         edindexm           esch           eschf      \n Min.   :0.7660   Min.   :0.7570   Min.   :15.13   Min.   :15.25  \n 1st Qu.:0.8085   1st Qu.:0.7870   1st Qu.:17.04   1st Qu.:17.40  \n Median :0.8500   Median :0.8400   Median :17.77   Median :18.00  \n Mean   :0.8371   Mean   :0.8271   Mean   :17.42   Mean   :17.60  \n 3rd Qu.:0.8600   3rd Qu.:0.8535   3rd Qu.:18.00   3rd Qu.:18.00  \n Max.   :0.8760   Max.   :0.8880   Max.   :18.00   Max.   :18.00  \n                                                                  \n     eschm            msch            mschf            mschm       \n Min.   :14.99   Min.   : 9.462   Min.   : 9.399   Min.   : 9.548  \n 1st Qu.:16.61   1st Qu.:10.029   1st Qu.: 9.986   1st Qu.:10.159  \n Median :17.34   Median :10.552   Median :10.513   Median :10.548  \n Mean   :17.10   Mean   :10.498   Mean   :10.442   Mean   :10.562  \n 3rd Qu.:17.82   3rd Qu.:10.898   3rd Qu.:10.805   3rd Qu.:10.955  \n Max.   :18.00   Max.   :11.444   Max.   :11.290   Max.   :11.634  \n                                                                   \n     lifexp         lifexpf         lifexpm           gnic      \n Min.   :80.46   Min.   :83.00   Min.   :77.89   Min.   :27583  \n 1st Qu.:82.19   1st Qu.:85.28   1st Qu.:79.32   1st Qu.:30418  \n Median :82.93   Median :85.67   Median :80.06   Median :34612  \n Mean   :82.74   Mean   :85.52   Mean   :79.99   Mean   :36767  \n 3rd Qu.:83.38   3rd Qu.:86.21   3rd Qu.:80.56   3rd Qu.:41466  \n Max.   :84.81   Max.   :87.25   Max.   :82.04   Max.   :52774  \n                                                                \n     gnicf           gnicm           lgnic           lgnicf     \n Min.   :22592   Min.   :32745   Min.   :10.22   Min.   :10.03  \n 1st Qu.:24867   1st Qu.:36170   1st Qu.:10.32   1st Qu.:10.12  \n Median :28224   Median :41247   Median :10.45   Median :10.25  \n Mean   :29934   Mean   :43875   Mean   :10.49   Mean   :10.29  \n 3rd Qu.:33694   3rd Qu.:49565   3rd Qu.:10.63   3rd Qu.:10.43  \n Max.   :42681   Max.   :63336   Max.   :10.87   Max.   :10.66  \n                                                                \n     lgnicm           pop     \n Min.   :10.40   Min.   : NA  \n 1st Qu.:10.50   1st Qu.: NA  \n Median :10.63   Median : NA  \n Mean   :10.67   Mean   :NaN  \n 3rd Qu.:10.81   3rd Qu.: NA  \n Max.   :11.06   Max.   : NA  \n                 NA's   :19   \n\n# Diferencias regionales durante el período (box plots)\n# Comparación entre continentes\ndf1 %&gt;%\n  plot_ly(x = ~shdi, y = ~continent, frame = ~year, color = ~continent, \n          type = 'box') %&gt;%\n    layout(xaxis = list(title = \"SHDI\"),\n           yaxis = list(title = \"Continente\"))\n\n\n\n\n# Comparación entre varios países\nsubset(df1, country %in% c(\"Spain\", \"Portugal\", \"France\")) %&gt;%\n  plot_ly(x = ~shdi, y = ~country, frame = ~year, color = ~country, \n          type = 'box') %&gt;%\n    layout(xaxis = list(title = \"SHDI\"),\n           yaxis = list(title = \"País\"))\n\n\n\n\n# Evolución regional dentro de un país (series temporales)\nplot_ly(df1[df1$country == \"Spain\",], x = ~year, y = ~shdi, \n        color = ~region, type = \"scatter\", mode = \"lines\") %&gt;%\n    layout(xaxis = list(title = \"Año\"),\n           yaxis = list(title = \"SHDI\", type = \"log\"))\n\n\n\n\n# Correlación desarrollo humano-renta per cápita (scatter plots)\nplot_ly(df1, \n        y = ~shdi, \n        x = ~lgnic,\n        frame = ~year,\n        type = 'scatter', \n        mode = 'markers', \n        color = ~continent, \n        colors = 'Set1') %&gt;%\n    layout(xaxis = list(title = \"Renta nacional bruta per capita (log)\"),\n           yaxis = list(title = \"SHDI\"))\n\n\n\n\n# Análisis exploratorio espacial (ESDA)\n# Mapa de distribución espacial del SHDI en 2021\ndf2021_2 &lt;- df2021 %&gt;% \n  rename(GDLcode = GDLCODE)\ngdf2021 &lt;- inner_join(map, df2021_2, by = \"GDLcode\")\ncolnames(gdf2021)\n\n [1] \"GDLcode\"      \"constant\"     \"iso_code.x\"   \"country.x\"    \"region.x\"    \n [6] \"...1\"         \"iso_code.y\"   \"country.y\"    \"year\"         \"level\"       \n[11] \"region.y\"     \"continent\"    \"sgdi\"         \"shdi\"         \"shdif\"       \n[16] \"shdim\"        \"healthindex\"  \"healthindexf\" \"healthindexm\" \"incindex\"    \n[21] \"incindexf\"    \"incindexm\"    \"edindex\"      \"edindexf\"     \"edindexm\"    \n[26] \"esch\"         \"eschf\"        \"eschm\"        \"msch\"         \"mschf\"       \n[31] \"mschm\"        \"lifexp\"       \"lifexpf\"      \"lifexpm\"      \"gnic\"        \n[36] \"gnicf\"        \"gnicm\"        \"lgnic\"        \"lgnicf\"       \"lgnicm\"      \n[41] \"pop\"          \"geometry\"    \n\nprint(gdf2021)\n\nSimple feature collection with 1714 features and 41 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -55.98403 xmax: 180 ymax: 83.10833\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   GDLcode constant iso_code.x   country.x\n1  AFGr101    World        AFG Afghanistan\n2  AFGr102    World        AFG Afghanistan\n3  AFGr103    World        AFG Afghanistan\n4  AFGr104    World        AFG Afghanistan\n5  AFGr105    World        AFG Afghanistan\n6  AFGr106    World        AFG Afghanistan\n7  AFGr107    World        AFG Afghanistan\n8  AFGr108    World        AFG Afghanistan\n9  AGOr201    World        AGO      Angola\n10 AGOr202    World        AGO      Angola\n                                              region.x ...1 iso_code.y\n1  Central (Kabul Wardak Kapisa Logar Parwan Panjsher)  280        AFG\n2                  Central Highlands (Bamyan Daikundi)  281        AFG\n3             East (Nangarhar Kunar Laghman Nooristan)  282        AFG\n4      North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)  283        AFG\n5        North East (Baghlan Takhar Badakhshan Kunduz)  284        AFG\n6        South (Uruzgan Helmand Zabul Nimroz Kandahar)  285        AFG\n7             South East (Ghazni Paktya Paktika Khost)  286        AFG\n8                      West (Ghor Herat Badghis Farah)  287        AFG\n9                                              Cabinda  707        AGO\n10                                               Zaire  708        AGO\n     country.y year  level                                            region.y\n1  Afghanistan 2021 Subnat Central (Kabul Wardak Kapisa Logar Parwan Panjsher)\n2  Afghanistan 2021 Subnat                 Central Highlands (Bamyan Daikundi)\n3  Afghanistan 2021 Subnat            East (Nangarhar Kunar Laghman Nooristan)\n4  Afghanistan 2021 Subnat     North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)\n5  Afghanistan 2021 Subnat       North East (Baghlan Takhar Badakhshan Kunduz)\n6  Afghanistan 2021 Subnat       South (Uruzgan Helmand Zabul Nimroz Kandahar)\n7  Afghanistan 2021 Subnat            South East (Ghazni Paktya Paktika Khost)\n8  Afghanistan 2021 Subnat                     West (Ghor Herat Badghis Farah)\n9       Angola 2021 Subnat                                             Cabinda\n10      Angola 2021 Subnat                                               Zaire\n      continent  sgdi  shdi shdif shdim healthindex healthindexf healthindexm\n1  Asia/Pacific 0.734 0.550 0.444 0.605       0.675        0.694        0.664\n2  Asia/Pacific 0.704 0.472 0.368 0.522       0.653        0.667        0.643\n3  Asia/Pacific 0.583 0.459 0.310 0.532       0.638        0.648        0.630\n4  Asia/Pacific 0.749 0.497 0.405 0.541       0.628        0.636        0.620\n5  Asia/Pacific 0.667 0.444 0.332 0.498       0.623        0.629        0.615\n6  Asia/Pacific 0.563 0.407 0.269 0.478       0.643        0.655        0.635\n7  Asia/Pacific 0.567 0.476 0.315 0.556       0.684        0.706        0.673\n8  Asia/Pacific 0.692 0.447 0.344 0.497       0.637        0.646        0.628\n9        Africa 0.938 0.681 0.660 0.704       0.723        0.741        0.716\n10       Africa 0.892 0.615 0.581 0.651       0.698        0.711        0.693\n   incindex incindexf incindexm edindex edindexf edindexm   esch  eschf  eschm\n1     0.471     0.280     0.553   0.524    0.451    0.604 12.898 10.399 15.407\n2     0.396     0.217     0.472   0.408    0.343    0.468 12.447 10.958 14.155\n3     0.394     0.215     0.470   0.385    0.214    0.510  9.858  6.043 13.270\n4     0.464     0.274     0.546   0.420    0.382    0.467 11.456 10.004 12.857\n5     0.416     0.234     0.494   0.338    0.249    0.407  9.288  7.202 11.235\n6     0.434     0.249     0.513   0.242    0.120    0.336  6.369  3.276  9.275\n7     0.425     0.242     0.504   0.370    0.184    0.507 10.663  5.785 14.871\n8     0.424     0.241     0.503   0.330    0.261    0.389  9.314  7.546 11.006\n9     0.673     0.651     0.693   0.649    0.597    0.703 14.015 13.636 14.497\n10    0.601     0.580     0.620   0.556    0.476    0.644 11.963 10.921 13.080\n    msch mschf mschm lifexp lifexpf lifexpm     gnic    gnicf    gnicm lgnic\n1  4.975 4.851 5.281 63.843  67.633  60.672 2264.832  638.644 3894.162 7.725\n2  1.857 1.168 2.256 62.415  65.829  59.326 1374.650  420.676 2282.217 7.226\n3  3.325 1.397 4.232 61.471  64.627  58.426 1355.298  415.719 2247.852 7.212\n4  3.058 3.124 3.305 60.843  63.825  57.822 2159.844  613.795 3701.300 7.678\n5  2.390 1.473 2.842 60.500  63.384  57.490 1571.877  470.580 2634.320 7.360\n6  1.942 0.863 2.343 61.811  65.061  58.751 1770.461  519.798 2991.997 7.479\n7  2.208 0.686 2.824 64.435  68.377  61.224 1671.820  495.470 2813.958 7.422\n8  2.136 1.549 2.492 61.378  64.509  58.337 1657.965  492.035 2789.009 7.413\n9  7.781 6.556 9.013 67.003  70.673  64.051 8600.724 7421.829 9815.778 9.060\n10 6.706 5.181 8.405 65.339  68.714  62.516 5346.571 4649.549 6059.734 8.584\n   lgnicf lgnicm pop                       geometry\n1   6.459  8.267  NA MULTIPOLYGON (((67.61506 34...\n2   6.042  7.733  NA MULTIPOLYGON (((65.23611 33...\n3   6.030  7.718  NA MULTIPOLYGON (((69.92137 34...\n4   6.420  8.216  NA MULTIPOLYGON (((66.38873 34...\n5   6.154  7.876  NA MULTIPOLYGON (((67.39591 35...\n6   6.253  8.004  NA MULTIPOLYGON (((60.89944 29...\n7   6.206  7.942  NA MULTIPOLYGON (((68.10873 31...\n8   6.199  7.933  NA MULTIPOLYGON (((61.12394 31...\n9   8.912  9.192  NA MULTIPOLYGON (((12.21127 -5...\n10  8.445  8.709  NA MULTIPOLYGON (((13.08792 -7...\n\nggplot(gdf2021) +\n  geom_sf(aes(fill=shdi)) +\n  theme_bw() +\n  labs(title = \"Distribución espacial del SHDI en 2021\") +\n  scale_fill_viridis(option=\"OrRd\")\n\n\n\n# El SHDI español en 2021\ngdf2021Spain &lt;- gdf2021[gdf2021$country.x == \"Spain\",]\nggplot(gdf2021Spain) + geom_sf(aes(fill=shdi)) +\n  theme_bw() +\n  labs(title = \"Distribución espacial del SHDI español en 2021\") +\n  scale_fill_viridis(option=\"OrRd\")\n\n\n\n# Gráfica sólo con las regiones peninsulares\nggplot(gdf2021Spain_2 &lt;- gdf2021Spain[-c(14,17),]) + geom_sf(aes(fill=shdi)) +\n  theme_bw() +\n  labs(title = \"Distribución espacial del SHDI peninsular español en 2021\") +\n  scale_fill_viridis(option=\"OrRd\")"
  },
  {
    "objectID": "p1c2-app3b.html#código-python",
    "href": "p1c2-app3b.html#código-python",
    "title": "Aplicación 1.3b (Gestión y representación gráfica de datos espaciales): Desarrollo humano al nivel mundial",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nfrom matplotlib.ticker import FormatStrFormatter\nfrom matplotlib_scalebar.scalebar import ScaleBar\nfrom pylab import rcParams\nimport matplotlib as mpl\nmpl.rcParams['figure.dpi'] = 72\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport chart_studio\nimport chart_studio.plotly as save2cs\nimport geopandas as gpd\nimport warnings\nwarnings.filterwarnings('ignore')\n# Lectura de datos\ndf = pd.read_csv('data/GDLdbase.csv', index_col=0)\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 58884 entries, 1 to 58884\nData columns (total 36 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   iso_code      58884 non-null  object \n 1   country       58884 non-null  object \n 2   year          58884 non-null  int64  \n 3   GDLCODE       58884 non-null  object \n 4   level         58884 non-null  object \n 5   region        58884 non-null  object \n 6   continent     58884 non-null  object \n 7   sgdi          38810 non-null  float64\n 8   shdi          58482 non-null  float64\n 9   shdif         38825 non-null  float64\n 10  shdim         38813 non-null  float64\n 11  healthindex   58820 non-null  float64\n 12  healthindexf  39649 non-null  float64\n 13  healthindexm  39649 non-null  float64\n 14  incindex      58659 non-null  float64\n 15  incindexf     39953 non-null  float64\n 16  incindexm     39953 non-null  float64\n 17  edindex       58777 non-null  float64\n 18  edindexf      39176 non-null  float64\n 19  edindexm      39164 non-null  float64\n 20  esch          58882 non-null  float64\n 21  eschf         39371 non-null  float64\n 22  eschm         39370 non-null  float64\n 23  msch          58779 non-null  float64\n 24  mschf         39405 non-null  float64\n 25  mschm         39394 non-null  float64\n 26  lifexp        58820 non-null  float64\n 27  lifexpf       39649 non-null  float64\n 28  lifexpm       39649 non-null  float64\n 29  gnic          58659 non-null  float64\n 30  gnicf         39953 non-null  float64\n 31  gnicm         39953 non-null  float64\n 32  lgnic         58659 non-null  float64\n 33  lgnicf        39953 non-null  float64\n 34  lgnicm        39953 non-null  float64\n 35  pop           96 non-null     float64\ndtypes: float64(29), int64(1), object(6)\nmemory usage: 16.6+ MB\n\ndf\n\n      iso_code      country  year  GDLCODE     level  \\\n1          AFG  Afghanistan  1990  AFGr101    Subnat   \n2          AFG  Afghanistan  1990  AFGr102    Subnat   \n3          AFG  Afghanistan  1990  AFGr103    Subnat   \n4          AFG  Afghanistan  1990  AFGr104    Subnat   \n5          AFG  Afghanistan  1990  AFGr105    Subnat   \n...        ...          ...   ...      ...       ...   \n58880      ZWE     Zimbabwe  2021  ZWEr107    Subnat   \n58881      ZWE     Zimbabwe  2021  ZWEr108    Subnat   \n58882      ZWE     Zimbabwe  2021  ZWEr109    Subnat   \n58883      ZWE     Zimbabwe  2021  ZWEr110    Subnat   \n58884      ZWE     Zimbabwe  2021     ZWEt  National   \n\n                                                  region     continent   sgdi  \\\n1      Central (Kabul Wardak Kapisa Logar Parwan Panj...  Asia/Pacific    NaN   \n2                    Central Highlands (Bamyan Daikundi)  Asia/Pacific    NaN   \n3               East (Nangarhar Kunar Laghman Nooristan)  Asia/Pacific    NaN   \n4        North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)  Asia/Pacific    NaN   \n5          North East (Baghlan Takhar Badakhshan Kunduz)  Asia/Pacific    NaN   \n...                                                  ...           ...    ...   \n58880                                           Midlands        Africa  0.958   \n58881                                           Masvingo        Africa  0.962   \n58882                                             Harare        Africa  0.962   \n58883                                           Bulawayo        Africa  0.985   \n58884                                              Total        Africa  0.961   \n\n        shdi  shdif  shdim  healthindex  healthindexf  healthindexm  incindex  \\\n1      0.332    NaN    NaN        0.415           NaN           NaN     0.539   \n2      0.281    NaN    NaN        0.375           NaN           NaN     0.469   \n3      0.287    NaN    NaN        0.453           NaN           NaN     0.472   \n4      0.259    NaN    NaN        0.375           NaN           NaN     0.477   \n5      0.266    NaN    NaN        0.404           NaN           NaN     0.494   \n...      ...    ...    ...          ...           ...           ...       ...   \n58880  0.590  0.577  0.602        0.593         0.595         0.586     0.544   \n58881  0.588  0.578  0.601        0.650         0.664         0.639     0.520   \n58882  0.665  0.652  0.678        0.619         0.627         0.610     0.648   \n58883  0.693  0.689  0.699        0.656         0.670         0.644     0.688   \n58884  0.593  0.580  0.604        0.604         0.608         0.596     0.550   \n\n       incindexf  incindexm  edindex  edindexf  edindexm    esch   eschf  \\\n1            NaN        NaN    0.164       NaN       NaN   3.500     NaN   \n2            NaN        NaN    0.126       NaN       NaN   3.644     NaN   \n3            NaN        NaN    0.110       NaN       NaN   2.556     NaN   \n4            NaN        NaN    0.097       NaN       NaN   2.731     NaN   \n5            NaN        NaN    0.094       NaN       NaN   2.535     NaN   \n...          ...        ...      ...       ...       ...     ...     ...   \n58880      0.522      0.566    0.635     0.618     0.659  12.668  12.575   \n58881      0.498      0.541    0.602     0.584     0.628  12.058  12.013   \n58882      0.624      0.672    0.732     0.707     0.759  13.156  12.470   \n58883      0.663      0.712    0.739     0.735     0.746  14.115  14.173   \n58884      0.528      0.572    0.627     0.609     0.647  12.111  11.965   \n\n        eschm    msch   mschf   mschm  lifexp  lifexpf  lifexpm      gnic  \\\n1         NaN   1.989     NaN     NaN  46.975      NaN      NaN  3549.393   \n2         NaN   0.752     NaN     NaN  44.402      NaN      NaN  2224.831   \n3         NaN   1.175     NaN     NaN  49.445      NaN      NaN  2279.290   \n4         NaN   0.627     NaN     NaN  44.385      NaN      NaN  2356.842   \n5         NaN   0.710     NaN     NaN  46.269      NaN      NaN  2623.883   \n...       ...     ...     ...     ...     ...      ...      ...       ...   \n58880  12.858   8.492   8.073   9.045  58.544   61.193   55.566  3670.709   \n58881  12.184   8.013   7.504   8.685  62.276   65.641   59.025  3127.485   \n58882  13.981  10.993  10.825  11.114  60.261   63.250   57.171  7314.452   \n58883  14.218  10.405  10.246  10.541  62.628   66.056   59.346  9516.362   \n58884  12.271   8.711   8.297   9.191  59.253   62.045   56.232  3809.887   \n\n          gnicf      gnicm  lgnic  lgnicf  lgnicm  pop  \n1           NaN        NaN  8.175     NaN     NaN  NaN  \n2           NaN        NaN  7.707     NaN     NaN  NaN  \n3           NaN        NaN  7.732     NaN     NaN  NaN  \n4           NaN        NaN  7.765     NaN     NaN  NaN  \n5           NaN        NaN  7.872     NaN     NaN  NaN  \n...         ...        ...    ...     ...     ...  ...  \n58880  3168.011   4233.422  8.208   8.061   8.351  NaN  \n58881  2706.948   3596.899  8.048   7.904   8.188  NaN  \n58882  6235.132   8537.414  8.898   8.738   9.052  NaN  \n58883  8073.914  11158.386  9.161   8.996   9.320  NaN  \n58884  3285.934   4396.778  8.245   8.097   8.389  NaN  \n\n[58884 rows x 36 columns]\n\nmap = gpd.read_file(\"data/GDLmap.geojson\")\nmap.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 1745 entries, 0 to 1744\nData columns (total 6 columns):\n #   Column    Non-Null Count  Dtype   \n---  ------    --------------  -----   \n 0   GDLcode   1745 non-null   object  \n 1   constant  1745 non-null   object  \n 2   iso_code  1742 non-null   object  \n 3   country   1742 non-null   object  \n 4   region    1742 non-null   object  \n 5   geometry  1745 non-null   geometry\ndtypes: geometry(1), object(5)\nmemory usage: 81.9+ KB\n\nmap\n\n      GDLcode constant iso_code      country  \\\n0     AFGr101    World      AFG  Afghanistan   \n1     AFGr102    World      AFG  Afghanistan   \n2     AFGr103    World      AFG  Afghanistan   \n3     AFGr104    World      AFG  Afghanistan   \n4     AFGr105    World      AFG  Afghanistan   \n...       ...      ...      ...          ...   \n1740  ZWEr106    World      ZWE     Zimbabwe   \n1741  ZWEr107    World      ZWE     Zimbabwe   \n1742  ZWEr108    World      ZWE     Zimbabwe   \n1743  ZWEr109    World      ZWE     Zimbabwe   \n1744  ZWEr110    World      ZWE     Zimbabwe   \n\n                                                 region  \\\n0     Central (Kabul Wardak Kapisa Logar Parwan Panj...   \n1                   Central Highlands (Bamyan Daikundi)   \n2              East (Nangarhar Kunar Laghman Nooristan)   \n3       North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)   \n4         North East (Baghlan Takhar Badakhshan Kunduz)   \n...                                                 ...   \n1740                                 Matebeleland South   \n1741                                           Midlands   \n1742                                           Masvingo   \n1743                                             Harare   \n1744                                           Bulawayo   \n\n                                               geometry  \n0     MULTIPOLYGON (((67.61506 34.23957, 67.59259 34...  \n1     MULTIPOLYGON (((65.23611 33.37125, 65.25839 33...  \n2     MULTIPOLYGON (((69.92137 34.02534, 69.90879 34...  \n3     MULTIPOLYGON (((66.38873 34.93133, 66.33110 34...  \n4     MULTIPOLYGON (((67.39591 35.43840, 67.45535 35...  \n...                                                 ...  \n1740  MULTIPOLYGON (((29.36831 -22.19781, 29.33401 -...  \n1741  MULTIPOLYGON (((29.22650 -19.48012, 29.21404 -...  \n1742  MULTIPOLYGON (((31.06733 -22.34189, 31.08549 -...  \n1743  MULTIPOLYGON (((31.08852 -17.66625, 31.11562 -...  \n1744  MULTIPOLYGON (((28.61305 -20.23587, 28.60440 -...  \n\n[1745 rows x 6 columns]\n\n# Preparación de datos\n# Eliminación de observaciones nacionales (variable level -&gt; National)\ndf1 = df[df.level != 'National']\ndf1\n\n      iso_code      country  year  GDLCODE   level  \\\n1          AFG  Afghanistan  1990  AFGr101  Subnat   \n2          AFG  Afghanistan  1990  AFGr102  Subnat   \n3          AFG  Afghanistan  1990  AFGr103  Subnat   \n4          AFG  Afghanistan  1990  AFGr104  Subnat   \n5          AFG  Afghanistan  1990  AFGr105  Subnat   \n...        ...          ...   ...      ...     ...   \n58879      ZWE     Zimbabwe  2021  ZWEr106  Subnat   \n58880      ZWE     Zimbabwe  2021  ZWEr107  Subnat   \n58881      ZWE     Zimbabwe  2021  ZWEr108  Subnat   \n58882      ZWE     Zimbabwe  2021  ZWEr109  Subnat   \n58883      ZWE     Zimbabwe  2021  ZWEr110  Subnat   \n\n                                                  region     continent   sgdi  \\\n1      Central (Kabul Wardak Kapisa Logar Parwan Panj...  Asia/Pacific    NaN   \n2                    Central Highlands (Bamyan Daikundi)  Asia/Pacific    NaN   \n3               East (Nangarhar Kunar Laghman Nooristan)  Asia/Pacific    NaN   \n4        North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)  Asia/Pacific    NaN   \n5          North East (Baghlan Takhar Badakhshan Kunduz)  Asia/Pacific    NaN   \n...                                                  ...           ...    ...   \n58879                                 Matebeleland South        Africa  0.985   \n58880                                           Midlands        Africa  0.958   \n58881                                           Masvingo        Africa  0.962   \n58882                                             Harare        Africa  0.962   \n58883                                           Bulawayo        Africa  0.985   \n\n        shdi  shdif  shdim  healthindex  healthindexf  healthindexm  incindex  \\\n1      0.332    NaN    NaN        0.415           NaN           NaN     0.539   \n2      0.281    NaN    NaN        0.375           NaN           NaN     0.469   \n3      0.287    NaN    NaN        0.453           NaN           NaN     0.472   \n4      0.259    NaN    NaN        0.375           NaN           NaN     0.477   \n5      0.266    NaN    NaN        0.404           NaN           NaN     0.494   \n...      ...    ...    ...          ...           ...           ...       ...   \n58879  0.585  0.581  0.590        0.665         0.681         0.652     0.530   \n58880  0.590  0.577  0.602        0.593         0.595         0.586     0.544   \n58881  0.588  0.578  0.601        0.650         0.664         0.639     0.520   \n58882  0.665  0.652  0.678        0.619         0.627         0.610     0.648   \n58883  0.693  0.689  0.699        0.656         0.670         0.644     0.688   \n\n       incindexf  incindexm  edindex  edindexf  edindexm    esch   eschf  \\\n1            NaN        NaN    0.164       NaN       NaN   3.500     NaN   \n2            NaN        NaN    0.126       NaN       NaN   3.644     NaN   \n3            NaN        NaN    0.110       NaN       NaN   2.556     NaN   \n4            NaN        NaN    0.097       NaN       NaN   2.731     NaN   \n5            NaN        NaN    0.094       NaN       NaN   2.535     NaN   \n...          ...        ...      ...       ...       ...     ...     ...   \n58879      0.508      0.551    0.566     0.566     0.570  10.989  11.145   \n58880      0.522      0.566    0.635     0.618     0.659  12.668  12.575   \n58881      0.498      0.541    0.602     0.584     0.628  12.058  12.013   \n58882      0.624      0.672    0.732     0.707     0.759  13.156  12.470   \n58883      0.663      0.712    0.739     0.735     0.746  14.115  14.173   \n\n        eschm    msch   mschf   mschm  lifexp  lifexpf  lifexpm      gnic  \\\n1         NaN   1.989     NaN     NaN  46.975      NaN      NaN  3549.393   \n2         NaN   0.752     NaN     NaN  44.402      NaN      NaN  2224.831   \n3         NaN   1.175     NaN     NaN  49.445      NaN      NaN  2279.290   \n4         NaN   0.627     NaN     NaN  44.385      NaN      NaN  2356.842   \n5         NaN   0.710     NaN     NaN  46.269      NaN      NaN  2623.883   \n...       ...     ...     ...     ...     ...      ...      ...       ...   \n58879  10.863   7.834   7.697   8.044  63.246   66.784   59.907  3339.052   \n58880  12.858   8.492   8.073   9.045  58.544   61.193   55.566  3670.709   \n58881  12.184   8.013   7.504   8.685  62.276   65.641   59.025  3127.485   \n58882  13.981  10.993  10.825  11.114  60.261   63.250   57.171  7314.452   \n58883  14.218  10.405  10.246  10.541  62.628   66.056   59.346  9516.362   \n\n          gnicf      gnicm  lgnic  lgnicf  lgnicm  pop  \n1           NaN        NaN  8.175     NaN     NaN  NaN  \n2           NaN        NaN  7.707     NaN     NaN  NaN  \n3           NaN        NaN  7.732     NaN     NaN  NaN  \n4           NaN        NaN  7.765     NaN     NaN  NaN  \n5           NaN        NaN  7.872     NaN     NaN  NaN  \n...         ...        ...    ...     ...     ...  ...  \n58879  2886.675   3844.591  8.113   7.968   8.254  NaN  \n58880  3168.011   4233.422  8.208   8.061   8.351  NaN  \n58881  2706.948   3596.899  8.048   7.904   8.188  NaN  \n58882  6235.132   8537.414  8.898   8.738   9.052  NaN  \n58883  8073.914  11158.386  9.161   8.996   9.320  NaN  \n\n[53410 rows x 36 columns]\n\ndf1.columns\n\nIndex(['iso_code', 'country', 'year', 'GDLCODE', 'level', 'region',\n       'continent', 'sgdi', 'shdi', 'shdif', 'shdim', 'healthindex',\n       'healthindexf', 'healthindexm', 'incindex', 'incindexf', 'incindexm',\n       'edindex', 'edindexf', 'edindexm', 'esch', 'eschf', 'eschm', 'msch',\n       'mschf', 'mschm', 'lifexp', 'lifexpf', 'lifexpm', 'gnic', 'gnicf',\n       'gnicm', 'lgnic', 'lgnicf', 'lgnicm', 'pop'],\n      dtype='object')\n\n# Selección del año de análisis, 2021\ndf1[\"year\"]= df1[\"year\"].astype(str)\ndf2021 = df1[df1['year'] == '2021']\ndf2021\n\n      iso_code      country  year  GDLCODE   level  \\\n280        AFG  Afghanistan  2021  AFGr101  Subnat   \n281        AFG  Afghanistan  2021  AFGr102  Subnat   \n282        AFG  Afghanistan  2021  AFGr103  Subnat   \n283        AFG  Afghanistan  2021  AFGr104  Subnat   \n284        AFG  Afghanistan  2021  AFGr105  Subnat   \n...        ...          ...   ...      ...     ...   \n58879      ZWE     Zimbabwe  2021  ZWEr106  Subnat   \n58880      ZWE     Zimbabwe  2021  ZWEr107  Subnat   \n58881      ZWE     Zimbabwe  2021  ZWEr108  Subnat   \n58882      ZWE     Zimbabwe  2021  ZWEr109  Subnat   \n58883      ZWE     Zimbabwe  2021  ZWEr110  Subnat   \n\n                                                  region     continent   sgdi  \\\n280    Central (Kabul Wardak Kapisa Logar Parwan Panj...  Asia/Pacific  0.734   \n281                  Central Highlands (Bamyan Daikundi)  Asia/Pacific  0.704   \n282             East (Nangarhar Kunar Laghman Nooristan)  Asia/Pacific  0.583   \n283      North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)  Asia/Pacific  0.749   \n284        North East (Baghlan Takhar Badakhshan Kunduz)  Asia/Pacific  0.667   \n...                                                  ...           ...    ...   \n58879                                 Matebeleland South        Africa  0.985   \n58880                                           Midlands        Africa  0.958   \n58881                                           Masvingo        Africa  0.962   \n58882                                             Harare        Africa  0.962   \n58883                                           Bulawayo        Africa  0.985   \n\n        shdi  shdif  shdim  healthindex  healthindexf  healthindexm  incindex  \\\n280    0.550  0.444  0.605        0.675         0.694         0.664     0.471   \n281    0.472  0.368  0.522        0.653         0.667         0.643     0.396   \n282    0.459  0.310  0.532        0.638         0.648         0.630     0.394   \n283    0.497  0.405  0.541        0.628         0.636         0.620     0.464   \n284    0.444  0.332  0.498        0.623         0.629         0.615     0.416   \n...      ...    ...    ...          ...           ...           ...       ...   \n58879  0.585  0.581  0.590        0.665         0.681         0.652     0.530   \n58880  0.590  0.577  0.602        0.593         0.595         0.586     0.544   \n58881  0.588  0.578  0.601        0.650         0.664         0.639     0.520   \n58882  0.665  0.652  0.678        0.619         0.627         0.610     0.648   \n58883  0.693  0.689  0.699        0.656         0.670         0.644     0.688   \n\n       incindexf  incindexm  edindex  edindexf  edindexm    esch   eschf  \\\n280        0.280      0.553    0.524     0.451     0.604  12.898  10.399   \n281        0.217      0.472    0.408     0.343     0.468  12.447  10.958   \n282        0.215      0.470    0.385     0.214     0.510   9.858   6.043   \n283        0.274      0.546    0.420     0.382     0.467  11.456  10.004   \n284        0.234      0.494    0.338     0.249     0.407   9.288   7.202   \n...          ...        ...      ...       ...       ...     ...     ...   \n58879      0.508      0.551    0.566     0.566     0.570  10.989  11.145   \n58880      0.522      0.566    0.635     0.618     0.659  12.668  12.575   \n58881      0.498      0.541    0.602     0.584     0.628  12.058  12.013   \n58882      0.624      0.672    0.732     0.707     0.759  13.156  12.470   \n58883      0.663      0.712    0.739     0.735     0.746  14.115  14.173   \n\n        eschm    msch   mschf   mschm  lifexp  lifexpf  lifexpm      gnic  \\\n280    15.407   4.975   4.851   5.281  63.843   67.633   60.672  2264.832   \n281    14.155   1.857   1.168   2.256  62.415   65.829   59.326  1374.650   \n282    13.270   3.325   1.397   4.232  61.471   64.627   58.426  1355.298   \n283    12.857   3.058   3.124   3.305  60.843   63.825   57.822  2159.844   \n284    11.235   2.390   1.473   2.842  60.500   63.384   57.490  1571.877   \n...       ...     ...     ...     ...     ...      ...      ...       ...   \n58879  10.863   7.834   7.697   8.044  63.246   66.784   59.907  3339.052   \n58880  12.858   8.492   8.073   9.045  58.544   61.193   55.566  3670.709   \n58881  12.184   8.013   7.504   8.685  62.276   65.641   59.025  3127.485   \n58882  13.981  10.993  10.825  11.114  60.261   63.250   57.171  7314.452   \n58883  14.218  10.405  10.246  10.541  62.628   66.056   59.346  9516.362   \n\n          gnicf      gnicm  lgnic  lgnicf  lgnicm  pop  \n280     638.644   3894.162  7.725   6.459   8.267  NaN  \n281     420.676   2282.217  7.226   6.042   7.733  NaN  \n282     415.719   2247.852  7.212   6.030   7.718  NaN  \n283     613.795   3701.300  7.678   6.420   8.216  NaN  \n284     470.580   2634.320  7.360   6.154   7.876  NaN  \n...         ...        ...    ...     ...     ...  ...  \n58879  2886.675   3844.591  8.113   7.968   8.254  NaN  \n58880  3168.011   4233.422  8.208   8.061   8.351  NaN  \n58881  2706.948   3596.899  8.048   7.904   8.188  NaN  \n58882  6235.132   8537.414  8.898   8.738   9.052  NaN  \n58883  8073.914  11158.386  9.161   8.996   9.320  NaN  \n\n[1786 rows x 36 columns]\n\ndf2021['continent'].unique()\n\narray(['Asia/Pacific', 'Africa', 'Europe', 'America'], dtype=object)\n\ndf2021['country'].unique()\n\narray(['Afghanistan', 'Angola', 'Albania', 'Argentina urban', 'Armenia',\n       'Australia', 'Austria', 'Azerbaijan', 'Burundi', 'Belgium',\n       'Benin', 'Burkina Faso', 'Bangladesh', 'Bulgaria',\n       'Bosnia and Herzegovina', 'Belarus', 'Belize', 'Bolivia', 'Brazil',\n       'Barbados', 'Bhutan', 'Botswana', 'Central African Republic CAR',\n       'Canada', 'Switzerland', 'Chili', 'China', \"Cote d'Ivoire\",\n       'Cameroon', 'Congo Democratic Republic', 'Congo Brazzaville',\n       'Colombia', 'Comoros', 'Cape Verde', 'Costa Rica', 'Cuba',\n       'Czech Republic', 'Germany', 'Djibouti', 'Denmark',\n       'Dominican Republic', 'Algeria', 'Ecuador', 'Egypt', 'Eritrea',\n       'Spain', 'Estonia', 'Ethiopia', 'Finland', 'Fiji', 'France',\n       'Gabon', 'United Kingdom', 'Georgia', 'Ghana', 'Guinea', 'Gambia',\n       'Guinea Bissau', 'Equatorial Guinea', 'Greece', 'Guatemala',\n       'Guyana', 'Honduras', 'Croatia', 'Haiti', 'Hungary', 'Indonesia',\n       'India', 'Ireland', 'Iran', 'Iraq', 'Italy', 'Jamaica', 'Jordan',\n       'Japan', 'Kazakhstan', 'Kenya', 'Kyrgyzstan', 'Cambodia',\n       'Kiribati', 'South Korea', 'Kuwait', 'Lao', 'Lebanon', 'Liberia',\n       'Libya', 'Saint Lucia', 'Lesotho', 'Lithuania', 'Latvia',\n       'Morocco', 'Moldova', 'Madagascar', 'Maldives', 'Mexico',\n       'North Macedonia', 'Mali', 'Myanmar', 'Monte Negro', 'Mongolia',\n       'Mozambique', 'Mauritania', 'Mauritius', 'Malawi', 'Malaysia',\n       'Namibia', 'Niger', 'Nigeria', 'Nicaragua', 'Netherlands',\n       'Norway', 'Nepal', 'New Zealand', 'Pakistan', 'Panama', 'Peru',\n       'Philippines', 'Papua New Guinea', 'Poland', 'Portugal',\n       'Paraguay', 'Palestine', 'Romania', 'Russian Federation', 'Rwanda',\n       'Saudi Arabia', 'Sudan', 'Senegal', 'Sierra Leone', 'El Salvador',\n       'Somalia', 'Serbia', 'South Sudan', 'Sao Tome & Principe',\n       'Suriname', 'Slovakia', 'Slovenia', 'Sweden', 'Eswatini', 'Syria',\n       'Chad', 'Togo', 'Thailand', 'Tajikistan', 'Turkmenistan',\n       'Timor Leste', 'Tonga', 'Trinidad & Tobago', 'Tunisia', 'Turkey',\n       'Tuvalu', 'Tanzania', 'Uganda', 'Ukraine', 'Uruguay',\n       'United States', 'Uzbekistan', 'Venezuela', 'Vietnam', 'Vanuatu',\n       'Samoa', 'Kosovo', 'Yemen', 'South Africa', 'Zambia', 'Zimbabwe'],\n      dtype=object)\n\n# Análisis exploratorio básico (EDA)\n# Estadísticos para todo el período\ndf1.loc[:, (df1.columns != 'iso_code') & (df1.columns != 'year') & (df1.columns != 'country') & (df1.columns != 'GDLCODE') & (df1.columns != 'level') & (df1.columns != 'region') & (df1.columns != 'continent')].describe().round(3)\n\n            sgdi       shdi      shdif      shdim  healthindex  healthindexf  \\\ncount  35460.000  53036.000  35475.000  35463.000    53346.000     36177.000   \nmean       0.923      0.645      0.645      0.691        0.746         0.767   \nstd        0.079      0.171      0.177      0.155        0.143         0.145   \nmin        0.369      0.172      0.126      0.236       -0.102         0.250   \n25%        0.881      0.515      0.511      0.576        0.654         0.677   \n50%        0.947      0.661      0.659      0.707        0.776         0.804   \n75%        0.982      0.776      0.788      0.805        0.856         0.880   \nmax        1.070      0.989      0.974      0.996        1.000         1.000   \n\n       healthindexm   incindex  incindexf  incindexm    edindex   edindexf  \\\ncount     36177.000  53205.000  36391.000  36391.000  53310.000  35763.000   \nmean          0.767      0.652      0.610      0.708      0.566      0.590   \nstd           0.130      0.177      0.182      0.176      0.204      0.214   \nmin           0.318      0.192      0.038      0.256      0.040      0.029   \n25%           0.683      0.511      0.468      0.571      0.418      0.427   \n50%           0.788      0.662      0.600      0.731      0.574      0.610   \n75%           0.864      0.785      0.752      0.839      0.720      0.758   \nmax           1.000      1.000      1.000      1.000      1.000      0.995   \n\n        edindexm       esch      eschf      eschm       msch      mschf  \\\ncount  35751.000  53410.000  35935.000  35934.000  53310.000  35953.000   \nmean       0.617     11.733     12.441     12.450      7.204      7.305   \nstd        0.177      3.489      3.551      2.859      3.496      3.732   \nmin        0.077      0.342      0.867      2.042      0.137      0.067   \n25%        0.494      9.613     10.136     10.755      4.353      4.204   \n50%        0.621     11.983     12.780     12.543      7.127      7.506   \n75%        0.754     14.266     15.150     14.505     10.020     10.373   \nmax        0.993     18.000     18.000     18.000     15.000     14.981   \n\n           mschm     lifexp    lifexpf    lifexpm        gnic       gnicf  \\\ncount  35942.000  53346.000  36177.000  36177.000   53205.000   36391.000   \nmean       8.113     68.471     72.378     67.344   13960.715   11004.433   \nstd        3.240      9.297      9.409      8.469   15985.435   13128.047   \nmin        0.207     13.338     38.782     38.170     355.461     128.186   \n25%        5.624     62.495     66.493     61.923    2950.815    2216.530   \n50%        8.111     70.420     74.738     68.706    7982.057    5325.338   \n75%       10.742     75.612     79.686     73.636   18058.970   14565.901   \nmax       14.854     85.608     88.290     84.525  209791.914  162951.184   \n\n            gnicm      lgnic     lgnicf     lgnicm      pop  \ncount   36391.000  53205.000  36391.000  36391.000   84.000  \nmean    19599.252      8.925      8.641      9.294  256.912  \nstd     21123.788      1.172      1.203      1.173  110.797  \nmin       545.888      5.873      4.853      6.302  161.098  \n25%      4387.379      7.990      7.704      8.386  188.407  \n50%     12615.949      8.985      8.580      9.443  199.020  \n75%     25888.424      9.801      9.586     10.162  280.385  \nmax    258567.313     12.254     12.001     12.463  555.660  \n\n# Estadísticos para el año 2021\ndf2021.describe().round(3)\n\n           sgdi      shdi     shdif     shdim  healthindex  healthindexf  \\\ncount  1723.000  1784.000  1723.000  1723.000     1784.000      1775.000   \nmean      0.941     0.693     0.676     0.712        0.776         0.780   \nstd       0.071     0.158     0.167     0.147        0.119         0.125   \nmin       0.369     0.232     0.174     0.293        0.400         0.312   \n25%       0.905     0.578     0.555     0.603        0.692         0.692   \n50%       0.962     0.707     0.682     0.724        0.784         0.798   \n75%       0.990     0.811     0.808     0.819        0.860         0.872   \nmax       1.060     0.989     0.974     0.996        1.000         1.000   \n\n       healthindexm  incindex  incindexf  incindexm   edindex  edindexf  \\\ncount      1775.000  1786.000   1771.000   1771.000  1786.000  1728.000   \nmean          0.774     0.681      0.626      0.716     0.642     0.641   \nstd           0.117     0.174      0.185      0.175     0.191     0.204   \nmin           0.390     0.279      0.038      0.291     0.061     0.063   \n25%           0.694     0.556      0.494      0.589     0.497     0.481   \n50%           0.777     0.698      0.613      0.744     0.662     0.673   \n75%           0.854     0.811      0.774      0.844     0.790     0.798   \nmax           1.000     1.000      1.000      1.000     1.000     0.994   \n\n       edindexm      esch     eschf     eschm      msch     mschf     mschm  \\\ncount  1728.000  1786.000  1750.000  1750.000  1786.000  1733.000  1733.000   \nmean      0.656    13.052    13.261    13.065     8.393     8.124     8.745   \nstd       0.170     3.163     3.251     2.736     3.447     3.725     3.172   \nmin       0.110     0.369     1.395     3.332     0.330     0.136     0.524   \n25%       0.527    11.145    11.086    11.363     5.626     5.136     6.250   \n50%       0.663    13.303    13.642    13.187     8.558     8.521     8.870   \n75%       0.787    15.343    15.706    14.998    11.227    11.146    11.354   \nmax       0.993    18.000    18.000    18.000    15.000    14.981    14.843   \n\n         lifexp   lifexpf   lifexpm        gnic       gnicf       gnicm  \\\ncount  1784.000  1775.000  1775.000    1786.000    1771.000    1771.000   \nmean     70.449    73.194    67.835   16411.868   12440.010   20564.405   \nstd       7.751     8.146     7.593   18232.444   14887.574   21984.616   \nmin      45.978    42.782    42.830     632.458     128.186     687.484   \n25%      64.985    67.494    62.640    3960.012    2637.606    4939.909   \n50%      70.986    74.375    67.990   10156.434    5802.553   13755.222   \n75%      75.882    79.173    72.997   21422.519   16763.350   26757.780   \nmax      85.608    88.290    84.525  209791.914  162951.184  258567.313   \n\n          lgnic    lgnicf    lgnicm      pop  \ncount  1786.000  1771.000  1771.000    7.000  \nmean      9.116     8.750     9.353  247.140  \nstd       1.154     1.226     1.166  137.766  \nmin       6.450     4.853     6.533  161.098  \n25%       8.284     7.877     8.505  172.455  \n50%       9.226     8.666     9.529  189.798  \n75%       9.972     9.727    10.194  242.433  \nmax      12.254    12.001    12.463  549.310  \n\n# Estadísticos para España en el año 2021\ndf2021.query(\"country == 'Spain'\").describe().round(3)\n\n         sgdi    shdi   shdif   shdim  healthindex  healthindexf  \\\ncount  19.000  19.000  19.000  19.000       19.000        19.000   \nmean    0.985   0.894   0.886   0.900        0.965         0.970   \nstd     0.004   0.026   0.024   0.027        0.017         0.017   \nmin     0.975   0.853   0.849   0.856        0.930         0.931   \n25%     0.984   0.872   0.865   0.878        0.957         0.966   \n50%     0.985   0.900   0.890   0.905        0.968         0.972   \n75%     0.987   0.911   0.903   0.918        0.975         0.980   \nmax     0.996   0.940   0.927   0.951        0.997         0.996   \n\n       healthindexm  incindex  incindexf  incindexm  edindex  edindexf  \\\ncount        19.000    19.000     19.000     19.000   19.000    19.000   \nmean          0.961     0.889      0.858      0.916    0.834     0.837   \nstd           0.016     0.031      0.030      0.031    0.037     0.033   \nmin           0.929     0.849      0.819      0.875    0.761     0.766   \n25%           0.951     0.863      0.833      0.890    0.798     0.808   \n50%           0.963     0.883      0.852      0.910    0.852     0.850   \n75%           0.970     0.911      0.879      0.938    0.858     0.860   \nmax           0.993     0.947      0.915      0.974    0.881     0.876   \n\n       edindexm    esch   eschf   eschm    msch   mschf   mschm  lifexp  \\\ncount    19.000  19.000  19.000  19.000  19.000  19.000  19.000  19.000   \nmean      0.827  17.415  17.605  17.097  10.498  10.442  10.562  82.744   \nstd       0.040   0.823   0.733   0.896   0.570   0.540   0.604   1.102   \nmin       0.757  15.127  15.253  14.988   9.462   9.399   9.548  80.461   \n25%       0.787  17.038  17.402  16.614  10.029   9.986  10.160  82.190   \n50%       0.840  17.773  18.000  17.341  10.552  10.513  10.548  82.932   \n75%       0.853  18.000  18.000  17.820  10.898  10.805  10.955  83.376   \nmax       0.888  18.000  18.000  18.000  11.444  11.290  11.634  84.810   \n\n       lifexpf  lifexpm       gnic      gnicf      gnicm   lgnic  lgnicf  \\\ncount   19.000   19.000     19.000     19.000     19.000  19.000  19.000   \nmean    85.525   79.993  36767.182  29934.452  43874.659  10.492  10.287   \nstd      1.120    1.051   7792.902   6216.995   9460.374   0.204   0.201   \nmin     82.999   77.891  27582.996  22592.294  32745.203  10.225  10.025   \n25%     85.275   79.324  30417.830  24866.672  36169.910  10.323  10.121   \n50%     85.670   80.065  34612.370  28224.467  41246.942  10.452  10.248   \n75%     86.214   80.560  41466.415  33694.492  49564.842  10.632  10.425   \nmax     87.253   82.042  52773.822  42681.253  63336.277  10.874  10.662   \n\n       lgnicm  pop  \ncount  19.000  0.0  \nmean   10.668  NaN  \nstd     0.208  NaN  \nmin    10.397  NaN  \n25%    10.496  NaN  \n50%    10.627  NaN  \n75%    10.811  NaN  \nmax    11.056  NaN  \n\n# Diferencias regionales durante el período (box plots)\n# Comparación entre continentes\npx.box(df1,\n         x = 'shdi',\n         y = 'continent',\n         range_x= [0, 1], \n         color = 'continent', \n         hover_name= 'region',  \n         hover_data = ['country'],\n         animation_frame= 'year',\n         labels=dict(continent = \"Continente\",\n                     shdi =\"SHDI\")\n         )\n\n\n                        \n                                            \n\n# Comparación entre países\npx.box(df1[df1['country'].isin(['Spain', 'Portugal', 'France'])],\n         x = 'shdi',\n         y = 'country',\n         range_x= [0.70, 1],\n         color = 'country', \n         hover_name= 'region',  \n         hover_data = ['country'],\n         animation_frame= 'year',\n         labels=dict(country = \"País\",\n                     shdi =\"SHDI\")\n         )\n\n\n                        \n                                            \n\n# Evolución regional dentro de un país (series temporales)\nfig = px.line(\n    df1[df1['country'].isin(['Spain'])],\n    x=\"year\",\n    y=\"shdi\",\n    log_y= True,\n    color=\"region\",\n    hover_name=\"country\",\n    hover_data= ['country'],\n    labels=dict(shdi=\"SHDI\",\n                year = \"Año\"),\n    facet_col=\"country\",\n    facet_col_wrap = 2,\n    facet_row_spacing = 0.01,\n    height= 500\n    )\nfig.update_layout(showlegend=False)\n\n\n                        \n                                            \n\n# Correlación desarrollo humano-renta per cápita (scatter plots)\npx.scatter(df1,\n            y = \"shdi\", \n            x = \"lgnic\",\n            range_y= [0, 1],\n            range_x= [5, 13],  \n            hover_name = \"region\",\n            hover_data= ['country'], \n            color = \"continent\", \n            #size = \"pop\", size_max = 60,\n            trendline= 'ols',\n            animation_frame= 'year',\n            labels=dict(country = \"País\",\n                        continent = \"Continente\",\n                        lgnic =\"Renta nacional bruta per capita (log)\",\n                        shdi=\"SHDI\")\n            )\n\n\n                        \n                                            \n\n# Análisis exploratorio espacial (ESDA)\n# Mapa de distribución espacial del SHDI en 2021\ndf2021_2 = df2021.copy()   \ndf2021_2 = df2021_2.rename(columns = {\"GDLCODE\": \"GDLcode\"})\ngdf2021 = map.merge(df2021_2, on = 'GDLcode', how = 'left')\ngdf2021.columns\n\nIndex(['GDLcode', 'constant', 'iso_code_x', 'country_x', 'region_x',\n       'geometry', 'iso_code_y', 'country_y', 'year', 'level', 'region_y',\n       'continent', 'sgdi', 'shdi', 'shdif', 'shdim', 'healthindex',\n       'healthindexf', 'healthindexm', 'incindex', 'incindexf', 'incindexm',\n       'edindex', 'edindexf', 'edindexm', 'esch', 'eschf', 'eschm', 'msch',\n       'mschf', 'mschm', 'lifexp', 'lifexpf', 'lifexpm', 'gnic', 'gnicf',\n       'gnicm', 'lgnic', 'lgnicf', 'lgnicm', 'pop'],\n      dtype='object')\n\ngdf2021\n\n      GDLcode constant iso_code_x    country_x  \\\n0     AFGr101    World        AFG  Afghanistan   \n1     AFGr102    World        AFG  Afghanistan   \n2     AFGr103    World        AFG  Afghanistan   \n3     AFGr104    World        AFG  Afghanistan   \n4     AFGr105    World        AFG  Afghanistan   \n...       ...      ...        ...          ...   \n1740  ZWEr106    World        ZWE     Zimbabwe   \n1741  ZWEr107    World        ZWE     Zimbabwe   \n1742  ZWEr108    World        ZWE     Zimbabwe   \n1743  ZWEr109    World        ZWE     Zimbabwe   \n1744  ZWEr110    World        ZWE     Zimbabwe   \n\n                                               region_x  \\\n0     Central (Kabul Wardak Kapisa Logar Parwan Panj...   \n1                   Central Highlands (Bamyan Daikundi)   \n2              East (Nangarhar Kunar Laghman Nooristan)   \n3       North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)   \n4         North East (Baghlan Takhar Badakhshan Kunduz)   \n...                                                 ...   \n1740                                 Matebeleland South   \n1741                                           Midlands   \n1742                                           Masvingo   \n1743                                             Harare   \n1744                                           Bulawayo   \n\n                                               geometry iso_code_y  \\\n0     MULTIPOLYGON (((67.61506 34.23957, 67.59259 34...        AFG   \n1     MULTIPOLYGON (((65.23611 33.37125, 65.25839 33...        AFG   \n2     MULTIPOLYGON (((69.92137 34.02534, 69.90879 34...        AFG   \n3     MULTIPOLYGON (((66.38873 34.93133, 66.33110 34...        AFG   \n4     MULTIPOLYGON (((67.39591 35.43840, 67.45535 35...        AFG   \n...                                                 ...        ...   \n1740  MULTIPOLYGON (((29.36831 -22.19781, 29.33401 -...        ZWE   \n1741  MULTIPOLYGON (((29.22650 -19.48012, 29.21404 -...        ZWE   \n1742  MULTIPOLYGON (((31.06733 -22.34189, 31.08549 -...        ZWE   \n1743  MULTIPOLYGON (((31.08852 -17.66625, 31.11562 -...        ZWE   \n1744  MULTIPOLYGON (((28.61305 -20.23587, 28.60440 -...        ZWE   \n\n        country_y  year   level  \\\n0     Afghanistan  2021  Subnat   \n1     Afghanistan  2021  Subnat   \n2     Afghanistan  2021  Subnat   \n3     Afghanistan  2021  Subnat   \n4     Afghanistan  2021  Subnat   \n...           ...   ...     ...   \n1740     Zimbabwe  2021  Subnat   \n1741     Zimbabwe  2021  Subnat   \n1742     Zimbabwe  2021  Subnat   \n1743     Zimbabwe  2021  Subnat   \n1744     Zimbabwe  2021  Subnat   \n\n                                               region_y     continent   sgdi  \\\n0     Central (Kabul Wardak Kapisa Logar Parwan Panj...  Asia/Pacific  0.734   \n1                   Central Highlands (Bamyan Daikundi)  Asia/Pacific  0.704   \n2              East (Nangarhar Kunar Laghman Nooristan)  Asia/Pacific  0.583   \n3       North (Samangan Sar-e-Pul Balkh Jawzjan Faryab)  Asia/Pacific  0.749   \n4         North East (Baghlan Takhar Badakhshan Kunduz)  Asia/Pacific  0.667   \n...                                                 ...           ...    ...   \n1740                                 Matebeleland South        Africa  0.985   \n1741                                           Midlands        Africa  0.958   \n1742                                           Masvingo        Africa  0.962   \n1743                                             Harare        Africa  0.962   \n1744                                           Bulawayo        Africa  0.985   \n\n       shdi  shdif  shdim  healthindex  healthindexf  healthindexm  incindex  \\\n0     0.550  0.444  0.605        0.675         0.694         0.664     0.471   \n1     0.472  0.368  0.522        0.653         0.667         0.643     0.396   \n2     0.459  0.310  0.532        0.638         0.648         0.630     0.394   \n3     0.497  0.405  0.541        0.628         0.636         0.620     0.464   \n4     0.444  0.332  0.498        0.623         0.629         0.615     0.416   \n...     ...    ...    ...          ...           ...           ...       ...   \n1740  0.585  0.581  0.590        0.665         0.681         0.652     0.530   \n1741  0.590  0.577  0.602        0.593         0.595         0.586     0.544   \n1742  0.588  0.578  0.601        0.650         0.664         0.639     0.520   \n1743  0.665  0.652  0.678        0.619         0.627         0.610     0.648   \n1744  0.693  0.689  0.699        0.656         0.670         0.644     0.688   \n\n      incindexf  incindexm  edindex  edindexf  edindexm    esch   eschf  \\\n0         0.280      0.553    0.524     0.451     0.604  12.898  10.399   \n1         0.217      0.472    0.408     0.343     0.468  12.447  10.958   \n2         0.215      0.470    0.385     0.214     0.510   9.858   6.043   \n3         0.274      0.546    0.420     0.382     0.467  11.456  10.004   \n4         0.234      0.494    0.338     0.249     0.407   9.288   7.202   \n...         ...        ...      ...       ...       ...     ...     ...   \n1740      0.508      0.551    0.566     0.566     0.570  10.989  11.145   \n1741      0.522      0.566    0.635     0.618     0.659  12.668  12.575   \n1742      0.498      0.541    0.602     0.584     0.628  12.058  12.013   \n1743      0.624      0.672    0.732     0.707     0.759  13.156  12.470   \n1744      0.663      0.712    0.739     0.735     0.746  14.115  14.173   \n\n       eschm    msch   mschf   mschm  lifexp  lifexpf  lifexpm      gnic  \\\n0     15.407   4.975   4.851   5.281  63.843   67.633   60.672  2264.832   \n1     14.155   1.857   1.168   2.256  62.415   65.829   59.326  1374.650   \n2     13.270   3.325   1.397   4.232  61.471   64.627   58.426  1355.298   \n3     12.857   3.058   3.124   3.305  60.843   63.825   57.822  2159.844   \n4     11.235   2.390   1.473   2.842  60.500   63.384   57.490  1571.877   \n...      ...     ...     ...     ...     ...      ...      ...       ...   \n1740  10.863   7.834   7.697   8.044  63.246   66.784   59.907  3339.052   \n1741  12.858   8.492   8.073   9.045  58.544   61.193   55.566  3670.709   \n1742  12.184   8.013   7.504   8.685  62.276   65.641   59.025  3127.485   \n1743  13.981  10.993  10.825  11.114  60.261   63.250   57.171  7314.452   \n1744  14.218  10.405  10.246  10.541  62.628   66.056   59.346  9516.362   \n\n         gnicf      gnicm  lgnic  lgnicf  lgnicm  pop  \n0      638.644   3894.162  7.725   6.459   8.267  NaN  \n1      420.676   2282.217  7.226   6.042   7.733  NaN  \n2      415.719   2247.852  7.212   6.030   7.718  NaN  \n3      613.795   3701.300  7.678   6.420   8.216  NaN  \n4      470.580   2634.320  7.360   6.154   7.876  NaN  \n...        ...        ...    ...     ...     ...  ...  \n1740  2886.675   3844.591  8.113   7.968   8.254  NaN  \n1741  3168.011   4233.422  8.208   8.061   8.351  NaN  \n1742  2706.948   3596.899  8.048   7.904   8.188  NaN  \n1743  6235.132   8537.414  8.898   8.738   9.052  NaN  \n1744  8073.914  11158.386  9.161   8.996   9.320  NaN  \n\n[1745 rows x 41 columns]\n\nfig, ax = plt.subplots(1,1)\ngdf2021.plot(column=\"shdi\",\n           legend=True,\n           ax=ax)\nplt.title('Distribución espacial del SHDI en 2021')\nplt.tight_layout()\nplt.show()\n\n\n\n# El SHDI español en 2021\ngdf2021Spain = gdf2021.query(\"country_x =='Spain'\").reset_index(drop=True)\ngdf2021Spain\n\n    GDLcode constant iso_code_x country_x                    region_x  \\\n0   ESPr101    World        ESP     Spain                     Galicia   \n1   ESPr102    World        ESP     Spain      Principado de Asturias   \n2   ESPr103    World        ESP     Spain                   Cantabria   \n3   ESPr104    World        ESP     Spain                  Pais Vasco   \n4   ESPr105    World        ESP     Spain  Comunidad Foral de Navarra   \n5   ESPr106    World        ESP     Spain                    La Rioja   \n6   ESPr107    World        ESP     Spain                      Aragon   \n7   ESPr108    World        ESP     Spain         Comunidad de Madrid   \n8   ESPr109    World        ESP     Spain             Castilla y Leon   \n9   ESPr110    World        ESP     Spain          Castilla-la Mancha   \n10  ESPr111    World        ESP     Spain                 Extremadura   \n11  ESPr112    World        ESP     Spain                    Cataluna   \n12  ESPr113    World        ESP     Spain        Comunidad Valenciana   \n13  ESPr114    World        ESP     Spain               Illes Balears   \n14  ESPr115    World        ESP     Spain                   Andalucia   \n15  ESPr116    World        ESP     Spain            Region de Murcia   \n16  ESPr119    World        ESP     Spain                    Canarias   \n\n                                             geometry iso_code_y country_y  \\\n0   MULTIPOLYGON (((-8.92069 42.40208, -8.93236 42...        ESP     Spain   \n1   MULTIPOLYGON (((-4.84094 43.18074, -4.86007 43...        ESP     Spain   \n2   MULTIPOLYGON (((-3.28500 43.19767, -3.29785 43...        ESP     Spain   \n3   MULTIPOLYGON (((-3.41760 43.13341, -3.43341 43...        ESP     Spain   \n4   MULTIPOLYGON (((-1.84713 42.00800, -1.85517 42...        ESP     Spain   \n5   MULTIPOLYGON (((-2.85804 42.63819, -2.84284 42...        ESP     Spain   \n6   MULTIPOLYGON (((-1.14233 39.97187, -1.14729 39...        ESP     Spain   \n7   MULTIPOLYGON (((-4.57890 40.21741, -4.55891 40...        ESP     Spain   \n8   MULTIPOLYGON (((-2.86188 42.74551, -2.85371 42...        ESP     Spain   \n9   MULTIPOLYGON (((-5.33587 40.11582, -5.31573 40...        ESP     Spain   \n10  MULTIPOLYGON (((-7.54169 39.66368, -7.53376 39...        ESP     Spain   \n11  MULTIPOLYGON (((0.51514 40.52296, 0.44904 40.5...        ESP     Spain   \n12  MULTIPOLYGON (((-0.76236 37.84698, -0.79037 37...        ESP     Spain   \n13  MULTIPOLYGON (((1.42069 38.79125, 1.42819 38.7...        ESP     Spain   \n14  MULTIPOLYGON (((-6.98236 37.24811, -6.97403 37...        ESP     Spain   \n15  MULTIPOLYGON (((-2.34153 38.02604, -2.32980 38...        ESP     Spain   \n16  MULTIPOLYGON (((-18.04792 27.69042, -18.12514 ...        ESP     Spain   \n\n    year   level                    region_y continent   sgdi   shdi  shdif  \\\n0   2021  Subnat                     Galicia    Europe  0.985  0.900  0.892   \n1   2021  Subnat      Principado de Asturias    Europe  0.983  0.900  0.890   \n2   2021  Subnat                   Cantabria    Europe  0.986  0.905  0.896   \n3   2021  Subnat                  Pais Vasco    Europe  0.981  0.932  0.922   \n4   2021  Subnat  Comunidad Foral de Navarra    Europe  0.985  0.926  0.917   \n5   2021  Subnat                    La Rioja    Europe  0.984  0.910  0.902   \n6   2021  Subnat                      Aragon    Europe  0.985  0.912  0.904   \n7   2021  Subnat         Comunidad de Madrid    Europe  0.975  0.940  0.927   \n8   2021  Subnat             Castilla y Leon    Europe  0.983  0.906  0.898   \n9   2021  Subnat          Castilla-la Mancha    Europe  0.985  0.870  0.863   \n10  2021  Subnat                 Extremadura    Europe  0.996  0.867  0.865   \n11  2021  Subnat                    Cataluna    Europe  0.990  0.916  0.909   \n12  2021  Subnat        Comunidad Valenciana    Europe  0.989  0.895  0.886   \n13  2021  Subnat               Illes Balears    Europe  0.982  0.876  0.868   \n14  2021  Subnat                   Andalucia    Europe  0.988  0.874  0.866   \n15  2021  Subnat            Region de Murcia    Europe  0.986  0.882  0.873   \n16  2021  Subnat                    Canarias    Europe  0.985  0.871  0.864   \n\n    shdim  healthindex  healthindexf  healthindexm  incindex  incindexf  \\\n0   0.905        0.970         0.978         0.963     0.883      0.852   \n1   0.906        0.958         0.966         0.947     0.879      0.848   \n2   0.909        0.968         0.973         0.963     0.886      0.856   \n3   0.940        0.977         0.986         0.969     0.939      0.907   \n4   0.932        0.985         0.986         0.984     0.929      0.898   \n5   0.917        0.973         0.979         0.967     0.909      0.878   \n6   0.918        0.976         0.981         0.970     0.912      0.880   \n7   0.951        0.997         0.996         0.993     0.947      0.915   \n8   0.913        0.980         0.987         0.975     0.890      0.859   \n9   0.876        0.968         0.970         0.970     0.863      0.833   \n10  0.868        0.956         0.966         0.950     0.851      0.821   \n11  0.918        0.974         0.979         0.967     0.924      0.893   \n12  0.897        0.962         0.967         0.958     0.879      0.848   \n13  0.883        0.973         0.972         0.973     0.909      0.878   \n14  0.877        0.948         0.952         0.944     0.852      0.822   \n15  0.886        0.953         0.954         0.952     0.867      0.837   \n16  0.878        0.962         0.966         0.961     0.864      0.834   \n\n    incindexm  edindex  edindexf  edindexm    esch   eschf   eschm    msch  \\\n0       0.910    0.852     0.850     0.846  18.000  18.000  17.758  10.552   \n1       0.906    0.866     0.861     0.867  18.000  18.000  17.883  10.966   \n2       0.913    0.862     0.864     0.854  17.898  18.000  17.534  10.956   \n3       0.966    0.881     0.876     0.887  18.000  18.000  18.000  11.444   \n4       0.957    0.868     0.873     0.859  17.773  18.000  17.373  11.242   \n5       0.936    0.853     0.855     0.852  18.000  18.000  18.000  10.597   \n6       0.939    0.852     0.855     0.849  17.773  18.000  17.515  10.763   \n7       0.974    0.881     0.874     0.888  18.000  18.000  18.000  11.422   \n8       0.916    0.853     0.854     0.853  18.000  18.000  18.000  10.596   \n9       0.889    0.787     0.795     0.779  16.392  16.755  16.040   9.950   \n10      0.877    0.800     0.816     0.784  17.187  17.623  16.759   9.666   \n11      0.952    0.855     0.859     0.840  17.763  18.000  17.149  10.839   \n12      0.905    0.848     0.850     0.832  17.946  18.000  17.341  10.494   \n13      0.936    0.761     0.766     0.757  15.127  15.253  14.988  10.228   \n14      0.878    0.826     0.831     0.814  17.693  18.000  17.144  10.023   \n15      0.894    0.829     0.835     0.816  17.811  18.000  17.314  10.035   \n16      0.891    0.795     0.801     0.790  16.355  16.683  16.026  10.233   \n\n     mschf   mschm  lifexp  lifexpf  lifexpm       gnic      gnicf      gnicm  \\\n0   10.513  10.592  83.031   86.066   80.065  34612.370  28224.467  41246.942   \n1   10.842  11.095  82.240   85.275   79.077  33711.940  27504.365  40156.153   \n2   10.906  10.999  82.932   85.769   80.065  35363.363  28824.781  42157.068   \n3   11.290  11.604  83.525   86.561   80.461  50033.150  40506.858  59993.367   \n4   11.189  11.305  84.019   86.561   81.449  46994.202  38093.089  56290.236   \n5   10.648  10.548  83.228   86.165   80.362  41088.651  33393.523  49105.725   \n6   10.662  10.863  83.426   86.264   80.560  41844.179  33995.462  50023.959   \n7   11.217  11.634  84.810   87.253   82.042  52773.822  42681.253  63336.277   \n8   10.621  10.579  83.722   86.660   80.856  36114.923  29425.297  43068.204   \n9    9.899  10.010  82.932   85.572   80.560  30268.374  24746.877  35989.210   \n10   9.784   9.561  82.141   85.275   79.275  28029.940  22951.168  33284.768   \n11  10.768  10.911  83.327   86.165   80.362  45477.308  36887.125  54443.302   \n12  10.486  10.508  82.536   85.374   79.769  33561.951  27384.377  39974.501   \n13  10.258  10.207  83.228   85.670   80.757  41088.651  33393.523  49105.725   \n14   9.924  10.125  81.647   84.384   78.879  28178.977  23070.812  33464.724   \n15  10.047  10.064  81.943   84.483   79.373  31165.419  25465.762  37073.962   \n16  10.132  10.334  82.536   85.275   79.967  30567.286  24986.468  36350.610   \n\n     lgnic  lgnicf  lgnicm  pop  \n0   10.452  10.248  10.627  NaN  \n1   10.426  10.222  10.601  NaN  \n2   10.473  10.269  10.649  NaN  \n3   10.820  10.609  11.002  NaN  \n4   10.758  10.548  10.938  NaN  \n5   10.623  10.416  10.802  NaN  \n6   10.642  10.434  10.820  NaN  \n7   10.874  10.662  11.056  NaN  \n8   10.494  10.290  10.671  NaN  \n9   10.318  10.116  10.491  NaN  \n10  10.241  10.041  10.413  NaN  \n11  10.725  10.516  10.905  NaN  \n12  10.421  10.218  10.596  NaN  \n13  10.623  10.416  10.802  NaN  \n14  10.246  10.046  10.418  NaN  \n15  10.347  10.145  10.521  NaN  \n16  10.328  10.126  10.501  NaN  \n\nfig, ax = plt.subplots(1,1)\ngdf2021Spain.plot(column=\"shdi\",\n           legend=True,\n           ax=ax)\nplt.title('Distribución del SHDI español en 2021')\nplt.tight_layout()\nplt.show()\n\n\n\n# Gráfica sólo con las regiones peninsulares\ngdf2021Spain_2 = gdf2021Spain.drop(labels=[13,16])\ngdf2021Spain_2\n\n    GDLcode constant iso_code_x country_x                    region_x  \\\n0   ESPr101    World        ESP     Spain                     Galicia   \n1   ESPr102    World        ESP     Spain      Principado de Asturias   \n2   ESPr103    World        ESP     Spain                   Cantabria   \n3   ESPr104    World        ESP     Spain                  Pais Vasco   \n4   ESPr105    World        ESP     Spain  Comunidad Foral de Navarra   \n5   ESPr106    World        ESP     Spain                    La Rioja   \n6   ESPr107    World        ESP     Spain                      Aragon   \n7   ESPr108    World        ESP     Spain         Comunidad de Madrid   \n8   ESPr109    World        ESP     Spain             Castilla y Leon   \n9   ESPr110    World        ESP     Spain          Castilla-la Mancha   \n10  ESPr111    World        ESP     Spain                 Extremadura   \n11  ESPr112    World        ESP     Spain                    Cataluna   \n12  ESPr113    World        ESP     Spain        Comunidad Valenciana   \n14  ESPr115    World        ESP     Spain                   Andalucia   \n15  ESPr116    World        ESP     Spain            Region de Murcia   \n\n                                             geometry iso_code_y country_y  \\\n0   MULTIPOLYGON (((-8.92069 42.40208, -8.93236 42...        ESP     Spain   \n1   MULTIPOLYGON (((-4.84094 43.18074, -4.86007 43...        ESP     Spain   \n2   MULTIPOLYGON (((-3.28500 43.19767, -3.29785 43...        ESP     Spain   \n3   MULTIPOLYGON (((-3.41760 43.13341, -3.43341 43...        ESP     Spain   \n4   MULTIPOLYGON (((-1.84713 42.00800, -1.85517 42...        ESP     Spain   \n5   MULTIPOLYGON (((-2.85804 42.63819, -2.84284 42...        ESP     Spain   \n6   MULTIPOLYGON (((-1.14233 39.97187, -1.14729 39...        ESP     Spain   \n7   MULTIPOLYGON (((-4.57890 40.21741, -4.55891 40...        ESP     Spain   \n8   MULTIPOLYGON (((-2.86188 42.74551, -2.85371 42...        ESP     Spain   \n9   MULTIPOLYGON (((-5.33587 40.11582, -5.31573 40...        ESP     Spain   \n10  MULTIPOLYGON (((-7.54169 39.66368, -7.53376 39...        ESP     Spain   \n11  MULTIPOLYGON (((0.51514 40.52296, 0.44904 40.5...        ESP     Spain   \n12  MULTIPOLYGON (((-0.76236 37.84698, -0.79037 37...        ESP     Spain   \n14  MULTIPOLYGON (((-6.98236 37.24811, -6.97403 37...        ESP     Spain   \n15  MULTIPOLYGON (((-2.34153 38.02604, -2.32980 38...        ESP     Spain   \n\n    year   level                    region_y continent   sgdi   shdi  shdif  \\\n0   2021  Subnat                     Galicia    Europe  0.985  0.900  0.892   \n1   2021  Subnat      Principado de Asturias    Europe  0.983  0.900  0.890   \n2   2021  Subnat                   Cantabria    Europe  0.986  0.905  0.896   \n3   2021  Subnat                  Pais Vasco    Europe  0.981  0.932  0.922   \n4   2021  Subnat  Comunidad Foral de Navarra    Europe  0.985  0.926  0.917   \n5   2021  Subnat                    La Rioja    Europe  0.984  0.910  0.902   \n6   2021  Subnat                      Aragon    Europe  0.985  0.912  0.904   \n7   2021  Subnat         Comunidad de Madrid    Europe  0.975  0.940  0.927   \n8   2021  Subnat             Castilla y Leon    Europe  0.983  0.906  0.898   \n9   2021  Subnat          Castilla-la Mancha    Europe  0.985  0.870  0.863   \n10  2021  Subnat                 Extremadura    Europe  0.996  0.867  0.865   \n11  2021  Subnat                    Cataluna    Europe  0.990  0.916  0.909   \n12  2021  Subnat        Comunidad Valenciana    Europe  0.989  0.895  0.886   \n14  2021  Subnat                   Andalucia    Europe  0.988  0.874  0.866   \n15  2021  Subnat            Region de Murcia    Europe  0.986  0.882  0.873   \n\n    shdim  healthindex  healthindexf  healthindexm  incindex  incindexf  \\\n0   0.905        0.970         0.978         0.963     0.883      0.852   \n1   0.906        0.958         0.966         0.947     0.879      0.848   \n2   0.909        0.968         0.973         0.963     0.886      0.856   \n3   0.940        0.977         0.986         0.969     0.939      0.907   \n4   0.932        0.985         0.986         0.984     0.929      0.898   \n5   0.917        0.973         0.979         0.967     0.909      0.878   \n6   0.918        0.976         0.981         0.970     0.912      0.880   \n7   0.951        0.997         0.996         0.993     0.947      0.915   \n8   0.913        0.980         0.987         0.975     0.890      0.859   \n9   0.876        0.968         0.970         0.970     0.863      0.833   \n10  0.868        0.956         0.966         0.950     0.851      0.821   \n11  0.918        0.974         0.979         0.967     0.924      0.893   \n12  0.897        0.962         0.967         0.958     0.879      0.848   \n14  0.877        0.948         0.952         0.944     0.852      0.822   \n15  0.886        0.953         0.954         0.952     0.867      0.837   \n\n    incindexm  edindex  edindexf  edindexm    esch   eschf   eschm    msch  \\\n0       0.910    0.852     0.850     0.846  18.000  18.000  17.758  10.552   \n1       0.906    0.866     0.861     0.867  18.000  18.000  17.883  10.966   \n2       0.913    0.862     0.864     0.854  17.898  18.000  17.534  10.956   \n3       0.966    0.881     0.876     0.887  18.000  18.000  18.000  11.444   \n4       0.957    0.868     0.873     0.859  17.773  18.000  17.373  11.242   \n5       0.936    0.853     0.855     0.852  18.000  18.000  18.000  10.597   \n6       0.939    0.852     0.855     0.849  17.773  18.000  17.515  10.763   \n7       0.974    0.881     0.874     0.888  18.000  18.000  18.000  11.422   \n8       0.916    0.853     0.854     0.853  18.000  18.000  18.000  10.596   \n9       0.889    0.787     0.795     0.779  16.392  16.755  16.040   9.950   \n10      0.877    0.800     0.816     0.784  17.187  17.623  16.759   9.666   \n11      0.952    0.855     0.859     0.840  17.763  18.000  17.149  10.839   \n12      0.905    0.848     0.850     0.832  17.946  18.000  17.341  10.494   \n14      0.878    0.826     0.831     0.814  17.693  18.000  17.144  10.023   \n15      0.894    0.829     0.835     0.816  17.811  18.000  17.314  10.035   \n\n     mschf   mschm  lifexp  lifexpf  lifexpm       gnic      gnicf      gnicm  \\\n0   10.513  10.592  83.031   86.066   80.065  34612.370  28224.467  41246.942   \n1   10.842  11.095  82.240   85.275   79.077  33711.940  27504.365  40156.153   \n2   10.906  10.999  82.932   85.769   80.065  35363.363  28824.781  42157.068   \n3   11.290  11.604  83.525   86.561   80.461  50033.150  40506.858  59993.367   \n4   11.189  11.305  84.019   86.561   81.449  46994.202  38093.089  56290.236   \n5   10.648  10.548  83.228   86.165   80.362  41088.651  33393.523  49105.725   \n6   10.662  10.863  83.426   86.264   80.560  41844.179  33995.462  50023.959   \n7   11.217  11.634  84.810   87.253   82.042  52773.822  42681.253  63336.277   \n8   10.621  10.579  83.722   86.660   80.856  36114.923  29425.297  43068.204   \n9    9.899  10.010  82.932   85.572   80.560  30268.374  24746.877  35989.210   \n10   9.784   9.561  82.141   85.275   79.275  28029.940  22951.168  33284.768   \n11  10.768  10.911  83.327   86.165   80.362  45477.308  36887.125  54443.302   \n12  10.486  10.508  82.536   85.374   79.769  33561.951  27384.377  39974.501   \n14   9.924  10.125  81.647   84.384   78.879  28178.977  23070.812  33464.724   \n15  10.047  10.064  81.943   84.483   79.373  31165.419  25465.762  37073.962   \n\n     lgnic  lgnicf  lgnicm  pop  \n0   10.452  10.248  10.627  NaN  \n1   10.426  10.222  10.601  NaN  \n2   10.473  10.269  10.649  NaN  \n3   10.820  10.609  11.002  NaN  \n4   10.758  10.548  10.938  NaN  \n5   10.623  10.416  10.802  NaN  \n6   10.642  10.434  10.820  NaN  \n7   10.874  10.662  11.056  NaN  \n8   10.494  10.290  10.671  NaN  \n9   10.318  10.116  10.491  NaN  \n10  10.241  10.041  10.413  NaN  \n11  10.725  10.516  10.905  NaN  \n12  10.421  10.218  10.596  NaN  \n14  10.246  10.046  10.418  NaN  \n15  10.347  10.145  10.521  NaN  \n\nfig, ax = plt.subplots(1,1)\ngdf2021Spain_2.plot(column=\"shdi\",\n           legend=True,\n           ax=ax)\nplt.title('Distribución del SHDI peninsular español en 2021')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "p1c2-app4.html",
    "href": "p1c2-app4.html",
    "title": "Aplicación 1.4 (Regresiones con datos de corte transversal): Demanda familiar de carne",
    "section": "",
    "text": "En esta aplicación se estimará una función de demanda de carne con datos microeconómicos sobre 30 familias americanas ( i = 1, 2,…, 30):\n\\[Q_{i} = f(P_{i}, Y_{i}) + e_{i}\\]\ndonde Q representa la cantidad demandada, P es el precio pagado por ella en el mercado y, finalmente, Y es la renta familiar neta disponible.\nDesde el punto de vista técnico, en el ejemplo se utilizarán distintas funciones y librerías que permiten la estimación de modelos estadísticos. Concretamente, en el caso del lenguaje R se usa la función lm() (https://rstudio.github.io/r-manuals/r-intro/Statistical-models-in-R.html) para el ajuste del modelo lineal propuesto, y en el caso de Python se proponen tanto el uso de la librería estándar en este lenguaje de programación para la estimación de modelos estadísticos y econométricos, statsmodels (https://www.statsmodels.org/), como la librería scikit-learn (https://scikit-learn.org/), si bien esta última está más especializada en técnicas generales de machine learning.\n\n\nCódigo R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(modelsummary)\nlibrary(skimr)\n# Lectura de datos\nDEM_CARNE &lt;- read_csv(\"data/DEM_CARNE.csv\")\n# Descripción de la base muestral\ndim(DEM_CARNE)\n\n[1] 30  3\n\nstr(DEM_CARNE)\n\nspc_tbl_ [30 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ P: num [1:30] 10.76 13.03 9.24 4.61 13.04 ...\n $ Q: num [1:30] 11.63 12.03 8.92 33.91 4.56 ...\n $ Y: num [1:30] 488 365 541 760 422 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   P = col_double(),\n  ..   Q = col_double(),\n  ..   Y = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nhead(DEM_CARNE)\n\n# A tibble: 6 × 3\n      P     Q     Y\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 10.8  11.6   488.\n2 13.0  12.0   365.\n3  9.24  8.92  541.\n4  4.61 33.9   760.\n5 13.0   4.56  422.\n6  7.71 17.6   578.\n\ntail(DEM_CARNE)\n\n# A tibble: 6 × 3\n      P     Q     Y\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  5.48  2.90  256.\n2  7.89  3.14  185.\n3  8.46 15.3   359.\n4  6.20 22.2   629.\n5  6.74 10.0   307.\n6 12.0   3.98  347.\n\n# Análisis exploratorio (EDA)\n# Estadística descriptiva\n# Resultados estándar (R 'base')\nsummary(DEM_CARNE)\n\n       P                Q                Y        \n Min.   : 4.016   Min.   : 2.903   Min.   :184.8  \n 1st Qu.: 6.556   1st Qu.: 6.288   1st Qu.:320.4  \n Median : 7.737   Median : 9.813   Median :385.9  \n Mean   : 8.374   Mean   :10.892   Mean   :409.4  \n 3rd Qu.:10.523   3rd Qu.:14.089   3rd Qu.:485.4  \n Max.   :14.219   Max.   :33.908   Max.   :760.3  \n\n# Librería skimr (https://cran.r-project.org/web/packages/skimr/)\nskim(DEM_CARNE)\n\n\n\n\nData summary\n\n\n\n\nName\n\n\nDEM_CARNE\n\n\n\n\nNumber of rows\n\n\n30\n\n\n\n\nNumber of columns\n\n\n3\n\n\n\n\n_______________________\n\n\n\n\n\n\nColumn type frequency:\n\n\n\n\n\n\nnumeric\n\n\n3\n\n\n\n\n________________________\n\n\n\n\n\n\nGroup variables\n\n\nNone\n\n\n\n\n\nVariable type: numeric\n\n\n\n\n\nskim_variable\n\n\nn_missing\n\n\ncomplete_rate\n\n\nmean\n\n\nsd\n\n\np0\n\n\np25\n\n\np50\n\n\np75\n\n\np100\n\n\nhist\n\n\n\n\n\n\nP\n\n\n0\n\n\n1\n\n\n8.37\n\n\n2.84\n\n\n4.02\n\n\n6.56\n\n\n7.74\n\n\n10.52\n\n\n14.22\n\n\n▅▇▃▃▃\n\n\n\n\nQ\n\n\n0\n\n\n1\n\n\n10.89\n\n\n6.67\n\n\n2.90\n\n\n6.29\n\n\n9.81\n\n\n14.09\n\n\n33.91\n\n\n▇▅▃▁▁\n\n\n\n\nY\n\n\n0\n\n\n1\n\n\n409.42\n\n\n127.84\n\n\n184.80\n\n\n320.38\n\n\n385.93\n\n\n485.45\n\n\n760.34\n\n\n▂▇▃▂▁\n\n\n\n\n\n\n# Librería modelsummary (https://modelsummary.com/)\ndatasummary_correlation(DEM_CARNE)\n\n\n\n\n\nP\nQ\nY\n\n\n\n\nP\n1\n.\n.\n\n\nQ\n−.33\n1\n.\n\n\nY\n−.01\n.75\n1\n\n\n\n\n\n\n# Gráficas parciales\n# Librería GGally\nGGally::ggpairs(DEM_CARNE)\n\n\n\n# Librería ggplot\nggplot(DEM_CARNE, aes(x = P, y = Q)) +\n  geom_point() +\n  geom_smooth(method='lm', formula = y~x, se = FALSE) +\n  xlab(\"P (precio)\") +\n  ylab(\"Q (cantidad)\") +\n  theme_minimal()\n\n\n\nggplot(DEM_CARNE, aes(x = Y, y = Q)) +\n  geom_point() +\n  geom_smooth(method='lm', formula = y~x, se = FALSE) +\n  xlab(\"Y (renta)\") +\n  ylab(\"Q (cantidad)\") +\n  theme_minimal()\n\n\n\n# Regresión por MCO del modelo lineal Q = beta1 + beta2*P + beta3*Y + e\n# Comando lm() de R-stats (&lt;https://rdrr.io/r/stats/lm.html&gt;).\nlin_model &lt;- lm(formula = Q ~ P + Y, data = DEM_CARNE)\n# Resultados estándar (R base)\nsummary(lin_model)\n\n\nCall:\nlm(formula = Q ~ P + Y, data = DEM_CARNE)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.4429 -2.6144 -0.5625  1.7284  6.8800 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.345236   3.301677   0.407  0.68690    \nP           -0.767780   0.259243  -2.962  0.00631 ** \nY            0.039020   0.005762   6.772 2.84e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.966 on 27 degrees of freedom\nMultiple R-squared:  0.6709,    Adjusted R-squared:  0.6465 \nF-statistic: 27.52 on 2 and 27 DF,  p-value: 3.052e-07\n\n# Resultados formateados (librería modelsummary)\nmodelsummary(lin_model)\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n1.345\n\n\n\n(3.302)\n\n\nP\n−0.768\n\n\n\n(0.259)\n\n\nY\n0.039\n\n\n\n(0.006)\n\n\nNum.Obs.\n30\n\n\nR2\n0.671\n\n\nR2 Adj.\n0.646\n\n\nAIC\n172.6\n\n\nBIC\n178.3\n\n\nLog.Lik.\n−82.324\n\n\nF\n27.516\n\n\nRMSE\n3.76\n\n\n\n\n\n\nmodelplot(lin_model)\n\n\n\n# ANEXO: Regresión por MCO del modelo propuesto en versión logarítmica\n# log(Q) = beta1 + beta2*log(P) + beta3*log(Y) + e\nlog_model &lt;- lm(formula = log(Q) ~ log(P) + log(Y), data = DEM_CARNE)\nsummary(log_model)\n\n\nCall:\nlm(formula = log(Q) ~ log(P) + log(Y), data = DEM_CARNE)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.75112 -0.24829  0.01212  0.14647  0.67313 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -5.1704     1.4151  -3.654   0.0011 ** \nlog(P)       -0.5663     0.2148  -2.636   0.0137 *  \nlog(Y)        1.4337     0.2287   6.270 1.04e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3941 on 27 degrees of freedom\nMultiple R-squared:  0.6234,    Adjusted R-squared:  0.5955 \nF-statistic: 22.35 on 2 and 27 DF,  p-value: 1.882e-06\n\n\n\n\nCódigo Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotnine import *\n# https://www.statsmodels.org/stable/api.html\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n# https://scikit-learn.org/stable/modules/linear_model.html\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score\n# from skimpy import skim\n\n# Lectura de datos\nDEM_CARNE = pd.read_csv(\"data/DEM_CARNE.csv\")\n# Descripción de la base muestral\nDEM_CARNE.shape\n\n(30, 3)\n\nDEM_CARNE.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 30 entries, 0 to 29\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   P       30 non-null     float64\n 1   Q       30 non-null     float64\n 2   Y       30 non-null     float64\ndtypes: float64(3)\nmemory usage: 848.0 bytes\n\nDEM_CARNE.head()\n\n        P       Q        Y\n0  10.763  11.632  487.648\n1  13.033  12.029  364.877\n2   9.244   8.916  541.037\n3   4.605  33.908  760.343\n4  13.045   4.561  421.746\n\nDEM_CARNE.tail()\n\n         P       Q        Y\n25   7.890   3.138  184.798\n26   8.460  15.315  359.084\n27   6.195  22.240  629.378\n28   6.743  10.012  306.527\n29  11.977   3.982  347.488\n\n# Análisis exploratorio (EDA)\n# Estadística descriptiva\n# Resultados estándar (Python 'base')\nDEM_CARNE.describe()\n\n               P          Q           Y\ncount  30.000000  30.000000   30.000000\nmean    8.373533  10.891567  409.418633\nstd     2.841277   6.671015  127.842689\nmin     4.016000   2.903000  184.798000\n25%     6.555500   6.287750  320.382250\n50%     7.737500   9.813000  385.925500\n75%    10.523250  14.089500  485.449750\nmax    14.219000  33.908000  760.343000\n\n# Librería Skimpy (https://aeturrell.github.io/skimpy/)\n# skim(DEM_CARNE)\n# Gráficas parciales\n# Librería seaborn\nsns.pairplot(data = DEM_CARNE, diag_kind = 'kde');\nplt.show()\n\n\n\n# Librería plotnine (ggplot en Python)\n(ggplot(DEM_CARNE,aes('P','Q')) + \ngeom_point() + \ngeom_smooth(method='lm',se=False, color = \"blue\") + \nlabs(x=\"P (precio)\",y=\"Q (cantidad)\") + theme_bw())\n\n&lt;ggplot: (324967770)&gt;\n\n\n\n\n(ggplot(DEM_CARNE,aes('Y','Q')) + \ngeom_point() + \ngeom_smooth(method='lm',se=False, color = \"blue\") + \nlabs(x=\"Y (renta)\",y=\"Q (cantidad)\") + theme_bw())\n\n&lt;ggplot: (322813556)&gt;\n\n\n\n\n# Regresión por MCO del modelo lineal Q = beta1 + beta2*P + beta3*Y + e\n# Comando `smf.ols` de la librería `statsmodels` \n# (&lt;https://www.statsmodels.org/&gt;)\nmodel = smf.ols(formula = \"Q ~ P + Y\", data = DEM_CARNE)\nlin_model_1 = model.fit()\nprint(lin_model_1.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      Q   R-squared:                       0.671\nModel:                            OLS   Adj. R-squared:                  0.646\nMethod:                 Least Squares   F-statistic:                     27.52\nDate:                Tue, 14 Nov 2023   Prob (F-statistic):           3.05e-07\nTime:                        17:41:53   Log-Likelihood:                -82.324\nNo. Observations:                  30   AIC:                             170.6\nDf Residuals:                      27   BIC:                             174.9\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      1.3452      3.302      0.407      0.687      -5.429       8.120\nP             -0.7678      0.259     -2.962      0.006      -1.300      -0.236\nY              0.0390      0.006      6.772      0.000       0.027       0.051\n==============================================================================\nOmnibus:                        1.346   Durbin-Watson:                   2.328\nProb(Omnibus):                  0.510   Jarque-Bera (JB):                1.218\nSkew:                           0.347   Prob(JB):                        0.544\nKurtosis:                       2.297   Cond. No.                     1.96e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.96e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n# Comando `linear_model` de la librería `scikit-learn` \n# (&lt;https://scikit-learn.org/&gt;)\nlr = linear_model.LinearRegression()\nlin_model_2 = lr.fit (X=DEM_CARNE[[\"P\", \"Y\"]], y=DEM_CARNE[\"Q\"])\nprint(\"Ordenada en el origen: \\n\", lin_model_2.intercept_)\n\nOrdenada en el origen: \n 1.3452364833219423\n\nprint(\"Efectos marginales: \\n\", lin_model_2.coef_)\n\nEfectos marginales: \n [-0.76777964  0.03901962]\n\n# ANEXO: Regresión por MCO del modelo propuesto en versión logarítmica\n# log(Q) = beta1 + beta2*log(P) + beta3*log(Y) + e\nmodel = smf.ols(formula = \"np.log(Q) ~ np.log(P) + np.log(Y)\", data = DEM_CARNE)\nlog_model = model.fit()\nprint(log_model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              np.log(Q)   R-squared:                       0.623\nModel:                            OLS   Adj. R-squared:                  0.595\nMethod:                 Least Squares   F-statistic:                     22.35\nDate:                Tue, 14 Nov 2023   Prob (F-statistic):           1.88e-06\nTime:                        17:41:53   Log-Likelihood:                -13.053\nNo. Observations:                  30   AIC:                             32.11\nDf Residuals:                      27   BIC:                             36.31\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -5.1704      1.415     -3.654      0.001      -8.074      -2.267\nnp.log(P)     -0.5663      0.215     -2.636      0.014      -1.007      -0.126\nnp.log(Y)      1.4337      0.229      6.270      0.000       0.965       1.903\n==============================================================================\nOmnibus:                        0.530   Durbin-Watson:                   2.252\nProb(Omnibus):                  0.767   Jarque-Bera (JB):                0.636\nSkew:                           0.147   Prob(JB):                        0.728\nKurtosis:                       2.350   Cond. No.                         127.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "p1c2-app5.html",
    "href": "p1c2-app5.html",
    "title": "Aplicación 1.5 (Regresiones con datos de series temporales): Consumo privado en Estados Unidos",
    "section": "",
    "text": "En esta aplicación se estimará una función de consumo de tipo Keynesiano agregada (consumidor representativo), usando datos de series temporales para Estados Unidos del período 1959-2015:\n\\[C_{t} = \\beta_0 + \\beta_1  Y_{t} + e_{t}\\]\ndonde \\(C\\) representa la consumo privado, e \\(Y\\) es la renta disponible neta (después de impuestos).\nDesde el punto de vista técnico, el objetivo principal del ejemplo es la introducción de las principales funciones y librerías especializadas de R y Python para el análisis de series temporales.\n\n\nCódigo R\n\n# Lectura de librerías\nlibrary(tidyverse)\n# Lectura de datos\nCONS_USA &lt;- read_delim(\"data/CONS_USA_ts.csv\", delim = \";\")\nhead(CONS_USA)\n\n# A tibble: 6 × 3\n  date           C     Y\n  &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 1959-01-01 1840. 2092.\n2 1960-01-01 1891  2147 \n3 1961-01-01 1930. 2223.\n4 1962-01-01 2025. 2329 \n5 1963-01-01 2109. 2417.\n6 1964-01-01 2234. 2588.\n\ntail(CONS_USA)\n\n# A tibble: 6 × 3\n  date            C      Y\n  &lt;date&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n1 2010-01-01 10036. 11055.\n2 2011-01-01 10264. 11331.\n3 2012-01-01 10413. 11688.\n4 2013-01-01 10565. 11528.\n5 2014-01-01 10869. 11931 \n6 2015-01-01 11215. 12343.\n\n# Asignación del formato de series temporales\n# (https://cran.r-project.org/web/views/TimeSeries.html)\n# Aquí se usará la clase básica \"ts\", válida para series temporales \n# regulares (espaciadas de forma homogénea en el tiempo).\n# Pueden usarse otras clases más generales, siendo las más usadas:\n# \"zoo\": https://cran.r-project.org/web/packages/zoo/index.html \n# \"xts\": https://github.com/joshuaulrich/xts\n# \"tsibble\": https://github.com/robjhyndman/fpp3package\n# Ver anexo para una demostración sobre el tidyverts, \n# el complemento al tidyverse para el análisis de series temporales.\n#\nts_CONS_USA &lt;- ts(CONS_USA[,2:3], start=c(1959), end = c(2015))\n#\n# Estadística descriptiva\nsummary(ts_CONS_USA)\n\n       C               Y        \n Min.   : 1840   Min.   : 2092  \n 1st Qu.: 3330   1st Qu.: 3924  \n Median : 5184   Median : 5811  \n Mean   : 5747   Mean   : 6418  \n 3rd Qu.: 8383   3rd Qu.: 9149  \n Max.   :11215   Max.   :12343  \n\n# Gráficas\ng1 &lt;- ggplot(data = CONS_USA, aes(x = date)) +\n  geom_line(aes(y = C)) +\n  labs(y = \"Consumo privado en Estados Unidos (millones US $)\", x = \"Año\")\ng1\n\n\n\ng2 &lt;- ggplot(data = CONS_USA, aes(x = date)) +\n  geom_line(aes(y = Y)) +\n  labs(y = \"Renta disponible en Estados Unidos (millones US $)\", x = \"Año\")\ng2\n\n\n\n# Diagrama de puntos con línea de regresión\ng3 &lt;- ggplot(CONS_USA, aes(x = Y, y = C)) + \n               geom_point() +  \n               stat_smooth(method = lm) +  \n               labs(x = \"Renta disponible\",y = \"Consumo privado\")\ng3\n\n\n\n# Regresión por MCO\nKEYNES_model &lt;- lm (formula = C ~ Y, data = ts_CONS_USA)\nsummary(KEYNES_model)\n\n\nCall:\nlm(formula = C ~ Y, data = ts_CONS_USA)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-252.922  -52.961   -6.074   55.160  263.545 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.455e+02  2.828e+01  -8.681 6.87e-12 ***\nY            9.336e-01  3.967e-03 235.338  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 92.95 on 55 degrees of freedom\nMultiple R-squared:  0.999, Adjusted R-squared:  0.999 \nF-statistic: 5.538e+04 on 1 and 55 DF,  p-value: &lt; 2.2e-16\n\n\n\n# ANEXO: La  librería fpp3 y el tidyverts' (https://tidyverts.org/)\n# La macro-librería `fpp3` contiene varias librerías específicas\n# y otras generales, como `tidyverse` y  `lubridate`.\n# La clase `tsibble` proporciona una infraestructura de datos para ordenar\n# y manipular series temporales. Se pueden encontrar los detalles en la\n# página web https://tsibble.tidyverts.org/index.html.\n# Toda la información de la librería fpp3 se encuentra en:\n# https://github.com/robjhyndman/fpp3package. \n# El libro de texto que acompaña a esta librería es el siguiente:\n# FORECASTING: PRINCIPLES AND PRACTICE -&gt; https://otexts.com/fpp3/.\n#\n# NOTA:\n# Existen otras librerías especializadas en el análisis de series temporales, \n# como `TSstudio` (https://ramikrispin.github.io/TSstudio/),\n# `timetk` (https://business-science.github.io/timetk/) o \n# `tsbox`(https://docs.ropensci.org/tsbox/).\n#\nlibrary(fpp3) \n# Creación del objeto tsibble\nCONS_USA_ts &lt;-  CONS_USA[,2:3] %&gt;%\n  mutate(Year = 1959:2015) %&gt;%\n  as_tsibble(index = Year)\n# Gráficas individuales\nCONS_USA_ts %&gt;% autoplot(C) +\n  ggtitle(\"Consumo privado en Estados Unidos\") +\n  ylab(\"$ million\") + xlab(\"Year\")\n\n\n\nCONS_USA_ts %&gt;% autoplot(Y) +\n  ggtitle(\"Renta disponible en Estados Unidos\") +\n  ylab(\"$ million\") + xlab(\"Year\")\n\n\n\n# Diagrama de puntos junto con la recta de regresión estimada\nCONS_USA_ts %&gt;%\n  ggplot(aes(x=Y, y=C)) +\n  ylab(\"Consumo\") +\n  xlab(\"Renta\") +\n  geom_point() +\n  geom_smooth(method=\"lm\", se=FALSE)\n\n\n\n# Regresión por MCO\nCONS_USA_ts %&gt;%\n  model(tslm = TSLM(C ~ Y)) %&gt;%\n  report()\n\nSeries: C \nModel: TSLM \n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-252.922  -52.961   -6.074   55.160  263.545 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.455e+02  2.828e+01  -8.681 6.87e-12 ***\nY            9.336e-01  3.967e-03 235.338  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 92.95 on 55 degrees of freedom\nMultiple R-squared: 0.999,  Adjusted R-squared: 0.999\nF-statistic: 5.538e+04 on 1 and 55 DF, p-value: &lt; 2.22e-16\n\n\n\n\nCódigo Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\n# Lectura de datos \n# (al introducir la opción index_col se está asignando en este caso\n# de forma implícita un formato temporal para el resto de columnas)\nCONS_USA = pd.read_csv(\"data/CONS_USA_ts.csv\", delimiter=';', index_col=0)\n#\n# Asignación del formato temporal \n# (https://pandas.pydata.org/docs/user_guide/timeseries.html)\n# Un análisis detallado puede encontrarse en la siguiente página web:\n# https://jakevdp.github.io/PythonDataScienceHandbook/\n# 03.11-working-with-time-series.html\nts_CONS_USA = pd.read_csv(\"data/CONS_USA_ts.csv\", delimiter=';', \nparse_dates=['date'], index_col='date')\nts_CONS_USA.head()\n\n                 C       Y\ndate                      \n1959-01-01  1840.5  2092.1\n1960-01-01  1891.0  2147.0\n1961-01-01  1929.9  2222.7\n1962-01-01  2025.4  2329.0\n1963-01-01  2108.8  2416.6\n\nts_CONS_USA.tail()\n\n                  C        Y\ndate                        \n2011-01-01  10263.5  11331.3\n2012-01-01  10413.2  11687.8\n2013-01-01  10565.4  11527.6\n2014-01-01  10868.9  11931.0\n2015-01-01  11214.7  12343.2\n\n# Estadística descriptiva\nts_CONS_USA.describe()\n\n                  C             Y\ncount     57.000000     57.000000\nmean    5746.605263   6418.347368\nstd     2924.557484   3131.033192\nmin     1840.500000   2092.100000\n25%     3329.500000   3923.900000\n50%     5183.600000   5811.100000\n75%     8382.600000   9148.800000\nmax    11214.700000  12343.200000\n\n# Gráficas\nplt.plot(ts_CONS_USA[\"C\"])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Consumo privado en Estados Unidos (mill. US $)\")\nplt.show()\n\n\n\nplt.plot(ts_CONS_USA[\"Y\"])\nplt.xlabel(\"Date\")\nplt.ylabel(\"Renta disponible en Estados Unidos (mill. US $)\")\nplt.show()\n\n\n\n# Diagrama de puntos con línea de regresión\nreg = smf.ols(formula = \"C ~ Y\", data = ts_CONS_USA)\nres = reg.fit()\nplt.scatter(ts_CONS_USA[\"Y\"], ts_CONS_USA[\"C\"], color = \"black\")\nplt.plot(ts_CONS_USA[\"Y\"], res.fittedvalues, color = \"blue\")\nplt.xlabel(\"Renta disponible\")\nplt.ylabel(\"Consumo privado\")\nplt.show()\n\n\n\n# Regresión por MCO\nmodel = smf.ols(formula = \"C ~ Y\", data = ts_CONS_USA)\nKEYNES_model = model.fit()\nprint(KEYNES_model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      C   R-squared:                       0.999\nModel:                            OLS   Adj. R-squared:                  0.999\nMethod:                 Least Squares   F-statistic:                 5.538e+04\nDate:                Tue, 14 Nov 2023   Prob (F-statistic):           2.72e-84\nTime:                        20:15:53   Log-Likelihood:                -338.19\nNo. Observations:                  57   AIC:                             680.4\nDf Residuals:                      55   BIC:                             684.5\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept   -245.5102     28.282     -8.681      0.000    -302.189    -188.832\nY              0.9336      0.004    235.338      0.000       0.926       0.942\n==============================================================================\nOmnibus:                        2.088   Durbin-Watson:                   0.691\nProb(Omnibus):                  0.352   Jarque-Bera (JB):                1.264\nSkew:                           0.240   Prob(JB):                        0.532\nKurtosis:                       3.549   Cond. No.                     1.64e+04\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.64e+04. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n\n\n# ANEXO: Clases de modelos y funciones específicas de la librería\n# `statsmodels` para el análisis de series temporales \n# (https://www.statsmodels.org/stable/tsa.html)\n#\nfrom statsmodels.tsa.api import ARDL\nendog = ts_CONS_USA[[\"C\"]]\nexog = ts_CONS_USA[[\"Y\"]]   # exogs = data[[\"X2\", \"X3\",...]]\nmodel = ARDL(endog, 0, exog, 0) # retardos=0 equivale a mod. estático\nKEYNES_ardl_model = model.fit()\nprint(KEYNES_ardl_model.summary())\n\n                              ARDL Model Results                              \n==============================================================================\nDep. Variable:                      C   No. Observations:                   57\nModel:                     ARDL(0, 0)   Log Likelihood                -338.189\nMethod:               Conditional MLE   S.D. of innovations             91.304\nDate:                Tue, 14 Nov 2023   AIC                            682.377\nTime:                        20:15:54   BIC                            688.506\nSample:                    01-01-1959   HQIC                           684.759\n                         - 01-01-2015                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       -245.5102     28.282     -8.681      0.000    -302.189    -188.832\nY.L0           0.9336      0.004    235.338      0.000       0.926       0.942\n=============================================================================="
  },
  {
    "objectID": "p2-mrl-basico.html",
    "href": "p2-mrl-basico.html",
    "title": "CAPÍTULO 2: EL MODELO DE REGRESIÓN LINEAL Y SUS HIPÓTESIS BÁSICAS",
    "section": "",
    "text": "En este capítulo se exponen los fundamentos sobre los que se sostiene el uso del modelo de regresión lineal en el contexto económico, incidiéndose en las hipótesis básicas que subyacen en dicho modelo. También se introducen la inferencia estadística asociada al modelo lineal general, el uso de éste para usos predictivos y, finalmente, se discuten algunos aspectos asociados con la forma funcional utilizada."
  },
  {
    "objectID": "p2c1-teoria.html#introducción",
    "href": "p2c1-teoria.html#introducción",
    "title": "2  El modelo de regresión lineal y sus hipótesis básicas",
    "section": "2.1 Introducción",
    "text": "2.1 Introducción\nA través del contenido recogido en este tema pretendemos sentar las bases que permitirán llegar a realizar un análisis de regresión con variables económicas, siendo capaz de juzgar la validez del modelo y de interpretar sus resultados desde los puntos de vista estadístico y económico.\nAsí, analizaremos relaciones econométricas del tipo\n\\[y = \\beta_{1} + \\beta_{2}x_{2} + \\ldots + \\beta_{K}x_{K} + e\\]\nes decir, regresiones con una variable dependiente, \\(y\\), y varias variables explicativas, \\(x_{j}\\), las cuales ayudan a explicar parcialmente el comportamiento de la variable \\(y\\)."
  },
  {
    "objectID": "p2c1-teoria.html#el-modelo-de-regresión-lineal",
    "href": "p2c1-teoria.html#el-modelo-de-regresión-lineal",
    "title": "2  El modelo de regresión lineal y sus hipótesis básicas",
    "section": "2.2 El modelo de regresión lineal",
    "text": "2.2 El modelo de regresión lineal\n\n2.2.1 Especificación\nConsideremos que, de acuerdo con la teoría económica, una variable \\(y\\), que describe el comportamiento de un agente económico o un determinado aspecto de un sistema económico bajo estudio, está relacionada con un conjunto de variables explicativas\\(\\ x_{2},x_{3},\\ldots,x_{K}\\), según la relación lineal \\(\\ y = \\beta_{1} + \\beta_{2}x_{2} + \\ldots + \\beta_{K}x_{K} + e\\) . En esta ecuación supondremos que \\(\\beta_{1},\\beta_{2},\\ldots,\\beta_{K}\\) son parámetros fijos y que \\(e\\) es una variable aleatoria, es decir, sus valores se determinan por un mecanismo probabilista.\nPor tanto, al expresar la variable y mediante la relación anterior, estamos suponiendo que tiene dos componentes: una parte explicada o sistemática, que vendría dada por \\(\\beta_{1} + \\beta_{2}x_{2} + \\ldots + \\beta_{K}x_{K}\\) y una parte no explicada, \\(e\\), conocida como perturbación aleatoria o error del modelo.\nLa perturbación aleatoria del modelo (\\(e\\)) recoge factores tales como:\n\nEl comportamiento aleatorio propio de los agentes económicos.\nLos errores de medida en la variable y o en las variables &gt; explicativas x’s.\nEl efecto conjunto de otras variables no incluidas en el modelo.\n\nEl objetivo básico de la econometría inicialmente se centrará en la estimación del conjunto de parámetros estructurales, \\(\\mathbf{\\beta} = \\left( \\beta_{1},\\beta_{2},\\ldots,\\beta_{K} \\right)'\\), siendo el principal interés el obtener dichas estimaciones y realizar inferencias sobre los parámetros poblacionales y, por tanto, sobre la estructura del sistema económico analizado.\nLa finalidad última consistirá en realizar predicciones sobre valores futuros de y, evaluar políticas concretas (cómo varía y al cambiar los valores de alguna de las x’s) o realizar análisis de control (qué valor debe tomar alguna o algunas de las variables explicativas para alcanzar un determinado valor de y).\nComo es habitual en estadística, intentaremos construir un estimador, es decir, una función que a cada muestra le haga corresponder un valor de los parámetros, que posea buenas propiedades. Para ello consideraremos que disponemos de una muestra de n (o T) observaciones de las variables x’s e y.\nSe llama modelo de regresión lineal (MRL) al modelo probabilístico\n\\[y = \\beta_{1} + \\beta_{2}x_{2} + \\ldots + \\beta_{K}x_{K} + e\\]\ndonde, \\(y\\), la variable dependiente o explicada, es una variable observable aleatoria; \\(x_{2},x_{3},\\ldots,x_{K}\\) las variables explicativas, son variables observables, aleatorias o que toman valores fijos en muestras repetidas; \\(\\mathbf{\\beta} = \\left( \\beta_{1},\\beta_{2},\\ldots,\\beta_{K} \\right)'\\), los parámetros estructurales del modelo, son un conjunto de constantes fijas y desconocidas; y \\(e\\), el término de error, es una variable aleatoria.\nPara la estimación del modelo se dispone de una muestra de n observaciones \\(\\left( y_{i},x_{2i},\\ldots,x_{Ki} \\right)\\) independientes e idénticamente distribuidas (IID) extraídas de la distribución conjunta asociada al MRL, de modo que para cada \\(i = 1,2,\\ldots,n\\) se tiene que\n\\[y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i}\\]\nEste conjunto de ecuaciones puede expresarse matricialmente por:\n\\[\\begin{bmatrix}\ny_{1} \\\\\n\\vdots \\\\\ny_{n} \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n1 & x_{21} & \\ldots & x_{K1} \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\n1 & x_{2n} & \\ldots & x_{Kn} \\\\\n\\end{bmatrix}\\begin{bmatrix}\n\\beta_{1} \\\\\n\\vdots \\\\\n\\beta_{K} \\\\\n\\end{bmatrix} + \\begin{bmatrix}\ne_{1} \\\\\n\\vdots \\\\\ne_{n} \\\\\n\\end{bmatrix}\\]\no también, de forma más compacta, como\n\\[\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\]\ndonde: \\(\\mathbf{y} = \\left( y_{1},y_{2},\\ldots,y_{n} \\right)'\\) es el \\(n \\times 1\\) vector columna de las observaciones de la variable endógena; \\(\\mathbf{X} = \\left(\\mathbf{x}_{1},\\mathbf{x}_{2},\\ldots,\\mathbf{x}_{K} \\right)\\) es la matriz, de orden \\(n \\times K\\) que en cada columna consigna las observaciones de las variables exógenas \\(\\mathbf{x}_{j}\\) (\\(j = 1,2,\\ldots,K\\)), considerando \\(\\mathbf{x}_{j} = \\left( x_{j1},x_{j2},\\ldots,x_{jn} \\right)'\\), siendo \\(x_{1i} = 1\\ \\forall\\ i = 1,2,\\ldots,n\\); \\(\\mathbf{\\beta} = \\left( \\beta_{1},\\beta_{2},\\ldots,\\beta_{K} \\right)'\\) es el \\(K \\times 1\\) vector que contiene los coeficientes desconocidos (parámetros estructurales) del modelo; y \\(\\mathbf{e} = \\left( e_{1},e_{2},\\ldots,e_{n} \\right)'\\) es el \\(n \\times 1\\) vector de los errores o perturbaciones aleatorias del modelo.\n\n\n2.2.2 Hipótesis básicas del MRL (condiciones de regularidad)\nPara que el estimador de mínimos cuadrados ordinarios (MCO), que se expondrá más adelante, tenga las propiedades estadísticas adecuadas, deben cumplirse las siguientes hipótesis:\nH1: Respecto a la especificación del modelo:\n\nH1.1: Aparecen todas las variables relevantes: el modelo no excluye ninguna variable explicativa esencial (completitud), ni incluye variables irrelevantes (exactitud).\nH1.2: El término de error, \\(e\\), actúa de forma aditiva (aditividad).\nH1.3: La forma funcional es correcta y, además, es lineal en los parámetros (linealidad).\nH1.4: Los parámetros estructurales \\(\\beta_{j}\\) son constantes (estabilidad estructural).\n\nH2: Respecto a los regresores del modelo:\n\nH2.1: O bien las variables explicativas son no estocásticas y toman valores fijos en muestras repetidas (y además los valores no son todos iguales entre si, es decir, la varianza muestral debe ser distinta de cero) o, en el caso más común en economía, donde los datos son de tipo no experimental, si las variables explicativas son aleatorias, deben estar incorrelacionadas con los factores contenidos en el término de error, \\(E(\\mathbf{e}|\\mathbf{X}) = \\mathbf{0}\\) (exogeneidad estricta).\nH2.2: Debe cumplirse que \\(n &gt; \\ K\\) y \\(\\ rango\\left( \\mathbf{X} \\right) = K\\), es decir, (1) debe haber un número mayor de observaciones que de parámetros a estimar, y (2) puesto que el rango de la matriz X debe ser completo (\\(K\\)), ninguna variable explicativa puede ser combinación lineal exacta de las restantes, es decir, deben ser linealmente independientes (ausencia de colinealidad perfecta).\n\nH3: Respecto a los errores del modelo:\n\nH3.1: \\(Var\\left( e_{i}|\\mathbf{X} \\right) = \\sigma^{2}\\ \\ \\forall\\ i = 1,2,\\ldots,n\\) (homoscedasticidad). El parámetro de escala \\(\\sigma\\) se conoce como desviación estándar de la regresión (o del modelo), midiendo “el tamaño medio de los errores del modelo”.\nH3.2: \\(Cov\\left( e_{i},e_{j}|\\mathbf{X} \\right) = 0\\ \\ \\ \\forall\\ i \\neq j\\) (ausencia de correlación).\nH3.3: Los errores siguen una distribución normal, \\(e_{i}|\\mathbf{X}\\sim N\\ \\ \\forall\\ i = 1,2,\\ldots,n\\) (normalidad).\n\n\n\n2.2.3 Algunas propiedades, interpretaciones o representaciones del MRL\n\nLa hipótesis de exogeneidad estricta implica que \\(E\\left( e_{i} \\right) = 0\\ \\ \\forall\\ i\\), \\(E(\\mathbf{Xe}) = \\mathbf{0}\\) y \\(Cov(\\mathbf{X},\\mathbf{e}) = \\mathbf{0}\\). En este sentido, en lugar de la propiedad estricta, suele utilizarse la hipótesis derivada \\(Cov\\left( \\mathbf{x}_{j},\\mathbf{e} \\right) = 0\\) para cada variable explicativa \\(x_{j}\\), \\(j = 1,2,\\ldots,K\\) (exogeneidad débil), lo que significa que no debe existir ninguna correlación lineal entre las variables explicativas y el término de error. Si no se verifica esta hipótesis, es decir, cuando \\(Cov\\left( \\mathbf{x}_{k},\\mathbf{e} \\right) \\neq 0\\) para alguna variable explicativa \\(\\mathbf{x}_{k}\\), se dice que ese regresor es endógeno, y en este caso el estimador de mínimos cuadrados ordinarios que propondremos más adelante deja de tener buenas propiedades estadísticas (en concreto, será sesgado e inconsistente).\nLa ausencia de multicolinealidad estricta implica que \\(\\det(\\mathbf{X}^{\\mathbf{'}}\\mathbf{X}) \\neq \\mathbf{0}\\), lo que garantiza la existencia de la inversa de la matriz \\(\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)\\) que aparece en el cálculo de las estimacones mínimo-cuadráticas.\nLas sub-hipótesis H3.2 y H3.3 pueden agruparse en una única expresión matricial: \\[\\mathbf{\\Omega} = Cov\\left( \\mathbf{e} \\right) = \\begin{bmatrix}\nVar\\left( e_{1} \\right) & \\cdots & Cov\\ \\left( e_{1},e_{n} \\right) \\\\\n\\vdots & \\ddots & \\vdots \\\\Cov\\ \\left( e_{1},e_{n} \\right) & \\cdots & Var\\left( e_{n} \\right) \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n\\sigma^{2} & \\cdots & 0 \\\\\n\\vdots & \\ddots & \\vdots \\\\\n0 & \\cdots & \\sigma^{2} \\\\\n\\end{bmatrix} = \\sigma^{2}\\mathbf{I}\\]\n\nLas perturbaciones que cumplen estas dos propiedades (homoscedasticidad y ausencia de correlación) son conocidas como perturbaciones esféricas.\n\nPuesto que se cumple que \\[\\mathbf{e}\\mathbf{|}\\mathbf{X}\\sim N_{n}(\\mathbf{0}_{n},\\sigma^{2}\\mathbf{I}_{n}\\mathbf{)}\\] en términos de la variable dependiente la expresión anterior es equivalente a decir que el vector de respuestas \\(\\mathbf{y}\\) sigue tiene una distribución normal multivariante\n\n\\[\\mathbf{y}\\mathbf{|}\\mathbf{X}\\sim N_{n}(\\mathbf{X\\beta},\\sigma^{2}\\mathbf{I}_{n}\\mathbf{)}\\]\nSe tiene entonces que, al igual que para el vector de errores e, la matriz de covarianzas de \\(\\mathbf{y}\\) viene dada por \\(Cov\\left( \\mathbf{y}\\mathbf{|}\\mathbf{X} \\right) = \\sigma^{2}\\mathbf{I}_{n}\\).\nDe igual manera, la función de regresión poblacional es una función lineal dada por \\[E(y_{i}\\mathbf{|}\\mathbf{X}\\mathbf{) =}\\mathbf{X}_{i}\\mathbf{\\beta}\\] siendo \\(\\mathbf{X}_{i} = \\left( 1,x_{2i},\\ldots,x_{Ki} \\right)\\) la i-ésima fila de la matriz \\(\\mathbf{X}\\), que también puede escribirse en forma no matricial como\n\\[E\\left( y_{i}|x_{2i},\\ldots,x_{Ki} \\right) = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}\\]\nverificándose, por tanto, que\n\\[\\beta_{j} = \\frac{\\partial E\\left( y|\\mathbf{X} \\right)}{\\partial x_{j}}\\]\nEntonces, cada parámetro \\(\\beta_{j}\\) mide aproximadamente el efecto parcial (tasa de cambio marginal) sobre la media (condicional) de la variable dependiente \\(y\\) de un cambio unitario en la variable explicativa \\(x_{j}\\), bajo la hipótesis de que el resto de las variables explicativas permanece constante (supuesto ‘ceteris paribus’ que, en la práctica, dado el carácter en general ‘observacional’ de los datos económicos, debe ser asumido con cautela).\nUna vez estimado el modelo, al substituir los parámetros desconocidos por sus estimaciones, se tiene entonces que:\n\\[{\\widehat{\\beta}}_{j} \\cong \\mathrm{\\Delta}\\widehat{E}\\left( y|x_{2},\\ldots,x_{K} \\right)\\ \\ cuando\\ \\ \\mathrm{\\Delta}x_{j} = 1\\ \\ y\\ \\ \\mathrm{\\Delta}x_{i} = 0\\ \\ para\\ \\ i \\neq j\\]\nSe puede visualizar el efecto de una variable \\(x_{j}\\) sobre la media condicional estimada fijando el valor del resto de regresores \\(x_{i}\\ (i \\neq j)\\) en los valores medios muestrales \\(x_{i} = {\\overline{x}}_{i}\\), y representando la variable \\(E(y|{\\overline{x}}_{2},\\ldots,x_{j},\\ldots,{\\overline{x}}_{K})\\) como función de \\(x_{j}\\). Estas figuras se conocen como gráficas de efectos (’effect plots’), y suelen representarse junto con el intervalo de confianza para los valores estimados. Contienen, por tanto, una información similar a las parejas parámetro-desviación típica estimados, \\(\\left( {\\widehat{\\beta}}_{j},se\\left( {\\widehat{\\beta}}_{j} \\right) \\right)\\), que se verán más adelante, y que miden el efecto parcial, y su variabilidad, de cada variable explicativa.\nPor otra parte, en la discusión anterior se está asumiendo que cuando un regresor cambia el resto de las variables explicativas permanece constante, lo que implica que no existe correlación entre ellas. Si quiere medirse el efecto de una variable explicativa cuando ya existen otros regresores (correlacionados o no con la primera), suelen utilizarse las llamadas gráficas de variables añadidas (’added-variable plots’), que miden el efecto de una variable sobre la media condicional descontando el efecto del resto de regresores. Se construyen realizando regresiones auxiliares de la variable dependiente y la variable explicativa de interés sobre el resto de los regresores, y representando posteriormente la parte no explicada de ambas regresiones (los residuos) una frente a la otra. La pendiente de dicha regresión coincide con el parámetro \\(\\beta\\) correspondiente a la regresión que incluye todas las variables del modelo, lo que sugiere que las estimaciones de un modelo de regresión lineal múltiple llevan descontado el efecto del resto de regresores en la función media.\nComo resumen de este compendio de anotaciones sobre el MRL, el modelo de regresión lineal \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\) debe cumplir las siguientes hipótesis:\n\n(H1-Linealidad): \\(E\\left( y_{i} \\middle| \\mathbf{X} \\right) = \\mathbf{X}_{i}\\mathbf{\\beta}\\)\n(H2-Homoscedasticidad): \\(Var\\left( y_{i} \\middle| \\mathbf{X} \\right) = \\sigma^{2}\\ ,\\ \\ i = 1,2,\\ldots,n\\)\n(H3-Incorrelación): \\(Cov\\left( y_{i},y_{j} \\middle| \\mathbf{X} \\right) = 0  ,  i \\neq j\\)\n(H4-Normalidad): \\(y_{i}\\mathbf{|}\\mathbf{X}\\ \\sim N\\left( \\mathbf{X}_{i}\\mathbf{\\beta},\\sigma^{2} \\right)\\ \\ ,\\ \\ i = 1,2,\\ldots,n\\)\n(H5-Exogeneidad): \\(Cov\\left( \\mathbf{x}_{k},\\mathbf{e} \\right) = 0 ,  k = 1,2,\\ldots,K\\)\n\n\n\n2.2.4 Estimación de los parámetros estructurales: el método de mínimos cuadrados ordinarios (MCO)\nSea \\(E(y_{i}|x_{2i},\\ldots,x_{Ki}) = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}\\) la función de regresión poblacional que se deriva de un cierto modelo económico, es decir, \\(E(y_{i})\\) representa el valor esperado (condicional) de la variable y dado un cierto valor de las variables x’s. Dada la naturaleza aleatoria de la variable dependiente, los valores que se observan de y diferirán generalmente de \\(E(y_{i})\\) por múltiples causas, por lo que se tendrá la relación \\(y_{i} = E\\left( y_{i} \\right) + e_{i}\\) donde el término de error \\(e_{i}\\) representa el efecto combinado de esos factores que ‘perturban’ la relación teórica.\nEn el caso del modelo con una sola variable explicativa, la representación gráfica de la relación \\(y_{i} = E\\left( y_{i} \\right) + e_{i}\\) sería la siguiente:\n\n\n\nFigura 1\n\n\nSupongamos que se dispone de una muestra de observaciones independientes para un conjunto de individuos (\\(i = 1,\\ldots,n\\)) o de períodos de tiempo (\\(t = 1,\\ldots,T\\)). El método de mínimos cuadrados ordinarios (MCO) toma como estimación de la regresión poblacional la función más próxima al conjunto de puntos muestrales, para lo cual encuentra estimaciones \\(b_{i}\\) para cada parámetro \\(\\beta_{i}\\) de la regresión poblacional.\nFormalmente, si se define la función de regresión muestral como\n\\[\\widehat{y} = b_{1} + b_{2}x_{2} + \\ldots + b_{K}x_{K}\\]\nentonces para cada observación de las variables exógenas \\(\\mathbf{X}_{i} = \\left( 1,x_{2i},\\ldots,x_{Ki} \\right)\\) el correspondiente punto sobre dicha función viene dado por \\({\\widehat{y}}_{i} = b_{1} + b_{2}x_{2i} + \\ldots + b_{K}x_{Ki} = \\mathbf{X}_{i}\\mathbf{b}\\). Si se definen los errores estimados (residuos) del modelo, para cada observación, como las distancias verticales\n\\[{\\widehat{e}}_{i} = y_{i} - {\\widehat{y}}_{i}\\]\nel método de mínimos cuadrados intenta minimizar la suma de los cuadrados de los residuos:\n\\[S\\left( b_{1},b_{2},\\ldots,b_{K} \\right) = \\sum_{i = 1}^{n}{{\\widehat{e}}_{i}^{2} = \\sum_{i = 1}^{n}\\left( y_{i} - {\\widehat{y}}_{i} \\right)^{2}}\\]\nGráficamente, para el modelo de dos variables, la recta MCO estimada sería como la mostrada a continuación:\n\n\n\nFigura 2\n\n\nTécnicamente, la función a minimizar se puede expresar matricialmente de la forma siguiente:\n\\[S\\left( \\mathbf{b} \\right) = \\sum_{i = 1}^{n}{{\\widehat{e}}_{i}^{2} = {\\widehat{\\mathbf{e}}}^{\\mathbf{'}}\\mathbf{e}\\mathbf{= (}\\mathbf{y}\\mathbf{-}\\mathbf{Xb}\\mathbf{)'(}\\mathbf{y}\\mathbf{-}\\mathbf{Xb}\\mathbf{)}}\\]\nPara obtener los valores de las estimaciones que minimizan dicha función derivamos respecto de \\(\\mathbf{b}\\), e igualamos a 0 (condición de primer orden), obteniéndose el siguiente conjunto de ecuaciones:\n\\[\\frac{\\partial S\\left( \\mathbf{b} \\right)}{\\partial\\mathbf{b}} = \\mathbf{0}\\ \\  \\Longleftrightarrow \\ \\ \\mathbf{X}^{\\mathbf{'}}\\mathbf{Xb}\\mathbf{=}\\mathbf{X}^{\\mathbf{'}}\\mathbf{y}\\]\nque es conocido como sistema de ecuaciones normales.\nComo \\(\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)\\) es una matriz cuadrada de orden K, y rango también igual a K, tiene matriz inversa, dada por \\(\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{- 1}\\), lo cual nos permite pre-multiplicar las ecuaciones normales por dicha matriz inversa, obteniéndose las estimaciones MCO del vector β, dadas por\n\\[\\mathbf{b}\\mathbf{=}\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}}\\mathbf{X}^{\\mathbf{'}}\\mathbf{y}\\]\n\n\n2.2.5 Propiedades estadísticas y algebraicas del estimador MCO, \\(\\widehat{\\mathbf{\\beta}}\\)\nCuando la expresión \\(\\mathbf{b} = \\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{- 1}\\mathbf{X}\\mathbf{'}\\mathbf{y}\\) se considera función de los valores de la variable y para distintas muestras, hablaremos del estimador MCO,\n\\[\\widehat{\\mathbf{\\beta}}\\mathbf{=}\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}}\\mathbf{X}^{\\mathbf{'}}\\mathbf{y}\\]\ndel cual cabe preguntarse, al tratarse de una variable aleatoria, qué propiedades caracterizan su distribución. Pues bien, si se verifican todas las hipótesis hechas para el MRL, las propiedades del estimador MCO son las siguientes:\n1. El estimador \\(\\widehat{\\mathbf{\\beta}} = \\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{- 1}\\mathbf{X}\\mathbf{'}\\mathbf{y}\\) es una función lineal de y.\n2. \\(E\\left( \\widehat{\\mathbf{\\beta}}\\mathbf{|}\\mathbf{X} \\right) = \\mathbf{\\beta}\\), es decir, \\(\\widehat{\\mathbf{\\beta}}\\) es un estimador insesgado.\n3. La matriz de varianzas-covarianzas viene dada por \\(Cov\\left( \\widehat{\\mathbf{\\beta}}\\mathbf{|}\\mathbf{X} \\right) = \\sigma^{2}\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}}\\).\n4. Teorema de Gauss-Markov: el estimador \\(\\widehat{\\mathbf{\\beta}}\\) es el mejor estimador lineal insesgado (MELI) de los parámetros estructurales del modelo de regresión, proporcionando varianzas mínimas dentro de esa clase de estimadores.\n5. Si se cumple la hipótesis de normalidad, se puede demostrar que el estimador MCO es también eficiente, es decir, el mejor de todos los estimadores insesgados, sean lineales o no. Esta propiedad se deriva del hecho de que, asumiendo la normalidad de los errores, el estimador MCO del vector de parámetros \\(\\mathbf{\\beta}\\) coincide con el estimador de máxima verosimilitud (MV). Puede demostrarse fácilmente este resultado teniendo en cuenta que el logaritmo de la función de verosimilitud del modelo de regresión lineal múltiple normal viene dado por la expresión \\(\\log{\\left\\lbrack L(\\mathbf{\\beta},\\sigma^{2}|\\mathbf{y} \\right\\rbrack = - {\\frac{n}{2}\\log(2\\pi)} - {\\frac{n}{2}\\log{\\left( \\sigma^{2} \\right) - {\\frac{1}{2\\sigma^{2}}\\sum_{i = 1}^{n}\\left( y_{i} - \\mathbf{X}_{i}\\mathbf{\\beta} \\right)^{2}}}}}\\) y que el vector \\(\\mathbf{\\beta}\\) sólo aparece en el último término, lo que implica que maximizar \\({log}L\\) respecto a \\(\\mathbf{\\beta}\\) equivale a minimizar \\(\\sum_{i = 1}^{n}\\left( y_{i} - \\mathbf{X}_{i}\\mathbf{\\beta} \\right)^{2}\\) respecto a dicho vector. Por otra parte, diferenciando \\(\\log L\\) respecto a \\(\\sigma^{2}\\) e igualando a cero el resultado, se obtiene la estimación MV de la varianza residual, \\({\\widetilde{\\sigma}}^{2} = \\frac{\\sum_{i = 1}^{n}\\left( y_{i} - \\mathbf{X}_{i}\\widehat{\\mathbf{\\beta}} \\right)^{2}}{n}\\), similar a la estimación MCO de dicho parámetro que se verá más adelante, salvo por el hecho de que aquí en el cociente aparece n en lugar de n-K.\n6. Bajo la hipótesis de normalidad, y teniendo en cuenta 2 y 3, se tiene que \\(\\widehat{\\mathbf{\\beta}}\\sim N\\left( \\mathbf{\\beta},\\sigma^{2}\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}} \\right)\\), es decir, el estimador \\(\\widehat{\\mathbf{\\beta}}\\) sigue una distribución normal multivariante.\n7. El estimador MCO, \\(\\widehat{\\mathbf{\\beta}}\\), es consistente, \\(plim\\left( \\widehat{\\mathbf{\\beta}} \\right) = \\mathbf{\\beta}\\), lo que significa que conforme aumenta el tamaño de la muestra crece la probabilidad de que las estimaciones se encuentren cerca de los valores poblacionales verdaderos que se intentan estimar: \\[\\ \\lim_{n \\rightarrow \\infty}{P\\left( \\left| {\\widehat{\\beta}}_{j} - \\beta_{j} \\right| &gt; \\varepsilon \\right)} = 0\\ \\ \\ \\ \\ \\forall\\varepsilon &gt; 0\\] Una condición necesaria para que se cumpla la propiedad de consistencia es que se verifique que \\(\\lim_{n \\rightarrow \\infty}{E\\left( {\\widehat{\\beta}}_{j} \\right) = \\beta_{j}}\\) y \\(\\lim_{n \\rightarrow \\infty}{Var\\left( {\\widehat{\\beta}}_{j} \\right) = 0}\\)].\n\n\n2.2.6 Propiedades algebraicas de los residuos y de la regresión MCO\nEn una aplicación concreta, una vez que se han calculado las estimaciones MCO, se verifica que:\n1. Los residuos del modelo, \\({\\widehat{e}}_{i} = y_{i} - {\\widehat{y}}_{i}\\), cumplen \\(\\sum_{i = 1}^{n}{x_{ji}\\widehat{e}}_{i} = 0,\\ \\ j = 2,\\ldots,\\ K\\) y, por tanto, el vector de residuos es ortogonal a la matriz de variables explicativas: \\(\\mathbf{X}^{'}\\widehat{\\mathbf{e}} = 0\\)\n2. La suma de los residuos es cero, \\(\\sum_{i = 1}^{n}{\\widehat{e}}_{i} = 0\\) y, por tanto, la media muestral de los mismos es nula, \\(\\overline{\\widehat{\\mathbf{e}}} = 0\\).\n3. Puesto que la media de los errores estimados es cero, debe cumplirse entonces que \\(\\overline{y} = b_{1} + b_{2}{\\overline{x}}_{2} + \\ldots + b_{K}{\\overline{x}}_{K}\\) y, por tanto, la función de regresión muestral siempre pasa por la media muestral de los datos.\n\n\n2.2.7 Estimación de la varianza de los errores, \\(\\mathbf{\\sigma}^{\\mathbf{2}}\\)\nDado que \\(Cov\\left( \\widehat{\\mathbf{\\beta}}|\\mathbf{X} \\right) = \\sigma^{2}{(\\mathbf{X}^{'}\\mathbf{X})}^{- 1}\\), para conocer la precisión con la que se estiman los parámetros se necesita estimar la varianza de las perturbaciones aleatorias, \\(\\sigma^{2}\\). Teniendo en cuenta que \\(\\sigma^{2} = Var\\left( e_{i} \\right) = E\\left( e_{i}^{2} \\right)\\), como estimación de la varianza poblacional \\(\\mathbf{\\sigma}^{\\mathbf{2}}\\) se toma la varianza residual muestral \\(\\mathbf{s}^{\\mathbf{2}}\\), dada por la expresión\n\\[s^{2} = \\frac{\\sum_{i = 1}^{n}{\\widehat{e}}_{\\mathbf{i}}^{\\mathbf{2}}}{n - K}\\]\nsiendo su raíz cuadrada, \\(s\\), el error estándar estimado, también llamado desviación típica de la regresión.\nCuando la expresión de \\(s^{\\mathbf{2}}\\) se considera función de los valores de la variable y para distintas muestras, hablaremos del *estimador de la varianza residual,\n\\[{\\widehat{\\sigma}}^{2} = \\frac{\\mathbf{y}^{'}\\left( \\mathbf{I} - {\\mathbf{X}\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)}^{\\mathbf{-}\\mathbf{1}}\\mathbf{X}^{\\mathbf{'}} \\right)\\mathbf{y}}{n - K} = \\frac{{\\widehat{\\mathbf{e}}}^{\\mathbf{'}}\\widehat{\\mathbf{e}}}{n - K}\\]\nAl igual que en el caso del estimador MCO del vector de parámetros estructurales β, se puede demostrar que la varianza residual es un estimador insesgado de σ2, cumpliéndose entonces que \\(\\ E({\\widehat{\\sigma}}^{2}) = \\sigma^{2}\\).\nEn el caso del estimador MV de la varianza residual, se puede demostrar que \\(E\\left( {\\widetilde{\\sigma}}^{2} \\right) = \\frac{n - K}{n}\\sigma^{2}\\). Por tanto, aunque el estimador es sesgado, dicho sesgo desaparece asintóticamente al cumplirse que \\(\\lim_{n \\rightarrow \\infty}{\\left( \\frac{n - K}{n} \\right) = 1}\\)."
  },
  {
    "objectID": "p2c1-teoria.html#grado-de-ajuste-de-una-regresión",
    "href": "p2c1-teoria.html#grado-de-ajuste-de-una-regresión",
    "title": "2  El modelo de regresión lineal y sus hipótesis básicas",
    "section": "2.3 Grado de ajuste de una regresión",
    "text": "2.3 Grado de ajuste de una regresión\nSe entiende por grado (o bondad) de(l) ajuste de una regresión como “el nivel de proximidad de la función de regresión muestral, \\({\\widehat{y}}_{i} = b_{1} + b_{2}x_{2i} + \\ldots + b_{K}x_{Ki}\\), al conjunto de datos que sirve de soporte para la estimación”.\nComo se ha mencionado anteriormente, la regresión estimada por MCO es la que proporciona la menor suma de los cuadrados de los residuos, \\(SRC = \\sum_{i = 1}^{n}{\\widehat{e}}_{i}^{2} = \\sum_{i = 1}^{n}\\left( y_{i} - {\\widehat{y}}_{i} \\right)^{2}\\), que llamaremos suma residual de cuadrados. Esta medida podría ser una primera aproximación válida del ajuste de una regresión, pero se ve afectada por las unidades de medida de cada una de las variables, de modo que es posible variar su magnitud solo con el cambio de escala de alguna de los regresores. Este hecho hace imprescindible la introducción de otras medidas de ajuste que sean homogéneas y que, en caso necesario, permitan comparar la bondad del ajuste entre modelos diferentes.\n\n2.3.1 Coeficiente de determinación\nTal y como se muestra en la gráfica posterior, en el modelo de regresión lineal general, una vez estimada la función de regresión muestral, se cumple la igualdad:\n\\(y_{i} - \\overline{y} = \\left( {\\widehat{y}}_{i} - \\overline{y} \\right) + \\left( y_{i} - {\\widehat{y}}_{i} \\right) = \\left( {\\widehat{y}}_{i} - \\overline{y} \\right) + {\\widehat{e}}_{i}\\).\n\n\n\nFigura 3\n\n\nPor tanto, puede descomponerse la variabilidad total de los valores de la variable endógena alrededor de su media,\n\\[STC = \\Sigma(y_{i} - \\overline{y})^{2}\\]\nen dos partes, la suma de cuadrados explicada por la regresión (SEC) y la suma residual de cuadrados (SRC)\n\\[STC = SEC + SRC\\]\nes decir,\n\\[\\Sigma(y_{i} - \\overline{y})^{2} = \\Sigma({\\widehat{y}}_{i} - \\overline{y})^{2} + \\Sigma{ê_{i}}^{2}\\]\nA partir de esta descomposición de la variación total de la variable y, se define el coeficiente de determinación como la proporción de la variación total de y explicada por la regresión, es decir,\n\\[R^{2} = \\frac{SEC}{STC} = 1 - \\frac{SRC}{STC}\\]\nEste coeficiente cumple las siguientes propiedades:\n\n\\(0 \\leq R^{2} \\leq 1\\).\n\\(R^{2} = \\left( r_{y,\\widehat{y}} \\right)^{2}\\), es decir, el &gt; coeficiente de determinación coincide con el cuadrado del &gt; coeficiente de correlación lineal entre los valores observados de &gt; \\(y\\) y los valores estimados \\(\\widehat{y}\\).\n\\(R^{2} = 1\\) cuando \\(STC = SEC\\) o, equivalentemente, \\(SRC = 0\\); es &gt; decir, cuando todos los puntos muestrales están sobre la función &gt; de regresión (\\(\\sum_{i = 1}^{n}{\\widehat{e}}_{i}^{2} = 0\\)) y, por &gt; tanto, el ajuste del modelo de regresión es perfecto.\n\\(R^{2} = 0\\) cuando \\(SEC = 0\\), es decir, \\(STC = SRC\\) y, por tanto, &gt; todos los \\(b_{i}\\), para \\(i &gt; 1\\), son nulos y el modelo se reduce a &gt; \\(y_{i} = \\overline{y} + e_{i}\\). Consecuentemente, las variables &gt; exógenas no tendrán ninguna influencia en la variación de los &gt; valores de variable y, es decir, no tendrán ningún valor &gt; explicativo y el ajuste del modelo de regresión es nulo.\n\n\n\n2.3.2 Coeficiente de determinación ajustado\nSe puede demostrar que, si se incrementa el número de variables explicativas del modelo, aunque no tengan relación alguna con la variable dependiente, nunca disminuye el \\(R^{2}\\) de la regresión. Esto hace que comparar dos regresiones en base al \\(R^{2}\\) obtenido, con la misma variable dependiente y diferente número de regresores, no sea fiable. De hecho, la inclusión discrecional en el modelo de variables explicativas ajenas al sistema económico estudiado puede elevar artificialmente su valor.\nPor tal razón, y con el fin de descontar el efecto que el número de variables explicativas (y la consiguiente pérdida de grados de libertad) introduce en el \\(R^{2}\\), se define el coeficiente de determinación ajustado (ajusta el \\(R^{2}\\) original por los grados de libertad de cada suma de cuadrados):\n\\[{\\overline{R}}^{2} = 1 - \\frac{\\frac{SRC}{(n - K)}}{\\frac{STC}{(n - 1)}}\\]\nDe su definición, es inmediata la relación\n\\[{\\overline{R}}^{2} = 1 - (1 - R^{2})\\frac{n - 1}{n - K}\\]\ny, por tanto, el aumento del valor del \\({\\overline{R}}^{2}\\) al incluir una nueva variable explicativa dependerá de su contribución ‘real’ al modelo y, a diferencia de lo que ocurre con el \\(R^{2}\\) estándar, puede disminuir cuando se incorporan nuevas variables si no compensa la pérdida de grados de libertad.\nPuede observarse, de la propia definición del estadístico, que se cumple la igualdad\n\\[{\\overline{R}}^{2} = 1 - \\frac{{\\widehat{\\sigma}}^{2}}{\\frac{STC}{(n - 1)}}\\]\nlo que implica que cuanto mayor sea la dispersión de los residuos, es decir, cuando más elevada sea la variación de las desviaciones de los valores observados respecto a la función de regresión muestral estimada, menor será el ajuste proporcionado por el modelo. Esta expresión nos muestra también que conseguir un buen ajuste del modelo, maximizando el estadístico \\({\\overline{R}}^{2}\\), es equivalente a minimizar la varianza residual de la regresión, \\({\\widehat{\\sigma}}^{2}\\)."
  },
  {
    "objectID": "p2c1-teoria.html#inferencia-estadística-i-intervalos-de-confianza-y-contrastes-de-hipótesis-para-los-parámetros-del-modelo",
    "href": "p2c1-teoria.html#inferencia-estadística-i-intervalos-de-confianza-y-contrastes-de-hipótesis-para-los-parámetros-del-modelo",
    "title": "2  El modelo de regresión lineal y sus hipótesis básicas",
    "section": "2.4 Inferencia estadística (I): Intervalos de confianza y contrastes de hipótesis para los parámetros del modelo",
    "text": "2.4 Inferencia estadística (I): Intervalos de confianza y contrastes de hipótesis para los parámetros del modelo\n\n2.4.1 Distribución de los estimadores de los parámetros estructurales\nDe las hipótesis hechas para el modelo de regresión lineal se tiene que \\(\\widehat{\\mathbf{\\beta}}\\sim N(\\mathbf{\\beta},\\sigma^{2}\\left( \\mathbf{X}^{\\mathbf{'}}\\mathbf{X} \\right)^{- 1})\\). Por tanto, las distribuciones marginales vienen dadas por\n\\[{\\widehat{\\beta}}_{k}\\sim N(\\beta_{k},\\sigma^{2}a_{kk})\\]\ndonde \\(a_{kk}\\) es el elemento k-ésimo de la diagonal de la matriz \\({(\\mathbf{X}^{'}\\mathbf{X})}^{- 1}\\) y, en consecuencia, cada elemento \\(\\sigma^{2}a_{kk}\\) representa la varianza del estimador \\({\\widehat{\\beta}}_{k}\\), y su raíz cuadrada la desviación estándar del mismo.\nSi se estima la desviación típica de cada \\({\\widehat{\\beta}}_{k}\\) por \\(se({\\widehat{\\beta}}_{k}) = \\widehat{\\sigma}\\sqrt{a_{kk}}\\), se puede demostrar entonces que el estadístico \\(\\frac{({\\widehat{\\beta}}_{k} - \\beta_{k})}{se({\\widehat{\\beta}}_{k})}\\) sigue una distribución t de Student con n-K grados de libertad, es decir,\n\\[\\frac{{\\widehat{\\beta}}_{k} - \\beta_{k}}{se({\\widehat{\\beta}}_{k})}\\sim t_{n - K}\\]\nEste resultado permite la obtención de expresiones sencillas de los intervalos de confianza para cada uno de los parámetros estructurales, βk, y la realización de contrastes estadísticos acerca de sus posibles valores.\n\n\n2.4.2 Intervalos de confianza para los parámetros estructurales\nPuesto que \\(\\frac{{\\widehat{\\beta}}_{k} - \\beta_{k}}{se\\left( {\\widehat{\\beta}}_{k} \\right)}\\sim t_{n - K}\\) se sigue que \\(P\\left( - t_{n - K,\\frac{\\alpha}{2}} &lt; \\frac{{\\widehat{\\beta}}_{k} - \\beta_{k}}{se({\\widehat{\\beta}}_{k})} &lt; t_{n - K,\\frac{\\alpha}{2}} \\right) = 1 - \\alpha\\) y, realizando algunas operaciones aritméticas elementales, se llega a la siguiente expresión:\n\\[P\\left( {\\widehat{\\beta}}_{k} - t_{n - K,\\frac{\\alpha}{2}}se({\\widehat{\\beta}}_{k}) &lt; \\beta_{k} &lt; {\\widehat{\\beta}}_{k} + t_{n - K,\\frac{\\alpha}{2}}se({\\widehat{\\beta}}_{k}) \\right) = 1 - \\alpha\\]\nPor tanto, el intervalo de confianza al 100(1-α)% para el parámetro βk viene dado por:\n\\[I_{100(1 - \\alpha)\\%}(\\beta_{k}) = \\left( {\\widehat{\\beta}}_{k} - t_{n - K,\\frac{\\alpha}{2}}se({\\widehat{\\beta}}_{k}),{\\widehat{\\beta}}_{k} + t_{n - K,\\frac{\\alpha}{2}}se({\\widehat{\\beta}}_{k}) \\right)\\]\nDebemos tener presente que, dada una muestra concreta, la probabilidad de que el intervalo obtenido contenga al verdadero valor de βk es 1, si contiene al verdadero valor, ó 0 si no lo contiene. Sin embargo, nuestra confianza de que el intervalo contenga al verdadero valor de βk es del \\(100(1 - \\alpha)\\) por ciento porque, en un contexto de muestras repetidas, este sería el porcentaje de intervalos de este tipo que contendrían al verdadero valor βk.\n\n\n2.4.3 Contrastes de hipótesis sobre parámetros estructurales\nPara contrastes de hipótesis bilaterales del tipo\n\\[{H_{0}:\\left\\{ \\beta_{k} = c \\right\\}\\text{\\ \\ frente\\ a\\ \\ }H}_{1}:\\left\\{ \\beta_{k} \\neq c \\right\\}\\]\nse utiliza como estadístico de prueba el valor\n\\[t_{0} = \\frac{{\\widehat{\\beta}}_{k} - c}{se({\\widehat{\\beta}}_{k})}\\]\nque, bajo \\(H_{0}\\), sigue una distribución t de Student con n-K grados de libertad, \\(t_{0}\\sim t_{n - K}\\). Por tanto, la región crítica (de rechazo de \\(H_{0}\\)) al nivel de significación α viene dada por \\(\\left| t_{0} \\right| &gt; t_{n - K,\\alpha/2}\\), tal y como se muestra en el gráfico siguiente:\n\n\n\nFigura 4\n\n\nResultan de especial interés los contrastes de las hipótesis individuales:\n\\[{H_{0}:\\left\\{ \\beta_{k} = 0 \\right\\}\\text{\\ \\ frente\\ a\\ \\ }H}_{1}:\\left\\{ \\beta_{k} \\neq 0 \\right\\}\\]\nque equivalen a contrastar la significación estadística de cada una de las variables explicativas del modelo (contrastes de significación individual de los parámetros del modelo). En este caso, los estadísticos \\(t_{0}\\) toman la expresión \\(t_{\\beta_{k}} = \\frac{{\\widehat{\\beta}}_{k}}{se({\\widehat{\\beta}}_{k})}\\), valores que se conocen como estadísticos t o t-ratios de cada parámetro. Se dirá que un parámetro \\(\\beta_{k}\\) es estadísticamente significativo cuando se cumpla que \\(\\left| t_{\\beta_{k}} \\right| &gt; t_{n - K,\\alpha/2}\\) (también puede utilizarse el método del P-valor, que se explicará más adelante, como criterio de significación estadística).\nTambién son habituales los contrastes unilaterales del tipo\n\\[{H_{0}:\\left\\{ \\beta_{k} \\leq c \\right\\}\\text{\\ \\ frente\\ a\\ \\ }H}_{1}:\\left\\{ \\beta_{k} &gt; c \\right\\}\\]\no el complementario\n\\[{H_{0}:\\left\\{ \\beta_{k} \\geq c \\right\\}\\text{\\ \\ frente\\ a\\ \\ }H}_{1}:\\left\\{ \\beta_{k} &lt; c \\right\\}\\]\nPara realizar estos contrastes propuestos también se utiliza la prueba t: basándonos en que \\(\\frac{{\\widehat{\\beta}}_{k} - \\beta_{k}}{se\\left( {\\widehat{\\beta}}_{k} \\right)}\\sim t_{n - K}\\), si se verifica la hipótesis nula, entonces ha de cumplirse que \\(t_{0} = \\frac{{\\widehat{\\beta}}_{k} - c}{se({\\widehat{\\beta}}_{k})}\\) sigue una distribución t de Student con n-K grados de libertad. A partir de este resultado, para un nivel de significación α, la región de rechazo para el estadístico de contraste t0 vendrá dada por \\(t_{0} \\geq t_{n - K,\\alpha}\\)para el contraste unilateral por la derecha , y por \\(t_{0} \\leq - t_{n - K,\\alpha}\\) para el contraste unilateral por la izquierda. Ambas regiones se muestran en las gráficas siguientes:\n\n\n\nFigura 5\n\n\n\n\n\nFigura 6\n\n\n\n\n2.4.4 Intervalo de confianza y contrastes de hipótesis para la varianza residual\nDado que se verifica que\n\\[\\frac{(n - K){\\widehat{\\sigma}}^{2}}{\\sigma^{2}}\\sim\\chi_{n - K}^{2}\\]\ny teniendo en cuenta que la distribución Chi-cuadrado no es simétrica, obtenemos que \\(P\\left( \\chi_{n - K,1 - \\frac{\\alpha}{2}}^{2} &lt; \\frac{(n - K)\\widehat{\\sigma}^{2}}{\\sigma^{2}} &lt; \\chi_{n - K,\\frac{\\alpha}{2}}^{2} \\right) = 1 - \\alpha\\).\nEntonces, de nuevo mediante operaciones aritméticas simples para despejar la varianza residual, se llega a que\n\\[P\\left( \\frac{(n - K)\\widehat{\\sigma}^{2}}{\\chi_{n - K,\\frac{\\alpha}{2}}^{2}} &lt; \\sigma^{2} &lt; \\frac{(n - K)\\widehat{\\sigma}^{2}}{\\chi_{n - K,1 - \\frac{\\alpha}{2}}^{2}} \\right) = 1 - \\alpha\\]\nPor tanto, el intervalo al 100(1-α)% de confianza para el parámetro σ2 viene dado por\n\\[I_{100(1 - \\alpha)\\%}(\\sigma^{2}) = \\left( \\frac{(n - K)\\widehat{\\sigma}^{2}}{\\chi_{n - K,\\frac{\\alpha}{2}}^{2}},\\frac{(n - K)\\widehat{\\sigma}^{2}}{\\chi_{n - K,1 - \\frac{\\alpha}{2}}^{2}} \\right)\\]\nPara realizar un contraste donde la hipótesis nula es \\(H_{0}:\\left\\{ \\sigma^{2} = c \\right\\}\\) y la alternativa viene dada por \\(H_{1}:\\left\\{ \\sigma^{2} \\neq c \\right\\}\\), con un nivel de significación α, el estadístico utilizado es \\(\\chi_{0}^{2} = \\frac{(n - K)\\widehat{\\sigma}^{2}}{c}\\), y la región crítica viene dada en este caso por las zonas (de rechazo) \\(\\chi_{0}^{2} &lt; \\chi_{n - K,1 - \\frac{\\alpha}{2}}^{2}\\) y \\(\\chi_{0}^{2} &gt; \\chi_{n - K,\\frac{\\alpha}{2}}^{2}\\)."
  },
  {
    "objectID": "p2c1-teoria.html#inferencia-estadística-ii-contrastes-conjuntos-de-restricciones-y-el-estimador-de-mínimos-cuadrados-restringidos",
    "href": "p2c1-teoria.html#inferencia-estadística-ii-contrastes-conjuntos-de-restricciones-y-el-estimador-de-mínimos-cuadrados-restringidos",
    "title": "2  El modelo de regresión lineal y sus hipótesis básicas",
    "section": "2.5 Inferencia estadística (II): Contrastes conjuntos de restricciones y el estimador de mínimos cuadrados restringidos",
    "text": "2.5 Inferencia estadística (II): Contrastes conjuntos de restricciones y el estimador de mínimos cuadrados restringidos\n\n2.5.1 Distribución de los estimadores de combinaciones lineales de parámetros estructurales\nPara llevar a cabo contrastes conjuntos en el MRL, debemos utilizar un resultado estadístico general sobre distribuciones de variables aleatorias multivariantes. Concretamente, dada una matriz \\(\\mathbf{R}\\) de orden \\(q \\times K\\), del hecho de que \\(\\widehat{\\mathbf{\\beta}}\\sim N(\\mathbf{\\beta},\\sigma^{2}\\left( \\mathbf{X}^{\\mathbf{'}}\\mathbf{X} \\right)^{- 1})\\) se tiene que \\(\\mathbf{R}\\widehat{\\mathbf{\\beta}}\\sim N(\\mathbf{R\\beta},\\sigma^{2}\\mathbf{R}\\left( \\mathbf{X}^{\\mathbf{'}}\\mathbf{X} \\right)^{- 1}\\mathbf{R}')\\) y, entonces,\n\\[\\frac{\\frac{\\left( \\mathbf{R}\\widehat{\\mathbf{\\beta}} - \\mathbf{R\\beta} \\right)^{'}\\left\\lbrack {\\mathbf{R}\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}}\\mathbf{R}}^{\\mathbf{'}} \\right\\rbrack^{- 1}\\left( \\mathbf{R}\\widehat{\\mathbf{\\beta}} - \\mathbf{R\\beta} \\right)}{q}}{{\\widehat{\\sigma}}^{2}}\\sim F_{q,n - K}\\]\nresultado que permite la realización de cualquier contraste de restricciones lineales múltiples.\n\n\n2.5.2 Contrastes conjuntos de restricciones lineales sobre el vector \\(\\mathbf{\\beta}\\)\nSea \\(\\mathbf{R}\\) una matriz de restricciones lineales sobre \\(\\mathbf{\\beta}\\), siendo \\(rango\\left( \\mathbf{R} \\right) = q\\), donde q representa el número de restricciones. Por ejemplo, el conjunto de \\(q = 4\\) restricciones\n\\[\\beta_{2} = 0,\\ \\beta_{3} = \\beta_{4},\\ \\beta_{1} + 2\\beta_{5} + 3\\beta_{6} = 2,\\ \\beta_{1} + \\beta_{4} + \\beta_{5} + \\beta_{6} = 0\\]\npuede expresarse matricialmente como:\n\\[\\begin{bmatrix}\n0 & 1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & - 1 & 0 & 0 \\\\\n1 & 0 & 0 & 0 & 2 & 3 \\\\\n1 & 0 & 0 & 1 & 1 & 1 \\\\\n\\end{bmatrix}\\begin{bmatrix}\n\\beta_{1} \\\\\n\\beta_{2} \\\\\n\\beta_{3} \\\\\n\\beta_{4} \\\\\n\\beta_{5} \\\\\n\\beta_{6} \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n0 \\\\\n0 \\\\\n2 \\\\\n0 \\\\\n\\end{bmatrix}\\]\nEn general, cualquier conjunto de restricciones lineales puede escribirse como\n\\[\\left\\{ \\ \\begin{matrix}\nr_{11}\\beta_{1} + r_{12}\\beta_{2} + \\cdots + r_{1K}\\beta_{K} = r_{1} \\\\\n\\vdots \\\\\nr_{q1}\\beta_{1} + r_{q2}\\beta_{2} + \\cdots + r_{qK}\\beta_{K} = r_{q} \\\\\n\\end{matrix} \\right.\\ \\]\nsistema de ecuaciones que en forma matricial se expresa como \\(\\mathbf{R\\beta} = \\mathbf{r}\\).\nTeniendo en cuenta el resultado estadístico general, para el contraste de restricciones lineales donde la hipótesis nula \\(H_{0}\\mathbf{:}\\left\\{ \\mathbf{R\\beta} = \\mathbf{r} \\right\\}\\) se confronta a la alternativa \\(H_{1}\\mathbf{:}\\left\\{ \\mathbf{R\\beta} \\neq \\mathbf{r} \\right\\}\\), se puede utilizar el estadístico F de Fisher-Snedecor, el cual bajo \\(H_{0}\\) se distribuye como\n\\[F_{0} = \\frac{\\frac{\\left( \\mathbf{R}\\widehat{\\mathbf{\\beta}} - \\mathbf{r} \\right)^{'}\\left\\lbrack {\\mathbf{R}\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}}\\mathbf{R}}^{\\mathbf{'}} \\right\\rbrack^{- 1}\\left( \\mathbf{R}\\widehat{\\mathbf{\\beta}} - \\mathbf{r} \\right)}{q}}{{\\widehat{\\sigma}}^{2}}\\sim F_{q,n - K}\\]\nEn consecuencia, se rechazará la hipótesis nula \\(H_{0}\\) cuando el valor del estadístico muestral \\(F_{0}\\) supere el valor crítico teórico, \\(F_{0} &gt; F_{q,n - K,\\alpha}\\), mientras que si se cumple que \\(F_{0} \\leq F_{q,n - K,\\alpha}\\) entonces no se rechazará \\(H_{0}:\\left\\{ \\mathbf{R\\beta} = \\mathbf{r} \\right\\}\\).\nTambién puede utilizarse para el contraste de restricciones lineales el estadístico de Wald\n\\[W_{0} = \\frac{\\left( \\mathbf{R}\\widehat{\\mathbf{\\beta}} - \\mathbf{r} \\right)^{'}\\left\\lbrack {\\mathbf{R}\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}}\\mathbf{R}}^{\\mathbf{'}} \\right\\rbrack^{- 1}\\left( \\mathbf{R}\\widehat{\\mathbf{\\beta}} - \\mathbf{r} \\right)}{{\\widehat{\\sigma}}^{2}}\\overset{as}{\\sim}F_{q,n - K}\\]\ncumpliéndose que \\(W_{0} = qF_{0}\\).\nLógicamente, este contraste no ofrece ninguna ventaja sobre el estadístico F0 para el caso lineal (de hecho, al tratarse de un contraste asintótico, sólo es fiable si el tamaño de la muestra es suficientemente grande); en cambio, puede utilizarse para situaciones mucho más generales que el primero, en particular, para contrastar restricciones no lineales para las que el estadístico F0 resulta inaplicable.\nAsí, si el contraste que se quiere realizar tiene la forma general \\(H_{0}:\\left\\{ \\mathbf{g}\\left( \\mathbf{\\beta} \\right) = \\mathbf{r} \\right\\}\\) frente a \\(H_{1}:\\left\\{ \\mathbf{g}\\left( \\mathbf{\\beta} \\right) \\neq \\mathbf{r} \\right\\}\\)para algún conjunto de funciones no lineales \\(\\mathbf{g} = (g_{1},g_{2},\\ldots,g_{q})\\), debe utilizarse necesariamente la prueba de Wald, que ahora toma la expresión\n\\[W_{0} = \\frac{\\left( \\mathbf{g}\\left( \\widehat{\\mathbf{\\beta}} \\right) - \\mathbf{r} \\right)^{'}\\left\\lbrack {\\mathbf{G}\\left( \\widehat{\\mathbf{\\beta}} \\right)\\left( \\mathbf{X}\\mathbf{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}}\\mathbf{G}\\left( \\widehat{\\mathbf{\\beta}} \\right)}^{\\mathbf{'}} \\right\\rbrack^{- 1}\\left( \\mathbf{g}\\left( \\widehat{\\mathbf{\\beta}} \\right) - \\mathbf{r} \\right)}{{\\widehat{\\sigma}}^{2}}\\]\ndonde \\(\\mathbf{G} = \\left( \\frac{\\partial g_{1}}{\\partial\\mathbf{\\beta}'},\\frac{\\partial g_{2}}{\\partial\\mathbf{\\beta}'},\\ldots,\\frac{\\partial g_{q}}{\\partial\\mathbf{\\beta}'} \\right)\\). Si la hipótesis nula es cierta, la distribución asintótica del estadístico W0 es una variable \\(\\chi^{2}\\), \\(W_{0}\\overset{as}{\\sim}\\chi_{q}^{2}\\) .\n\n\n2.5.3 Contraste de validez general del modelo de regresión\nEl contraste de significación conjunta (global) de los parámetros del modelo de regresión lineal viene dado por\n\\[H_{0}:\\left\\{ \\beta_{2} = 0,\\beta_{3} = 0,\\ldots,\\beta_{K} = 0 \\right\\}\\ \\ frente\\ a\\ \\ H_{1}:\\left\\{ \\exists j &gt; 1/\\beta_{j} \\neq 0 \\right\\}\\]\nlo que equivale a contrastar\n\\[H_{0}:\\left\\{ y_{i} = \\beta_{1} + e_{i} \\right\\}\\ \\ frente\\ a\\ \\ H_{1}:\\left\\{ y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i} \\right\\}\\]\nes decir, la hipótesis nula de que ninguna de las variables explicativas ejerce una influencia estadísticamente significativa sobre la variable dependiente, frente a la alternativa de que al menos una de ellas resulta estadísticamente significativa.\nEn este caso particular, puede calcularse el valor del estadístico de prueba F0 a partir de la expresión\n\\[F_{0} = \\frac{\\frac{SEC}{(K - 1)}}{\\frac{SRC}{(n - K)}}\\]\nlo cual permite realizar el siguiente cuadro de análisis de la varianza para el modelo de regresión lineal:\n\n\n\n\n\n\n\n\n\n\nFuente de variación\nSuma de cuadrados\nGrados de libertad\n‘Media’ de cuadrados\nF0\n\n\nRegresión\n\\[SEC = {\\widehat{\\mathbf{\\beta}}}^{'}\\mathbf{X}^{'}\\mathbf{y} - n{\\overline{y}}^{2}\\]\n\\[K - 1\\]\n\\[\\frac{SEC}{(K - 1)}\\]\n\\[\\frac{\\frac{SEC}{(K - 1)}}{\\frac{SRC}{(n - K)}}\\]\n\n\nResidual\n\\[SRC = \\mathbf{y}^{'}\\mathbf{y} - \\widehat{\\mathbf{\\beta}}\\mathbf{X}^{'}\\mathbf{y}\\]\n\\[n - K\\]\n\\[\\frac{SRC}{(n - K)}\\]\n\n\n\nTotal\n\\[STC = \\mathbf{y}^{'}\\mathbf{y} - n{\\overline{y}}^{2}\\]\n\\[n - 1\\]\n\n\n\n\n\nTambién puede demostrarse que, para este contraste de validez general del modelo de regresión, se tiene que\n\\[F_{0} = \\frac{\\frac{R^{2}}{(K - 1)}}{\\frac{(1 - R^{2})}{(n - K)}}\\]\nlo que permite interpretar el estadístico F0 como la “versión estadística del coeficiente R2”: si el R2 de una regresión es suficientemente alto, el estadístico F0 rechazará fácilmente la hipótesis nula \\(H_{0}:\\left\\{ \\beta_{2} = 0,\\beta_{3} = 0,\\ldots,\\beta_{K} = 0 \\right\\}\\), mientras que si el valor R2 es muy bajo no se rechazará dicha hipótesis, lo que implica que ninguna de las variables del modelo de regresión planteado resulta estadísticamente significativa.\n\n\n2.5.4 El estimador de mínimos cuadrados restringidos\nEn ocasiones, las restricciones lineales sobre los parámetros del modelo vienen ‘impuestas’ por la teoría económica subyacente, es decir, se trata de restricciones poblacionales en forma de información a priori. Otras veces, sin embargo, dichas restricciones son de tipo muestral, esto es, se alude a restricciones a posteriori. En cualquier caso, puede plantearse la idea de incorporar tal información extra al modelo de regresión al objeto de mejorar los resultados. Estaríamos en este caso ante el método conocido como mínimos cuadrados restringidos (MCR).\nLas estimaciones de mínimos cuadrados restringidos se obtienen minimizando la función objetivo estándar de MCO, \\(S(\\mathbf{\\beta}) = (\\mathbf{y} - \\mathbf{X\\beta})'(\\mathbf{y} - \\mathbf{X\\beta})\\), sujeta a un cierto conjunto de restricciones, \\(\\mathbf{R\\beta} = \\mathbf{r}\\). Matemáticamente, esto equivale a minimizar la función\n\\[L\\left( \\mathbf{\\beta} \\right) = \\left( \\mathbf{y} - \\mathbf{X\\beta} \\right)^{'}\\left( \\mathbf{y} - \\mathbf{X\\beta} \\right) - \\mathbf{\\lambda}'\\left( \\mathbf{R\\beta} - \\mathbf{r} \\right)\\]\ndonde \\(\\mathbf{\\lambda} = \\left( \\lambda_{1},\\ldots,\\lambda_{q} \\right)^{'}\\) es el llamado vector de multiplicadores de Lagrange. La solución matemática a este problema da lugar a las estimaciones MCR, que vienen dadas por la expresión:\n\\[\\mathbf{b}_{MCR} = \\mathbf{b} + {(\\mathbf{X}^{\\mathbf{'}}\\mathbf{X})}^{- 1}\\mathbf{R}'\\left\\lbrack \\mathbf{R}\\left( \\mathbf{X}^{'}\\mathbf{X} \\right)^{- 1}\\mathbf{R}^{'} \\right\\rbrack^{- 1}(\\mathbf{r} - \\mathbf{Rb})\\]\nPuede demostrarse que las estimaciones obtenidas son equivalentes a las que se llegaría re-parametrizando el modelo original (no restringido) mediante la incorporación al mismo de las restricciones\\(\\mathbf{\\ }\\mathbf{R\\beta} = \\mathbf{r}\\), y estimando este último (el modelo restringido) por MCO. De ahí el nombre del estimador.\nEn cuanto a las propiedades estadísticas y algebraicas del estimador MCR, \\({\\widehat{\\mathbf{\\beta}}}_{MCR}\\), se cumple lo siguiente:\n\n\\(E\\left( {\\widehat{\\mathbf{\\beta}}}_{MCR} \\right) = \\mathbf{\\beta}\\) &gt; si y sólo si \\(\\mathbf{R\\beta}\\mathbf{=}\\mathbf{r}\\), es decir, &gt; el estimador MCR sólo es insesgado si las restricciones son &gt; ciertas.\n\\(Cov\\left( {\\widehat{\\mathbf{\\beta}}}_{MCR} \\right) \\leq Cov\\left( {\\widehat{\\mathbf{\\beta}}}_{MCO} \\right)\\) &gt; aún cuando las restricciones sean falsas, es decir, el estimador &gt; MCR es siempre más eficiente que el estimador MCO.\n\nPor tanto, si las restricciones \\(\\mathbf{R\\beta} = \\mathbf{r}\\) son válidas, \\({\\widehat{\\mathbf{\\beta}}}_{MCR}\\) es mejor que \\({\\widehat{\\mathbf{\\beta}}}_{MCO}\\) por ser insesgado y de menor varianza. En otro caso, el estimador \\({\\widehat{\\mathbf{\\beta}}}_{MCR}\\) es sesgado aún cuando pueda tener menor varianza que el estimador \\({\\widehat{\\mathbf{\\beta}}}_{MCO}\\) y, por tanto, tenga un error cuadrático medio menor.\nPara contrastar la validez de las restricciones, \\(H_{0}:\\left\\{ \\mathbf{R\\beta} = \\mathbf{r} \\right\\}\\), puede utilizarse el estadístico \\(F_{0}\\), pudiendo demostrarse en este caso que dicho estadístico viene dado por la expresión\n\\[F_{0} = \\frac{(SRC_{R} - SRC_{NR})/q}{SRC_{NR}/(n - K)}\\]\ndonde SRCNR representa la suma de residuos al cuadrado del modelo no restringido y SRCR la suma de cuadrados residual correspondiente al modelo restringido, siendo q el número de restricciones incluidas en\\(\\mathbf{\\ }\\mathbf{R\\beta} = \\mathbf{r}\\)."
  },
  {
    "objectID": "p2c1-teoria.html#predicciones",
    "href": "p2c1-teoria.html#predicciones",
    "title": "2  El modelo de regresión lineal y sus hipótesis básicas",
    "section": "2.6 Predicciones",
    "text": "2.6 Predicciones\nSupongamos que se parte del modelo de regresión lineal \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\), el cual produce valores ajustados del tipo \\(\\widehat{\\mathbf{y}} = \\mathbf{Xb}\\) al ser estimado mediante MCO. Dado un nuevo conjunto de valores de las variables exógenas, \\(\\mathbf{X}_{0} = \\left( 1,x_{20},\\ldots,x_{K0} \\right)\\), el objetivo de la predicción consiste en estimar el valor desconocido \\(y_{0}\\) dados los distintos valores (conocidos) de las variables explicativas contenidos en el vector \\(\\mathbf{X}_{0}\\). De forma lógica, la estimación propuesta para dicho valor viene dada por la expresión \\({\\widehat{y}}_{0} = b_{1} + b_{2}x_{20} + \\ldots + b_{K}x_{K0} = \\mathbf{X}_{0}\\mathbf{b}\\).\nEl estimador propuesto, denominado predictor, tiene la expresión\n\\[{\\widehat{y}}_{0} = \\mathbf{X}_{0}\\widehat{\\mathbf{\\beta}}\\]\ny debemos tener presente que, según el modelo de regresión, \\(y_{0} = \\mathbf{X}_{0}\\mathbf{\\beta}\\mathbf{+}e_{0}\\), por lo que si la predicción viene dada por \\({\\widehat{y}}_{0} = \\mathbf{X}_{0}\\widehat{\\mathbf{\\beta}}\\), el error de predicción que se cometerá será\n\\[{e_{0}^{P} = y_{0} - \\widehat{y}}_{0}\\]\nTeniendo en cuenta que si se verifican las hipótesis del MRL se cumple que \\(\\widehat{\\mathbf{\\beta}}\\sim N(\\mathbf{\\beta},\\sigma^{2}\\left( \\mathbf{X}^{\\mathbf{'}}\\mathbf{X} \\right)^{- 1})\\), entonces la distribución de \\({\\widehat{y}}_{0}\\) viene dada por\n\\[{\\widehat{y}}_{0} = \\mathbf{X}_{0}\\widehat{\\mathbf{\\beta}}\\mathbf{\\sim}N(\\mathbf{X}_{0}\\mathbf{\\beta}\\mathbf{,}\\mathbf{X}_{0}Cov\\left( \\widehat{\\mathbf{\\beta}} \\right)\\mathbf{X}_{0}^{\\mathbf{'}})\\]\npor lo que es obvio que se cumple que \\({E\\left( e_{0}^{P} \\right)}_{\\ }\\)=0 y, por tanto, \\({\\widehat{y}}_{0}\\) es un estimador insesgado del valor \\(y_{0}\\).\nPor otra parte, teniendo en cuenta las propiedades encontradas para el estimador MCO, se cumple que \\({\\widehat{y}}_{0} = \\mathbf{X}_{0}\\widehat{\\mathbf{\\beta}}\\) es el mejor predictor lineal insesgado para el valor y0.\nTambién se puede demostrar que la varianza del error de predicción puntual toma la expresión\n\\[{Var\\left( e_{0}^{P} \\right) = \\sigma^{2}\\left( 1 + \\mathbf{X}_{0}\\left( \\mathbf{X}^{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}}\\mathbf{X}_{0}^{\\mathbf{'}} \\right)\\ }_{\\ }\\]\nSubstituyendo el valor de \\(\\sigma^{2}\\) por su estimación MCO, \\({\\widehat{\\sigma}}^{2}\\), y tras la normalización correspondiente, se puede demostrar que\n\\[\\frac{e_{0}^{P}}{\\sqrt{\\widehat{Var\\left( e_{0}^{P} \\right)}}} = \\frac{y_{0}\\mathbf{-}\\mathbf{X}_{0}\\widehat{\\mathbf{\\beta}}\\mathbf{\\ }}{\\widehat{\\sigma}\\sqrt{\\ 1 + \\mathbf{X}_{0}\\left( \\mathbf{X}^{'}\\mathbf{X} \\right)^{- 1}\\mathbf{X}_{0}^{\\mathbf{'}}}\\ }\\sim t_{n - K}\\]\nEste resultado nos permite realizar contrastes sobre los valores de las predicciones, así como construir un intervalo de confianza para la predicción realizada, el cual está dado por la expresión:\n\\[I_{100(1 - \\alpha)\\%}(y_{0}) = \\left( {\\widehat{y}}_{0} - t_{n - K,\\frac{\\alpha}{2}}se\\left( {\\widehat{e}}_{0}^{P} \\right)\\ ,\\ {\\widehat{y}}_{0} + t_{n - K,\\frac{\\alpha}{2}}se({\\widehat{e}}_{0}^{P}) \\right)\\]\ndonde \\(se\\left( {\\widehat{e}}_{0}^{P} \\right)\\) representa la desviación típica estimada del error de predicción, \\(se\\left( {\\widehat{e}}_{0}^{P} \\right) = \\sqrt{\\widehat{Var\\left( e_{0}^{P} \\right)}}\\).\nLa expresión anterior para el intervalo de confianza nos muestra que, cuanto más alejado esté el valor \\(\\mathbf{X}_{0} = \\left( 1,x_{20},\\ldots,x_{K0} \\right)\\) de la media de los datos muestrales, \\(\\overline{\\mathbf{X}} = \\left( 1,{\\overline{x}}_{2},\\ldots,{\\overline{x}}_{K} \\right)\\), mayor será la amplitud del intervalo de predicción y, por tanto, menos fiables serán las predicciones. En la gráfica siguiente se muestra este comportamiento de los intervalos de predicción:\n\n\n\nFigura 7"
  },
  {
    "objectID": "p2c1-teoria.html#forma-funcional",
    "href": "p2c1-teoria.html#forma-funcional",
    "title": "2  El modelo de regresión lineal y sus hipótesis básicas",
    "section": "2.7 Forma funcional",
    "text": "2.7 Forma funcional\nEl modelo de regresión estándar, \\(y = \\beta_{1} + \\beta_{2}x_{2} + \\ldots + \\beta_{K}x_{K} + e\\), se caracteriza por ser lineal no sólo en los parámetros, sino también en las variables. No obstante, existen otros modelos que, si bien no son lineales en las variables, son lineales en los parámetros. Entre estos se encuentran una amplia gama de especificaciones que son aplicadas con frecuencia en la práctica econométrica.\nHaremos referencia a continuación a las formas funcionales más habituales, utilizando como soporte para la exposición el modelo de regresión lineal con una sola variable explicativa \\(x\\), \\(y_{i} = \\beta_{1} + \\beta_{2}x_{i} + e_{i}\\). En la gráfica siguiente se muestran algunas de las funciones a las que nos referiremos en los próximos párrafos:\n\n\n\nFigura 8\n\n\n\n2.7.1 Regresiones cuadráticas o polinómicas\nEl modelo de regresión cuadrático se expresa matemáticamente como\n\\[y_{i} = \\beta_{1} + \\beta_{2}x_{i} + \\beta_{3}x_{i}^{2} + e_{i}\\]\nEn este modelo, a diferencia del caso lineal básico, la pendiente de la curva de regresión no es constante, sino que depende de los valores de la variable x. Concretamente, se tiene que \\(\\frac{\\partial y_{i}}{\\partial x_{i}} = \\beta_{2} + 2\\beta_{3}x_{i}\\) y, por tanto, según que el parámetro \\(\\beta_{3}\\) sea positivo o negativo, la tasa de cambio de la variable y frente a la variable x aumentará o disminuirá conforme lo haga la variable x.\nEl modelo cuadrático puede generalizarse añadiendo potencias de orden superior en la variable \\(x\\), por ejemplo, \\(x^{3}\\) o \\(x^{4}\\), con lo que se consigue mayor flexibilidad en el modelo de respuestas \\(\\frac{\\partial y_{i}}{\\partial x_{i}}\\) posible:\n\\[y_{i} = \\beta_{1} + \\beta_{2}x_{i} + \\beta_{3}x_{i}^{2} + \\beta_{4}x_{i}^{3} + \\ldots + e_{i}\\]\nEjemplos de regresiones polinómicas son las funciones de costes, totales o medios, para las que pueden llegar a observarse modelos cúbicos o cuadráticos, respectivamente.\n\n\n2.7.2 Regresiones logarítmicas\nEl modelo dado por la función potencial, \\(y_{i} = \\alpha_{0}x_{i}^{\\alpha_{1}}e^{e_{i}}\\), es conocido como logarítmico (log-log). Para poder aplicar los resultados obtenidos para el modelo lineal se transforma la expresión original tomando logaritmos naturales, obteniéndose\n\\[\\log y_{i} = \\beta_{1} + \\beta_{2}\\log x_{i} + e_{i}\\]\ndonde \\(\\beta_{1} = \\log\\alpha_{0}\\) y \\(\\beta_{2} = \\alpha_{1}\\).\nEl modelo transformado es lineal en los parámetros y puede estimarse por mínimos cuadrados ordinarios. Para ello, se definen \\(y_{i}^{*} = \\log y_{i}\\) y \\(x_{i}^{*} = \\log x_{i}\\), y se reescribe el modelo transformado como \\(y_{i}^{*} = \\beta_{1} + \\beta_{2}x_{i}^{*} + e_{i}\\).\nEste modelo también se conoce como modelo de elasticidad constante, pues el coeficiente β2 es la elasticidad de la variable y respecto de x ya que \\(\\beta_{2} = \\frac{\\partial y_{i}^{*}}{\\partial x_{i}^{*}} = \\frac{\\partial logy}{\\partial logx} = \\frac{\\partial y/y}{\\partial x/x} = e_{y|x}\\). Entonces, un 1% de cambio en la variable x llevará asociado, en promedio, un cambio en la variable y del β2%.\nUn ejemplo clásico de modelo logarítmico es la especificación Cobb-Douglas para una función de producción, \\(Y_{i} = AL_{i}^{\\alpha}K_{i}^{\\beta}e^{e_{i}}\\), que tras tomar logaritmos se convierte en \\(\\log Y_{i} = \\beta_{1} + \\beta_{2}\\log L_{i} + \\beta_{3}\\log K_{i} + e_{i}\\). En este caso, los parámetros \\(\\beta_{1}\\) y \\(\\beta_{2}\\) representan, respectivamente, las elasticidades de la producción (Y) respecto al trabajo (L) y el capital (K).\n\n\n2.7.3 Regresiones semi-logarítmicas\nSi nos interesa medir el cambio porcentual en y, ante un cambio unitario absoluto en x, el modelo a utilizar deberá ser del tipo logarítmico-lineal (log-lin)\n\\[\\log y_{i} = \\beta_{1} + \\beta_{2}x_{i} + e_{i}\\]\nel cual se obtiene tras tomar logaritmos en una función exponencial del tipo \\(y_{i} = \\alpha_{0}e^{\\beta_{\\, 2}x_{i}}e^{e_{i}}\\) (y denotando \\(\\beta_{1} = \\log\\alpha_{0}\\)). Para este modelo, el cambio relativo en y producido por un cambio absoluto de una unidad en x viene dado por 100β2%.\nEsta forma funcional aparece frecuentemente cuando se analizan funciones de demanda de dinero, por ejemplo, de la forma \\(\\log M_{t} = \\beta_{1} + \\beta_{2}r_{t} + e_{t}\\), donde M es la cantidad de dinero en circulación y r el tipo de interés. En este caso, 100β2 es la semi-elasticidad de la demanda de dinero respecto al tipo de interés: un cambio de un punto en los tipos de interés llevará asociado, en promedio, un cambio del 100β2% en la demanda agregada de dinero.\nCuando interesa medir el cambio absoluto en y ante cambios relativos en x, el modelo adecuado será del tipo lineal-logarítmico (lin-log)\n\\[y_{i} = \\beta_{1} + \\beta_{2}\\log x_{i} + e_{i}\\]\ny, en este caso, el cambio absoluto en la variable y producido por un cambio relativo del 1% en la variable x será de β2/100 unidades.\n\n\n2.7.4 Regresión recíproca\nSe trata de un modelo del tipo\n\\[y_{i} = \\beta_{1} + \\beta_{2}\\frac{1}{x_{i}} + e_{i}\\]\nexistiendo, por tanto, una relación inversa entre las variables x e y (aparte del término de error). Estos modelos se caracterizan porque, al crecer x indefinidamente, y tiende hacia un valor asintótico \\(\\beta_{1}\\), es decir, \\(\\lim_{x \\rightarrow \\infty}y = \\beta_{1}\\).\n\n\n2.7.5 Regresiones con términos de interacción\nEl modelo de regresión con interacciones se expresa matemáticamente como\n\\[y_{i} = \\beta_{1} + \\beta_{2}x_{i} + \\beta_{3}x_{i}z_{i} + e_{i}\\ \\]\nEn este modelo, igual que en el caso cuadrático, la pendiente de la curva de regresión no es constante, sino que depende ahora de los valores de la variable z. Concretamente, se cumple que \\(\\frac{\\partial y_{i}}{\\partial x_{i}} = \\beta_{2} + \\beta_{3}z_{i}\\) y, por tanto, según que el parámetro \\(\\beta_{3}\\) sea positivo o negativo, la tasa de cambio de la variable y frente a la variable x aumentará o disminuirá conforme lo haga la variable z."
  },
  {
    "objectID": "p2c2-app1.html#código-r",
    "href": "p2c2-app1.html#código-r",
    "title": "Aplicación 2.1 (Estimación MCO y contrastes de hipótesis): Modelo CAPM para las acciones del Banco Santander",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\n# Lectura de datos\nCAPM_ESP &lt;- read_delim(\"data/CAPM_ESP.csv\", delim = \";\")\nhead(CAPM_ESP)\n\n# A tibble: 6 × 6\n  date       P_INDITEX P_SANTANDER P_TELEFONICA P_IBEX35 R_LT1Y\n  &lt;date&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 2001-05-22      2.94        6.55        14.1     9543.   4.54\n2 2001-06-22      3.75        6.26        11.5     9602.   4.25\n3 2001-07-22      3.61        5.76        10.5     8788.   4.12\n4 2001-08-22      3.86        5.81         9.81    8565.   4.09\n5 2001-09-22      3.06        4.08         8.67    8117.   3.84\n6 2001-10-22      3.88        5.32        10.0     7169.   3.28\n\ntail(CAPM_ESP)\n\n# A tibble: 6 × 6\n  date       P_INDITEX P_SANTANDER P_TELEFONICA P_IBEX35 R_LT1Y\n  &lt;date&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 2017-08-22      33.7        5.44         9.16   10658.  -0.41\n2 2017-09-22      31.9        5.70         9.05   10180.  -0.37\n3 2017-10-22      31.0        5.6          8.86   10215.  -0.35\n4 2017-11-22      29.3        5.50         8.50   10358.  -0.38\n5 2017-12-22      29.6        5.59         8.26   10211.  -0.37\n6 2018-01-22      28.7        6.03         8.42   10411.  -0.48\n\n# Transformación de variables\nCAPM_ESP$r_SAN = c(NA,100*diff(log(CAPM_ESP$P_SANTANDER)))\nCAPM_ESP$r_IBEX = c(NA,100*diff(log(CAPM_ESP$P_IBEX35)))\nCAPM_ESP$r_LT1Y = CAPM_ESP$R_LT1Y/12\nCAPM_ESP$er_SAN = CAPM_ESP$r_SAN - CAPM_ESP$r_LT1Y\nCAPM_ESP$er_IBEX = CAPM_ESP$r_IBEX - CAPM_ESP$r_LT1Y\n# Formato de series temporales\nts_CAPM_ESP &lt;- ts(CAPM_ESP, \n                  start = c(2001,5), \n                  end = c(2018,1), \n                  frequency = 12)\n# Algunas gráficas de las variables básicas del modelo\nts.plot(ts_CAPM_ESP[,\"P_IBEX35\"])\n\n\n\nts.plot(ts_CAPM_ESP[,\"P_SANTANDER\"])\n\n\n\nts.plot(ts_CAPM_ESP[,\"er_SAN\"],ts_CAPM_ESP[,\"er_IBEX\"])\n\n\n\n# Modelo CAPM para las acciones del Banco Santander \nCAPM_SANTANDER  &lt;-  lm(er_SAN ~ er_IBEX, data = ts_CAPM_ESP)\nsummary(CAPM_SANTANDER)\n\n\nCall:\nlm(formula = er_SAN ~ er_IBEX, data = ts_CAPM_ESP)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.114  -3.816   0.342   4.659  32.331 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.1461     0.6464  -0.226    0.821    \ner_IBEX       0.4632     0.1016   4.558 9.03e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.14 on 198 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.09496,   Adjusted R-squared:  0.09039 \nF-statistic: 20.77 on 1 and 198 DF,  p-value: 9.03e-06\n\n# Intervalos de confianza para los parámetros estructurales del modelo\n# Cálculo de forma 'manual'\nalpha &lt;- 0.05\ndf &lt;- df.residual(CAPM_SANTANDER) # grados de libertad\nt_c &lt;- qt(1-alpha/2, df)\nb1 &lt;- coef(CAPM_SANTANDER)[[1]] # estimación del parámetro beta1\nb1\n\n[1] -0.1461435\n\nseb1 &lt;- sqrt(vcov(CAPM_SANTANDER)[1,1]) # eest. desviación típica beta1\nseb1\n\n[1] 0.6463839\n\ninf_b1 &lt;- b1-t_c*seb1 # cota inferior\nsup_b1 &lt;- b1+t_c*seb1 # cota superior\ninf_b1 ; sup_b1\n\n[1] -1.420824\n\n\n[1] 1.128537\n\nb2 &lt;- coef(CAPM_SANTANDER)[[2]] # estimación del parámetro beta2\nb2\n\n[1] 0.4632261\n\nseb2 &lt;- sqrt(vcov(CAPM_SANTANDER)[2,2]) # est. desviación típica beta2\nseb2\n\n[1] 0.1016302\n\ninf_b2 &lt;- b2-t_c*seb2 # cota inferior\nsup_b2 &lt;- b2+t_c*seb2 # cota superior\ninf_b2 ; sup_b2\n\n[1] 0.2628095\n\n\n[1] 0.6636427\n\n# Cálculo automático\nconfint(CAPM_SANTANDER)\n\n                 2.5 %    97.5 %\n(Intercept) -1.4208239 1.1285369\ner_IBEX      0.2628095 0.6636427\n\n# Ajuste del modelo (R^2) y ANOVA\ns_CAPM_SANTANDER &lt;- summary(CAPM_SANTANDER)\nprint(s_CAPM_SANTANDER)\n\n\nCall:\nlm(formula = er_SAN ~ er_IBEX, data = ts_CAPM_ESP)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.114  -3.816   0.342   4.659  32.331 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.1461     0.6464  -0.226    0.821    \ner_IBEX       0.4632     0.1016   4.558 9.03e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.14 on 198 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.09496,   Adjusted R-squared:  0.09039 \nF-statistic: 20.77 on 1 and 198 DF,  p-value: 9.03e-06\n\nnames(s_CAPM_SANTANDER)\n\n [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\" \n [5] \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"    \n [9] \"adj.r.squared\" \"fstatistic\"    \"cov.unscaled\"  \"na.action\"    \n\nR2 &lt;- s_CAPM_SANTANDER$r.squared\nR2\n\n[1] 0.0949604\n\nanova(CAPM_SANTANDER)\n\nAnalysis of Variance Table\n\nResponse: er_SAN\n           Df  Sum Sq Mean Sq F value   Pr(&gt;F)    \ner_IBEX     1  1735.4 1735.45  20.775 9.03e-06 ***\nResiduals 198 16540.0   83.54                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Número de obsevaciones\nT &lt;- nobs(CAPM_SANTANDER)\nT\n\n[1] 200\n\n# Número de parámetros\nK &lt;- T-df\nK\n\n[1] 2\n\n# Estadístico F de significación global\nF_0 &lt;- (R2/(K-1))/((1-R2)/(T-K))\nF_0\n\n[1] 20.77496\n\n# Residuos del modelo\nres &lt;- s_CAPM_SANTANDER$residuals\nres &lt;- ts(res, start=c(2001,5), end = c(2018,1), frequency = 12)\nplot(res)\n\n\n\n# Histograma de los residuos y comparación con la distribución normal\nehat &lt;- resid(CAPM_SANTANDER)\nebar &lt;- mean(ehat)\nsdehat &lt;- sd(ehat)\nhist(ehat, col=\"grey\", breaks = 20, freq=FALSE, main=\"\", \n     ylab=\"density\", xlab=\"ehat\")\ncurve(dnorm(x, ebar, sdehat), col=2, add=TRUE, ylab=\"density\", xlab=\"ehat\")\n\n\n\n# Contrastes de hipótesis bilaterales\n#\n# \"Valor alfa\" del activo: beta1=0 versus beta1≠0\n# Estadístico t\nalpha &lt;- 0.05 # nivel de significación\nb1 &lt;- coef(CAPM_SANTANDER)[[1]] # estimación del parámetro beta1\nb1\n\n[1] -0.1461435\n\nseb1 &lt;- sqrt(vcov(CAPM_SANTANDER)[1,1]) # est. desviación típica beta1\nseb1\n\n[1] 0.6463839\n\nc &lt;- 0\ndf &lt;- df.residual(CAPM_SANTANDER) # grados de libertad\nt_0 &lt;- (b1-c)/seb1 # estadístico t\nt_0\n\n[1] -0.2260939\n\n# Método del valor crítico\nt_c &lt;- qt(1-alpha/2, df) # valor crítico\nt_c\n\n[1] 1.972017\n\n# Gráfico de la función de densidad de la distribución t de Student, \n# del valor crítico y del estadístico t_0\ncurve(dt(x, df), -5, 5, ylab=\" \", xlab=\"t\")\nabline(v=c(-t_c, t_c, t_0), col=c(\"red\", \"red\", \"blue\"), lty=c(2,2,3))\nlegend(\"topleft\", legend=c(\"-t_c\", \"t_c\", \"t_0\"), \n       col=c(\"red\", \"red\", \"blue\"), lty=c(2, 2, 3))\n\n\n\n# Método del P-valor\np &lt;- 2*(1-pt(abs(t_0), df))\np\n\n[1] 0.8213616\n\n# Gráfico de la función de densidad de la distribución t y del estadístico t_0\ncurve(dt(x, df), -5, 5, ylab=\" \", xlab=\"t\")\nabline(v=c(t_0), col=c(\"blue\"), lty=c(3))\nlegend(\"topleft\", legend=c(\"t_0\"), col=c(\"blue\"), lty=c(3))\n\n\n\n# Estadístico F\nlibrary(car)\nH_0 &lt;- \"(Intercept) = 0\"\nlinearHypothesis(CAPM_SANTANDER, H_0, test=\"F\")\n\nLinear hypothesis test\n\nHypothesis:\n(Intercept) = 0\n\nModel 1: restricted model\nModel 2: er_SAN ~ er_IBEX\n\n  Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)\n1    199 16544                           \n2    198 16540  1    4.2702 0.0511 0.8214\n\n# Gráfico de la función de densidad de la distribución F de Fisher-Snedecor, \n# del valor crítico y del estadístico F_0\nF_0 &lt;- linearHypothesis(CAPM_SANTANDER, H_0, test=\"F\")[2,5] # estadístico F\nF_0\n\n[1] 0.05111845\n\nF_c &lt;- qf(1-alpha, 1, df) # valor crítico\nF_c\n\n[1] 3.888853\n\ncurve(df(x, 1, df), 0, 5, ylab=\" \", xlab=\"F\")\nabline(v=c(F_0,F_c), col=c(\"blue\",\"red\"), lty=c(2,3))\nlegend(\"topleft\", legend=c(\"F\",\"Fcr\"), col=c(\"blue\",\"red\"), lty=c(2,3))\n\n\n\n# \"Valor beta\" del activo: beta2=1 versus beta2≠1\n# Estadístico t\nalpha &lt;- 0.05 # nivel de significación\nb2 &lt;- coef(CAPM_SANTANDER)[[2]] # estimación del parámetro beta2\nb2\n\n[1] 0.4632261\n\nseb2 &lt;- sqrt(vcov(CAPM_SANTANDER)[2,2]) # eest. desviación típica beta2\nseb2\n\n[1] 0.1016302\n\nc &lt;- 1\ndf &lt;- df.residual(CAPM_SANTANDER) # grados de libertad\nt_0 &lt;- (b2-c)/seb2 # estadístico t\nt_0\n\n[1] -5.281636\n\n# Método del valor crítico\nt_c &lt;- qt(1-alpha/2, df) # valor crítico\nt_c\n\n[1] 1.972017\n\n# Gráfico de la función de densidad de la distribución t, del valor crítico \n# y del estadístico t_0\ncurve(dt(x, df), -6, 6, ylab=\" \", xlab=\"t\")\nabline(v=c(-t_c, t_c, t_0), col=c(\"red\", \"red\", \"blue\"), lty=c(2,2,3))\nlegend(\"topleft\", legend=c(\"-t_c\", \"t_c\", \"t_0\"), \n       col=c(\"red\", \"red\", \"blue\"), lty=c(2, 2, 3))\n\n\n\n# Método del P-valor\np &lt;- 2*(1-pt(abs(t_0), df))\np\n\n[1] 3.357104e-07\n\n# Gráfico de la función de densidad de la distribución t y del estadístico t_0\ncurve(dt(x, df), -6, 6, ylab=\" \", xlab=\"t\")\nabline(v=c(t_0), col=c(\"blue\"), lty=c(3))\nlegend(\"topleft\", legend=c(\"t_0\"), col=c(\"blue\"), lty=c(3))\n\n\n\n# Estadístico F\nH_0 &lt;- \"er_IBEX = 1\"\nlinearHypothesis(CAPM_SANTANDER,H_0,test=\"F\")\n\nLinear hypothesis test\n\nHypothesis:\ner_IBEX = 1\n\nModel 1: restricted model\nModel 2: er_SAN ~ er_IBEX\n\n  Res.Df   RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    199 18870                                  \n2    198 16540  1    2330.3 27.896 3.357e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Contraste conjunto de la hipótesis beta1=0, beta2=1\nH_0 &lt;- c(\"(Intercept) = 0\", \"er_IBEX = 1\")\nlinearHypothesis(CAPM_SANTANDER,H_0,test=\"F\")\n\nLinear hypothesis test\n\nHypothesis:\n(Intercept) = 0\ner_IBEX = 1\n\nModel 1: restricted model\nModel 2: er_SAN ~ er_IBEX\n\n  Res.Df   RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    200 18872                                  \n2    198 16540  2    2331.7 13.956 2.136e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Contrastes unilaterales\n#\n# ¿Activo defensivo o agresivo?: beta2≤1 versus beta2&gt;1\nc &lt;- 1\nalpha &lt;- 0.05\nt_0 &lt;- (b2-c)/seb2\nt_0\n\n[1] -5.281636\n\n# Método del valor crítico\nt_c &lt;- qt(1-alpha, df) # alpha no se divide por 2\nt_c\n\n[1] 1.652586\n\ncurve(dt(x, df), -6, 6, ylab=\" \", xlab=\"t\")\nabline(v=c(t_c, t_0), col=c(\"red\", \"blue\"), lty=c(2, 3))\nlegend(\"topleft\", legend=c(\"t_c\", \"t_0\"), col=c(\"red\", \"blue\"), lty=c(2, 3))\n\n\n\n# Método del P-valor\np &lt;- 1-pt(t_0, df)\np\n\n[1] 0.9999998\n\n# ¿Activo ultra-agresivo?: beta2≥2 versus beta2&lt;2\nc &lt;- 2\nalpha &lt;- 0.05\nt_0 &lt;- (b2-c)/seb2\nt_0\n\n[1] -15.12123\n\n# Método del valor crítico\nt_c &lt;- qt(alpha, df) # alpha no se divide por 2\nt_c\n\n[1] -1.652586\n\ncurve(dt(x, df), -20, 20, ylab=\" \", xlab=\"t\")\nabline(v=c(t_c, t_0), col=c(\"red\", \"blue\"), lty=c(2, 3))\nlegend(\"topleft\", legend=c(\"t_c\", \"t_0\"), col=c(\"red\", \"blue\"), lty=c(2, 3))\n\n\n\n# Método del P-valor\np &lt;- pt(t_0, df)\np\n\n[1] 3.786304e-35\n\n# NOTA:\n# Distribuciones de probabilidad en R -&gt;\n# https://rstudio.github.io/r-manuals/r-intro/Probability-distributions.html"
  },
  {
    "objectID": "p2c2-app1.html#código-python",
    "href": "p2c2-app1.html#código-python",
    "title": "Aplicación 2.1 (Estimación MCO y contrastes de hipótesis): Modelo CAPM para las acciones del Banco Santander",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n# Librería SciPy (stats): https://docs.scipy.org/doc/scipy/tutorial/stats.html\nimport scipy as sp \n# Lectura de datos\nCAPM_ESP = pd.read_csv('data/CAPM_ESP.csv', delimiter=';', \nparse_dates=['date'], index_col='date')\nCAPM_ESP.head()\n\n            P_INDITEX  P_SANTANDER  P_TELEFONICA  P_IBEX35  R_LT1Y\ndate                                                              \n2001-05-22      2.940       6.5528       14.1485    9542.7    4.54\n2001-06-22      3.746       6.2643       11.4884    9601.8    4.25\n2001-07-22      3.610       5.7639       10.4938    8787.6    4.12\n2001-08-22      3.860       5.8110        9.8076    8564.7    4.09\n2001-09-22      3.060       4.0801        8.6741    8117.3    3.84\n\nCAPM_ESP.tail()\n\n            P_INDITEX  P_SANTANDER  P_TELEFONICA  P_IBEX35  R_LT1Y\ndate                                                              \n2017-09-22     31.905       5.6989         9.047   10179.8   -0.37\n2017-10-22     30.990       5.6000         8.864   10214.7   -0.35\n2017-11-22     29.280       5.4970         8.497   10357.8   -0.38\n2017-12-22     29.615       5.5940         8.255   10211.3   -0.37\n2018-01-22     28.720       6.0340         8.417   10411.4   -0.48\n\n# Transformación de variables\ndef LogDiff(x):\n    x_diff = 100*np.log(x/x.shift(1))\n    return x_diff\nCAPM_ESP['r_IBEX'] = LogDiff(CAPM_ESP['P_IBEX35'])\nCAPM_ESP['r_SAN'] = LogDiff(CAPM_ESP['P_SANTANDER'])\nCAPM_ESP['r_LT1Y'] = CAPM_ESP['R_LT1Y']/12\nCAPM_ESP['er_IBEX'] = LogDiff(CAPM_ESP['P_IBEX35']) - CAPM_ESP['R_LT1Y']/12\nCAPM_ESP['er_SAN'] = LogDiff(CAPM_ESP['P_SANTANDER']) - CAPM_ESP['R_LT1Y']/12\n# Gráficas de las variables del modelo\nplt.figure(1)\nplt.plot(CAPM_ESP['er_IBEX'], label='Exceso de rendimiento IBEX35')\nplt.plot(CAPM_ESP['er_SAN'], label='Exceso de rendimiento Banco Santander')\nplt.xlabel('Date')\nplt.ylabel('%')\nplt.title('Variables del modelo CAPM para el Banco Santander')\nplt.legend()\nplt.show()\n\n\n\n# Diagrama de puntos asociado a la regresión\nplt.figure(2)\nplt.scatter(CAPM_ESP['er_IBEX'], CAPM_ESP['er_SAN'])\nplt.xlabel('er_IBEX')\nplt.ylabel('er_SAN')\nplt.title('Exceso de rendimiento de SAN frente a IBEX')\nplt.show()\n\n\n\n# Modelo CAPM para las acciones del Banco Santander\nformula = 'er_SAN ~ er_IBEX'\nCAPM_SANTANDER = smf.ols(formula, CAPM_ESP).fit()\nprint(CAPM_SANTANDER.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 er_SAN   R-squared:                       0.095\nModel:                            OLS   Adj. R-squared:                  0.090\nMethod:                 Least Squares   F-statistic:                     20.77\nDate:                Tue, 14 Nov 2023   Prob (F-statistic):           9.03e-06\nTime:                        20:29:36   Log-Likelihood:                -725.31\nNo. Observations:                 200   AIC:                             1455.\nDf Residuals:                     198   BIC:                             1461.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -0.1461      0.646     -0.226      0.821      -1.421       1.129\ner_IBEX        0.4632      0.102      4.558      0.000       0.263       0.664\n==============================================================================\nOmnibus:                       23.804   Durbin-Watson:                   2.378\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               82.551\nSkew:                          -0.352   Prob(JB):                     1.19e-18\nKurtosis:                       6.068   Cond. No.                         6.36\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Intervalos de confianza para los parámetros estructurales del modelo\n# Automático\nCAPM_SANTANDER.conf_int()\n\n                  0         1\nIntercept -1.420824  1.128537\ner_IBEX    0.262809  0.663643\n\n# Manualmente\nt_c = np.array(sp.stats.t.interval(0.95,CAPM_SANTANDER.df_resid))\nCAPM_SANTANDER.params[0]+CAPM_SANTANDER.bse[0]*t_c\n\narray([-1.42082387,  1.12853695])\n\nCAPM_SANTANDER.params[1]+CAPM_SANTANDER.bse[1]*t_c\n\narray([0.26280949, 0.66364269])\n\n# ANOVA\nsm.stats.anova_lm(CAPM_SANTANDER)\n\n             df        sum_sq      mean_sq          F    PR(&gt;F)\ner_IBEX     1.0   1735.445734  1735.445734  20.774958  0.000009\nResidual  198.0  16540.021306    83.535461        NaN       NaN\n\n# Ajuste del modelo (R^2)\nCAPM_SANTANDER.rsquared\n\n0.09496040403004358\n\n# Estadístico F de significación global\nCAPM_SANTANDER.fvalue, CAPM_SANTANDER.f_pvalue\n\n(20.774958445655425, 9.0300657558589e-06)\n\n# Estadístico F y R^2\nF_0 = (CAPM_SANTANDER.rsquared/(CAPM_SANTANDER.df_model))/((1-CAPM_SANTANDER.rsquared)/(CAPM_SANTANDER.df_resid))\nF_0, 1-sp.stats.f.cdf(F_0, CAPM_SANTANDER.df_model, CAPM_SANTANDER.df_resid)\n\n(20.774958445655436, 9.030065755810668e-06)\n\n# Número de obsevaciones\nCAPM_SANTANDER.nobs\n\n200.0\n\n# Número de parámetros\n1+CAPM_SANTANDER.df_model\n\n2.0\n\n# Errores estimados (residuos) del modelo\nplt.figure(3)\nplt.plot(CAPM_SANTANDER.resid, label='res')\nplt.xlabel('Date')\nplt.title('Residuos del modelo CAPM para el Banco Santander')\nplt.legend()\nplt.show()\n\n\n\n# Histograma de los residuos y comparación con la distribución normal\nebar = np.mean(CAPM_SANTANDER.resid)\nsdehat = np.std(CAPM_SANTANDER.resid)\nplt.figure(4)\nfig, ax = plt.subplots()\nax.hist(CAPM_SANTANDER.resid, bins=20, density=True, \nedgecolor='white', linewidth=1.2)\nx = np.linspace(min(CAPM_SANTANDER.resid), max(CAPM_SANTANDER.resid), 100)\nax.plot(x, sp.stats.norm.pdf(x, ebar, sdehat), color='black', \nlabel = 'Distribución normal')\nplt.title('Residuos del modelo CAPM para el Banco Santander')\nplt.xlabel('Residuos')\nplt.ylabel('Densidad')\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()\n\n\n\n# Contrastes de hipótesis bilaterales\n# beta1=0 versus beta1≠0\n# Estadístico t\nt_stat = (CAPM_SANTANDER.params['Intercept']-0)/CAPM_SANTANDER.bse['Intercept']\nt_stat, 2*sp.stats.t.cdf(t_stat, CAPM_SANTANDER.df_resid)\n\n(-0.22609389919232573, 0.8213616110920402)\n\n# Estadístico F y P-valor\nH_0 = 'Intercept = 0'\nF_0 = CAPM_SANTANDER.f_test(H_0)\nprint(F_0)\n\n&lt;F test: F=0.05111845125198955, p=0.8213616110920228, df_denom=198, df_num=1&gt;\n\n# beta2=1 versus beta2≠1\n# Estadístico t y P-valor\nt_0 = (CAPM_SANTANDER.params['er_IBEX']-1)/CAPM_SANTANDER.bse['er_IBEX']\nt_0, 2*(1-sp.stats.t.cdf(abs(t_0), CAPM_SANTANDER.df_resid))\n\n(-5.281635967748109, 3.3571043878133366e-07)\n\n# Estadístico F y P-valor\nH_0 = 'er_IBEX = 1'\nF_0 = CAPM_SANTANDER.f_test(H_0)\nprint(F_0)\n\n&lt;F test: F=27.895678495810504, p=3.357104388598483e-07, df_denom=198, df_num=1&gt;\n\n# Contraste conjunto de la hipótesis beta1=0, beta2=1\n# Estadístico F y P-valor\nH_0 = 'Intercept = 0 , er_IBEX = 1'\nF_0 = CAPM_SANTANDER.f_test(H_0)\nprint(F_0)\n\n&lt;F test: F=13.956448346309095, p=2.1364485558886642e-06, df_denom=198, df_num=2&gt;\n\n# Contrastes unilaterales\n# beta2≤1 versus beta2&gt;1\n# Estadístico t y P-valor\nt_0 = (CAPM_SANTANDER.params['er_IBEX']-1)/CAPM_SANTANDER.bse['er_IBEX']\nt_0, 1-sp.stats.t.cdf(t_0, CAPM_SANTANDER.df_resid)\n\n(-5.281635967748109, 0.9999998321447806)\n\n# beta2≥2 versus beta2&lt;2\n# Estadístico t y P-valor\nt_0 = (CAPM_SANTANDER.params['er_IBEX']-2)/CAPM_SANTANDER.bse['er_IBEX']\nt_0, sp.stats.t.cdf(t_0, CAPM_SANTANDER.df_resid)\n\n(-15.121227447088602, 3.786304271337718e-35)\n\n# NOTA:\n# Distribuciones de probabilidad en Python (librería SciPy) -&gt;\n# https://docs.scipy.org/doc/scipy/reference/stats.html"
  },
  {
    "objectID": "p2c2-app2.html#código-r",
    "href": "p2c2-app2.html#código-r",
    "title": "Aplicación 2.2 (Predicción con el modelo de regresión lineal): Curva de Engel para el gasto en alimentos",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\n# Lectura de datos\nENGEL_ALIM &lt;- read_delim(\"data/ENGEL_ALIM_USA.csv\", \";\", \n                         escape_double = FALSE, trim_ws = TRUE)\n# Diagrama de puntos (scatter plot) de las variables RENTA y GALIM\nggplot(ENGEL_ALIM, aes(x = RENTA, y = GALIM)) + \n  geom_point() + \n  scale_x_continuous(limits = c(350, 5000), expand = c(0, 0)) + \n  theme_bw() + \n  labs(x = \"Renta\", y = \"Gasto en alimentos\")\n\n\n\nggplot(ENGEL_ALIM, aes(x = RENTA, y = GALIM)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  scale_x_continuous(limits = c(350, 5000), expand = c(0, 0)) + \n  theme_bw() + \n  labs(x = \"Renta\", y = \"Gasto en alimentos\")\n\n\n\n# Estimación de una curva de Engel lineal por MCO\nCURVA_ENGEL_LINEAL &lt;- lm(GALIM ~ RENTA, data = ENGEL_ALIM)\nsummary(CURVA_ENGEL_LINEAL)\n\n\nCall:\nlm(formula = GALIM ~ RENTA, data = ENGEL_ALIM)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-725.70  -60.24   -4.32   53.41  515.77 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 147.47539   15.95708   9.242   &lt;2e-16 ***\nRENTA         0.48518    0.01437  33.772   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 114.1 on 233 degrees of freedom\nMultiple R-squared:  0.8304,    Adjusted R-squared:  0.8296 \nF-statistic:  1141 on 1 and 233 DF,  p-value: &lt; 2.2e-16\n\n# Predicción\n# Vector que contiene los nuevos valores de las variables explicativas\nnew_RENTA &lt;- data.frame(RENTA=c(400, 2000, 4500))\nnew_RENTA\n\n  RENTA\n1   400\n2  2000\n3  4500\n\n# Predicción puntual\npred_GALIM &lt;- predict(CURVA_ENGEL_LINEAL, new_RENTA)\nnames(pred_GALIM) &lt;-c(\"Renta = 400\", \"2000\", \"4500\")\npred_GALIM\n\nRenta = 400        2000        4500 \n   341.5468   1117.8322   2330.7783 \n\n# Predicción del valor esperado con intervalo de confianza\npred_GALIM_IC &lt;- predict(CURVA_ENGEL_LINEAL, new_RENTA, interval=\"confidence\", level=0.95)\npred_GALIM_IC\n\n        fit       lwr       upr\n1  341.5468  319.4814  363.6122\n2 1117.8322 1085.5127 1150.1518\n3 2330.7783 2230.1418 2431.4148"
  },
  {
    "objectID": "p2c2-app2.html#código-python",
    "href": "p2c2-app2.html#código-python",
    "title": "Aplicación 2.2 (Predicción con el modelo de regresión lineal): Curva de Engel para el gasto en alimentos",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\n# Lectura de datos\nENGEL_ALIM = pd.read_csv('data/ENGEL_ALIM_USA.csv', delimiter=';')\n# Estimación del modelo\nCURVA_ENGEL_LINEAL = smf.ols('GALIM ~ RENTA', data=ENGEL_ALIM)\nresults=CURVA_ENGEL_LINEAL.fit()\nprint(results.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                  GALIM   R-squared:                       0.830\nModel:                            OLS   Adj. R-squared:                  0.830\nMethod:                 Least Squares   F-statistic:                     1141.\nDate:                Tue, 07 Nov 2023   Prob (F-statistic):           9.92e-92\nTime:                        07:02:13   Log-Likelihood:                -1445.7\nNo. Observations:                 235   AIC:                             2895.\nDf Residuals:                     233   BIC:                             2902.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept    147.4754     15.957      9.242      0.000     116.037     178.914\nRENTA          0.4852      0.014     33.772      0.000       0.457       0.513\n==============================================================================\nOmnibus:                       68.110   Durbin-Watson:                   1.411\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              927.676\nSkew:                          -0.670   Prob(JB):                    3.61e-202\nKurtosis:                      12.641   Cond. No.                     2.38e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 2.38e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n# Predicción\n# Generar un vector que contiene los nuevos valores de las variables explicativas\nnew_RENTA = pd.DataFrame({'RENTA': [400, 2000, 4500]}, index=['newRENTA1', 'newRENTA2', 'newRENTA3'])\nprint(f'new_RENTA: \\n{new_RENTA}\\n')\n\nnew_RENTA: \n           RENTA\nnewRENTA1    400\nnewRENTA2   2000\nnewRENTA3   4500\n\n# Predicción puntual\npred_GALIM = results.predict(new_RENTA)\nprint(f'pred_GALIM: \\n{pred_GALIM}\\n')\n\npred_GALIM: \nnewRENTA1     341.546758\nnewRENTA2    1117.832236\nnewRENTA3    2330.778295\ndtype: float64\n\n# Predicción con intervalo de confianza\npred_GALIM_IC = results.get_prediction(new_RENTA).summary_frame(alpha=0.05)\nprint(f'pred_GALIM_IC: \\n{pred_GALIM_IC}\\n')\n\npred_GALIM_IC: \n          mean    mean_se  ...  obs_ci_lower  obs_ci_upper\n0   341.546758  11.199590  ...    115.651327    567.442189\n1  1117.832236  16.404210  ...    890.705804   1344.958668\n2  2330.778295  51.079406  ...   2084.466352   2577.090238\n\n[3 rows x 6 columns]"
  },
  {
    "objectID": "p2c2-app3.html#código-r",
    "href": "p2c2-app3.html#código-r",
    "title": "Aplicación 2.3 (Modelo de regresión lineal con forma funcional polinómica): Curva de costes en el sector textil",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\n# Lectura de datos\nCOST_TEXT &lt;- read_csv(\"data/COST_TEXT.csv\")\n# Gráfica de los valores observados\nggplot(COST_TEXT, aes(x = Q, y = COST)) + geom_point(size = 2, color = \"blue\")\n\n\n\n# Estimación del modelo\nmodel &lt;- lm(formula = COST ~ Q + I(Q^2), data = COST_TEXT)\n# fórmula alternativa: formula = COST ~ poly(Q, 2, raw = TRUE)\nsummary(model)\n\n\nCall:\nlm(formula = COST ~ Q + I(Q^2), data = COST_TEXT)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-59.710 -20.401   3.813  18.627  84.682 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  185.154     26.461   6.997 2.47e-07 ***\nQ             -8.461     11.603  -0.729    0.473    \nI(Q^2)         5.853      1.112   5.264 1.88e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 37.74 on 25 degrees of freedom\nMultiple R-squared:  0.9282,    Adjusted R-squared:  0.9224 \nF-statistic: 161.6 on 2 and 25 DF,  p-value: 5.043e-15\n\n# Función de costes estimada\nggplot(data = COST_TEXT, aes(x = Q, y = COST)) +\n  geom_line(aes(y = predict(model, \n                            newdata = data.frame(Q = Q, Q2 = Q^2))), \n            color = \"blue\") +\n  geom_point(size = 2, color = \"blue\") +\n  labs(title = \"Función de costes estimada\", \n       x = \"Cantidad producida\", \n       y = \"Coste total\") +\n  theme_minimal()"
  },
  {
    "objectID": "p2c2-app3.html#código-python",
    "href": "p2c2-app3.html#código-python",
    "title": "Aplicación 2.3 (Modelo de regresión lineal con forma funcional polinómica): Curva de costes en el sector textil",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\n# Lectura de datos\nCOST_TEXT = pd.read_csv('data/COST_TEXT.csv')\n# Gráfica de los valores observados\nplt.scatter(COST_TEXT['Q'], COST_TEXT['COST'])\nplt.show()\n\n\n\n# Estimación del modelo\nmodel = smf.ols(formula = 'COST ~ Q + I(Q**2)', data = COST_TEXT).fit()\n# fórmula alternativa: formula = COST ~ Q + np.power(Q, 2)\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   COST   R-squared:                       0.928\nModel:                            OLS   Adj. R-squared:                  0.922\nMethod:                 Least Squares   F-statistic:                     161.6\nDate:                Tue, 14 Nov 2023   Prob (F-statistic):           5.04e-15\nTime:                        20:43:05   Log-Likelihood:                -139.80\nNo. Observations:                  28   AIC:                             285.6\nDf Residuals:                      25   BIC:                             289.6\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept    185.1539     26.461      6.997      0.000     130.656     239.652\nQ             -8.4608     11.603     -0.729      0.473     -32.358      15.436\nI(Q ** 2)      5.8535      1.112      5.264      0.000       3.563       8.143\n==============================================================================\nOmnibus:                        0.128   Durbin-Watson:                   1.805\nProb(Omnibus):                  0.938   Jarque-Bera (JB):                0.266\nSkew:                           0.138   Prob(JB):                        0.875\nKurtosis:                       2.610   Cond. No.                         150.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Función de costes estimada\nQ_min = COST_TEXT['Q'].min()\nQ_max = COST_TEXT['Q'].max()\nQ_values = np.linspace(Q_min, Q_max, num=100)\nC_values=model.params[0] + model.params[1]*Q_values + model.params[2]*Q_values**2\nplt.plot(Q_values, C_values)\nplt.scatter(COST_TEXT['Q'], COST_TEXT['COST'])\nplt.xlabel('Cantidad producida')\nplt.ylabel('Coste total')\nplt.show()"
  },
  {
    "objectID": "p2c2-app4.html#código-r",
    "href": "p2c2-app4.html#código-r",
    "title": "Aplicación 2.4 (Modelo de regresión lineal con términos de interacción): Efectos diferenciados de la publicidad sobre las ventas",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(plotly)\n# Lectura de datos\nPUB_VENTAS &lt;- read_csv(\"data/PUB_VENTAS.csv\")\n# Estimación del modelo lineal\nmodel1 &lt;- lm(data = PUB_VENTAS, formula = VENTAS ~ TV + RADIO)\nsummary(model1)\n\n\nCall:\nlm(formula = VENTAS ~ TV + RADIO, data = PUB_VENTAS)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7977 -0.8752  0.2422  1.1708  2.8328 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***\nTV           0.04575    0.00139  32.909   &lt;2e-16 ***\nRADIO        0.18799    0.00804  23.382   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.681 on 197 degrees of freedom\nMultiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 \nF-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16\n\n# Gráfica del ajuste\nplot_ly(data = PUB_VENTAS) %&gt;%\n    add_trace(x = ~TV, y = ~RADIO, z = ~VENTAS, \n              mode = \"markers\", type = \"scatter3d\",\n              marker = list(size = 5, color = \"blue\", symbol = 104), \n              name = \"Observaciones\") %&gt;% \n    add_trace(z = model1$fitted.values, x = ~TV, y = ~RADIO, \n              type = \"mesh3d\", \n              name = \"Valores ajustados\") %&gt;%\n    layout(scene = list(xaxis = list(title = 'TV'), \n                        yaxis = list(title = 'RADIO'),\n                        camera = list(eye = list(x = -1.5, y = 1.5, z = 0)),\n                        zaxis = list(title = 'VENTAS'), aspectmode='cube'))\n\n\n\n\n# Estimación del modelo con interacción\nmodel2 &lt;- lm(data = PUB_VENTAS, formula = VENTAS ~ TV * RADIO)\nsummary(model2)\n\n\nCall:\nlm(formula = VENTAS ~ TV * RADIO, data = PUB_VENTAS)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.3366 -0.4028  0.1831  0.5948  1.5246 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 6.750e+00  2.479e-01  27.233   &lt;2e-16 ***\nTV          1.910e-02  1.504e-03  12.699   &lt;2e-16 ***\nRADIO       2.886e-02  8.905e-03   3.241   0.0014 ** \nTV:RADIO    1.086e-03  5.242e-05  20.727   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9435 on 196 degrees of freedom\nMultiple R-squared:  0.9678,    Adjusted R-squared:  0.9673 \nF-statistic:  1963 on 3 and 196 DF,  p-value: &lt; 2.2e-16\n\n# Gráfica del ajuste\nplot_ly(data = PUB_VENTAS) %&gt;%\n    add_trace(x = ~TV, y = ~RADIO, z = ~VENTAS, \n              mode = \"markers\", type = \"scatter3d\",\n              marker = list(size = 5, color = \"blue\", symbol = 104), \n              name = \"Observaciones\") %&gt;% \n    add_trace(z = model2$fitted.values, x = ~TV, y = ~RADIO, type = \"mesh3d\", \n              name = \"Valores ajustados\") %&gt;%\n    layout(scene = list(xaxis = list(title = 'TV'), \n                        yaxis = list(title = 'RADIO'),\n                        camera = list(eye = list(x = -1.5, y = 1.5, z = 0)),\n                        zaxis = list(title = 'VENTAS'), aspectmode='cube'))"
  },
  {
    "objectID": "p2c2-app4.html#código-python",
    "href": "p2c2-app4.html#código-python",
    "title": "Aplicación 2.4 (Modelo de regresión lineal con términos de interacción): Efectos diferenciados de la publicidad sobre las ventas",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\n\n# Lectura de datos\nPUB_VENTAS = pd.read_csv('data/PUB_VENTAS.csv')\n# Estimación del modelo lineal\nmodel1 = smf.ols('VENTAS ~ TV + RADIO', data=PUB_VENTAS)\nprint(model1.fit().summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 VENTAS   R-squared:                       0.897\nModel:                            OLS   Adj. R-squared:                  0.896\nMethod:                 Least Squares   F-statistic:                     859.6\nDate:                Tue, 14 Nov 2023   Prob (F-statistic):           4.83e-98\nTime:                        20:49:18   Log-Likelihood:                -386.20\nNo. Observations:                 200   AIC:                             778.4\nDf Residuals:                     197   BIC:                             788.3\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      2.9211      0.294      9.919      0.000       2.340       3.502\nTV             0.0458      0.001     32.909      0.000       0.043       0.048\nRADIO          0.1880      0.008     23.382      0.000       0.172       0.204\n==============================================================================\nOmnibus:                       60.022   Durbin-Watson:                   2.081\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              148.679\nSkew:                          -1.323   Prob(JB):                     5.19e-33\nKurtosis:                       6.292   Cond. No.                         425.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Estimación del modelo con interacción\nmodel2 = smf.ols('VENTAS ~ TV * RADIO', data=PUB_VENTAS)\nprint(model2.fit().summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 VENTAS   R-squared:                       0.968\nModel:                            OLS   Adj. R-squared:                  0.967\nMethod:                 Least Squares   F-statistic:                     1963.\nDate:                Tue, 14 Nov 2023   Prob (F-statistic):          6.68e-146\nTime:                        20:49:18   Log-Likelihood:                -270.14\nNo. Observations:                 200   AIC:                             548.3\nDf Residuals:                     196   BIC:                             561.5\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      6.7502      0.248     27.233      0.000       6.261       7.239\nTV             0.0191      0.002     12.699      0.000       0.016       0.022\nRADIO          0.0289      0.009      3.241      0.001       0.011       0.046\nTV:RADIO       0.0011   5.24e-05     20.727      0.000       0.001       0.001\n==============================================================================\nOmnibus:                      128.132   Durbin-Watson:                   2.224\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1183.719\nSkew:                          -2.323   Prob(JB):                    9.09e-258\nKurtosis:                      13.975   Cond. No.                     1.80e+04\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.8e+04. This might indicate that there are\nstrong multicollinearity or other numerical problems."
  },
  {
    "objectID": "p2c2-app5.html#código-r",
    "href": "p2c2-app5.html#código-r",
    "title": "Aplicación 2.5 (Modelo de regresión lineal con variables cualitativas): Brecha salarial entre hombres y mujeres en Estados Unidos",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(huxtable)\n#\n# INFORMACIÓN SOBRE EL CONJUNTO ORIGINAL DE DATOS Y SOBRE\n# LA OBTENCIÓN DE LA SUBMUESTRA USADA EN LA APLICACIÓN\n#\n#  USA 2014 CENSUS DATA: MORG14_USA.csv\n# - Cross-sectional data: year 2014\n# - Observations are individuals of age 15 to 85 \n#   (representative sample of this sub-pop.)\n# - ID variables:\n#   HHID:   houeshold id\n#   HRHHID2: 2nd part of houeshold id (some original hhid-s are split)\n#   LINENO:  person (\"line\") number in household\n#   AGE:    age\n#   SEX:    gender\n#   EARNWKE: weakly earnings\n#   UHOURSE: usual work hours\n#   OCC2012:    occupational code (census 2010 classification)\n#   GRADE92:    highest educational grade completed\n# - Labels of the variables are downlodable from here:\n#   &lt;http://data.nber.org/morg/docs/cpsx.pdf&gt;\n# - Occupational classification (census 2010) codes:\n#   &lt;https://www.bls.gov/cps/cenocc2010.htm&gt;\n#\n# FILTRADO PREVIO DE OBSERVACIONES: \n#\n# Edad entre 24 to 64 años; \n# Haber trabajado más de 20 horas semanales; \n# Ingresos semanales positivos; \n# Empleados con estudios universitarios (grade92&gt;44)\n#\n# Operación sobre el fichero original [cps = read_csv(\"MORG14_USA.csv\")]:\n# cps &lt;- cps %&gt;% \n# filter(age&gt;=24 & age&lt;=64 & uhours&gt;=20 & earnwke&gt;0 & grade92&gt;=44)\n#\n# Lectura de datos\ncps &lt;- read_csv(\"data/CPS2014_USA.csv\")\n# Transformación de variables\ncps &lt;- cps %&gt;% mutate(female=sex==2, w=earnwke/uhours) %&gt;% filter(w&gt;=1)\n# Distribución de los salarios\ncps %&gt;% dplyr::select(earnwke,uhours,w) %&gt;% summary()\n\n    earnwke         uhours            w          \n Min.   :  38   Min.   :20.00   Min.   :  1.026  \n 1st Qu.: 923   1st Qu.:40.00   1st Qu.: 21.634  \n Median :1346   Median :40.00   Median : 31.250  \n Mean   :1483   Mean   :42.97   Mean   : 34.565  \n 3rd Qu.:1923   3rd Qu.:47.00   3rd Qu.: 45.673  \n Max.   :2885   Max.   :99.00   Max.   :144.231  \n\n# Histograma diferenciado por género\nearnings_hist&lt;- ggplot(data = cps, \n                       aes (x = w, y = 2*(..count..)/sum(..count..))) +\n  geom_histogram(binwidth = 4,  size = 0.25, alpha = 0.8,  \n                 boundary=0, closed='left',  show.legend=F, na.rm =TRUE) +\n  labs(x = \"Hourly earnings (dollars)\", y = \"Percent\") +\n  facet_wrap(~ifelse(female, \"Female\", \"Male\"))+\n  labs(x = \"Hourly earnings (dollars)\",y = \"Percent\")+\n  scale_x_continuous(limits = c(0,100) , breaks = seq(1, 100, by = 10),) +\n  scale_y_continuous(limits=c(0, 0.20), breaks = seq(0, 0.20, by = 0.05),\n                     labels = scales::percent_format(accuracy = 5L))\nearnings_hist\n\n\n\n# Densidad estimada diferenciada por género\nggplot(data = cps) + geom_density(aes(x = w, fill = female), alpha=0.3)\n\n\n\n# SALARIOS, EDAD Y GÉNERO\nreg0 &lt;- lm(log(w) ~ female, data=cps)\nreg1 &lt;- lm(log(w) ~ female + age, data=cps)\nreg2 &lt;- lm(log(w) ~ female*age, data=cps) # Interacción entre género y edad\nreg21 &lt;- lm(log(w) ~ age, data=cps %&gt;% filter(female==1)) # Ec. mujeres\nreg22 &lt;- lm(log(w) ~ age, data=cps %&gt;% filter(female==0)) # Ec. hombres\nhuxreg(reg0, reg1, reg2, reg21, reg22, \n       statistics = c(N = \"nobs\", R2 = \"r.squared\"))\n\n\n\n\n\n(1)\n(2)\n(3)\n(4)\n(5)\n\n\n(Intercept)\n3.522 ***\n3.196 ***\n3.117 ***\n3.081 ***\n3.117 ***\n\n\n\n(0.006)   \n(0.017)   \n(0.023)   \n(0.021)   \n(0.023)   \n\n\nfemaleTRUE\n-0.193 ***\n-0.182 ***\n-0.036    \n        \n        \n\n\n\n(0.008)   \n(0.008)   \n(0.032)   \n        \n        \n\n\nage\n        \n0.007 ***\n0.009 ***\n0.006 ***\n0.009 ***\n\n\n\n        \n(0.000)   \n(0.001)   \n(0.000)   \n(0.001)   \n\n\nfemaleTRUE:age\n        \n        \n-0.003 ***\n        \n        \n\n\n\n        \n        \n(0.001)   \n        \n        \n\n\nN\n18220        \n18220        \n18220        \n9672        \n8548        \n\n\nR2\n0.034    \n0.057    \n0.058    \n0.015    \n0.036    \n\n\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.\n\n\n\n\n\n\n# No linealidad en la edad\ncps &lt;- cps %&gt;% mutate(age2=age**2, age3=age**3, age4=age**4)\nreg3 &lt;- lm(log(w) ~ female + age + age2 + age3 + age4, data=cps)\nhuxreg(reg1, reg3, statistics = c(N = \"nobs\", R2 = \"r.squared\"))\n\n\n\n\n\n(1)\n(2)\n\n\n(Intercept)\n3.196 ***\n-3.131 ** \n\n\n\n(0.017)   \n(1.059)   \n\n\nfemaleTRUE\n-0.182 ***\n-0.180 ***\n\n\n\n(0.008)   \n(0.007)   \n\n\nage\n0.007 ***\n0.525 ***\n\n\n\n(0.000)   \n(0.103)   \n\n\nage2\n        \n-0.016 ***\n\n\n\n        \n(0.004)   \n\n\nage3\n        \n0.000 ***\n\n\n\n        \n(0.000)   \n\n\nage4\n        \n-0.000 ** \n\n\n\n        \n(0.000)   \n\n\nN\n18220        \n18220        \n\n\nR2\n0.057    \n0.079    \n\n\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.\n\n\n\n\n\n\n# SALARIOS, SEXO, EDAD Y NIVEL DE EDUCACIÓN\ncps &lt;- cps %&gt;% mutate(ed_MA=as.numeric(grade92==44), \n                      ed_PSD = as.numeric(grade92==45), \n                      ed_DD = as.numeric(grade92==46))\nreg4 &lt;- lm(log(w) ~ female + age + age2 + age3 + age4 + ed_PSD + ed_DD, \n           data=cps)\nhuxreg(reg3, reg4, statistics = c(N = \"nobs\", R2 = \"r.squared\"))\n\n\n\n\n\n(1)\n(2)\n\n\n(Intercept)\n-3.131 ** \n-2.789 ** \n\n\n\n(1.059)   \n(1.052)   \n\n\nfemaleTRUE\n-0.180 ***\n-0.167 ***\n\n\n\n(0.007)   \n(0.007)   \n\n\nage\n0.525 ***\n0.491 ***\n\n\n\n(0.103)   \n(0.102)   \n\n\nage2\n-0.016 ***\n-0.014 ***\n\n\n\n(0.004)   \n(0.004)   \n\n\nage3\n0.000 ***\n0.000 ***\n\n\n\n(0.000)   \n(0.000)   \n\n\nage4\n-0.000 ** \n-0.000 ** \n\n\n\n(0.000)   \n(0.000)   \n\n\ned_PSD\n        \n0.142 ***\n\n\n\n        \n(0.012)   \n\n\ned_DD\n        \n0.129 ***\n\n\n\n        \n(0.011)   \n\n\nN\n18220        \n18220        \n\n\nR2\n0.079    \n0.091    \n\n\n*** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.\n\n\n\n\n\n\n# SALARIOS, SEXO, EDAD, EDUCACIÓN Y OTROS FACTORES (CUALITATIVOS) ADICIONALES\n# Construcción de factores condicionantes\n# Factores demográficos (predeterminados)\ncps &lt;- cps %&gt;% mutate(white=as.numeric(race==1),\n                      afram = as.numeric(race==2),\n                      asian = as.numeric(race==4),\n                      hisp = !is.na(ethnic),\n                      othernonw = as.numeric(white==0 & afram==0 \n                                             & asian==0 & hisp==0),\n                      nonUSborn = as.numeric(\n                        prcitshp==\"Foreign Born, US Cit By Naturalization\" | \n                          prcitshp==\"Foreign Born, Not a US Citizen\") \n)\n# Factores demográficos (potencialmente endógenos)\ncps &lt;- cps %&gt;% mutate(married = as.numeric(marital==1 | marital==2),\n                      divorced = as.numeric(marital==3 | marital==5 | \n                                              marital==6),\n                      wirowed = as.numeric(marital==4),\n                      nevermar = as.numeric(marital==7),\n                      child0 = as.numeric(chldpres==0),\n                      child1 = as.numeric(chldpres==1),\n                      child2 = as.numeric(chldpres==2),\n                      child3 = as.numeric(chldpres==3),\n                      child4pl = as.numeric(chldpres&gt;=4))\n# Factores laborales\ncps &lt;- cps %&gt;% mutate(fedgov = as.numeric(class==\"Government - Federal\"),\n                      stagov = as.numeric(class==\"Government - State\"),\n                      locgov = as.numeric(class==\"Government - Local\"),\n                      nonprof = as.numeric(class==\"Private, Nonprofit\"),\n                      ind2dig = as.integer(as.numeric(as.factor(ind02))/100),\n                      occ2dig = as.integer(occ2012/100),\n                      union = as.numeric(unionmme==\"Yes\" | unioncov==\"Yes\"))\n# Regresión con factores\nreg5 &lt;- lm(log(w) ~ female \n           + age + age2 + age3 + age4 \n           + ed_PSD + ed_DD \n           + afram + hisp + asian + othernonw + nonUSborn \n           + married + divorced + wirowed + child1 + child2 + child3 +child4pl\n           + uhours + fedgov + stagov + locgov + nonprof + union \n           + as.factor(stfips) + as.factor(ind2dig) + as.factor(occ2dig), \n           data=cps)\nsummary(reg5)\n\n\nCall:\nlm(formula = log(w) ~ female + age + age2 + age3 + age4 + ed_PSD + \n    ed_DD + afram + hisp + asian + othernonw + nonUSborn + married + \n    divorced + wirowed + child1 + child2 + child3 + child4pl + \n    uhours + fedgov + stagov + locgov + nonprof + union + as.factor(stfips) + \n    as.factor(ind2dig) + as.factor(occ2dig), data = cps)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6504 -0.2513  0.0367  0.2953  1.5951 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           1.540e-01  9.778e-01   0.157 0.874859    \nfemaleTRUE           -1.117e-01  7.428e-03 -15.034  &lt; 2e-16 ***\nage                   2.666e-01  9.527e-02   2.798 0.005141 ** \nage2                 -7.109e-03  3.390e-03  -2.097 0.036017 *  \nage3                  8.662e-05  5.222e-05   1.659 0.097183 .  \nage4                 -4.078e-07  2.942e-07  -1.386 0.165817    \ned_PSD                7.534e-02  1.333e-02   5.653 1.60e-08 ***\ned_DD                 1.139e-01  1.166e-02   9.764  &lt; 2e-16 ***\nafram                -8.387e-02  1.337e-02  -6.272 3.65e-10 ***\nhispTRUE             -2.341e-02  1.546e-02  -1.514 0.129996    \nasian                 2.119e-02  1.411e-02   1.502 0.133025    \nothernonw             2.047e-02  2.613e-02   0.783 0.433408    \nnonUSborn            -5.023e-02  1.161e-02  -4.328 1.51e-05 ***\nmarried               6.139e-02  1.049e-02   5.852 4.95e-09 ***\ndivorced              5.025e-02  1.359e-02   3.697 0.000219 ***\nwirowed               6.760e-02  3.606e-02   1.875 0.060876 .  \nchild1                5.796e-02  1.665e-02   3.480 0.000502 ***\nchild2                1.093e-02  2.036e-02   0.537 0.591310    \nchild3                2.589e-02  1.243e-02   2.083 0.037250 *  \nchild4pl              2.769e-02  9.711e-03   2.851 0.004359 ** \nuhours               -4.568e-03  3.873e-04 -11.795  &lt; 2e-16 ***\nfedgov                8.580e-02  1.535e-02   5.588 2.33e-08 ***\nstagov               -4.648e-02  1.272e-02  -3.654 0.000259 ***\nlocgov               -3.900e-02  1.312e-02  -2.974 0.002946 ** \nnonprof              -7.461e-02  1.075e-02  -6.939 4.08e-12 ***\nunion                 6.531e-02  1.067e-02   6.122 9.41e-10 ***\nas.factor(stfips)AL  -2.471e-01  4.712e-02  -5.245 1.58e-07 ***\nas.factor(stfips)AR  -2.096e-01  5.323e-02  -3.939 8.22e-05 ***\nas.factor(stfips)AZ  -1.321e-01  4.641e-02  -2.846 0.004436 ** \nas.factor(stfips)CA   3.500e-02  3.499e-02   1.000 0.317191    \nas.factor(stfips)CO  -9.456e-02  3.903e-02  -2.423 0.015409 *  \nas.factor(stfips)CT   2.059e-02  3.853e-02   0.534 0.593052    \nas.factor(stfips)DC   1.263e-01  3.664e-02   3.447 0.000569 ***\nas.factor(stfips)DE  -8.644e-02  4.360e-02  -1.983 0.047434 *  \nas.factor(stfips)FL  -1.453e-01  3.806e-02  -3.817 0.000136 ***\nas.factor(stfips)GA  -1.081e-01  4.055e-02  -2.667 0.007665 ** \nas.factor(stfips)HI  -1.569e-01  4.494e-02  -3.492 0.000481 ***\nas.factor(stfips)IA  -1.883e-01  4.391e-02  -4.288 1.81e-05 ***\nas.factor(stfips)ID  -1.807e-01  4.934e-02  -3.662 0.000251 ***\nas.factor(stfips)IL  -8.466e-02  3.758e-02  -2.253 0.024275 *  \nas.factor(stfips)IN  -1.404e-01  4.594e-02  -3.057 0.002241 ** \nas.factor(stfips)KS  -1.695e-01  4.228e-02  -4.010 6.10e-05 ***\nas.factor(stfips)KY  -2.156e-01  4.476e-02  -4.817 1.47e-06 ***\nas.factor(stfips)LA  -1.571e-01  4.781e-02  -3.285 0.001022 ** \nas.factor(stfips)MA  -5.402e-03  3.909e-02  -0.138 0.890090    \nas.factor(stfips)MD  -3.931e-02  3.767e-02  -1.044 0.296715    \nas.factor(stfips)ME  -1.688e-01  4.346e-02  -3.885 0.000103 ***\nas.factor(stfips)MI  -6.645e-02  4.041e-02  -1.644 0.100111    \nas.factor(stfips)MN  -5.169e-02  3.949e-02  -1.309 0.190542    \nas.factor(stfips)MO  -1.155e-01  4.354e-02  -2.653 0.007979 ** \nas.factor(stfips)MS  -1.933e-01  4.925e-02  -3.925 8.69e-05 ***\nas.factor(stfips)MT  -2.543e-01  4.967e-02  -5.121 3.07e-07 ***\nas.factor(stfips)NC  -1.602e-01  4.171e-02  -3.841 0.000123 ***\nas.factor(stfips)ND  -1.706e-01  4.657e-02  -3.663 0.000250 ***\nas.factor(stfips)NE  -2.020e-01  4.338e-02  -4.656 3.25e-06 ***\nas.factor(stfips)NH  -9.275e-02  4.036e-02  -2.298 0.021581 *  \nas.factor(stfips)NJ   4.035e-02  3.941e-02   1.024 0.305976    \nas.factor(stfips)NM  -1.522e-01  4.872e-02  -3.124 0.001784 ** \nas.factor(stfips)NV  -1.545e-01  4.747e-02  -3.255 0.001134 ** \nas.factor(stfips)NY   3.355e-02  3.604e-02   0.931 0.351794    \nas.factor(stfips)OH  -1.475e-01  3.994e-02  -3.694 0.000222 ***\nas.factor(stfips)OK  -1.969e-01  4.855e-02  -4.056 5.01e-05 ***\nas.factor(stfips)OR  -8.150e-02  4.307e-02  -1.892 0.058466 .  \nas.factor(stfips)PA  -7.683e-02  3.851e-02  -1.995 0.046071 *  \nas.factor(stfips)RI  -2.267e-02  4.185e-02  -0.542 0.588023    \nas.factor(stfips)SC  -2.086e-01  4.653e-02  -4.483 7.42e-06 ***\nas.factor(stfips)SD  -2.505e-01  4.683e-02  -5.350 8.90e-08 ***\nas.factor(stfips)TN  -1.922e-01  4.772e-02  -4.027 5.67e-05 ***\nas.factor(stfips)TX  -9.406e-02  3.691e-02  -2.548 0.010843 *  \nas.factor(stfips)UT  -1.021e-01  4.637e-02  -2.202 0.027679 *  \nas.factor(stfips)VA  -1.775e-02  3.870e-02  -0.459 0.646472    \nas.factor(stfips)VT  -1.210e-01  4.196e-02  -2.884 0.003932 ** \nas.factor(stfips)WA  -2.774e-02  4.105e-02  -0.676 0.499183    \nas.factor(stfips)WI  -9.754e-02  4.191e-02  -2.328 0.019943 *  \nas.factor(stfips)WV  -1.948e-01  4.651e-02  -4.187 2.84e-05 ***\nas.factor(stfips)WY  -1.534e-01  4.793e-02  -3.201 0.001373 ** \nas.factor(ind2dig)1   2.052e-02  9.260e-03   2.216 0.026685 *  \nas.factor(ind2dig)2  -8.211e-03  1.352e-02  -0.607 0.543716    \nas.factor(occ2dig)1  -4.142e-02  2.327e-02  -1.780 0.075074 .  \nas.factor(occ2dig)2  -1.594e-01  2.500e-02  -6.376 1.86e-10 ***\nas.factor(occ2dig)3  -9.494e-02  3.087e-02  -3.076 0.002103 ** \nas.factor(occ2dig)4  -9.839e-02  2.194e-02  -4.485 7.35e-06 ***\nas.factor(occ2dig)5  -2.686e-01  4.071e-02  -6.597 4.30e-11 ***\nas.factor(occ2dig)6  -2.539e-01  4.095e-02  -6.201 5.72e-10 ***\nas.factor(occ2dig)7  -7.895e-02  2.750e-02  -2.871 0.004095 ** \nas.factor(occ2dig)8  -1.457e-01  2.534e-02  -5.748 9.17e-09 ***\nas.factor(occ2dig)9  -1.297e-01  5.286e-02  -2.454 0.014144 *  \nas.factor(occ2dig)10 -7.087e-02  2.317e-02  -3.058 0.002230 ** \nas.factor(occ2dig)11 -7.689e-02  3.927e-02  -1.958 0.050245 .  \nas.factor(occ2dig)12 -1.407e-01  4.141e-02  -3.398 0.000679 ***\nas.factor(occ2dig)13 -1.240e-01  3.173e-02  -3.908 9.36e-05 ***\nas.factor(occ2dig)14 -6.905e-04  3.200e-02  -0.022 0.982787    \nas.factor(occ2dig)15 -6.228e-02  3.901e-02  -1.597 0.110381    \nas.factor(occ2dig)16 -2.731e-01  3.417e-02  -7.993 1.39e-15 ***\nas.factor(occ2dig)17 -1.805e-01  3.260e-02  -5.536 3.14e-08 ***\nas.factor(occ2dig)18 -2.434e-01  3.260e-02  -7.468 8.53e-14 ***\nas.factor(occ2dig)19 -3.420e-01  8.258e-02  -4.142 3.46e-05 ***\nas.factor(occ2dig)20 -4.054e-01  2.198e-02 -18.442  &lt; 2e-16 ***\nas.factor(occ2dig)21 -1.400e-01  2.341e-02  -5.980 2.27e-09 ***\nas.factor(occ2dig)22 -3.356e-01  2.314e-02 -14.499  &lt; 2e-16 ***\nas.factor(occ2dig)23 -3.713e-01  2.025e-02 -18.333  &lt; 2e-16 ***\nas.factor(occ2dig)24 -4.447e-01  3.779e-02 -11.765  &lt; 2e-16 ***\nas.factor(occ2dig)25 -4.854e-01  3.938e-02 -12.326  &lt; 2e-16 ***\nas.factor(occ2dig)26 -2.782e-01  6.122e-02  -4.544 5.55e-06 ***\nas.factor(occ2dig)27 -4.193e-01  5.510e-02  -7.610 2.88e-14 ***\nas.factor(occ2dig)28 -2.648e-01  3.883e-02  -6.820 9.40e-12 ***\nas.factor(occ2dig)29 -3.460e-01  1.599e-01  -2.164 0.030511 *  \nas.factor(occ2dig)30 -1.165e-01  2.295e-02  -5.077 3.87e-07 ***\nas.factor(occ2dig)31 -9.354e-02  3.050e-02  -3.067 0.002166 ** \nas.factor(occ2dig)32 -1.551e-01  2.342e-02  -6.620 3.70e-11 ***\nas.factor(occ2dig)33 -3.636e-01  7.318e-02  -4.968 6.82e-07 ***\nas.factor(occ2dig)34 -6.699e-01  9.335e-02  -7.176 7.44e-13 ***\nas.factor(occ2dig)35 -2.709e-01  5.356e-02  -5.057 4.31e-07 ***\nas.factor(occ2dig)36 -6.530e-01  5.767e-02 -11.323  &lt; 2e-16 ***\nas.factor(occ2dig)37 -2.927e-01  6.200e-02  -4.721 2.36e-06 ***\nas.factor(occ2dig)38 -5.000e-01  6.009e-02  -8.321  &lt; 2e-16 ***\nas.factor(occ2dig)39 -6.071e-01  7.307e-02  -8.309  &lt; 2e-16 ***\nas.factor(occ2dig)40 -1.005e+00  6.490e-02 -15.479  &lt; 2e-16 ***\nas.factor(occ2dig)41 -1.086e+00  1.001e-01 -10.847  &lt; 2e-16 ***\nas.factor(occ2dig)42 -9.658e-01  6.934e-02 -13.928  &lt; 2e-16 ***\nas.factor(occ2dig)43 -4.194e-01  1.074e-01  -3.905 9.47e-05 ***\nas.factor(occ2dig)44 -1.228e+00  1.598e-01  -7.685 1.60e-14 ***\nas.factor(occ2dig)45 -9.310e-01  9.541e-02  -9.757  &lt; 2e-16 ***\nas.factor(occ2dig)46 -7.886e-01  5.903e-02 -13.359  &lt; 2e-16 ***\nas.factor(occ2dig)47 -4.754e-01  3.038e-02 -15.647  &lt; 2e-16 ***\nas.factor(occ2dig)48 -2.589e-01  3.387e-02  -7.643 2.23e-14 ***\nas.factor(occ2dig)49 -4.440e-01  5.644e-02  -7.867 3.83e-15 ***\nas.factor(occ2dig)50 -3.438e-01  4.802e-02  -7.160 8.39e-13 ***\nas.factor(occ2dig)51 -5.860e-01  5.659e-02 -10.354  &lt; 2e-16 ***\nas.factor(occ2dig)52 -5.306e-01  4.572e-02 -11.606  &lt; 2e-16 ***\nas.factor(occ2dig)53 -6.387e-01  6.287e-02 -10.160  &lt; 2e-16 ***\nas.factor(occ2dig)54 -6.779e-01  7.299e-02  -9.287  &lt; 2e-16 ***\nas.factor(occ2dig)55 -6.143e-01  1.074e-01  -5.720 1.08e-08 ***\nas.factor(occ2dig)56 -3.998e-01  7.674e-02  -5.210 1.91e-07 ***\nas.factor(occ2dig)57 -6.743e-01  4.334e-02 -15.560  &lt; 2e-16 ***\nas.factor(occ2dig)58 -6.413e-01  5.626e-02 -11.400  &lt; 2e-16 ***\nas.factor(occ2dig)59 -5.035e-01  6.912e-02  -7.285 3.35e-13 ***\nas.factor(occ2dig)60 -4.953e-01  1.511e-01  -3.278 0.001048 ** \nas.factor(occ2dig)62 -6.111e-01  8.530e-02  -7.164 8.15e-13 ***\nas.factor(occ2dig)63 -4.139e-01  1.510e-01  -2.741 0.006137 ** \nas.factor(occ2dig)64 -5.010e-01  2.020e-01  -2.481 0.013126 *  \nas.factor(occ2dig)66 -2.778e-01  2.604e-01  -1.067 0.286138    \nas.factor(occ2dig)67 -1.139e+00  2.253e-01  -5.055 4.34e-07 ***\nas.factor(occ2dig)68  4.518e-01  4.499e-01   1.004 0.315280    \nas.factor(occ2dig)70 -3.977e-01  8.503e-02  -4.678 2.92e-06 ***\nas.factor(occ2dig)71 -3.346e-01  2.255e-01  -1.484 0.137858    \nas.factor(occ2dig)72 -6.765e-01  1.511e-01  -4.477 7.63e-06 ***\nas.factor(occ2dig)73 -3.578e-01  1.431e-01  -2.500 0.012420 *  \nas.factor(occ2dig)74 -4.804e-01  2.253e-01  -2.132 0.033028 *  \nas.factor(occ2dig)75 -1.129e+00  4.499e-01  -2.508 0.012136 *  \nas.factor(occ2dig)76 -7.677e-01  4.500e-01  -1.706 0.088066 .  \nas.factor(occ2dig)77 -3.976e-01  7.773e-02  -5.116 3.16e-07 ***\nas.factor(occ2dig)78 -7.281e-01  3.185e-01  -2.286 0.022248 *  \nas.factor(occ2dig)79 -1.216e+00  4.499e-01  -2.703 0.006888 ** \nas.factor(occ2dig)80  1.036e-01  4.499e-01   0.230 0.817887    \nas.factor(occ2dig)81 -6.093e-01  2.019e-01  -3.017 0.002555 ** \nas.factor(occ2dig)82 -6.297e-01  1.843e-01  -3.417 0.000635 ***\nas.factor(occ2dig)83 -1.262e+00  2.601e-01  -4.853 1.23e-06 ***\nas.factor(occ2dig)84 -7.511e-01  3.188e-01  -2.356 0.018494 *  \nas.factor(occ2dig)86 -2.707e-01  1.708e-01  -1.585 0.112883    \nas.factor(occ2dig)87 -4.341e-01  8.815e-02  -4.925 8.51e-07 ***\nas.factor(occ2dig)88 -9.160e-01  1.599e-01  -5.727 1.04e-08 ***\nas.factor(occ2dig)89 -4.953e-01  1.432e-01  -3.460 0.000542 ***\nas.factor(occ2dig)90 -1.211e-01  8.998e-02  -1.345 0.178527    \nas.factor(occ2dig)91 -8.391e-01  6.843e-02 -12.263  &lt; 2e-16 ***\nas.factor(occ2dig)93 -9.595e-01  2.260e-01  -4.245 2.19e-05 ***\nas.factor(occ2dig)94 -3.147e-01  1.711e-01  -1.839 0.065928 .  \nas.factor(occ2dig)96 -8.983e-01  1.212e-01  -7.408 1.34e-13 ***\nas.factor(occ2dig)97 -1.182e+00  4.501e-01  -2.625 0.008669 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4488 on 18051 degrees of freedom\nMultiple R-squared:  0.2641,    Adjusted R-squared:  0.2572 \nF-statistic: 38.56 on 168 and 18051 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "p2c2-app5.html#código-python",
    "href": "p2c2-app5.html#código-python",
    "title": "Aplicación 2.5 (Modelo de regresión lineal con variables cualitativas): Brecha salarial entre hombres y mujeres en Estados Unidos",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nfrom plotnine import *\nfrom scipy.stats import norm\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom mizani import transforms\nfrom mizani.formatters import percent_format\nfrom stargazer.stargazer import Stargazer\n#\n# FILTRADO PREVIO DE OBSERVACIONES: \n#\n# Operación sobre el fichero original: cps = pd.read_csv('data/MORG14_USA.csv')\n# cps = cps.query(\"age&gt;=24 & age&lt;=64 & uhours&gt;=20 & earnwke&gt;0 & grade92&gt;=44\")\n#\n# Lectura de datos\ncps = pd.read_csv('data/CPS2014_USA.csv')\n# Operaciones con variables\ncps[\"female\"] = (cps.sex == 2).astype(int)\ncps[\"w\"] = cps[\"earnwke\"] / cps[\"uhours\"]\ncps = cps.query(\"w&gt;=1\")\n# Distribución de los salarios\ncps.loc[:,[\"earnwke\",\"uhours\",\"w\"]].describe()\n\n            earnwke        uhours             w\ncount  18220.000000  18220.000000  18220.000000\nmean    1483.491212     42.970088     34.565432\nstd      746.672256      9.135281     16.622801\nmin       38.000000     20.000000      1.025556\n25%      923.000000     40.000000     21.634500\n50%     1346.000000     40.000000     31.250000\n75%     1923.070000     47.000000     45.673000\nmax     2884.610000     99.000000    144.230500\n\n# SALARIOS, SEXO Y EDAD\nreg0 = smf.ols(formula=\"np.log(w) ~ female\", data=cps).fit()\nprint(reg0.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              np.log(w)   R-squared:                       0.034\nModel:                            OLS   Adj. R-squared:                  0.034\nMethod:                 Least Squares   F-statistic:                     645.5\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):          5.68e-140\nTime:                        08:49:16   Log-Likelihood:                -13647.\nNo. Observations:               18220   AIC:                         2.730e+04\nDf Residuals:                   18218   BIC:                         2.731e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      3.5215      0.006    636.177      0.000       3.511       3.532\nfemale        -0.1930      0.008    -25.407      0.000      -0.208      -0.178\n==============================================================================\nOmnibus:                     1256.924   Durbin-Watson:                   1.853\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1732.098\nSkew:                          -0.603   Prob(JB):                         0.00\nKurtosis:                       3.910   Cond. No.                         2.70\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Histograma diferenciado por género\nggplot(cps, aes(x=\"w\", y=\"2*stat(count)/sum(stat(count))\")) + geom_histogram(\n    binwidth=4,\n    color=\"white\",\n    size=0.25,\n    alpha=0.8,\n    show_legend=False,\n    na_rm=True,\n) + labs(x=\"Hourly earnings (dollars)\", y=\"Percent\") + facet_wrap('~female',labeller={'0':\"Male\",'1':\"Female\"}\n) + labs(\n    x=\"Hourly earnings (dollars)\", y=\"Percent\"\n) + scale_x_continuous(\n    limits=(0, 100),\n) + scale_y_continuous(\n    limits=(0, 0.20), labels=percent_format()\n) + theme_bw()\n\n&lt;ggplot: (329785179)&gt;\n\n\n\n\n# Densidad estimada diferenciada por género\nggplot(cps, aes(x=\"w\", y=\"stat(density)\", color=\"factor(female)\")) + geom_density(\n    adjust=1.5, show_legend=False, na_rm=True, size=0.7\n) + labs(x=\"Hourly wage (dollars)\", y=\"Density\", color=\"\"\n)  + scale_x_continuous(\n    expand=(0.01, 0.01), limits=(0, 100),\n) + scale_y_continuous(\n    expand=(0.0, 0.0), limits=(0, 0.035),\n) + geom_text(\n    aes(x=55, y=0.028, label=\"'Male'\"),  size=10\n) + geom_text(\n    aes(x=55, y=0.020, label=\"'Female'\"), size=10\n) + theme_bw()\n\n&lt;ggplot: (329879973)&gt;\n\n\n\n\n# SALARIOS, EDAD Y GÉNERO\nreg0 = smf.ols(formula=\"np.log(w) ~ female\", data=cps).fit()\nreg1 = smf.ols(formula=\"np.log(w) ~ female + age\", data=cps).fit()\nreg2 = smf.ols(formula=\"np.log(w) ~ female*age\", data=cps).fit()\nreg21 = smf.ols(formula=\"np.log(w) ~ age\", data=cps.query(\"female==1\")).fit()\nreg22 = smf.ols(formula=\"np.log(w) ~ age\", data=cps.query(\"female==0\")).fit()\nstargazer = Stargazer([reg0, reg1, reg2])\nstargazer.custom_columns([\"log(w)\", \"log(w)\", \"log(w)\"], [1, 1, 1])\nstargazer.covariate_order([\"female\", \"age\", \"female:age\", \"Intercept\"])\nstargazer.rename_covariates({\"Intercept\": \"Constant\"})\nstargazer\n\n\nDependent variable:np.log(w)log(w)log(w)log(w)(1)(2)(3)female-0.193***-0.182***-0.036(0.008)(0.008)(0.032)age0.007***0.009***(0.000)(0.001)female:age-0.003***(0.001)Constant3.522***3.196***3.117***(0.006)(0.017)(0.023)Observations18,22018,22018,220R20.0340.0570.058Adjusted R20.0340.0570.058Residual Std. Error0.512 (df=18218)0.506 (df=18217)0.505 (df=18216)F Statistic645.532*** (df=1; 18218)548.583*** (df=2; 18217)373.761*** (df=3; 18216)Note:\n \n  *p&lt;0.1;\n  **p&lt;0.05;\n  ***p&lt;0.01\n \n\n# Regresiones diferenciadas por sexo\nprint(reg21.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              np.log(w)   R-squared:                       0.015\nModel:                            OLS   Adj. R-squared:                  0.014\nMethod:                 Least Squares   F-statistic:                     143.3\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           8.67e-33\nTime:                        08:49:55   Log-Likelihood:                -7149.3\nNo. Observations:                9672   AIC:                         1.430e+04\nDf Residuals:                    9670   BIC:                         1.432e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      3.0812      0.021    144.730      0.000       3.039       3.123\nage            0.0057      0.000     11.970      0.000       0.005       0.007\n==============================================================================\nOmnibus:                      575.878   Durbin-Watson:                   1.904\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              939.605\nSkew:                          -0.483   Prob(JB):                    9.27e-205\nKurtosis:                       4.183   Cond. No.                         184.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nprint(reg22.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              np.log(w)   R-squared:                       0.036\nModel:                            OLS   Adj. R-squared:                  0.036\nMethod:                 Least Squares   F-statistic:                     317.4\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           9.74e-70\nTime:                        08:49:55   Log-Likelihood:                -6270.8\nNo. Observations:                8548   AIC:                         1.255e+04\nDf Residuals:                    8546   BIC:                         1.256e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      3.1167      0.023    133.395      0.000       3.071       3.163\nage            0.0091      0.001     17.815      0.000       0.008       0.010\n==============================================================================\nOmnibus:                      878.941   Durbin-Watson:                   1.886\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1248.166\nSkew:                          -0.805   Prob(JB):                    9.21e-272\nKurtosis:                       3.956   Cond. No.                         197.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# No linealidad en la edad\ncps[\"age2\"] = np.power(cps[\"age\"], 2)\ncps[\"age3\"] = np.power(cps[\"age\"], 3)\ncps[\"age4\"] = np.power(cps[\"age\"], 4)\nreg3 = smf.ols(formula=\"np.log(w) ~ female + age + age2 + age3 + age4\", data=cps).fit()\nstargazer = Stargazer([reg1,reg3])\nstargazer.covariate_order(\n    [\"female\", \"age\", \"age2\",\"age3\",\"age4\",\"Intercept\"]\n)\nstargazer.rename_covariates({\"Intercept\": \"Constant\"})\nstargazer\n\n\nDependent variable:np.log(w)(1)(2)female-0.182***-0.180***(0.008)(0.007)age0.007***0.525***(0.000)(0.103)age2-0.016***(0.004)age30.000***(0.000)age4-0.000***(0.000)Constant3.196***-3.131***(0.017)(1.059)Observations18,22018,220R20.0570.079Adjusted R20.0570.078Residual Std. Error0.506 (df=18217)0.500 (df=18214)F Statistic548.583*** (df=2; 18217)310.523*** (df=5; 18214)Note:\n \n  *p&lt;0.1;\n  **p&lt;0.05;\n  ***p&lt;0.01\n \n\n# SALARIOS, SEXO, EDAD Y NIVEL DE EDUCACIÓN\ncps[\"ed_MA\"] = (cps[\"grade92\"] == 44).astype(int)\ncps[\"ed_PSD\"] = (cps[\"grade92\"] == 45).astype(int)\ncps[\"ed_DD\"] = (cps[\"grade92\"] == 46).astype(int)\nreg4 = smf.ols(formula=\"np.log(w) ~ female + age + age2 + age3 + age4 + ed_PSD + ed_DD\", data=cps).fit()\nstargazer = Stargazer([reg3,reg4])\nstargazer.covariate_order(\n    [\"female\", \"age\", \"age2\", \"age3\", \"age4\", \"ed_PSD\", \"ed_DD\", \"Intercept\"]\n)\nstargazer.rename_covariates({\"Intercept\": \"Constant\"})\nstargazer\n\n\nDependent variable:np.log(w)(1)(2)female-0.180***-0.167***(0.007)(0.007)age0.525***0.491***(0.103)(0.102)age2-0.016***-0.014***(0.004)(0.004)age30.000***0.000***(0.000)(0.000)age4-0.000***-0.000***(0.000)(0.000)ed_PSD0.142***(0.012)ed_DD0.129***(0.011)Constant-3.131***-2.789***(1.059)(1.052)Observations18,22018,220R20.0790.091Adjusted R20.0780.091Residual Std. Error0.500 (df=18214)0.497 (df=18212)F Statistic310.523*** (df=5; 18214)260.920*** (df=7; 18212)Note:\n \n  *p&lt;0.1;\n  **p&lt;0.05;\n  ***p&lt;0.01\n \n\n# SALARIOS, SEXO, EDAD, EDUCACIÓN Y OTROS FACTORES (CUALITATIVOS) ADICIONALES \n# Construcción de factores condicionantes\ncps[\"white\"] = (cps[\"race\"] == 1).astype(int)\ncps[\"afram\"] = (cps[\"race\"] == 2).astype(int)\ncps[\"asian\"] = (cps[\"race\"] == 4).astype(int)\ncps[\"hisp\"] = (cps[\"ethnic\"].notna()).astype(int)\ncps[\"othernonw\"] = (\n    (cps[\"white\"] == 0) & (cps[\"afram\"] == 0) & (cps[\"asian\"] == 0) & (cps[\"hisp\"] == 0)\n).astype(int)\ncps[\"nonUSborn\"] = (\n    (cps[\"prcitshp\"] == \"Foreign Born, US Cit By Naturalization\")\n    | (cps[\"prcitshp\"] == \"Foreign Born, Not a US Citizen\")\n).astype(int)\ncps['married']=((cps['marital']==1)|(cps['marital']==2)).astype(int)\ncps['divorced']=((cps['marital']==3)&(cps['marital']==5)).astype(int)\ncps['wirowed']=(cps['marital']==4).astype(int)\ncps['nevermar']=(cps['marital']==7).astype(int)\ncps['child0']=(cps['chldpres']==0).astype(int)\ncps['child1']=(cps['chldpres']==1).astype(int)\ncps['child2']=(cps['chldpres']==2).astype(int)\ncps['child3']=(cps['chldpres']==3).astype(int)\ncps['child4pl']=(cps['chldpres']&gt;=4).astype(int)\ncps['fedgov']=(cps['class']==\"Government - Federal\").astype(int)\ncps['stagov']=(cps['class']==\"Government - State\").astype(int)\ncps['locgov']=(cps['class']==\"Government - Local\").astype(int)\ncps['nonprof']=(cps['class']==\"Private, Nonprofit\").astype(int)\ncps['ind2dig']=((pd.Categorical(cps[\"ind02\"]).codes+1)/100).astype(int)\ncps['occ2dig']=(cps[\"occ2012\"]/100).astype(int)\ncps['union']=((cps['unionmme']==\"Yes\")|(cps['unioncov']==\"Yes\")).astype(int)\n# Regresión con factores\nreg5 = smf.ols(formula=\"np.log(w) ~ female + age + age2 + age3 + age4 + ed_DD + afram + hisp + asian + othernonw + nonUSborn +  married + divorced+ wirowed + child1 + child2 + child3 + child4pl + uhours + fedgov + stagov + locgov + nonprof + union + C(stfips) + C(ind2dig) + C(occ2dig)\", data=cps).fit()\nprint(reg5.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              np.log(w)   R-squared:                       0.262\nModel:                            OLS   Adj. R-squared:                  0.255\nMethod:                 Least Squares   F-statistic:                     38.65\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):               0.00\nTime:                        08:49:56   Log-Likelihood:                -11194.\nNo. Observations:               18220   AIC:                         2.272e+04\nDf Residuals:                   18053   BIC:                         2.403e+04\nDf Model:                         166                                         \nCovariance Type:            nonrobust                                         \n====================================================================================\n                       coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------------\nIntercept           -0.0673      0.978     -0.069      0.945      -1.984       1.849\nC(stfips)[T.AL]     -0.2414      0.047     -5.120      0.000      -0.334      -0.149\nC(stfips)[T.AR]     -0.2050      0.053     -3.846      0.000      -0.309      -0.101\nC(stfips)[T.AZ]     -0.1295      0.046     -2.787      0.005      -0.221      -0.038\nC(stfips)[T.CA]      0.0396      0.035      1.132      0.258      -0.029       0.108\nC(stfips)[T.CO]     -0.0921      0.039     -2.358      0.018      -0.169      -0.016\nC(stfips)[T.CT]      0.0258      0.039      0.669      0.504      -0.050       0.101\nC(stfips)[T.DC]      0.1292      0.037      3.526      0.000       0.057       0.201\nC(stfips)[T.DE]     -0.0844      0.044     -1.934      0.053      -0.170       0.001\nC(stfips)[T.FL]     -0.1402      0.038     -3.679      0.000      -0.215      -0.065\nC(stfips)[T.GA]     -0.1023      0.041     -2.519      0.012      -0.182      -0.023\nC(stfips)[T.HI]     -0.1536      0.045     -3.414      0.001      -0.242      -0.065\nC(stfips)[T.IA]     -0.1879      0.044     -4.275      0.000      -0.274      -0.102\nC(stfips)[T.ID]     -0.1747      0.049     -3.538      0.000      -0.272      -0.078\nC(stfips)[T.IL]     -0.0804      0.038     -2.138      0.033      -0.154      -0.007\nC(stfips)[T.IN]     -0.1358      0.046     -2.953      0.003      -0.226      -0.046\nC(stfips)[T.KS]     -0.1681      0.042     -3.972      0.000      -0.251      -0.085\nC(stfips)[T.KY]     -0.2147      0.045     -4.791      0.000      -0.303      -0.127\nC(stfips)[T.LA]     -0.1534      0.048     -3.204      0.001      -0.247      -0.060\nC(stfips)[T.MA]     -0.0010      0.039     -0.026      0.979      -0.078       0.076\nC(stfips)[T.MD]     -0.0354      0.038     -0.939      0.348      -0.109       0.039\nC(stfips)[T.ME]     -0.1641      0.044     -3.772      0.000      -0.249      -0.079\nC(stfips)[T.MI]     -0.0647      0.040     -1.600      0.110      -0.144       0.015\nC(stfips)[T.MN]     -0.0491      0.040     -1.241      0.215      -0.127       0.028\nC(stfips)[T.MO]     -0.1121      0.044     -2.571      0.010      -0.198      -0.027\nC(stfips)[T.MS]     -0.1887      0.049     -3.827      0.000      -0.285      -0.092\nC(stfips)[T.MT]     -0.2503      0.050     -5.035      0.000      -0.348      -0.153\nC(stfips)[T.NC]     -0.1553      0.042     -3.718      0.000      -0.237      -0.073\nC(stfips)[T.ND]     -0.1683      0.047     -3.609      0.000      -0.260      -0.077\nC(stfips)[T.NE]     -0.1980      0.043     -4.559      0.000      -0.283      -0.113\nC(stfips)[T.NH]     -0.0873      0.040     -2.160      0.031      -0.166      -0.008\nC(stfips)[T.NJ]      0.0441      0.039      1.119      0.263      -0.033       0.121\nC(stfips)[T.NM]     -0.1488      0.049     -3.050      0.002      -0.244      -0.053\nC(stfips)[T.NV]     -0.1505      0.048     -3.167      0.002      -0.244      -0.057\nC(stfips)[T.NY]      0.0363      0.036      1.005      0.315      -0.034       0.107\nC(stfips)[T.OH]     -0.1432      0.040     -3.581      0.000      -0.222      -0.065\nC(stfips)[T.OK]     -0.1949      0.049     -4.009      0.000      -0.290      -0.100\nC(stfips)[T.OR]     -0.0784      0.043     -1.819      0.069      -0.163       0.006\nC(stfips)[T.PA]     -0.0740      0.039     -1.919      0.055      -0.150       0.002\nC(stfips)[T.RI]     -0.0178      0.042     -0.426      0.670      -0.100       0.064\nC(stfips)[T.SC]     -0.2043      0.047     -4.386      0.000      -0.296      -0.113\nC(stfips)[T.SD]     -0.2440      0.047     -5.205      0.000      -0.336      -0.152\nC(stfips)[T.TN]     -0.1870      0.048     -3.914      0.000      -0.281      -0.093\nC(stfips)[T.TX]     -0.0901      0.037     -2.439      0.015      -0.163      -0.018\nC(stfips)[T.UT]     -0.1000      0.046     -2.154      0.031      -0.191      -0.009\nC(stfips)[T.VA]     -0.0159      0.039     -0.410      0.682      -0.092       0.060\nC(stfips)[T.VT]     -0.1170      0.042     -2.785      0.005      -0.199      -0.035\nC(stfips)[T.WA]     -0.0247      0.041     -0.602      0.547      -0.105       0.056\nC(stfips)[T.WI]     -0.0952      0.042     -2.268      0.023      -0.177      -0.013\nC(stfips)[T.WV]     -0.1922      0.047     -4.127      0.000      -0.283      -0.101\nC(stfips)[T.WY]     -0.1463      0.048     -3.050      0.002      -0.240      -0.052\nC(ind2dig)[T.1]      0.0220      0.009      2.372      0.018       0.004       0.040\nC(ind2dig)[T.2]     -0.0071      0.014     -0.526      0.599      -0.034       0.019\nC(occ2dig)[T.1]     -0.0451      0.023     -1.935      0.053      -0.091       0.001\nC(occ2dig)[T.2]     -0.1575      0.025     -6.293      0.000      -0.207      -0.108\nC(occ2dig)[T.3]     -0.0953      0.031     -3.085      0.002      -0.156      -0.035\nC(occ2dig)[T.4]     -0.0996      0.022     -4.532      0.000      -0.143      -0.056\nC(occ2dig)[T.5]     -0.2631      0.041     -6.457      0.000      -0.343      -0.183\nC(occ2dig)[T.6]     -0.2534      0.041     -6.180      0.000      -0.334      -0.173\nC(occ2dig)[T.7]     -0.0815      0.028     -2.959      0.003      -0.135      -0.027\nC(occ2dig)[T.8]     -0.1481      0.025     -5.837      0.000      -0.198      -0.098\nC(occ2dig)[T.9]     -0.1268      0.053     -2.396      0.017      -0.231      -0.023\nC(occ2dig)[T.10]    -0.0740      0.023     -3.190      0.001      -0.119      -0.029\nC(occ2dig)[T.11]    -0.0813      0.039     -2.067      0.039      -0.158      -0.004\nC(occ2dig)[T.12]    -0.1389      0.041     -3.351      0.001      -0.220      -0.058\nC(occ2dig)[T.13]    -0.1263      0.032     -3.976      0.000      -0.189      -0.064\nC(occ2dig)[T.14]    -0.0015      0.032     -0.046      0.963      -0.064       0.061\nC(occ2dig)[T.15]    -0.0629      0.039     -1.610      0.107      -0.139       0.014\nC(occ2dig)[T.16]    -0.2673      0.034     -7.822      0.000      -0.334      -0.200\nC(occ2dig)[T.17]    -0.1759      0.033     -5.392      0.000      -0.240      -0.112\nC(occ2dig)[T.18]    -0.2338      0.033     -7.171      0.000      -0.298      -0.170\nC(occ2dig)[T.19]    -0.3442      0.083     -4.163      0.000      -0.506      -0.182\nC(occ2dig)[T.20]    -0.4069      0.022    -18.488      0.000      -0.450      -0.364\nC(occ2dig)[T.21]    -0.0906      0.022     -4.185      0.000      -0.133      -0.048\nC(occ2dig)[T.22]    -0.3247      0.023    -14.069      0.000      -0.370      -0.279\nC(occ2dig)[T.23]    -0.3727      0.020    -18.384      0.000      -0.412      -0.333\nC(occ2dig)[T.24]    -0.4481      0.038    -11.844      0.000      -0.522      -0.374\nC(occ2dig)[T.25]    -0.4861      0.039    -12.331      0.000      -0.563      -0.409\nC(occ2dig)[T.26]    -0.2787      0.061     -4.547      0.000      -0.399      -0.159\nC(occ2dig)[T.27]    -0.4222      0.055     -7.655      0.000      -0.530      -0.314\nC(occ2dig)[T.28]    -0.2664      0.039     -6.852      0.000      -0.343      -0.190\nC(occ2dig)[T.29]    -0.3420      0.160     -2.136      0.033      -0.656      -0.028\nC(occ2dig)[T.30]    -0.0780      0.022     -3.564      0.000      -0.121      -0.035\nC(occ2dig)[T.31]    -0.0872      0.031     -2.859      0.004      -0.147      -0.027\nC(occ2dig)[T.32]    -0.1505      0.023     -6.421      0.000      -0.196      -0.105\nC(occ2dig)[T.33]    -0.3553      0.073     -4.850      0.000      -0.499      -0.212\nC(occ2dig)[T.34]    -0.6704      0.093     -7.173      0.000      -0.854      -0.487\nC(occ2dig)[T.35]    -0.2670      0.054     -4.982      0.000      -0.372      -0.162\nC(occ2dig)[T.36]    -0.6487      0.058    -11.238      0.000      -0.762      -0.536\nC(occ2dig)[T.37]    -0.2911      0.062     -4.690      0.000      -0.413      -0.169\nC(occ2dig)[T.38]    -0.5008      0.060     -8.324      0.000      -0.619      -0.383\nC(occ2dig)[T.39]    -0.6049      0.073     -8.269      0.000      -0.748      -0.462\nC(occ2dig)[T.40]    -1.0023      0.065    -15.425      0.000      -1.130      -0.875\nC(occ2dig)[T.41]    -1.0865      0.100    -10.840      0.000      -1.283      -0.890\nC(occ2dig)[T.42]    -0.9486      0.069    -13.672      0.000      -1.085      -0.813\nC(occ2dig)[T.43]    -0.4226      0.108     -3.930      0.000      -0.633      -0.212\nC(occ2dig)[T.44]    -1.2203      0.160     -7.625      0.000      -1.534      -0.907\nC(occ2dig)[T.45]    -0.9031      0.095     -9.465      0.000      -1.090      -0.716\nC(occ2dig)[T.46]    -0.7834      0.059    -13.257      0.000      -0.899      -0.668\nC(occ2dig)[T.47]    -0.4747      0.030    -15.604      0.000      -0.534      -0.415\nC(occ2dig)[T.48]    -0.2599      0.034     -7.664      0.000      -0.326      -0.193\nC(occ2dig)[T.49]    -0.4426      0.057     -7.832      0.000      -0.553      -0.332\nC(occ2dig)[T.50]    -0.3467      0.048     -7.211      0.000      -0.441      -0.252\nC(occ2dig)[T.51]    -0.5851      0.057    -10.327      0.000      -0.696      -0.474\nC(occ2dig)[T.52]    -0.5302      0.046    -11.584      0.000      -0.620      -0.441\nC(occ2dig)[T.53]    -0.6367      0.063    -10.116      0.000      -0.760      -0.513\nC(occ2dig)[T.54]    -0.6697      0.073     -9.165      0.000      -0.813      -0.527\nC(occ2dig)[T.55]    -0.6197      0.108     -5.763      0.000      -0.830      -0.409\nC(occ2dig)[T.56]    -0.4011      0.077     -5.220      0.000      -0.552      -0.251\nC(occ2dig)[T.57]    -0.6696      0.043    -15.436      0.000      -0.755      -0.585\nC(occ2dig)[T.58]    -0.6381      0.056    -11.332      0.000      -0.748      -0.528\nC(occ2dig)[T.59]    -0.4996      0.069     -7.220      0.000      -0.635      -0.364\nC(occ2dig)[T.60]    -0.5168      0.151     -3.417      0.001      -0.813      -0.220\nC(occ2dig)[T.62]    -0.6074      0.085     -7.114      0.000      -0.775      -0.440\nC(occ2dig)[T.63]    -0.4077      0.151     -2.696      0.007      -0.704      -0.111\nC(occ2dig)[T.64]    -0.4576      0.202     -2.264      0.024      -0.854      -0.061\nC(occ2dig)[T.66]    -0.2759      0.261     -1.058      0.290      -0.787       0.235\nC(occ2dig)[T.67]    -1.1496      0.226     -5.096      0.000      -1.592      -0.707\nC(occ2dig)[T.68]     0.4186      0.450      0.929      0.353      -0.464       1.301\nC(occ2dig)[T.70]    -0.3967      0.085     -4.660      0.000      -0.564      -0.230\nC(occ2dig)[T.71]    -0.3316      0.226     -1.469      0.142      -0.774       0.111\nC(occ2dig)[T.72]    -0.6387      0.151     -4.226      0.000      -0.935      -0.342\nC(occ2dig)[T.73]    -0.3348      0.143     -2.338      0.019      -0.616      -0.054\nC(occ2dig)[T.74]    -0.4782      0.226     -2.120      0.034      -0.920      -0.036\nC(occ2dig)[T.75]    -1.1064      0.450     -2.456      0.014      -1.989      -0.224\nC(occ2dig)[T.76]    -0.7803      0.451     -1.732      0.083      -1.664       0.103\nC(occ2dig)[T.77]    -0.3960      0.078     -5.089      0.000      -0.549      -0.244\nC(occ2dig)[T.78]    -0.7177      0.319     -2.251      0.024      -1.343      -0.093\nC(occ2dig)[T.79]    -1.1940      0.450     -2.651      0.008      -2.077      -0.311\nC(occ2dig)[T.80]     0.0937      0.450      0.208      0.835      -0.789       0.977\nC(occ2dig)[T.81]    -0.5483      0.202     -2.715      0.007      -0.944      -0.152\nC(occ2dig)[T.82]    -0.6376      0.185     -3.455      0.001      -0.999      -0.276\nC(occ2dig)[T.83]    -1.2454      0.260     -4.782      0.000      -1.756      -0.735\nC(occ2dig)[T.84]    -0.7570      0.319     -2.371      0.018      -1.383      -0.131\nC(occ2dig)[T.86]    -0.2736      0.171     -1.600      0.110      -0.609       0.062\nC(occ2dig)[T.87]    -0.4309      0.088     -4.882      0.000      -0.604      -0.258\nC(occ2dig)[T.88]    -0.9188      0.160     -5.738      0.000      -1.233      -0.605\nC(occ2dig)[T.89]    -0.4896      0.143     -3.416      0.001      -0.770      -0.209\nC(occ2dig)[T.90]    -0.1198      0.090     -1.330      0.183      -0.296       0.057\nC(occ2dig)[T.91]    -0.8280      0.068    -12.090      0.000      -0.962      -0.694\nC(occ2dig)[T.93]    -0.9628      0.226     -4.255      0.000      -1.406      -0.519\nC(occ2dig)[T.94]    -0.3066      0.171     -1.790      0.074      -0.642       0.029\nC(occ2dig)[T.96]    -0.8966      0.121     -7.386      0.000      -1.135      -0.659\nC(occ2dig)[T.97]    -1.1746      0.451     -2.606      0.009      -2.058      -0.291\nfemale              -0.1119      0.007    -15.065      0.000      -0.126      -0.097\nage                  0.2854      0.095      2.995      0.003       0.099       0.472\nage2                -0.0077      0.003     -2.262      0.024      -0.014      -0.001\nage3               9.42e-05   5.23e-05      1.803      0.071   -8.22e-06       0.000\nage4             -4.453e-07   2.94e-07     -1.512      0.131   -1.02e-06    1.32e-07\ned_DD                0.0925      0.011      8.395      0.000       0.071       0.114\nafram               -0.0845      0.013     -6.312      0.000      -0.111      -0.058\nhisp                -0.0243      0.015     -1.573      0.116      -0.055       0.006\nasian                0.0222      0.014      1.574      0.116      -0.005       0.050\nothernonw            0.0213      0.026      0.815      0.415      -0.030       0.073\nnonUSborn           -0.0498      0.012     -4.288      0.000      -0.073      -0.027\nmarried              0.0388      0.008      4.566      0.000       0.022       0.055\ndivorced           2.11e-16   2.12e-16      0.996      0.319   -2.04e-16    6.26e-16\nwirowed              0.0433      0.036      1.219      0.223      -0.026       0.113\nchild1               0.0657      0.017      3.966      0.000       0.033       0.098\nchild2               0.0171      0.020      0.839      0.401      -0.023       0.057\nchild3               0.0303      0.012      2.447      0.014       0.006       0.055\nchild4pl             0.0322      0.010      3.336      0.001       0.013       0.051\nuhours              -0.0044      0.000    -11.427      0.000      -0.005      -0.004\nfedgov               0.0863      0.015      5.617      0.000       0.056       0.116\nstagov              -0.0457      0.013     -3.589      0.000      -0.071      -0.021\nlocgov              -0.0395      0.013     -3.006      0.003      -0.065      -0.014\nnonprof             -0.0744      0.011     -6.914      0.000      -0.096      -0.053\nunion                0.0643      0.011      6.021      0.000       0.043       0.085\n==============================================================================\nOmnibus:                     2235.211   Durbin-Watson:                   1.947\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5280.553\nSkew:                          -0.725   Prob(JB):                         0.00\nKurtosis:                       5.204   Cond. No.                     1.32e+16\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 4.69e-15. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\n# COMPARACIÓN FINAL\nstargazer = Stargazer([reg0, reg5])\nstargazer.covariate_order([\"female\"])\nstargazer.add_line(\"Edad y educación\", [\"\", \"Yes\"])\nstargazer.add_line(\"Características familliares\", [\"\", \"Yes\"])\nstargazer.add_line(\"Características demográficas\", [\"\", \"Yes\"])\nstargazer.add_line(\"Características laborales\", [\"\", \"Yes\"])\nstargazer\n\n\nDependent variable:np.log(w)(1)(2)female-0.193***-0.112***(0.008)(0.007)Edad y educaciónYesCaracterísticas familliaresYesCaracterísticas demográficasYesCaracterísticas laboralesYesObservations18,22018,220R20.0340.262Adjusted R20.0340.255Residual Std. Error0.512 (df=18218)0.449 (df=18053)F Statistic645.532*** (df=1; 18218)38.651*** (df=166; 18053)Note:\n \n  *p&lt;0.1;\n  **p&lt;0.05;\n  ***p&lt;0.01"
  },
  {
    "objectID": "p2c2-app6.html#código-r",
    "href": "p2c2-app6.html#código-r",
    "title": "Aplicación 2.6 (Series temporales de alta frecuencia y estacionalidad): Demanda de electricidad en el estado de Victoria, Australia",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(fpp3)\n# Lectura de datos\nload(\"data/DEM_ELEC.RData\")\nclass(dem_elec_vict)\n\n[1] \"tbl_ts\"     \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n# Demanda de electricidad 2012-2014\ndem_elec_vict %&gt;% \n  autoplot(Demanda) +\n  labs(title = \"Demanda de electricidad (cada media hora, en MW)\", \n       subtitle = \"Victoria-Australia\")\n\n\n\n# Estacionalidad(es) en la demanda\n# Diaria\ndem_elec_vict %&gt;% gg_season(Demanda, period=\"day\") + \n  theme(legend.position = \"none\")\n\n\n\n# Semanal\ndem_elec_vict %&gt;% gg_season(Demanda, period=\"week\") + \n  theme(legend.position = \"none\")\n\n\n\n# Mensual\ndem_elec_vict %&gt;% gg_season(Demanda, period=\"year\")\n\n\n\n# Consumo y temperatura en el período 2012-2014\ndem_elec_vict %&gt;%\n  pivot_longer(Demanda:Temperatura, names_to = \"Series\") %&gt;%\n  ggplot(aes(x = Time, y = value)) +\n  geom_line() +\n  facet_grid(rows = vars(Series), scales = \"free_y\") +\n  labs(y = \"\")\n\n\n\n# Consumo versus temperatura\ndem_elec_vict %&gt;%\n  ggplot(aes(x = Temperatura, y = Demanda)) +\n  geom_point() +\n  ylab(\"Demanda (MWh)\") + xlab(\"Temperatura (ºC)\")\n\n\n\n# Comportamiento en días festivos\ndem_elec_vict %&gt;%\n  ggplot(aes(x = Temperatura, y = Demanda, col=Fiesta)) +\n  geom_point() +\n  ylab(\"Demanda (MWh)\") + xlab(\"Temperatura (ºC)\")\n\n\n\n# Comportamiento en días laborables\ndem_elec_vict %&gt;%\n  ggplot(aes(x = Temperatura, y = Demanda, col=Dia_lab)) +\n  geom_point() +\n  ylab(\"Demanda (MWh)\") + xlab(\"Temperatura (ºC)\")\n\n\n\n# Comportamiento por día de la semana\ndem_elec_vict %&gt;%\n  ggplot(aes(x = Temperatura, y = Demanda, col=Dia_sem)) +\n  geom_point() +\n  ylab(\"Demanda (MWh)\") + xlab(\"Temperatura (ºC)\")\n\n\n\n# Comportamiento en días de frío (&lt; 18ºC)\ndem_elec_vict %&gt;%\n  ggplot(aes(x = Temperatura, y = Demanda, col=Frio)) +\n  geom_point() +\n  ylab(\"Demanda (MWh)\") + xlab(\"Temperatura (ºC)\")\n\n\n\n# Comportamiento en días de calor (&gt; 28ºC)\ndem_elec_vict %&gt;%\n  ggplot(aes(x = Temperatura, y = Demanda, col=Calor)) +\n  geom_point() +\n  ylab(\"Demanda (MWh)\") + xlab(\"Temperatura (ºC)\")\n\n\n\n# Modelo de demanda de electricidad\ndem_elec &lt;- lm(log(Demanda) ~ Temperatura + I(Temperatura^2) + \n                 Dia_sem + Dia_lab + Frio + Calor, \n               data = dem_elec_vict)\nsummary(dem_elec)\n\n\nCall:\nlm(formula = log(Demanda) ~ Temperatura + I(Temperatura^2) + \n    Dia_sem + Dia_lab + Frio + Calor, data = dem_elec_vict)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.45248 -0.11107  0.02178  0.10933  0.45429 \n\nCoefficients:\n                   Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept)       8.449e+00  7.152e-03 1181.348  &lt; 2e-16 ***\nTemperatura      -2.707e-02  6.515e-04  -41.551  &lt; 2e-16 ***\nI(Temperatura^2)  9.218e-04  1.943e-05   47.439  &lt; 2e-16 ***\nDia_sem.L         2.621e-02  1.783e-03   14.695  &lt; 2e-16 ***\nDia_sem.Q         5.527e-02  4.781e-03   11.561  &lt; 2e-16 ***\nDia_sem.C         1.388e-02  1.784e-03    7.779 7.43e-15 ***\nDia_sem^4         3.442e-02  2.557e-03   13.462  &lt; 2e-16 ***\nDia_sem^5         6.508e-03  1.783e-03    3.650 0.000263 ***\nDia_sem^6         8.708e-03  1.796e-03    4.849 1.25e-06 ***\nDia_labTRUE       2.089e-01  4.179e-03   49.986  &lt; 2e-16 ***\nFrioTRUE          4.844e-03  2.500e-03    1.937 0.052713 .  \nCalorTRUE         5.543e-02  6.256e-03    8.859  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1544 on 52596 degrees of freedom\nMultiple R-squared:  0.3044,    Adjusted R-squared:  0.3043 \nF-statistic:  2093 on 11 and 52596 DF,  p-value: &lt; 2.2e-16\n\n# Predicción de consumo para un lunes laborable, suponiendo una \n# temperatura media de 26ª (podrían usarse predicciones del servicio \n# de meteorología local o nacional)\nXs_1d &lt;- new_data(dem_elec_vict, 1) %&gt;%\n    mutate(Temperatura = 26, Dia_sem = \"lun\" , Dia_lab = TRUE, \n           Frio = FALSE, Calor = FALSE)\npred_dem_IC &lt;- predict(dem_elec, Xs_1d[,2:6], \n                       interval = \"confidence\", level = 0.95)\npred_dem_IC\n\n       fit      lwr      upr\n1 8.554405 8.549117 8.559693\n\nexp(pred_dem_IC)\n\n       fit      lwr      upr\n1 5189.564 5162.194 5217.078"
  },
  {
    "objectID": "p2c2-app6.html#código-python",
    "href": "p2c2-app6.html#código-python",
    "title": "Aplicación 2.6 (Series temporales de alta frecuencia y estacionalidad): Demanda de electricidad en el estado de Victoria, Australia",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.formula.api as smf\n# Lectura de datos\ndem_elec_vict = pd.read_csv('data/DEM_ELEC.csv', index_col=0)\n# Gráfica consumo versus temperatura\nplt.figure(3)\nplt.scatter(dem_elec_vict['Temperatura'], dem_elec_vict['Demanda'])\nplt.xlabel('Temperatura (ºC)')\nplt.ylabel('Demanda (MWh)')\nplt.title('Consumo de electricidad versus temperatura')\nplt.grid(True)\nplt.show()\n\n\n\n# Modelo de demanda de electricidad\ndem_elec = smf.ols('np.log(Demanda) ~ Temperatura + np.power(Temperatura,2) + Dia_sem + Dia_lab + Frio + Calor', data=dem_elec_vict).fit()\nprint(dem_elec.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        np.log(Demanda)   R-squared:                       0.304\nModel:                            OLS   Adj. R-squared:                  0.304\nMethod:                 Least Squares   F-statistic:                     2093.\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):               0.00\nTime:                        08:22:18   Log-Likelihood:                 23634.\nNo. Observations:               52608   AIC:                        -4.724e+04\nDf Residuals:                   52596   BIC:                        -4.714e+04\nDf Model:                          11                                         \nCovariance Type:            nonrobust                                         \n============================================================================================\n                               coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------------------\nIntercept                    8.4662      0.007   1257.558      0.000       8.453       8.479\nDia_sem[T.jue]              -0.0257      0.005     -5.368      0.000      -0.035      -0.016\nDia_sem[T.lun]              -0.0401      0.005     -8.696      0.000      -0.049      -0.031\nDia_sem[T.mar]              -0.0314      0.005     -6.585      0.000      -0.041      -0.022\nDia_sem[T.mié]              -0.0307      0.005     -6.419      0.000      -0.040      -0.021\nDia_sem[T.sáb]               0.0425      0.003     16.853      0.000       0.038       0.047\nDia_sem[T.vie]              -0.0373      0.005     -7.820      0.000      -0.047      -0.028\nDia_lab[T.True]              0.2089      0.004     49.986      0.000       0.201       0.217\nFrio[T.True]                 0.0048      0.003      1.937      0.053   -5.68e-05       0.010\nCalor[T.True]                0.0554      0.006      8.859      0.000       0.043       0.068\nTemperatura                 -0.0271      0.001    -41.551      0.000      -0.028      -0.026\nnp.power(Temperatura, 2)     0.0009   1.94e-05     47.439      0.000       0.001       0.001\n==============================================================================\nOmnibus:                     1844.730   Durbin-Watson:                   0.055\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             1308.893\nSkew:                          -0.282   Prob(JB):                    5.99e-285\nKurtosis:                       2.472   Cond. No.                     5.87e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 5.87e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems."
  },
  {
    "objectID": "p3-mrl-extendido.html",
    "href": "p3-mrl-extendido.html",
    "title": "CAPÍTULO 3: DIAGNOSIS, CORRECCIONES Y EXTENSIONES DEL MODELO DE REGRESIÓN LINEAL",
    "section": "",
    "text": "En este último capítulo se lleva a cabo una introducción al proceso de diagnosis del modelo de regresión lineal, con especial referencia al cumplimiento de las hipótesis básicas. También, con el objeto de considerar posibles incumplimientos de dichas hipóteis, se proponen distintas correcciones y/o extensiones del modelo de regresión lineal."
  },
  {
    "objectID": "p3c1-teoria.html#criterios-generales-de-evaluación-y-validación-de-un-modelo-econométrico",
    "href": "p3c1-teoria.html#criterios-generales-de-evaluación-y-validación-de-un-modelo-econométrico",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.1 Criterios generales de evaluación y validación de un modelo econométrico",
    "text": "3.1 Criterios generales de evaluación y validación de un modelo econométrico\nUna vez que se ha estimado un modelo de regresión por MCO, se hace necesario calibrar hasta qué punto los resultados obtenidos pueden considerarse como aceptables, antes de proceder al uso empírico del modelo. Más aún, cuando se dispone de distintas especificaciones alternativas, de varias variables exógenas potenciales o de varias formas funcionales posibles, es preciso disponer de criterios que nos permitan seleccionar el modelo más idóneo.\nEn ambos casos, entre los criterios más importantes que pueden utilizarse para evaluar o validar uno o varios de los modelos estimados, se pueden destacar los siguientes:\n\n3.1.1 Coherencia del modelo estimado con los datos\nEn términos generales, al menos ha de exigirse que los modelos estimados ‘sean capaces de explicar los datos existentes’. Ello implica satisfacer distintas propiedades:\n\nEn primer lugar, se contrastará la significación conjunta del modelo (coeficientes \\(R^{2}\\) o \\({\\overline{R}}^{2}\\) y estadístico \\(F\\)) y la de los parámetros individuales (\\(t\\)-ratios), así como su adecuación a la teoría económica subyacente (signos y magnitudes de los coeficientes estimados correctos, propiedades de largo y corto plazo, etc.).\nTambién debe examinarse la coherencia a posteriori con las hipótesis establecidas a priori para el MRL. Aunque en los epígrafes 2 a 4 de este tema analizaremos de forma independiente cada una de ellas, existen en la literatura contrastes que permiten hacer una valoración general del cumplimiento de dichas hipótesis. En concreto, Peña y Slate (2006) han propuesto una prueba de validez global de las hipótesis del MRL que permite contrastar simultáneamente las propiedades P1-P4 que debe cumplir el modelo. El estadístico global se define por la expresión\n\\[{\\widehat{G}}_{4}^{2} = {\\widehat{S}}_{1}^{2} + {\\widehat{S}}_{2}^{2} + {\\widehat{S}}_{3}^{2} + {\\widehat{S}}_{4}^{2}\\]\ny cada componente de este, \\({\\widehat{S}}_{j}^{2}\\), es un estadístico direccional relacionado con el cumplimiento de las propiedades individuales. Como este estadístico tiene una distribución asintótica \\(\\chi^{2}\\), en términos prácticos puede asumirse que, siempre que se cumpla que \\(n - K \\geq 30\\), cuando se verifique \\({\\widehat{G}}_{4}^{2} &gt; \\chi_{4,\\alpha}^{2}\\) al menos una de las propiedades P1-P4 no es válida.\nAparte de estas medidas de coherencia global, los modelos elegidos deben ser ‘parsimoniosos’, esto es, no contener un excesivo número de parámetros, y a ser posible ‘anidar’ a todos los posibles modelos competidores. Esta última propiedad implica que el modelo empírico seleccionado no sólo debería ser coherente con los datos, sino también explicar por qué otros modelos competidores son capaces o no de hacer eso mismo.\n\n\n\n3.1.2 Estadísticos de precisión e información\nEstas medidas están basadas en la comparación entre los valores reales observados y los ajustados (predichos) por el modelo, e intentan medir el grado de acierto ex post en las predicciones del modelo. Existen diferentes formas de medir esta precisión de las predicciones.\nUna primera aproximación es representar, o bien los valores de la variable y frente a sus valores ajustados (estimados) \\(\\widehat{y}\\) , o los residuos de la estimación. Ambas representaciones pueden facilitar una importante información sobre la validez del modelo y el cumplimiento de las hipótesis básicas.\nEn segundo lugar, como medidas no gráficas de aproximación de las predicciones, o de la capacidad predictiva del modelo, se utilizan habitualmente los siguientes estadísticos de precisión:\n\nEl error cuadrático medio: &gt; \\(ECM = \\frac{\\sum_{i = 1}^{n}\\left( y_{i} - {\\widehat{y}}_{i} \\right)^{2}}{n}\\), &gt; o su raíz cuadrada, \\(RECM = \\sqrt{ECM}\\)\nEl error absoluto medio: &gt; \\(EAM = \\frac{\\sum_{i = 1}^{n}\\left| y_{i} - {\\widehat{y}}_{i} \\right|}{n}\\)\n\nFinalmente, también es habitual el uso de diferentes *estadísticos de información** para seleccionar entre los distintos modelos disponibles. Estos estadísticos están basados en el valor (del logaritmo) de la función de verosimilitud del MRL\n\\[\\log{L\\left( \\widehat{\\beta},{\\widehat{\\sigma}}^{2} \\right)} = - \\frac{n}{2}\\left\\lbrack 1 + \\log{2\\pi} + \\log(ECM) \\right\\rbrack\\]\nel cual mide la ‘distancia’ del modelo estimado respecto del modelo “real” y, por tanto, es una medida del ajuste estadístico proporcionado por las estimaciones. Entre los más importantes podemos mencionar los dos siguientes:\n\nCriterio de información de Akaike: \\(AIC = nlog(ECM) + 2K\\)\nCriterio Bayesiano de Schwarz: \\(BIC = nlog(ECM) + Klog(n)\\)\n\nPara cada uno de estos criterios se considera que el mejor modelo corresponde al menor valor del estadístico. Entre los dos criterios de selección propuestos, el \\(BIC\\) seleccionará en general el modelo más ‘parsimonioso’, es decir, el modelo con un menor número de parámetros libres a estimar, mientras que el \\(AIC\\) elegirá el más parametrizado."
  },
  {
    "objectID": "p3c1-teoria.html#especificación-del-modelo",
    "href": "p3c1-teoria.html#especificación-del-modelo",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.2 Especificación del modelo",
    "text": "3.2 Especificación del modelo\n\n3.2.1 Determinación de los regresores y de la forma funcional\nHasta el momento se ha tomado como punto de partida la hipótesis de que el modelo de regresión lineal \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\) está bien especificado. Este apartado se centrará en analizar las implicaciones prácticas que tiene una mala especificación del modelo de regresión.\nLos errores de especificación más frecuentes son la omisión de variables relevantes, la inclusión de variables irrelevantes o la elección de una forma funcional incorrecta. En general, estos errores proceden del desconocimiento del verdadero modelo que subyace tras un fenómeno económico, de la escasa disponibilidad de datos o de una teoría económica poco precisa. Un valor bajo del \\(R^{2}\\), signos incorrectos en las estimaciones de los parámetros o pocas variables significativas pueden ser indicativos de la omisión de variables importantes o de una forma funcional incorrecta. También puede ser útil el examen de los residuos, en los cuales puede detectarse algún patrón de comportamiento anormal, indicativo de la mala especificación del modelo.\n\n\n3.2.2 Omisión de variables relevantes\nCuando se omiten algunas variables relevantes de una regresión, \\(z_{1},z_{2},\\ldots,z_{s}\\), incluyendo en el modelo solo las variables \\(x_{1},x_{2},\\ldots,x_{K}\\), formalmente la situación que se plantea es la siguiente:\nModelo estimado: \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\)\nModelo verdadero: \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{Z\\gamma} + \\mathbf{e}\\)\nEn este caso, el estimador MCO puede escribirse como:\n\\[{\\widehat{\\mathbf{\\beta}}}_{MCO} = \\mathbf{\\beta} + (\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\mathbf{X}^{'}\\mathbf{Z\\gamma} + (\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\mathbf{X}^{'}\\mathbf{e}\\]\ny, en consecuencia, su esperanza viene dada por \\(E\\lbrack{\\widehat{\\mathbf{\\beta}}}_{MCO}\\rbrack = \\mathbf{\\beta} + (\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\mathbf{X}^{'}\\mathbf{Z\\gamma} \\neq \\mathbf{\\beta}\\). Por tanto, el estimador MCO es sesgado y además inconsistente, pues el sesgo \\((\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\mathbf{X}^{'}\\mathbf{Z\\gamma}\\) no desaparece al aumentar el tamaño de la muestra, salvo que se cumpla que \\(\\mathbf{X}^{'}\\mathbf{Z} = \\mathbf{0}\\), es decir, que las variables omitidas y las incluidas sean ortogonales entre sí, resultado bastante inusual en la práctica.\nTambién se puede demostrar que la varianza, \\(\\sigma^{2}\\), se estima con sesgo, \\(E({\\widehat{\\sigma}}^{2}) \\neq \\sigma^{2}\\) Por tanto, los intervalos de confianza y los contrastes de hipótesis son erróneos, lo cual puede dar lugar a conclusiones equivocadas.\n\n\n3.2.3 Inclusión de variables irrelevantes\nAhora el modelo estimado incluye algunas variables irrelevantes, \\(z_{1},z_{2},\\ldots,z_{s}\\), en su especificación. Es decir, la situación que se plantea es la siguiente:\nModelo verdadero: \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\)\nModelo estimado: \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{Z\\gamma} + \\mathbf{e}\\)\nSe puede demostrar que, en este caso, se tienen las siguientes propiedades:\n\n\\({\\widehat{\\mathbf{\\beta}}}_{MCO}\\) es un estimador insesgado y consistente de β, \\(E\\left( {\\widehat{\\mathbf{\\beta}}}_{MCO} \\right) = \\mathbf{\\beta}\\), aunque no es eficiente ya que el modelo verdadero coincide con el modelo estimado si se impone la restricción γ = 0, siendo entonces aplicables los resultados obtenidos con el estimador de mínimos cuadrados restringidos.\nLa varianza residual \\({\\widehat{\\sigma}}^{2} = \\frac{\\sum_{i = 1}^{n}{\\widehat{e}}_{i}^{2}}{n - K}\\) es un estimador insesgado, \\(E\\left( {\\widehat{\\sigma}}^{2} \\right) = \\sigma^{2}\\).\nLos procedimientos usuales de intervalos de confianza y contrastes de hipótesis siguen siendo válidos, aunque hay que tener en cuenta que las varianzas estimadas serán mayores que las del modelo verdadero (la inferencia estadística será, por tanto, menos fiable).\n\n\n\n3.2.4 El contraste RESET de especificación correcta de la forma funcional\nUn contraste muy utilizado para analizar la correcta especificación funcional de un modelo de regresión es la llamada prueba RESET (REgression Specification Error Test) de Ramsey. La esencia del test se basa en contrastar si en un modelo de regresión deben añadirse regresores adicionales, \\(z_{1},z_{2},\\ldots,z_{s}\\), a los ya considerados en el modelo estándar \\(x_{1},x_{2},\\ldots,x_{K}\\): si se comete un error por omisión de variables relevantes, las variables adicionales z’s deberían ser incluidas en la regresión; si el problema deriva de una forma funcional incorrecta, las variables incluidas deberán ser alguna función (logaritmos, potencias, recíprocos o alguna otra transformación) de las variables xj ya incluidas en la regresión. En ambos casos, los errores de especificación funcional provocan que el estimador MCO sea sesgado e inconsistente y los procedimientos de inferencia estándar no serán válidos.\nSi, a priori, se desconoce si se está cometiendo un error de especificación (del tipo que sea), Ramsey sugiere utilizar como aproximaciones de las posibles variables omitidas las potencias de los valores predichos de la variable dependiente (\\({\\widehat{y}}_{i}^{2},{\\widehat{y}}_{i}^{3},\\ldots\\)) al estimar el modelo \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\) por MCO, contrastando su significación al añadirlas al modelo original.\nAsí, en términos operativos, la prueba RESET consiste en contrastar\n\\[H_{0}:\\{ forma\\ funcional\\ correcta\\}\\ \\ frente\\ a\\ \\ H_{1}:\\{ forma\\ funcional\\ incorrecta\\}\\]\nPara llevar a cabo el test se procede del siguiente modo:\n\nSe estima el modelo original por MCO y se obtienen los valores ajustados de la regresión, \\(\\widehat{y}\\).\nSe estima la regresión de y frente a los regresores originales y las potencias de \\(\\widehat{y}\\). Cuando se incluye sólo la variable \\({\\widehat{y}}^{2}\\ \\)se denomina al test RESET(1) \\[y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + ... + \\beta_{K}x_{Ki} + \\gamma_{1}{\\widehat{y}}_{i}^{2} + e_{t}\\] mientras que si se incluyen las potencias segunda y tercera (\\({\\widehat{y}}_{i}^{2}\\) y \\({\\widehat{y}}_{i}^{3}\\)), RESET(2)\n\\[y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + ... + \\beta_{K}x_{Ki} + \\gamma_{1}{\\widehat{y}}_{i}^{2} + \\gamma_{2}{\\widehat{y}}_{i}^{3} + e_{t}\\]\ny así sucesivamente.\nPor último, se contrasta mediante un test F de restricciones lineales la significación de las potencias de \\(\\widehat{y}\\): \\(H_{0}:\\left\\{ \\gamma_{1} = 0 \\right\\}\\) para el test RESET(1), \\(H_{0}:\\left\\{ \\gamma_{1} = 0\\ ,\\ \\gamma_{2} = 0 \\right\\}\\) para el test RESET(2), etc.\n\nSi se rechaza la hipótesis nula, ello implicará que la forma funcional propuesta no es la adecuada, por lo que habrá que investigar si la variable dependiente y o alguna de las variables en la matriz de variables explicativas X deberían transformarse (por ejemplo, tomando logaritmos), si deberían añadirse regresores adicionales (por ejemplo, las potencias de alguna variable explicativa) o, de forma más general, si debería especificarse un modelo no lineal en lugar de una relación lineal."
  },
  {
    "objectID": "p3c1-teoria.html#estabilidad-de-los-parámetros-estructurales",
    "href": "p3c1-teoria.html#estabilidad-de-los-parámetros-estructurales",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.3 Estabilidad de los parámetros estructurales",
    "text": "3.3 Estabilidad de los parámetros estructurales\nEn el capítulo 2 se han tratado las cuestiones de cómo estimar el vector de parámetros \\(\\mathbf{\\beta}\\) del modelo lineal \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\), obtener intervalos o regiones de confianza, contrastar diferentes hipótesis y realizar predicciones. Para ello, partíamos de unas hipótesis básicas, que nos permitían obtener el estimador MCO y sus propiedades.\nUna de estas hipótesis, la constancia de los parámetros estructurales a lo largo de las observaciones muestrales es, en muchas ocasiones, difícilmente sostenible. Así, por ejemplo, si estimamos una función de producción de las empresas industriales, puede ser una hipótesis demasiado restrictiva considerar que la función es la misma para las empresas pequeñas y grandes; o si se está estudiando la función de consumo de las familias españolas desde 1950 hasta la actualidad, puede ocurrir que ésta no permanezca constante durante todo ese período.\nPor otro lado, si el objetivo de un estudio es la determinación de los factores que influyen en las ventas de unos grandes almacenes, debemos aceptar que existe una fuerte estacionalidad en el comportamiento de los consumidores, lo que puede hacer dudar acerca la hipótesis de constancia de los parámetros entre las distintas estaciones.\nPor último, pueden existir razones a priori para sospechar que durante el período de observación han existido fenómenos o hechos que han provocado un cambio o una ruptura en la estructura del modelo. Así, por ejemplo, la entrada en la Unión Europea, la implantación del euro, las guerras del petróleo de los años 70, las crisis financieras, la aparición de nuevas tecnologías, el cambio del marco legislativo, etc., pueden ser la causa de que exista cambio estructural.\nSi disponemos de datos de series temporales, y han existido uno o varios momentos en los cuales han cambiado las estructuras, en nuestro conjunto de datos existirán dos o más modelos. En el caso de datos de corte transversal, la situación puede ser análoga por la existencia de dos o más subpoblaciones, con diferentes parámetros estructurales cada una de ellas.\n\n3.3.1 Los contrastes de Chow y Quandt de cambio estructural\nDado un modelo lineal, para el cual se dispone de T observaciones temporales, supongamos que se conoce la existencia un momento en el período de observación que nos hace sospechar de un cambio estructural. Si el cambio ha tenido lugar en el momento T1+1, las primeras T1 observaciones y las T2 últimas (T=T1+T2) corresponderán a diferentes estructuras. Analíticamente:\n\\[y_{t} = \\beta_{1}^{1} + \\beta_{2}^{1}x_{2t} + \\cdots + \\beta_{K}^{1}x_{Kt} + e_{t}\\ \\ para\\ \\ t = 1,2,\\ldots,T_{1}\\]\n\\[y_{t} = \\beta_{1}^{2} + \\beta_{2}^{2}x_{2t} + \\cdots + \\beta_{K}^{2}x_{Kt} + e_{t}\\ \\ para\\ \\ t = T_{1} + 1,\\ldots,T\\]\no en forma matricial\n\\[\\mathbf{y}^{1} = \\mathbf{X}^{1}\\mathbf{\\beta}^{1} + \\mathbf{e}^{1}\\] \\[\\mathbf{y}^{2} = \\mathbf{X}^{2}\\mathbf{\\beta}^{2} + \\mathbf{e}^{2}\\]\ndonde \\(\\mathbf{\\beta}^{i}\\), yi, Xi, ei son los vectores y matrices con la estructura, los valores de las observaciones y los errores, respectivamente, para cada período i (i = 1, 2).\nDe este modo, la hipótesis de estabilidad estructural, o existencia de una sola estructura, vendrá dada por\n\\[H_{0}:\\{\\mathbf{\\beta}^{1} = \\mathbf{\\beta}^{2}\\}\\ \\ frente\\ a\\ \\ H_{1}:\\{\\mathbf{\\beta}^{1} \\neq \\mathbf{\\beta}^{2}\\}\\]\nSe trata de un contraste de hipótesis de K restricciones lineales que, por lo tanto, se puede realizar mediante el uso del estadístico F, lo cual da lugar a la prueba de Chow, que toma la forma siguiente:\n\\[CHOW = \\frac{(SRCT - (SRC1 + SRC2))/K}{(SRC1 + SRC2)/(T - 2K)}\\]\ndonde SRCT es la suma de cuadrados residual de la estimación MCO del modelo \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\) con las T observaciones, mientras que SRC1 y SRC2 denotan, respectivamente, las sumas de los cuadrados de los residuos de las estimaciones MCO de los modelos \\(\\mathbf{y}^{1} = \\mathbf{X}^{1}\\mathbf{\\beta}^{1} + \\mathbf{e}^{1}\\) y \\(\\mathbf{y}^{2} = \\mathbf{X}^{2}\\mathbf{\\beta}^{2} + \\mathbf{e}^{2}\\). Al ser un contraste F de restricciones lineales, el estadístico propuesto se distribuye bajo la hipótesis nula \\(H_{0}:\\{\\mathbf{\\beta}^{1} = \\mathbf{\\beta}^{2}\\}\\) como \\(\\ CHOW\\sim F_{K,\\ \\ T - 2K}\\) .\nSi en lugar de trabajar con datos de series temporales se contase con datos de corte transversal, la prueba de Chow comenzaría ordenando las observaciones respecto a alguna variable concreta (el origen del cambio estructural), que dividiría la muestra en dos subconjuntos distintos, y usando los grupos de las n1 primeras observaciones y de las n2 últimas observaciones para el contraste.\nEl test de Chow estándar es el más extendido en la literatura econométrica para contrastar la hipótesis de estabilidad estructural. No obstante, su aplicación presenta algunos problemas:\n\nTal como se ha expuesto, el test sólo permite contrastar la presencia, ante la hipótesis alternativa, de dos estructuras presentes en la muestra. Sin embargo, el contraste estándar puede extenderse al caso general en que puedan existir m estructuras diferentes en las observaciones muestrales. En esta ocasión, el estadístico de cambio estructural, con puntos de ruptura conocidos, tiene la forma expresión\n\\[CHOW = \\frac{(SRCT - (SRC1 + SRC2 + ... + SRCm)/(m - 1)K}{(SRC1 + SRC2 + ... + SRCm)/(T - mK)}\\]\ny, bajo la hipótesis nula \\(H_{0}:\\{\\mathbf{\\beta}^{1} = \\mathbf{\\beta}^{2} = \\ldots = \\mathbf{\\beta}^{m}\\}\\), sigue una distribución \\(CHOW\\sim F_{(m - 1)K,\\ \\ T - mK}\\ \\).\nSe necesita conocer el punto de la muestra en el que se produce el cambio estructural. Esto significa que, en el caso de series temporales, se ha de saber la fecha exacta en la que hipotéticamente se produce el cambio en los parámetros de la regresión; o, de igual modo, en el caso de datos de corte transversal, el grupo de observaciones que puede poseer una estructura diferente al resto debe estar localizado a priori. Cuando no se conoce el punto de ruptura en el que se produce el cambio estructural, el contraste de Chow puede modificarse, dando lugar al contraste de Quandt. Este se basa en la aplicación recursiva del test de Chow, calculando los estadísticos F de cambio estructural en ‘todos’ los puntos posibles de la muestra (para que los estadísticos propuestos tengan buenas propiedades asintóticas, en la práctica sólo se calculan los estadísticos sobre un subconjunto reducido de datos, prescindiendo de un porcentaje de observaciones en los extremos de la muestra) y computando después un estadístico resumido de dichos valores. En concreto, si llamamos \\(CHOW(\\tau)\\) al test que contrasta la presencia de cambio estructural en la observación \\(\\tau\\), el contraste de Quandt toma la expresión siguiente:\n\\[QLR = \\max_{\\tau_{1} \\leq \\tau \\leq \\tau_{2}}{CHOW(\\tau)}\\ \\]\ndonde \\(\\tau_{1}\\) y \\(\\tau_{2}\\) representan las observaciones entre las que se sospecha se puede producir el cambio estructural (se eliminan, por tanto, las observaciones anteriores a \\(\\tau_{1}\\), y la posteriores a \\(\\tau_{2}\\), normalmente un 15% del total). Este estadístico no tiene una distribución estándar y, por tanto, deben utilizarse valores críticos (o P-valores) específicos.\n\n\n\n3.3.2 Consecuencias de la presencia de cambio estructural\nUna vez visto cómo proceder para detectar la existencia de posibles cambios de estructura, cabe preguntarse cuáles son las consecuencias para el modelo de regresión de un resultado positivo en tal contraste estadístico.\nEn general, puede decirse que las consecuencias prácticas que origina la presencia de cambio estructural en un modelo de regresión son graves. Si se estima un modelo \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\), cuando realmente existen dos (o más) estructuras diferentes, \\(\\mathbf{y}^{1} = \\mathbf{X}^{1}\\mathbf{\\beta}^{1} + \\mathbf{e}^{1}\\) y \\(\\mathbf{y}^{2} = \\mathbf{X}^{2}\\mathbf{\\beta}^{2} + \\mathbf{e}^{2}\\), el estimador mínimo-cuadrático del vector β será una ‘mezcla’ de los correspondientes a cada submuestra y, por tanto, el estimador MCO de los parámetros estructurales será sesgado e inconsistente; del mismo modo, también estarán sesgadas las estimaciones de las varianzas y, por tanto, la inferencia estadística no será fiable, y, en general, se producirán errores en los contrastes de significación y en los intervalos de confianza.\n\n\n3.3.3 Regresiones con parámetros variables\nEn la práctica econométrica, existen situaciones en que la hipótesis de que los parámetros son constantes a lo largo de todas las observaciones puede no ser válida. Así, para datos de corte transversal puede existir heterogeneidad individual, de forma que los parámetros cambien a través de las diferentes unidades de la sección cruzada. De igual forma, para datos de series temporales pueden presentarse variaciones sistemáticas de los parámetros a lo largo del tiempo. Finalmente, en el caso mixto, para datos de panel puede haber variaciones de los parámetros tanto a lo largo del tiempo como para las distintas unidades.\n\n3.3.3.1 Modelos con variables ficticias\nSe han propuesto en la literatura diversos modelos para abordar el problema de la inestabilidad paramétrica en situaciones como las descritas en el párrafo anterior. Uno de los más utilizados consiste en la introducción de las denominadas variables ficticias (también llamadas variables tipo “dummy”) en los modelos econométricos como una forma de modelizar el cambio estructural que puede suponer la pertenencia a un determinado grupo de individuos (sexo, nivel de estudios, status socio-económico, raza, etc.), de empresas (tamaño, sector económico, stock de capital, etc.), de regiones/países (riqueza, ubicación geográfica, capital tecnológico, etc.) o a un determinado período temporal (entrada en la UE, creación del euro, períodos de recesión, crisis petrolíferas o financieras, etc.).\nLas variables ficticias permiten construir modelos econométricos en los que uno, varios, o todos los parámetros de la regresión varían en función de alguna característica o pertenencia de las observaciones a algún grupo concreto. En general, una variable ficticia de tipo binario, D, se define como sigue:\n\\[\\ D = \\left\\{ \\begin{matrix}\n\\ 1 & \\text{para\\ las\\ observaciones\\ que\\ cumplen\\ cierta\\ condición\\ } \\\\\n\\ 0 & \\text{para\\ las\\ observaciones\\ que\\ no\\ cumplen\\ dicha\\ condición\\ } \\\\\n\\end{matrix} \\right.\\ \\]\nSirvan como ejemplos los siguientes: Di = 1 si el individuo observado es una mujer (0 si es un hombre); Di = 1 si la empresa es grande (0 si es pequeña); o Dt = 1 si la observación pertenece a un cierto período de tiempo o es posterior a una cierta fecha (0 si es anterior). En todos los casos, el valor D = 0 define el grupo de referencia, también llamado categoría base de comparación.\nVeamos cómo se pueden utilizar estas variables dicotómicas para modelizar el cambio estructural en los modelos de regresión.\nSupongamos que nos encontramos con dos estructuras diferentes en un modelo de regresión: \\(\\ \\mathbf{y}^{1} = \\mathbf{X}^{1}\\mathbf{\\beta}^{1} + \\mathbf{e}^{1}\\ \\) y \\(\\ \\mathbf{y}^{2} = \\mathbf{X}^{2}\\mathbf{\\beta}^{2} + \\mathbf{e}^{2}\\). Se puede llegar a estos modelos parciales definiendo un modelo de regresión global con parámetros no constantes dado por\n\\[\\mathbf{y} = {\\mathbf{X}\\mathbf{\\beta}_{i} + \\mathbf{e}}_{\\mathbf{\\ }}\\]\ndonde\n\\[\\mathbf{\\beta}_{i} = {\\mathbf{\\beta} + \\mathbf{\\alpha}D_{i}}_{\\mathbf{\\ }}\\]\ncon \\(\\mathbf{\\alpha} = \\left( \\alpha_{1},\\alpha_{2},\\ldots,\\alpha_{K} \\right)^{'}\\), y Di = 0 para las observaciones de la primera estructura y Di = 1 para las observaciones de la segunda estructura. Se tiene entonces que \\(\\ \\mathbf{\\beta}^{1} = \\mathbf{\\beta}_{\\mathbf{\\ }}\\), si Di=0, y \\(\\ \\mathbf{\\beta}^{2} = {\\mathbf{\\beta} + \\mathbf{\\alpha}}_{\\mathbf{\\ }}\\) si Di = 1. Por tanto, pueden expresarse las dos estructuras mediante una única ecuación dada por\n\\[y_{t} = {\\beta_{1} + \\beta_{2}x_{2t} + \\ldots + \\beta_{K}x_{Kt} + \\alpha_{1}D_{t} + \\alpha_{2}x_{2t}D_{t} + \\ldots + \\alpha_{K}x_{Kt}D_{t} + e_{t}}_{\\mathbf{\\ }}\\]\no, en forma matricial,\n\\[\\mathbf{y} = {\\mathbf{X\\beta} + \\mathbf{X}^{*}\\mathbf{\\alpha} + \\mathbf{e}}_{\\ }\\]\ndonde la matriz \\(\\mathbf{X}^{*} = \\left( \\mathbf{X} \\times D \\right)\\) está compuesta por las que se conocen como variables de interacción, que son producto de los regresores originales x’s multiplicados por la ficticia D, y sus parámetros asociados, α’s, miden el cambio que se produce en las pendientes de la regresión al pasar de un grupo de observaciones al otro.\nPara los distintos grupos de observaciones se tiene que:\n\\[\\left\\{ \\begin{matrix}{\\ y}_{t} = \\beta_{1} + \\beta_{2}x_{2t} + \\ldots + \\beta_{K}x_{Kt} + e_{t}\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ para\\ D_{t} = 0 \\\\\n{\\ y}_{t} = {(\\beta}_{1} + \\alpha_{1}) + {(\\beta}_{2} + \\alpha_{2})x_{2t} + \\ldots + {(\\beta}_{K} + \\alpha_{K})x_{Kt} + e_{t}\\ \\ \\ \\ \\ \\ \\ para\\ D_{t} = 1 \\\\\n\\end{matrix} \\right.\\ \\]\nEl contraste de la hipótesis \\(H_{0}:\\left\\{ \\mathbf{\\beta}^{1} = \\mathbf{\\beta}^{2} \\right\\}\\) es equivalente a la prueba de igualdad a cero de los parámetros α’s, \\(H_{0}:\\left\\{ \\mathbf{\\alpha} = \\mathbf{0} \\right\\}\\). De hecho, se puede demostrar que el contraste F de la hipótesis \\(H_{0}:\\left\\{ \\alpha_{1} = \\alpha_{2} = \\ldots = \\alpha_{K} = 0 \\right\\}\\) coincide numéricamente con el valor del estadístico de CHOW de presencia de cambio estructural.\nEn general, el modelo \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{X}^{*}\\mathbf{\\alpha} + \\mathbf{e}\\) puede utilizarse para contrastar hipótesis intermedias de igualdad de cualquier subconjunto de parámetros individuales en subpoblaciones (ordenadas en el origen, pendientes, etc.) y, en todos los casos, la hipótesis de estabilidad paramétrica equivaldrá a un contraste F donde la hipótesis nula H0 sería la igualdad a cero de los correspondientes parámetros α’s.\nComo ejemplo, consideremos la siguiente regresión transversal \\(y_{i} = \\beta_{1} + \\beta_{2}x_{i} + e_{i}\\) que representa un modelo familiar de consumo de tipo Keynesiano, donde y denota el consumo total y x la renta disponible; en este caso particular, \\(\\beta_{1}\\) podría interpretarse como un “consumo autónomo” y \\(\\beta_{2}\\) será la propensión marginal al consumo respecto a la renta. Supongamos que se tiene la intuición de que el modelo de consumo de las familias que viven en un ambiente rural es distinto del modelo de comportamiento que se observa en las familias que residen en las ciudades. Para analizar si esta hipótesis es cierta, puede construirse una variable ficticia, D, que tome los siguientes valores:\n\\[D_{i} = \\left\\{ \\begin{matrix}\n\\ 1 & \\text{si\\ la\\ familia\\ }i\\text{\\ vive\\ en\\ una\\ zona\\ rural\\ } \\\\\n\\ 0 & \\text{si\\ la\\ familia\\ }i\\text{\\ vive\\ en\\ una\\ zona\\ urbana\\ } \\\\\n\\end{matrix} \\right.\\ \\]\ny, a continuación, introducir dicha variable en la regresión original, con lo que se llega al modelo\n\\[y_{i} = \\beta_{1} + \\beta_{2}x_{i} + \\alpha_{1}D_{i} + \\alpha_{2}{x_{i}D}_{i} + e_{i}\\]\nSuponiendo que se rechaza la hipótesis nula de ausencia de cambio estructural, \\(H_{0}:\\left\\{ \\alpha_{1} = 0,\\alpha_{2} = 0 \\right\\}\\), pueden darse las situaciones siguientes: que se produce sólo un cambio en la propensión marginal al consumo, que varíe solo el consumo autónomo y, finalmente, que varíen ambos parámetros.\n\n\n3.3.3.2 El caso general donde los parámetros son función de una variable conocida\nPuede generalizarse la especificación anterior asumiendo un modelo lineal del tipo\\(\\mathbf{\\ }y_{i} = {\\beta_{1i} + \\beta_{2i}x_{i} + e_{i}}_{\\mathbf{\\ }}\\), donde los parámetros β’s dependen de alguna(s) variable(s) conocida(s), no necesariamente ficticia. Así, si se supone que \\({\\ \\beta}_{1i} = {\\beta_{1} + \\alpha_{1}z_{i}}_{\\mathbf{\\ }}\\) y \\({\\ \\beta}_{2i} = {\\beta_{2} + \\alpha_{2}z_{i}}_{\\mathbf{\\ }}\\) para alguna variable zi, entonces, substituyendo estas expresiones en la ecuación de regresión inicial se llega a la expresión siguiente:\n\\[y_{i} = {\\beta_{1} + \\alpha_{1}z_{i} + \\beta_{2}x_{i} + \\alpha_{2}x_{i}z_{i} + e_{i}}_{\\mathbf{\\ }}\\]\nCuando los parámetros αj son iguales a cero en la regresión anterior, se obtiene el modelo clásico \\(y_{i} = \\beta_{1} + \\beta_{2}x_{i} + e_{i}\\). Por tanto, se puede contrastar fácilmente la hipótesis de constancia de los parámetros del modelo de regresión original mediante una prueba F de la hipótesis conjunta \\(H_{0}:\\left\\{ \\alpha_{1} = \\alpha_{2} = 0 \\right\\}\\).\nUn caso particular de regresión en el que uno de los parámetros depende de una variable z, en concreto, de tipo ficticio, lo constituyen los llamados modelos de regresión lineal por tramos. Este tipo de modelos forman parte de una clase general de diseños, las regresiones discontinuas (RD), que se utilizan en el análisis de evaluación del impacto de programas o políticas sobre un indicador de resultados.\nSupongamos que partimos de una especificación lineal \\(y_{t} = \\beta_{1} + \\beta_{2t}x_{t} + e_{t}\\) en la que el parámetro de la pendiente no es constante, sino que se tiene que \\(\\beta_{2t} = \\beta_{2} + \\alpha_{2}D_{t}\\), donde D es una variable ficticia definida por \\(D_{t} = \\left\\{ \\begin{matrix} 1\\ \\ si\\ x_{t} \\geq x^{*} \\\\ 0\\ \\ si\\ x_{t} &lt; x^{*} \\\\ \\end{matrix} \\right.\\ \\) . Entonces, el modelo de regresión\n\\[y_{t} = {\\beta_{1} + \\beta_{2}x_{t} + \\alpha_{2}{\\left( x_{t} - x^{*} \\right)D}_{t} + e_{t}}_{\\mathbf{\\ }}\\]\ntomará la forma de una regresión lineal discontinua a tramos que “pivota” sobre el punto \\(x^{*}\\).\nOtro ejemplo de modelos con parámetros dependientes de alguna variable es aquel en el que z representa alguna variable de escala de tipo cuantitativo. Por ejemplo, si se usan datos de corte transversal, la variable z puede describir el tamaño de la empresa, \\({\\ z}_{i} = tamaño_{i}\\) , medido a través del número de empleados o el volumen de activos. Para datos de series temporales, el caso más típico es aquel en que \\({\\ z}_{t} = t\\ \\), es decir, los parámetros evolucionan en el tiempo siguiendo una tendencia (creciente o decreciente); o el caso más general en el que en lugar de una recta se utiliza una parábola para describir la evolución temporal de los parámetros, \\({\\ \\beta}_{ji} = {\\beta_{j} + \\alpha_{j}^{1}z_{1i} + \\alpha_{j}^{2}z_{2i}}_{\\mathbf{\\ }}\\), donde \\({\\ z}_{1t} = t_{\\ }\\) y \\({\\ z}_{2t} = t_{\\ }^{2\\ }\\).\nFinalmente, también aparecen parámetros variables ante la presencia de efectos estacionales en modelos que usan datos de series temporales con frecuencia inferior a la anual (trimestres, meses o semanas). En estos casos, la especificación más común de estos efectos es aquella en la que la ordenada en el origen —pero no en las pendientes— varía de una “estación” a otra. Por ejemplo, para el caso de datos trimestrales, es frecuente proponer modelos de regresión del tipo \\(y_{t} = \\beta_{1t} + \\beta_{2}x_{t} + e_{t}\\), donde \\(\\ \\beta_{1t} = {\\beta_{1} + \\alpha_{1}^{1}D_{1t} + \\alpha_{1}^{2}D_{2t} + \\alpha_{1}^{3}D_{3t}}_{\\mathbf{\\ }}\\), siendo \\(D_{jt} = 1\\) para el j-ésimo trimestre y 0 en el resto de los trimestres. Como puede observarse, al haber introducido el parámetro β1 asociado a la constante, en el modelo sólo deben aparecer tres de las cuatro posibles variables ficticias, tomando como referencia una de ellas, en nuestro ejemplo la variable \\(D_{4t}\\) correspondiente al cuarto trimestre. Así se evita la llamada “trampa de las variables ficticias”, puesto que, si se introdujesen las cuatro variables ficticias, ello implicaría un problema de multicolinealidad perfecta, ya que por definición se cumple que \\(D_{1t} + D_{2t} + D_{3t} + D_{4t} = 1\\), es decir, son linealmente dependientes."
  },
  {
    "objectID": "p3c1-teoria.html#distribución-de-los-errores-del-modelo",
    "href": "p3c1-teoria.html#distribución-de-los-errores-del-modelo",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.4 Distribución de los errores del modelo",
    "text": "3.4 Distribución de los errores del modelo\n\n3.4.1 No normalidad de las perturbaciones\nAl obtener las propiedades del estimador MCO de \\(\\mathbf{\\beta}\\) en el modelo de regresión\\(\\mathbf{\\ }\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\), \\({\\widehat{\\mathbf{\\beta}}}_{MCO}\\mathbf{=}\\left( \\mathbf{X}^{'}\\mathbf{X} \\right)^{- 1}\\mathbf{X}^{'}\\mathbf{y}\\), se demuestra que es lineal, insesgado y de mínima varianza entre los estimadores lineales e insesgados (teorema de Gauss-Markov), todo ello sin utilizar la hipótesis de normalidad del vector de errores e. Si se cumple además esta última propiedad, \\(e_{\\mathbf{i}}\\sim N\\), el estimador MCO es eficiente, es decir, el mejor de todos los estimadores insesgados, incluyendo los estimadores no lineales.\nAdemás, para obtener la distribución de \\({\\widehat{\\mathbf{\\beta}}}_{MCO}\\) se necesita la propiedad de normalidad de la distribución de las perturbaciones, cumpliéndose entonces que \\({\\widehat{\\mathbf{\\beta}}}_{MCO}\\sim N_{n}(\\mathbf{\\beta},\\sigma^{2}\\left( \\mathbf{X}^{'}\\mathbf{X} \\right)^{\\mathbf{-}\\mathbf{1}}\\mathbf{)}\\). Este hecho permite realizar inferencias sobre el vector \\(\\mathbf{\\beta}\\) y sus componentes \\(\\beta_{i},\\ i = 1,2,\\ldots,K\\) (obtención de intervalos de confianza, contraste t sobre los parámetros individuales, test F para la significación global del modelo, restricciones lineales, etc.).\n\n\n3.4.2 Consecuencias de la no normalidad\nComo corolario de los dos resultados anteriores, cuando el término de error \\(\\mathbf{e}\\) no se distribuye como una variable aleatoria normal, \\(e_{\\mathbf{i}} ≄ N\\), el estimador MCO de β deja de ser eficiente y, además, no pueden en principio realizarse inferencias fiables por desconocerse la distribución exacta del estimador. Por tanto, los intervalos de confianza y los contrastes t y F dejan de ser válidos.\n\n\n3.4.3 El test de Jarque-Bera de normalidad\nPara saber si en un modelo de regresión se satisface la hipótesis de normalidad de los errores pueden utilizarse diferentes contrastes, entre los que podemos destacar, por su amplia difusión, la prueba de Jarque-Bera. La hipótesis que contrastar es\n\\[H_{0}:\\left\\{ e\\sim N \\right\\}\\ \\ \\ frente\\ a\\ \\ \\ H_{1}:\\left\\{ e\\sim\\ Ρ \\right\\}\\]\nsiendo \\(Ρ\\) la familia Pearson, una clase general de distribuciones probabilísticas continuas que incluye la Normal, Chi-cuadrado, Beta, Gamma, t de Student, F de Fisher-Snedecor, Pareto, etc.\nEl contraste se basa en el estadístico\n\\[JB = (n - K)\\left( \\frac{A^{2}}{6} + \\frac{(C - 3)^{2}}{24} \\right)\\]\nque se calcula utilizando los coeficientes de apuntamiento o asimetría (A) y curtosis o curvatura (C) de la distribución de residuos mínimo-cuadráticos. Si la distribución de los errores fuese exactamente una normal estándar, debería cumplirse que A=0 y C=3. El estadístico de Jarque-Bera sigue asintóticamente, si la hipótesis nula de normalidad es cierta, una distribución Chi-cuadrado, \\(JB\\overset{as}{\\sim}\\chi_{2}^{2}\\ \\).\nSi el valor obtenido para el test de Jarque-Bera es significativo (si se rechaza H0), los resultados de los contrastes t y F de la estimación MCO no son válidos en sentido estricto. Sin embargo, puede demostrarse que, bajo condiciones muy generales, se verifica que\n\\[\\ \\frac{{\\widehat{\\beta}}_{i} - \\beta_{i}}{se({\\widehat{\\beta}}_{i})}\\ \\overset{as}{\\sim}\\ N(0,1)\\]\nrazón por la cual, con un tamaño de muestra suficientemente grande, puede seguir utilizándose el estadístico t, aunque usando las tablas de la distribución normal estándar para contrastar hipótesis sobre los parámetros individuales. Por otra parte, en lugar del contraste F, puede utilizarse el test de Wald, que además es un test válido para contrastar cualquier tipo de restricciones, lineales y no lineales, cumpliéndose que \\(W\\ \\overset{as}{\\sim}\\chi_{q}^{2}\\ \\), siendo q el número de restricciones.\n\n\n3.4.4 Estimación robusta del MRL\nCuando la perturbación del MRL no se distribuye normalmente, el estimador MCO de los parámetros β del modelo es aún el mejor estimador lineal insesgado (MELI) y es consistente, pero no eficiente, ni siquiera asintóticamente. También se puede demostrar que el estimador propuesto para σ^2 es insesgado bajo la hipótesis alternativa de errores no normales, y además es consistente.\nPor otro lado, del teorema central del límite se obtiene que el estimador MCO de β tiene una distribución asintóticamente normal y que los intervalos de confianza y los contrastes de hipótesis siguen siendo asintóticamente válidos aún si los errores no son normales. Ello significa que todos los resultados del modelo de regresión lineal general valen de forma aproximada para muestras de tamaño elevado sea cual sea la distribución del término de perturbación.\nAhora bien, las estimaciones obtenidas por el método de MCO pueden ser bastante ineficientes (y, por tanto, imprecisas y poco fiables) respecto a otros métodos de estimación.\nSe ha criticado al método de MCO por ser excesivamente sensible a la presencia de observaciones atípicas en la muestra, que se estudiarán en un apartado posterior. Estas observaciones anormales pueden ser originadas, entre otras causas, por fenómenos climatológicos excepcionales, huelgas, sucesos políticos, crisis económicas o financieras, guerras, o simplemente por errores en la medición (incluso de transcripción) de las variables que aparecen en el modelo. Precisamente dichas desviaciones extremas suelen ser una de las causas más frecuentes del incumplimiento de la hipótesis de normalidad, ya que su alejamiento de los valores promedio hace que la distribución muestral de los residuos (los cuales serán grandes para esas observaciones) tenga colas más amplias y una varianza mayor (incluso infinita) de la que le correspondería si se tratase de una distribución normal.\nPor todo ello, se han propuesto en la literatura econométrica métodos alternativos al de MCO que son más robustos frente a la hipótesis de normalidad, en general, y a la presencia de observaciones extremas, en particular. Estos métodos son capaces de modelizar los errores de una forma más adecuada que el de MCO, permitiendo colas más gruesas y varianzas mayores en las distribuciones de los residuos del modelo. Debe entenderse por “robustez” la propiedad de que estos estimadores funcionan mucho mejor que el de MCO en el caso de no normalidad y de modo similar a aquel en el caso de que la distribución de los errores sea normal."
  },
  {
    "objectID": "p3c1-teoria.html#heteroscedasticidad",
    "href": "p3c1-teoria.html#heteroscedasticidad",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.5 Heteroscedasticidad",
    "text": "3.5 Heteroscedasticidad\nDecimos que en el modelo de regresión \\(y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i}\\) existe heteroscedasticidad cuando la varianza no es constante, sino que se cumple que \\(Var(e_{i}) = \\sigma_{i}^{2}\\ \\), siendo el resto de las hipótesis válidas.\n\n3.5.1 Naturaleza de la heteroscedasticidad\nLa heteroscedasticidad aparece casi exclusivamente en el caso de datos de corte transversal, mientras que es poco común en regresiones de series temporales. Por ejemplo, frecuentemente aparecen regresiones con errores heteroscedásticos cuando se estiman funciones de consumo para individuos o familias, ecuaciones de crecimiento entre países o regiones, ecuaciones de productividad entre empresas o industrias, funciones de demanda de horas trabajadas por los empleados de una empresa, etc.\nTambién puede generarse heteroscedasticidad, sobre todo en el caso de datos de series temporales, por una especificación errónea del modelo o debido a la presencia de cambio estructural. Así, la omisión de una variable explicativa relevante hace que el efecto de esta sea asumido por el error y, por tanto, que este varíe a lo largo de la muestra.\n\n\n3.5.2 Consecuencias de la heteroscedasticidad\nEn presencia de heteroscedasticidad, pueden establecerse las siguientes conclusiones respecto a la validez del estimador MCO:\n\n\\({\\widehat{\\mathbf{\\beta}}}_{MCO}\\ \\) mantiene las propiedades de insesgadez, consistencia y normalidad asintótica.\nLa presencia de heteroscedasticidad sesga las estimaciones estándar de las varianzas y covarianzas del estimador MCO.\nSon inválidos los resultados inferenciales obtenidos al usar los estadísticos t y F** de la estimación MCO si no se corrige adecuadamente la matriz de varianzas-covarianzas.\nAún corrigiendo adecuadamente la matriz de covarianzas, los estimadores MCO de los parámetros no son eficientes.\n\n\n\n3.5.3 Detección de la heteroscedasticidad\nPara detectar la presencia de heteroscedasticidad en los errores, se somete el modelo original a diferentes contrastes bajo la hipótesis nula de homoscedasticidad \\(H_{0}:\\{\\sigma_{1}^{2} = \\sigma_{2}^{2} = \\ldots = \\sigma_{n}^{2}\\}\\), frente a una alternativa específica que depende del procedimiento de estimación considerado y del patrón de comportamiento asumido para las varianzas de los errores.\n\n3.5.3.1 Examen gráfico de los residuos MCO\nUna primera aproximación para detectar si existe algún tipo de heteroscedasticidad consiste en observar el gráfico del valor absoluto, \\(\\left| {\\widehat{e}}_{i} \\right|\\), o de los cuadrados, \\({\\widehat{e}}_{i}^{2}\\), de los residuos MCO respecto a las variables explicativas del modelo o a otras variables externas al modelo que se crea puedan ser la causa de la heteroscedasticidad. La identificación de modelos sistemáticos en dichas gráficas puede verse como una primera evidencia de la violación de la hipótesis de varianza constante.\n\n\n3.5.3.2 Contraste general de White\nEl test de White tiene un carácter muy general, ya que\n\\[H_{0}:\\{\\sigma_{i}^{2} = \\sigma^{2}\\ \\ \\forall i\\}\\ \\ frente\\ a\\ \\ H_{1}:\\{\\sigma_{i}^{2} \\neq \\sigma_{j}^{2}\\}\\]\nsiendo básicamente una prueba de mala especificación del modelo de regresión. En una primera etapa, se realiza la regresión auxiliar de \\({\\widehat{e}}_{i}^{2}\\) frente a las variables originales, sus cuadrados y sus productos cruzados\n\\[ê_{i}^{2} = \\alpha_{0} + \\sum_{j}^{}{\\alpha_{j}x_{ji}} + \\sum_{k}^{}{\\alpha_{k}x_{ki}^{2}} + \\sum_{l,m}^{}{\\alpha_{lm}x_{li}x_{mi}} + u_{i}\\]\nEn segundo lugar, se calcula el estadístico\n\\[W = nR^{2}\\]\nsiendo R2 el coeficiente de determinación de esta regresión auxiliar. Se puede demostrar que, bajo la hipótesis nula H0, se cumple que \\(W\\overset{as}{\\sim}\\chi_{p}^{2}\\ \\), donde p es el número de variables explicativas de esta regresión auxiliar, sin incluir la constante.\nPor ejemplo, si el modelo propuesto es \\(y_{i} = \\beta_{1} + \\beta_{2}x_{i} + \\beta_{3}z_{i} + e_{i}\\), y denotamos por \\({\\widehat{e}}_{i}\\) a los residuos de su estimación MCO, la regresión auxiliar que debe utilizarse para efectuar el contraste de White viene dada por \\(ê_{i}^{2} = \\alpha_{1} + \\alpha_{2}x_{i} + \\alpha_{3}z_{i} + \\alpha_{4}x_{i}^{2} + \\alpha_{5}z_{i}^{2} + \\alpha_{6}x_{i}z_{i} + u_{i}\\), debiendo compararse el valor del estadístico \\(W = nR^{2}\\) de esta regresión con el valor crítico de una variable\\(\\chi_{5}^{2}\\).\nEl problema de este test es su generalidad, ya que, si el estadístico de contraste W resulta significativo, es decir, aceptamos la hipótesis de heteroscedasticidad, no tenemos ninguna información sobre su naturaleza. El contraste puede revelar heteroscedasticidad, pero también puede estar detectando alguna clase de error de especificación en el modelo (omisión de alguna variable relevante, cambio estructural, etc.).\n\n\n3.5.3.3 Contrastes de Breusch-Pagan, Harvey y Glejser\nEl test de Breusch-Pagan está diseñado para contrastar la hipótesis\n\\[\\ H_{0}:\\left\\{ \\sigma_{i}^{2} = \\sigma^{2}\\ \\ \\forall i \\right\\}\\ \\ \\ frente\\ a\\ \\ \\ \\ H_{1}:\\left\\{ \\sigma_{i}^{2} = f(\\alpha_{0} + \\alpha_{1}z_{1i} + \\cdots + \\alpha_{p}z_{pi}) \\right\\}\\ \\]\ndonde la función f es desconocida y los regresores z son variables exógenas que pueden ser la causa de la heteroscedasticidad. El contraste se lleva a cabo mediante los siguientes pasos:\n\nSe estima el modelo original por MCO y se calculan los errores estimados al cuadrado ‘escalados’, \\(\\frac{{\\widehat{e}}_{i}^{2}}{{\\widetilde{\\sigma}}^{2}}\\), donde \\({\\widetilde{\\sigma}}^{2} = \\sum_{i = 1}^{n}\\frac{{\\widehat{e}}_{i}^{2}}{n}\\) es la estimación MV de la varianza residual.\nSe estima la regresión auxiliar\n\n\\[\\ \\frac{{\\widehat{e}}_{i}^{2}}{{\\widetilde{\\sigma}}^{2}} = \\alpha_{0} + \\alpha_{1}z_{1i} + \\cdots + \\alpha_{p}z_{pi} + u_{i}\\ \\]\ny se calcula el valor del estadístico\\(\\ BP = \\ \\frac{SCE}{2}\\ \\), siendo SCE la suma de cuadrados explicada de dicha regresión.\n\nSi no existe heteroscedasticidad del tipo planteado, se tiene que \\(\\ BP\\overset{as}{\\sim}\\chi_{p}^{2}\\ \\), donde p es el número de regresores incluidos en la regresión auxiliar, sin incluir el término constante.\n\nTambién suele utilizarse una versión alternativa del contraste anterior, en la que se estima la regresión auxiliar \\({\\widehat{e}}_{i}^{2} = \\alpha_{0} + \\alpha_{1}z_{1i} + \\cdots + \\alpha_{p}z_{pi} + u_{i}\\) y, a continuación, se calcula el estadístico \\(nR^{2}\\), que tiene de nuevo una distribución asintótica \\(\\chi_{p}^{2}\\) .\nCuando se estima la regresión auxiliar \\(\\ \\log{\\widehat{e}}_{i}^{2} = \\alpha_{0} + \\alpha_{1}z_{1i} + \\cdots + \\alpha_{p}z_{pi} + u_{i}\\ \\) y se calcula el estadístico \\(H = nR^{2}\\ \\), al contraste resultante se le denomina test de Harvey de heteroscedasticidad multiplicativa, pues dicho contraste va asociado a la hipótesis alternativa \\(H_{1}:\\left\\{ \\sigma_{i}^{2} = e^{\\alpha_{0} + \\alpha_{1}z_{1i} + \\cdots + \\alpha_{p}z_{pi}} \\right\\}\\). Para este contraste, de nuevo se tiene que bajo la hipótesis nula \\(H\\overset{as}{\\sim}\\chi_{p}^{2}\\ \\) .\nDe igual manera, si se estima la regresión auxiliar \\(\\ \\left| {\\widehat{e}}_{i} \\right| = \\alpha_{0} + \\alpha_{1}z_{1i} + \\cdots + \\alpha_{p}z_{pi} + u_{i}\\ \\) y, a continuación, se calcula el estadístico \\(G = nR^{2}\\) , comparando dicho valor con una distribución \\(\\chi_{p}^{2}\\), a dicho contraste se le conoce en la literatura como test de Glejser, siendo en este caso la hipótesis alternativa la siguiente \\(H_{1}:\\left\\{ \\sigma_{i} = \\alpha_{0} + \\alpha_{1}z_{1i} + \\cdots + \\alpha_{p}z_{pi} \\right\\}\\).\n\n\n3.5.3.4 Otras formas de heteroscedasticidad: modelos de volatilidad variable en el tiempo\nCuando se trabaja con datos de corte transversal, la mayor preocupación (en lo que a incumplimiento de las hipótesis clásicas se refiere) se centra en el problema de la heteroscedasticidad, mientras que para datos de series temporales normalmente se analiza en profundidad la verificación de la hipótesis de ausencia de correlación serial en los residuos.\nSin embargo, existen modelos de series temporales, sobre todo en el ámbito de la economía financiera, en los que la varianza (condicional) no es estable en el tiempo. Concretamente, existe una forma especial de heteroscedasticidad en la que la varianza del error de predicción depende del tamaño de la perturbación precedente. A este tipo de modelos se les denomina procesos de heteroscedasticidad autorregresiva condicional (ARCH).\nLa versión más simple de un proceso ARCH en un modelo de regresión lineal es aquella en la que los residuos et siguen la forma autorregresiva de primer orden del tipo\n\\[{e_{t} = {u_{t}\\left\\lbrack \\alpha_{0} + \\alpha_{1}e_{t - 1}^{2} \\right\\rbrack}^{1/2}}_{\\ }\\]\ndonde los errores \\(u_{t}\\) siguen una distribución normal \\(N(0,1)\\) y son independientes entre sí. Otra forma de escribir dicha ecuación es\n\\[{h_{t} = \\alpha_{0} + \\alpha_{1}e_{t - 1}^{2}}_{\\ }\\]\nsiendo \\({h_{t} = Var\\left\\lbrack e_{t}|e_{t - 1} \\right\\rbrack}_{\\ }\\) la varianza condicional de los errores.\nEn este modelo se cumple que \\(E\\left\\lbrack e_{t}|e_{t - 1} \\right\\rbrack = 0\\) y, por tanto, \\(E\\left\\lbrack e_{t} \\right\\rbrack = 0\\) y \\(E\\left\\lbrack y_{t} \\right\\rbrack = {\\mathbf{x}^{\\mathbf{'}}}_{t}\\mathbf{\\beta}\\), como en el modelo clásico. Ahora bien, \\(Var\\left\\lbrack e_{t}|e_{t - 1} \\right\\rbrack = \\alpha_{0} + \\alpha_{1}e_{t - 1}^{2}\\), es decir, condicionada sobre \\(e_{t - 1}\\), el término de error \\(e_{t}\\) es heteroscedástico, aunque la varianza incondicional de \\(e_{t}\\) es \\(Var\\left\\lbrack e_{t} \\right\\rbrack = \\frac{\\alpha_{0}}{(1 - \\alpha_{1})}\\) y, por consiguiente, el término de error es (incondicionalmente) homoscedástico.\nEntonces, el modelo cumple todas las hipótesis clásicas del MRL por lo que el estimador MCO sigue siendo el mejor estimador lineal e insesgado de β (MELI). Sin embargo, al ser los errores condicionalmente heteroscedásticos, existe un estimador no lineal más eficiente que el de MCO, que es el estimador de máxima verosimilitud (MV), el cual utiliza la información contenida en la ecuación de la varianza condicional.\nUna extensión inmediata del modelo ARCH de primer orden expuesto viene dada por los modelos ARCH(q), en los que \\({h_{t} = Var\\left\\lbrack e_{t}|e_{t - 1},e_{t - 2},\\ldots,e_{t - q} \\right\\rbrack}_{\\ }\\) viene dada por la expresión\n\\[{h_{t} = \\alpha_{0} + \\alpha_{1}e_{t - 1}^{2} + \\alpha_{2}e_{t - 2}^{2} + \\ldots + \\alpha_{q}e_{t - q}^{2}}_{\\ }\\]\nTambién se han propuesto en la literatura otras ampliaciones, como los modelos ARCH generalizados (GARCH). Así, un caso sencillo viene dado por un modelo GARCH(1,1), cuya forma es\n\\[{h_{t} = \\alpha_{0} + \\alpha_{1}e_{t - 1}^{2} + \\delta_{1}h_{t - 1}}_{\\ }\\]\nA su vez, estos modelos pueden generalizarse, dando lugar a los modelos GARCH(p,q), con términos de orden superior en las dos dimensiones. Adicionalmente, se presentan otras posibilidades, como los modelos EGARCH, T-ARCH, GARCH-M, etc.\nExiste una sencilla prueba de multiplicadores de Lagrange, propuesta por Engle, para contrastar la presencia de modelos ARCH en los errores de un modelo de regresión. Para el caso de un modelo ARCH(1) –la extensión para el caso general resulta inmediata- el test de Engle consiste en estimar la ecuación original \\(y_{t} = \\beta_{1} + \\beta_{2}x_{2t} + \\cdots + \\beta_{K}x_{Kt} + e_{t}\\) por MCO, obtener los residuos \\({\\widehat{e}}_{t}\\) y estimar la regresión auxiliar siguiente\n\\[{{\\widehat{e}}_{t}^{2} = \\alpha_{0} + \\alpha_{1}{\\widehat{e}}_{t - 1}^{2} + \\nu_{t}}_{\\ }\\]\nconstruyéndose a continuación el estadístico\n\\[E = TR^{2}\\]\ncon el R2 de esta última regresión. Este estadístico, bajo la hipótesis nula de homoscedasticidad condicional \\({H_{0}:\\left\\{ h_{t} = \\alpha_{0} \\right\\}}_{\\ }\\) se distribuye asintóticamente como una variable Chi-cuadrado, \\(E\\overset{as}{\\sim}\\chi_{1}^{2}\\ \\).\nSi el contraste resulta significativo (aceptándose la hipótesis alternativa \\({H_{1}:\\left\\{ h_{t} = \\alpha_{0} + \\alpha_{1}e_{t - 1}^{2} \\right\\}}_{\\ }\\)), se puede seguir utilizando el estimador MCO, pero habrá que tener en cuenta que existe otro estimador, el de MV, que es más eficiente y, por tanto, dará lugar a resultados más fiables que el de mínimos cuadrados ordinarios (estimaciones más precisas, intervalos de predicción más estrechos, etc.).\n\n\n\n3.5.4 Regresiones heteroscedásticas\nUsando datos de corte transversal, supongamos que en el modelo de regresión \\(y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i}\\) existe heteroscedasticidad, es decir, \\(Var\\left( e_{i} \\right) = \\sigma_{i}^{2}\\), siendo el resto de las hipótesis válidas.\n\n3.5.4.1 El estimador de mínimos cuadrados corregidos (método de White)\nComo una de las posibles soluciones al problema de la presencia de heteroscedasticidad en los errores del modelo, White (1980) propuso tomar el estimador de MCO corregidos, ajustando la matriz de covarianzas estimada para el vector de parámetros β.\nWhite demostró que, bajo condiciones muy generales, si existe heteroscedasticidad, la matriz de covarianzas correcta del estimador MCO viene dada por \\(Cov(\\widehat{\\mathbf{\\beta}}) = (\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\left( \\mathbf{X}^{'}\\Omega\\mathbf{X} \\right)(\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\), donde \\(\\Omega = Cov(e)\\), y que ésta puede estimarse de forma consistente por la ‘matriz sandwich’ siguiente:\n\\[C\\widehat{o}v(\\widehat{\\mathbf{\\beta}})_{W} = (\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\mathbf{S}_{0}(\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\]\ndonde\n\\[\\mathbf{S}_{0} = \\frac{n}{n - K}\\sum_{i = 1}^{n}{ê_{i}^{2}\\mathbf{x}_{i}\\mathbf{x}_{i}^{'}}\\]\ny êi son los residuos MCO y xi el vector de la i-ésima fila de la matriz X.\n\n\n3.5.4.2 El estimador de mínimos cuadrados ponderados\nEl estimador de mínimos cuadrados ponderados (MCP) se obtiene multiplicando cada una de las observaciones del modelo original por la inversa de las estimaciones de las desviaciones típicas, es decir, “ponderando” cada observación por el valor \\(p_{i} = 1/{\\widehat{\\sigma}}_{i}\\) y aplicando MCO al modelo transformado:\n\\[y_{i}/{\\widehat{\\sigma}}_{i} = \\beta_{1}(1/{\\widehat{\\sigma}}_{i}) + \\beta_{2}(x_{2i}/{\\widehat{\\sigma}}_{i}) + ... + \\beta_{K}(x_{Ki}/{\\widehat{\\sigma}}_{i}) + e_{i}^{*}\\]\nSe puede demostrar que, si las perturbaciones del modelo original son normales, el estimador MCP de los parámetros estructurales, \\({\\widehat{\\mathbf{\\beta}}}_{MCP}\\), es insesgado, consistente y eficiente.\nEn general, el punto crucial en la aplicación del método MCP es obtener una estimación de la desviación estándar \\({\\widehat{\\sigma}}_{i}\\) para calcular las ponderaciones \\(p_{i} = 1/{\\widehat{\\sigma}}_{i}\\).\nVeamos cómo se pueden estimar dichos errores estándar en el caso de asumir una forma especial de heteroscedasticidad. Supongamos que la varianza toma la forma exponencial \\({\\ \\sigma_{i}^{2} = e^{\\alpha_{o} + \\alpha_{1}z_{1i} + \\ldots + \\alpha_{p}z_{pi}}}_{\\ }\\). Esta expresión tiene como caso especialel modelo de heteroscedasticidad multiplicativa \\(\\sigma_{i}^{2} = \\sigma^{2}\\left( w_{1i} \\right)^{\\alpha_{1}}\\left( w_{2i} \\right)^{\\alpha_{2}}\\cdots\\left( w_{pi} \\right)^{\\alpha_{p}}\\), donde \\(\\sigma^{2} = e^{\\alpha_{0}}\\) y \\(z = \\log(w)\\), es decir, cuando los regresores z’s vienen expresados en logaritmos.\nPara este caso especial, en el que se tiene que \\({\\ \\sigma_{i}^{2} = e^{\\alpha_{o} + \\alpha_{1}z_{1i} + \\ldots + \\alpha_{p}z_{pi}}}_{\\ }\\), se realiza en primer lugar la regresión auxiliar\n\\[log\\ {\\widehat{e}}_{i}^{2} = \\alpha_{0} + \\alpha_{1}z_{1i} + ... + \\alpha_{p}z_{pi} + u_{i}\\]\ny, dado que se puede demostrar que el estimador MCO del parámetro α0 está sesgado, se utilizan los valores \\(e^{{\\widehat{\\alpha}}_{1}z_{1i} + ... + {\\widehat{\\alpha}}_{p}z_{pi}}\\) para estimar las varianzas \\(\\sigma_{i}^{2}\\).\nEntonces, \\({\\widehat{\\sigma}}_{i} = \\sqrt{e^{{\\widehat{\\alpha}}_{1}z_{1i} + ... + {\\widehat{\\alpha}}_{p}z_{pi}}}\\) y por tanto, se toman los valores \\(p_{i} = 1/\\sqrt{e^{{\\widehat{\\alpha}}_{1}z_{1i} + ... + {\\widehat{\\alpha}}_{p}z_{pi}}}\\) como ponderaciones de las variables originales.\n\n\n3.5.4.3 El estimador de máxima verosimilitud para modelos de regresión con volatilidad variable en el tiempo\nCuando se trabaja con datos de series temporales, si se parte de un modelo de regresión lineal \\(y_{t} = \\beta_{1} + \\beta_{2}x_{2t} + \\cdots + \\beta_{K}x_{Kt} + e_{t}\\) en el que la varianza condicional de los residuos et no es constante\n\\[{h_{t} = Var\\left\\lbrack e_{t}|e_{t - 1},e_{t - 2},\\ldots,e_{t - q} \\right\\rbrack \\neq cte.}_{\\ }\\]\npuede proponerse una estructura ARCH del tipo\n\\[{h_{t} = \\alpha_{0} + \\alpha_{1}e_{t - 1}^{2} + \\alpha_{2}e_{t - 2}^{2} + \\ldots + \\alpha_{q}e_{t - q}^{2}}_{\\ }\\]\no una forma GARCH más general que incluiría términos autorregresivos para la varianza condicional\n\\[{h_{t} = \\alpha_{0} + \\alpha_{1}e_{t - 1}^{2} + \\alpha_{2}e_{t - 2}^{2} + \\ldots + \\alpha_{q}e_{t - q}^{2} + \\delta_{1}h_{t - 1} + \\delta_{2}h_{t - 2} + \\ldots + \\delta_{p}h_{t - p}}_{\\ }\\]\nEn estos casos, debe utilizarse el estimador de máxima verosimilitud (MV) en lugar del estimador MCO, puesto que será un estimador eficiente, aparte de ser consistente y con una distribución asintóticamente normal.\nEl método de máxima verosimilitud toma como criterio de optimización maximizar el logaritmo de la función de verosimilitud asociada al modelo de regresión, que para los modelos con efectos ARCH o GARCH toma la expresión\n\\[L(\\mathbf{\\beta},\\mathbf{\\alpha},\\mathbf{\\delta}) = f(y_{1},y_{2},\\ldots,y_{T}) = f(y_{1})f(y_{1}|y_{2})f(y_{1}|y_{2},y_{3})\\ldots f(y_{1}|y_{2},y_{3},\\ldots,y_{T})\\]\nEntonces, tomando logaritmos en la expresión anterior, la función a optimizar es la siguiente:\n\\[\\log L(\\mathbf{\\beta},\\mathbf{\\alpha},\\mathbf{\\delta}) = \\sum_{t = 1}^{T}{\\log f(y_{t}|Y_{t - 1})}\\]\ndonde la función f será la función de densidad asociada a una distribución \\(N(0,1)\\)."
  },
  {
    "objectID": "p3c1-teoria.html#autocorrelación",
    "href": "p3c1-teoria.html#autocorrelación",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.6 Autocorrelación",
    "text": "3.6 Autocorrelación\nDecimos que en el modelo de regresión \\(y_{t} = \\beta_{1} + \\beta_{2}x_{2t} + \\ldots + \\beta_{K}x_{Kt} + e_{t}\\) existe autocorrelación cuando existen covarianzas no nulas entre los errores, es decir, \\(Cov(e_{t},e_{s}) = \\sigma_{ts} \\neq 0\\ \\).\nLos procesos que habitualmente describen el comportamiento de errores con correlación serial en el tiempo son los denominados modelos autorregresivos de media móvil, ARMA(p,q), que incluyen los modelos autorregresivos, AR(p), y los de medias móviles, MA(q), como casos particulares.\nLa forma general de un modelo autorregresivo de orden p, AR(p), es\n\\[e_{t} = \\rho_{1}e_{t - 1} + \\rho_{2}e_{t - 2} + \\ldots + \\rho_{p}e_{t - p} + \\varepsilon_{t}\\]\ncon \\(\\varepsilon_{t} \\approx N(0,\\sigma_{\\varepsilon}^{2})\\), cumpliéndose que \\(Cov(\\mathbf{\\varepsilon}) = \\sigma_{\\varepsilon}^{2}\\mathbf{I}\\). Los casos más tratados en la literatura econométrica son los modelos AR(1) y AR(2).\nPor otro lado, los modelos de medias móviles de orden q, MA(q), toman la expresión general\n\\[e_{t} = \\varepsilon_{t} - \\theta_{1}\\varepsilon_{t - 1} - \\theta_{2}\\varepsilon_{t - 2} - \\ldots - \\theta_{q}\\varepsilon_{t - q}\\]\nsiendo las más utilizadas las formas MA(1) y MA(2).\nEn este apartado nos centraremos únicamente en el análisis de procesos AR(1), \\(e_{t} = \\rho e_{t - 1} + \\varepsilon_{t}\\), pero muchos de los resultados son fácilmente extrapolables al caso general de modelos AR(p); para los modelos MA(q), las modificaciones son mayores, sobre todo en lo referente a la estimación.\n\n3.6.1 Naturaleza y consecuencias de la autocorrelación\nLa existencia de autocorrelación en los errores es un problema frecuente con datos de series temporales. Viene originada, en muchas ocasiones, por una mala especificación de la dinámica temporal de interacción entre la variable dependiente y y los regresores x’s, aunque también puede deberse a situaciones como las siguientes:\n\nNaturaleza inercial del comportamiento de los agentes económicos.\nEspecificación errónea del modelo (variables omitidas, por ejemplo) o errores sistemáticos de medida en alguna(s) de las variables del modelo.\nSemejanzas de comportamiento en el espacio.\n‘Manipulación’ de datos (agregación, desestacionalización, eliminación de la tendencia, etc.).\n\nLas consecuencias de utilizar el estimador MCO de β en presencia de autocorrelación son las mismas que en el caso de existencia de heteroscedasticidad, al tratarse de un mismo caso de matriz de covarianzas no escalar: el estimador MCO será insesgado y consistente pero las varianzas y covarianzas MCO estarán sesgadas, de manera que cualquier inferencia que se haga sobre la base de dichas estimaciones será inválida. Además, aunque se corrija la estimación de la matriz de covarianzas estimada, el estimador MCO sigue siendo ineficiente.\n\n\n3.6.2 Detección de la autocorrelación\n\n3.6.2.1 Examen gráfico de los residuos MCO\nLa representación gráfica de los residuos \\({\\widehat{e}}_{t}\\) respecto al tiempo puede mostrarnos de forma clara el comportamiento autocorrelacionado de los errores. Así, existirían indicios de autocorrelación positiva de orden uno si los residuos MCO se agrupan en rachas con un signo determinado (positivos o negativos), seguidos de rachas del signo contrario. Por otra parte, será una señal de autocorrelación negativa de orden uno en los residuos si se observa que estos van alternando su signo con respecto a la observación anterior.\nTambién puede ser útil representar \\({\\widehat{e}}_{t}\\) frente a \\({\\widehat{e}}_{t - 1}\\): una agrupación de los puntos del gráfico alrededor de una línea creciente sería un indicio de que existe una correlación positiva en el tiempo, mientras que una agrupación alrededor de una recta con pendiente negativa sería un síntoma de autocorrelación negativa.\n\n\n3.6.2.2 Contraste de Durbin-Watson\nEstá diseñado para contrastar sólo la presencia de procesos autorregresivos del tipo AR(1) en los errores, es decir, partiendo del modelo \\(e_{t} = \\rho e_{t - 1} + \\varepsilon_{t}\\), se contrasta\n\\[H_{0}:\\{\\rho = 0\\}\\ \\ frente\\ a\\ \\ H_{1}:\\{\\rho \\neq 0\\}\\]\nEl estadístico propuesto por Durbin y Watson (1970) viene dado por:\n\\[DW = \\frac{\\sum_{t = 2}^{T}{(ê_{t} - ê_{t - 1})^{2}}}{\\sum_{t = 1}^{T}ê_{t}^{2}}\\]\ncumpliéndose que \\(DW \\cong 2(1 - \\widehat{\\rho})\\), donde \\(\\widehat{\\rho}\\) es una estimación del parámetro ρ basada en aplicar MCO a la regresión auxiliar \\({\\widehat{e}}_{t} = \\rho{\\widehat{e}}_{t - 1} + \\varepsilon_{t}\\).\nEntonces, se puede observar fácilmente que el estadístico DW tiene un recorrido entre 0 (\\(\\widehat{\\rho} = 1\\)) y 4 (\\(\\widehat{\\rho} = - 1\\)), y que \\(DW &lt; 2 \\ (&gt; 2)\\) es indicativo de autocorrelación positiva (negativa) de los errores \\(e_{t}\\),mientras que \\(DW \\cong 2\\) señala la ausencia de correlación (\\(\\widehat{\\rho} = 0\\)).\nEl problema que plantea este contraste es que la distribución del estadístico de Durbin-Watson, \\(f(d)\\), depende de la matriz de datos \\(\\mathbf{X}\\), aparte del número de observaciones (T) y del número de variables del modelo (K) y, por tanto, no existen tablas para el test exacto. Sin embargo, para cada aplicación concreta pueden calcularse el valor crítico y el P-valor específicos para dicho conjunto de datos (es decir, para la matriz X y los valores de T y K concretos se calculan el valor del estadístico \\(d_{c}\\left( \\mathbf{X},T,K \\right)\\) y del P-valor \\(\\ P\\left\\lbrack d &lt; d_{c}(\\mathbf{X},T,K) \\right\\rbrack\\)), y se toma la decisión respecto al contraste planteado (no rechazar H0 o “aceptar” H1) en base a esos valores concretos.\n\n\n3.6.2.3 Contraste general de Breusch-Godfrey\nSe trata de un test válido para detectar autocorrelación generada no sólo por procesos AR(1) sino también por procesos de orden general AR(p) (\\(p &gt; 1\\)), y es especialmente adecuado cuando el test de Durbin-Watson no lleva a ninguna conclusión o resulta inaplicable, como es la situación en que la variable dependiente retardada aparece entre los regresores, en cuyo caso el estadístico DW está sesgado hacia 2 aún en presencia de autocorrelación).\nAdemás, este contraste también tiene potencia para detectar modelos de correlación de medias móviles, MA(q), y modelo mixtos del tipo ARMA(p,q).\nPara aplicar el test de Breusch y Godfrey se llevan a cabo los siguientes pasos:\n\nSe aplican MCO a la regresión \\(y_{t} = \\beta_{1} + \\beta_{2}x_{2t} + \\ldots + \\beta_{K}x_{Kt} + e_{t}\\) y se obtienen los residuos estimados \\({\\widehat{e}}_{t}\\).\nSe estima por MCO la regresión auxiliar \\[\\ {\\widehat{e}}_{t} = \\alpha_{0} + \\alpha_{1}{\\widehat{e}}_{t - 1} + \\cdots + \\alpha_{p}{\\widehat{e}}_{t - p} + \\delta_{2}x_{2t} + \\cdots + \\delta_{K}x_{Kt} + u_{t}\\ \\] rellenando los valores omitidos para los residuos retardados con ceros.\nDe esta regresión auxiliar se toma el coeficiente \\(\\ R^{2}\\ \\), y se calcula el estadístico \\(\\ BG = T \\times R^{2}\\ \\).\nBajo la hipótesis nula de ausencia de correlación, \\(H_{0}:\\{ Cov(e_{t},e_{s}) = 0\\}\\), se cumple que \\(BG\\overset{as}{\\sim}\\chi_{p}^{2}\\ \\).\n\nTal como está diseñado, el test de Breusch-Godfrey tiene como hipótesis alternativa el caso general \\(H_{1}:\\{ AR(p),\\ MA(p)\\ \\ o\\ \\ ARMA(p,p)\\}\\), es decir, el tipo de correlación puede ser autorregresiva, de medias móviles o una mezcla de ambos procesos.\n\n\n3.6.2.4 Otras formas de autocorrelación: modelos autorregresivos con dependencia espacial\nEn este apartado se propone una familia de modelos diseñada para tratar una forma especial de correlación en los errores que aparece en el ámbito del análisis de datos de corte transversal referenciados geográficamente, la autocorrelación espacial.\nEn la vida real existen muchos procesos económicos que pueden dar lugar a aspectos espaciales en los datos. Por ejemplo, variables de tipo inobservable (como el clima, la calidad y riqueza del suelo o la disponibilidad de ciertas materias primas) pueden estar relacionadas ‘espacialmente’ y, por tanto, producir correlación en los errores; asimismo, patrones de mimetismo en el comportamiento económico de las unidades económicas pueden originar correlación espacial en las regresiones que describan dicho comportamiento.\nLos patrones de comportamiento espacial a menudo pueden describirse de forma adecuada en términos de dependencia espacial, pudiendo ésta definirse como la correlación positiva o negativa entre los valores de una variable para los individuos o las regiones de un espacio geográfico (tal espacio debe estar dividido en zonas que completen el mismo y que no se solapen).\nPor ejemplo, si consideramos las Comunidades Autónomas que componen España, un proceso de dependencia espacial puede caracterizarse por la relación entre los valores que toma una variable y en una comunidad y los valores que toma dicha variable en otras comunidades; así, una relación de primer orden entre la comunidad 2 y sus vecinas las comunidades 1, 8 y 3 puede describirse mediante la ecuación y2=φy1+φy8+φy3+e, donde e es un término de error con las propiedades estándar.\nLa correlación espacial en una variable podría en sí misma no tener mucho interés para los economistas; por ejemplo, si las familias pobres de una ciudad tienden a vivir en la periferia, resulta poco informativo encontrar que el modelo de consumo/ahorro de tales familias es muy parecido. Lo interesante podría ser contrastar la presencia de correlación espacial en los residuos una vez que se ha descontado el efecto riqueza, es decir, encontrar patrones de comportamiento espacial en los errores de un modelo del tipo \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\), donde la matriz \\(\\mathbf{X}\\) contiene las K variables que explican el comportamiento de la variable y.\nEl contraste más simple de correlación espacial es el estadístico propuesto por Moran (1948), el cual mide la covariación existente entre los errores de zonas ‘vecinas’ con relación a la varianza total de los errores.\nTécnicamente, asignando pesos unitarios a zonas vecinas (\\(w_{ij} = 1\\) si las zonas i y j tienen una frontera o un vértice común) y nulos en caso contrario (\\(w_{ij} = 0\\) si las zonas i y j no comparten frontera o vértice), y asumiendo por definición que \\(w_{ii} = 0\\) , el test de Moran se define como\n\\[I = \\frac{\\frac{\\sum_{i = 1}^{n}{\\sum_{j = 1}^{n}{{\\widehat{e}}_{i}w_{ij}{\\widehat{e}}_{j}}}}{2F}}{\\frac{\\sum_{i = 1}^{n}{\\widehat{e}}_{i}^{2}}{n}}\\]\ndonde F es el número total de fronteras o vértices y n es el número total de zonas.\nBajo la hipótesis nula de ausencia de correlación espacial, \\(H_{0}:\\{ Cov(e_{i},e_{j}) = 0\\}\\), el estadístico \\(I\\) se distribuye asintóticamente como una variable aleatoria normal, \\(I\\overset{as}{\\sim}N(\\mu_{I},\\sigma_{I}^{2})\\ \\), cuya media (\\(\\mu_{I}\\)) y varianza (\\(\\sigma_{I}^{2}\\)) se pueden calcular de forma relativamente sencilla. Tales valores dependen de la matriz \\(\\mathbf{X}\\) de variables explicativas, de la matriz \\(\\mathbf{W}\\) de pesos espaciales, y de los valores de F, n y K.\nCuando el estadístico \\(I\\) resulta significativo (\\(H_{1}:\\{ Cov(e_{i},e_{j}) \\neq 0\\}\\)), los valores positivos implican concentración espacial, mientras que valores negativos señalan dispersión en el espacio. Estos fenómenos de concentración-dispersión puede ser consistentes con varias estructuras espaciales, una de las cuales resulta de interés en el contexto de la autocorrelación.\nSe trata de procesos en los que el origen de la dependencia espacial está en el término de error y tiene la forma autorregresiva espacial en los errores, SEM, siguiente:\n\\[\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\] \\[\\mathbf{e} = \\lambda\\mathbf{We} + \\mathbf{u}\\]\nsiendo \\(\\mathbf{W}\\) la matriz de pesos espaciales, λ el parámetro que recoge la intensidad de las interdependencias espaciales en el término de perturbación, y \\(\\mathbf{u}\\sim N(\\mathbf{0},\\sigma^{2}\\mathbf{I})\\).\nEn la práctica, como matriz \\(\\mathbf{W}\\) se suele tomar la matriz de contigüidad tipo reina definida en el test de Moran, aunque en la literatura especializada (econometría espacial) se han propuesto otras definiciones de la matriz de pesos espaciales alternativas, algunas basadas en la utilización de la distancia entre regiones —geográfica o económica— o, más generalmente, definidas de forma específica para cada aplicación concreta.\n\n\n\n3.6.3 Regresiones con autocorrelación en los errores y modelos econométricos dinámicos\nSupongamos que en el modelo de regresión \\(y_{t} = \\beta_{1} + \\beta_{2}x_{2t} + \\ldots + \\beta_{K}x_{Kt} + e_{t}\\) existe autocorrelación temporal en los errores, es decir, se cumple que \\(Cov\\left( e_{t},e_{s} \\right) = \\sigma_{ts} \\neq 0\\) .\n\n3.6.3.1 El estimador de mínimos cuadrados corregidos (método de Newey-West)\nIgual que en el caso de heteroscedasticidad, en presencia de autocorrelación en los errores puede utilizarse el estimador de MCO corregidos, modificando apropiadamente la matriz de covarianzas estimada.\nAsí, Newey y West (1987) demostraron que la matriz de covarianzas correcta del estimador MCO, \\(Cov(\\widehat{\\mathbf{\\beta}}) = (\\mathbf{X}'\\mathbf{X})^{- 1}\\left( \\mathbf{X}'\\Omega\\mathbf{X} \\right)(\\mathbf{X}'\\mathbf{X})^{- 1}\\), puede estimarse de forma consistente mediante la matriz ‘sandwich’\n\\[{Cov}^{\\land}(\\widehat{\\mathbf{\\beta}})_{NW} = (\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\mathbf{S}^{*}(\\mathbf{X}^{'}\\mathbf{X})^{- 1}\\]\ndonde \\(\\mathbf{S}^{*} = \\mathbf{S}_{0} + \\frac{T}{T - K}\\sum_{j = 1}^{L}{\\sum_{t = j + 1}^{T}{w(j){\\widehat{e}}_{t}{\\widehat{e}}_{t - j}\\left\\lbrack \\mathbf{x}_{t - j}\\mathbf{x}_{t}^{'} + \\mathbf{x}_{t}\\mathbf{x}_{t - j}^{'} \\right\\rbrack}}\\) siendo \\(\\mathbf{S}_{0}\\) la matriz definida por White para el caso de heteroscedasticidad, \\(\\mathbf{S}_{0} = \\frac{T}{T - K}\\sum_{t = 1}^{T}{ê_{t}^{2}\\mathbf{x}_{t}\\mathbf{x}_{t}^{'}}\\), y \\(w(j) = 1 - \\left\\lbrack j/(L + 1) \\right\\rbrack\\).\nEl coeficiente L debe tomar un valor suficientemente elevado como para que las autocorrelaciones en retardos mayores que L sean despreciables. En general, valores de L iguales a 3 o 4 serán suficientes, aunque también pueden utilizarse reglas de corte, como la propuesta por los propios Newey y West (1994), quienes sugieren utilizar el valor \\(L \\cong {4\\left( \\frac{T}{100} \\right)}^{\\frac{2}{9}}\\).\nEl estimador resultante para la matriz de covarianzas es consistente, tanto en presencia de heteroscedasticidad como de autocorrelación de formas desconocidas.\n\n\n3.6.3.2 El estimador de mínimos cuadrados generalizados\nSi se detecta la presencia de autocorrelación en los errores del modelo, en lugar de MCO corregidos puede aplicarse el estimador de mínimos cuadrados generalizados (MCG), \\({\\widehat{\\mathbf{\\beta}}}_{MCG}\\), el cual garantiza la obtención de estimadores lineales, insesgados, consistentes y de mínima varianza (eficientes).\nCuando el proceso de autocorrelaciones sigue un modelo AR(1), \\(e_{t} = \\rho e_{t - 1} + \\varepsilon_{t}\\), el método MCG consiste en tomar \\(\\mathbf{\\rho}\\)-diferencias, esto es, en transformar el modelo original mediante el procedimiento \\(z_{t}^{*} = z_{t} - \\rho z_{t - 1}\\), donde \\(z\\) representa a cualquiera de las variables del modelo, y aplicar MCO al modelo transformado.\nAsí, si se parte de una estimación del coeficiente \\(\\widehat{\\rho}\\) a partir de la regresión\n\\[{\\widehat{e}}_{t} = \\rho{\\widehat{e}}_{t - 1} + \\varepsilon_{t}\\]\nel método de MCG consiste en transformar el modelo original mediante las operaciones \\(y_{t} - \\widehat{\\rho}y_{t - 1}\\) y \\(x_{mt} - \\widehat{\\rho}x_{m,t - 1}\\), para m = 2, ..., K, y aplicar MCO al modelo transformado\n\\[y_{t} - \\widehat{\\rho}y_{t - 1} = \\beta_{1}\\left( 1 - \\widehat{\\rho} \\right) + \\beta_{2}\\left( x_{2t} - \\widehat{\\rho}x_{2,t - 1} \\right) + \\ldots + \\beta_{K}\\left( x_{Kt} - \\widehat{\\rho}x_{K,t - 1} \\right) + e_{t}^{*}\\]\nEn la práctica, el método más utilizado para llevar a cabo la estimación MCG consiste en repetir el proceso anterior un número suficiente de veces hasta conseguir la “convergencia” de las estimaciones (minimizando la suma de los cuadrados de los residuos); este procedimiento recibe el nombre de método iterativo de Cochrane-Orcutt (1949).\nTambién puede optarse por utilizar directamente el método de máxima verosimilitud (MV) que, aparte de sus buenas propiedades estadísticas (consistencia, eficiencia y normalidad asintótica), tiene la ventaja respecto a los métodos de MCG iterativos de que puede usarse para estimar cualquier modelo autorregresivo, bien sea del tipo AR(p), MA(q), la mezcla de ambos, ARMA(p,q), o modelos con otros tipos de autocorrelación, como los expuestos a continuación.\n\n\n3.6.3.3 Modelos con correlación espacial en los errores\nSupongamos que se parte de un modelo de regresión que tiene la forma autorregresiva espacial siguiente, denominada tipo SEM en los errores del modelo:\n\\[\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\]\n\\[\\mathbf{e} = \\lambda\\mathbf{We} + \\mathbf{u}\\]\nEn estos casos, en lugar de usar el estimador MCO, puede utilizarse uno más eficiente, el estimador MV, \\({\\widehat{\\mathbf{\\beta}}}_{MV}\\), que garantiza las propiedades de consistencia, eficiencia y normalidad asintótica.\n\n\n3.6.3.4 Modelos con dinámica en el tiempo\nUna de las causas más comunes de la presencia de autocorrelación temporal en los errores es la mala especificación dinámica del modelo de regresión. Por dicho motivo, en este epígrafe desarrollaremos los aspectos básicos de los modelos econométricos dinámicos.\nEn el modelo de regresión lineal estándar, \\(y_{t} = \\beta_{1} + \\beta_{2}x_{2t} + \\ldots + \\beta_{K}x_{Kt} + e_{t}\\), cuando se produce un cambio unitario en una de las variables explicativas, \\(x_{j}\\), el correspondiente valor medio de la variable endógena, \\(y\\), incrementa o disminuye instantáneamente aproximadamente en \\(\\beta_{j}\\) unidades:\n\\[\\beta_{j} \\cong \\Delta E(y)\\ \\ \\ cuando\\ \\ \\ \\Delta x_{j} = 1\\ \\ \\left( y\\ \\ \\Delta x_{i} = 0\\ \\ \\ i \\neq j \\right)\\]\nEn otros términos, dada la forma en la que se especifica el modelo, el tiempo que transcurre desde que se produce el cambio en la variable explicativa xj hasta que se alcanza el equilibrio en el nuevo valor de la variable y es muy pequeño. Por tanto, este tipo de modelos es estático por su propia naturaleza.\nSin embargo, en economía la dinámica de respuesta de y ante cambios en las variables x raras veces es inmediata y el ajuste de la posición inicial del sistema a la nueva situación de equilibrio se “distribuye” de forma considerable en el tiempo.\nUna de las formas de introducir dinámica en el modelo de regresión estándar (estático) consiste en incluir variables retardadas entre los regresores. Así se llega a los modelos de retardos distribuidos (DL), si aparecen las variables exógenas retardadas, o a los modelos autorregresivos (AR), si aparece la endógena retardada entre las variables explicativas. La “mezcla” de ambos tipos de estructuras dinámicas forma un grupo más general, los denominados modelos autorregresivos con retardos distribuidos (ARDL). Un caso particular de este tipo de modelos viene dado por los modelos con corrección del error (MCE), que son el tipo de modelos más utilizados en la econometría moderna puesto que, aparte de integrar en una sola especificación las relaciones de corto y de largo plazo existentes entre un conjunto de variables, representan la solución matemática al problema de las regresiones espurias que durante mucho tiempo preocupó a los investigadores en economía aplicada.\n\n\n3.6.3.5 Modelos con retardos en las variables explicativas\nEn general, la justificación económica de este tipo de modelos viene dada por el hecho de que en muchas ocasiones el efecto total sobre la variable endógena de un cambio en una variable explicativa puede repartirse en diferentes períodos de tiempo por razones de inercia, tecnología o debido a razones de tipo institucional.\nEn el caso de una regresión lineal con una única variable explicativa x, si el efecto de la variable x sobre y se acaba agotando en el tiempo después de transcurridos q períodos, el modelo a utilizar es el de retardos distribuidos de orden q, DL(q), que toma la expresión\n\\[y_{t} = \\alpha_{0} + \\beta_{0}x_{t} + \\beta_{1}x_{t - 1} + \\ldots + \\beta_{q}x_{t - q} + e_{t}\\]\nEn este caso, la función de respuesta de y ante un impulso en la variable exógena x toma la forma de la sucesión \\(\\left\\{ \\beta_{0},\\beta_{1},\\ldots,\\beta_{q - 1},\\beta_{q},0,\\ 0,\\ldots \\right\\}\\): si en un cierto instante del tiempo se produce un cambio unitario en la variable explicativa x a partir de una hipotética situación de equilibrio, la respuesta de la variable endógena, en términos de desviación de su posición inicial de equilibrio, será β0 en el instante inicial, β1 en el siguiente período, y así sucesivamente hasta el período q, βq, siendo 0 a partir de ese instante.\nPara estos modelos de retardos distribuidos se pueden diferenciar dos efectos:\n\nEl efecto a corto plazo o multiplicador de impacto, dado por\n\n\\[\\beta_{0} \\cong \\Delta^{cp}E(y)\\ \\ \\ cuando\\ \\ \\ \\Delta x = 1\\]\n\nEl efecto a largo plazo (total) o multiplicador de equilibrio, dado por\n\n\\[\\beta_{0} + \\beta_{1} + \\ldots + \\beta_{q} \\cong \\Delta^{lp}E(y)\\ \\ \\ cuando\\ \\ \\ \\Delta x = 1\\]\nAunque se ha simplificado la notación al objeto de llevar a cabo una exposición más sencilla, el modelo de retardos puede contener varias variables explicativas, cada una de ellas con el orden de retardos correspondiente.\nPor otra parte, la estimación de los modelos DL plantea varios problemas generales:\n\nDebe determinarse la longitud concreta (q) de los retardos: la búsqueda del retardo óptimo no es adecuada si no se tiene en cuenta que los contrastes son secuenciales, no siendo válidos los niveles de significación estándar.\nSe produce una reducción importante en el número de grados de libertad por la pérdida de las observaciones iniciales necesarias para construir las variables retardadas. Esto hará inviable la estimación salvo que se disponga de una muestra de tamaño elevado.\nAún con muestras grandes, la probable alta correlación que se observará entre los retardos de una misma variable ocasionará graves problemas de multicolinealidad, impidiendo una estimación precisa de los parámetros β del modelo.\n\nPara evitar o, al menos, amortiguar algunos de estos problemas, se pueden establecer algunas hipótesis adicionales sobre el comportamiento de los parámetros, de manera que en la práctica pueden imponorse algún tipo de restricción sobre los coeficientes β, como por ejemplo las restricciones incluidas en los modelos de retardos polinomiales de Almon o las contenidas en los modelos de retardos geométricos de Koyck, ambos propuestos en la literatura econométrica sobre el tema.\n\n\n3.6.3.6 Modelos con retardos en la variable endógena\nUn modelo autorregresivo de orden p, AR(p), tiene la forma general\n\\[y_{t} = \\alpha_{0} + \\alpha_{1}y_{t - 1} + \\alpha_{2}y_{t - 2} + ... + \\alpha_{p}y_{t - p} + \\beta_{0}x_{t} + e_{t}\\]\nes decir, el valor la variable dependiente y en el instante t depende no sólo del valor de la variable explicativa x en dicho instante, sino también de sus propios valores pasados.\nPara estos modelos autorregresivos se pueden distinguir de nuevo dos efectos:\n\nEl efecto a corto plazo sobre la media de y de un cambio unitario en x es\n\n\\[\\beta_{0} \\cong \\Delta^{cp}E(y)\\ \\ \\ cuando\\ \\ \\ \\Delta x = 1\\]\n\nEl efecto a largo plazo viene dado por\n\n\\[\\frac{\\beta_{0}}{1 - \\alpha_{1} - \\alpha_{2} - \\ldots - \\alpha_{p}} \\cong \\Delta^{lp}E(y)\\ \\ \\ cuando\\ \\ \\ \\Delta x = 1\\]\nEn general, este tipo de modelos puede estimarse por MCO, salvo en el caso de que los errores del modelo, et, estén autocorrelacionados, lo que provoca la inconsistencia del estimador MCO y, por tanto, la necesidad de utilizar un estimador alternativo, el de variables instrumentales (VI) que se expondrá posteriormente.\nEn consecuencia, resulta de vital importancia el contraste de la hipótesis de ausencia de correlación en los modelos autorregresivos. En este sentido, hay que tener en cuenta que el test de Durbin-Watson, DW, está sesgado hacia 2 ante la presencia de retardos de la variable endógena entre los regresores, por lo que para estos casos puede utilizarse el contraste de Breusch-Godfrey, o el test h de Durbin (1970), que toma la expresión \\(h = \\left( 1 - \\frac{DW}{2} \\right)\\ \\sqrt{\\frac{T}{(1 - T\\left\\lbrack Var\\left( {\\widehat{\\alpha}}_{1} \\right) \\right\\rbrack)}}\\) y que, bajo la hipótesis nula de ausencia de correlación, tiene una distribución asintótica N(0,1).\n\n\n3.6.3.7 Modelos autorregresivos con retardos distribuidos\nUna clase general de modelos de regresión que anida tanto los modelos con retardos finitos en las variables exógenas como los modelos con retardos en la endógena la constituyen los llamados modelos autorregresivos con retardos distribuidos (ARDL). En estos modelos la variable dependiente, yt, se expresa como función de sus propios valores pasados, así como del valor presente y retardado de otras variables explicativas. Así, un modelo ARDL(p,q) con un único regresor tiene la forma siguiente:\n\\[y_{t} = \\alpha_{0} + \\alpha_{1}y_{t - 1} + \\ldots + \\alpha_{p}y_{t - p} + \\beta_{0}x_{t} + \\beta_{1}x_{t - 1} + \\ldots + \\beta_{q}x_{t - q} + e_{t}\\]\nla cual tiene una extensión inmediata al caso general de K variables explicativas, donde cada una de ellas podrá tener su propio retardo.\nPara estos modelos generales los efectos tienen la forma siguiente:\n\nEl efecto a corto plazo sobre la media de y de un cambio unitario en x es\n\n\\[\\beta_{0} \\cong \\Delta^{cp}E(y)\\ \\ \\ cuando\\ \\ \\ \\Delta x = 1\\]\n\nEl efecto a largo plazo viene dado por\n\n\\[\\frac{\\beta_{0} + \\beta_{1} + \\ldots + \\beta_{q}}{1 - \\alpha_{1} - \\alpha_{2} - \\ldots - \\alpha_{p}} \\cong \\Delta^{lp}E(y)\\ \\ \\ cuando\\ \\ \\ \\Delta x = 1\\]\nA partir de la expresión general de un modelo ARDL pueden obtenerse como casos particulares los modelos autorregresivos (βj = 0 para todo j) y los modelos con retardos distribuidos finitos (αj = 0 para todo j ≠ 0), aunque también pueden lograrse otras especificaciones económicamente interesantes según los valores de los β’s o los α’s.\n\n\n3.6.3.8 Modelos vectoriales autorregresivos\nUna clase más general que los modelos ARDL uniecuacionales viene dada por los llamados modelos vectoriales autorregresivos (VAR), que son la base del actual análisis multivariante de series temporales.\nEn el caso más simple, supongamos que tenemos dos variables x e y que se determinan simultáneamente y, por tanto, la especificación econométrica apropiada sería la forma estructural siguiente (por simplicidad, suponemos una dinámica ARDL(1,1) para cada variable):\n\\[\\mathbf{\\ }\\left\\{ \\begin{matrix} {\\ y}_{t} = \\alpha_{10} + \\alpha_{11}y_{t - 1} + \\beta_{10}x_{t} + \\beta_{11}x_{t - 1} + e_{1t} \\\\ {\\ x}_{t} = \\alpha_{20} + \\alpha_{21}x_{t - 1} + \\beta_{20}y_{t} + \\beta_{21}y_{t - 1} + e_{2t} \\\\ \\end{matrix} \\right.\\ \\]\ndonde asumiremos que \\(Cov\\left( e_{1t},e_{2t} \\right) = 0\\). Este sistema puede escribirse matricialmente como\n\\[\\begin{bmatrix}\n1 & - \\beta_{10} \\\\\n- \\beta_{20} & 1 \\\\\n\\end{bmatrix}\\begin{pmatrix}\ny_{t} \\\\\nx_{t} \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n\\alpha_{10} \\\\\n\\alpha_{20} \\\\\n\\end{pmatrix} + \\begin{bmatrix}\n\\alpha_{11} & \\beta_{11} \\\\\n\\beta_{21} & \\alpha_{21} \\\\\n\\end{bmatrix}\\begin{pmatrix}\ny_{t - 1} \\\\\nx_{t - 1} \\\\\n\\end{pmatrix} + \\begin{pmatrix}\ne_{1t} \\\\\ne_{2t} \\\\\n\\end{pmatrix}\\]\no escrito en forma compacta como \\(\\mathbf{Bz}_{t} = \\mathbf{\\Gamma}_{0} + \\mathbf{\\Gamma}_{1}\\mathbf{z}_{t - 1} + \\mathbf{e}_{t}\\), donde \\(\\mathbf{B},\\ \\mathbf{\\Gamma}_{0}\\ y\\ \\mathbf{\\Gamma}_{1}\\) son las correspondientes matrices del sistema anterior y \\(\\mathbf{z}_{t} = \\begin{pmatrix} y_{t} \\\\ x_{t} \\\\ \\end{pmatrix}\\ \\). Multiplicando por \\(\\mathbf{B}^{- 1}\\) el sistema anterior se llega a la expresión siguiente:\n\\[\\mathbf{z}_{t} = \\mathbf{A}_{0} + \\mathbf{A}_{1}\\mathbf{z}_{t - 1} + \\mathbf{u}_{t}\\]\nque se conoce como modelo VAR en forma reducida (en el sistema anterior \\(\\mathbf{A}_{0} = \\mathbf{B}^{- 1}\\ \\mathbf{\\Gamma}_{0}\\), \\(\\mathbf{A}_{1} = \\mathbf{B}^{- 1}\\ \\mathbf{\\Gamma}_{1}\\) y \\(\\mathbf{u}_{t} = \\mathbf{B}^{- 1}\\mathbf{e}_{t}\\)).\nEl modelo VAR anterior no es más que un modelo autorregresivo de primer orden para el vector de variables endógenas \\(\\mathbf{z}\\), que se puede generalizar de forma sencilla hacia un modelo VAR(p) que incluye p retardos en el vector \\(\\mathbf{z}\\):\n\\[\\mathbf{z}_{t} = \\mathbf{A}_{0} + \\mathbf{A}_{1}\\mathbf{z}_{t - 1} + \\mathbf{A}_{2}\\mathbf{z}_{t - 2} + \\ldots\\mathbf{A}_{p}\\mathbf{z}_{t - p} + \\mathbf{u}_{t}\\]\nEn la práctica, el uso que se hace de los modelos VAR no consiste en la explotación estructural de los mismos (interpretación de los parámetros estimados), sino que suelen emplearse para el análisis de correlación temporal entre variables macroeconómicas (causalidad de Granger), para la simulación de los efectos de shocks externos sobre un sistema económico (funciones de respuesta al impulso y de descomposición de la varianza), o para realizar predicciones a futuro de un conjunto de variables del modelo, etc.\n\n\n3.6.3.9 Modelos con corrección del error\nEn las últimas décadas, este tipo de modelos ha adquirido una importancia capital en el campo de la macroeconomía aplicada ya que proporcionan al económetra una herramienta adecuada para tratar con los problemas de no estacionariedad de las series temporales económicas y de existencia de regresiones espurias (erróneas o falsas). Además, son la pieza fundamental de la llamada teoría de la cointegración, que analiza la validez de las regresiones entre series económicas temporales con tendencias estocásticas. El desarrollo completo de estos conceptos excede el alcance de este manual, pero a continuación desarrollaremos algunas ideas básicas.\nComo punto de partida, consideremos un modelo ARDL(1,1), \\(y_{t} = \\alpha_{0} + \\alpha_{1}y_{t - 1} + \\beta_{0}x_{t} + \\beta_{1}x_{t - 1} + e_{t}\\), el cual puede escribirse como\n\\[\\Delta y_{t} = \\alpha_{0} + \\beta_{0}\\Delta x_{t} - \\lambda(y_{t - 1} - \\theta x_{t - 1}) + e_{t}\\]\ndonde \\(\\lambda = 1 - \\alpha_{1}\\) y \\(\\theta = (\\beta_{0} + \\beta_{1})/(1 - \\alpha_{1})\\). Esta relación se conoce como representación en forma de corrección del error (MCE) del modelo ARDL(1,1), el término \\((y_{t - 1} - \\theta x_{t - 1})\\) como error de desequilibrio (o término de corrección del error) y el parámetro \\(\\lambda\\) como velocidad del ajuste del sistema hacia el equilibrio a largo plazo. Hay que notar que el término de corrección representa la desviación de las variables y y x, en el período t − 1, respecto a su posición de equilibrio a largo plazo, dada por la ecuación \\(y^{*} = \\frac{\\alpha_{0}}{1 - \\alpha_{1}} + \\frac{\\beta_{0} + \\beta_{1}}{1 - \\alpha_{1}}x^{*}\\).\nEl punto clave en la teoría de la cointegración es el análisis de la validez de tal ecuación estable a largo plazo (conocida como relación de cointegración), para lo cual las tendencias estocásticas de las series temporables y y x deben “cancelarse”, lo que equivale a decir que los errores de desequilibrio deben ser estacionarios (técnicamente, las variables estacionarias se dice que no contienen raíces unitarias).\nEn los modelos MCE, el efecto a largo plazo sobre y de un cambio unitario en x viene dado por la expresión\n\\[\\frac{\\partial y^{*}}{\\partial x^{*}} = \\left( \\frac{\\beta_{0} + \\beta_{1}}{1 - \\alpha_{1}} \\right) = \\theta\\]\nmientras que, directamente de la expresión del modelo MCE, se tiene que el efecto a corto plazo de un cambio unitario en x sobre la media de y vendrá dado por\n\\[\\Delta E\\lbrack y\\rbrack \\cong \\beta_{0}\\ cuando\\ \\Delta x = 1\\]\nLos modelos de corrección del error, al ser no lineales, pueden estimarse por el método de MV, aunque su estimación suele realizarse siguiendo un procedimiento de dos etapas conocido como método de Engle y Granger.\nEste enfoque consiste en estimar en la primera etapa, utilizando el método de MCO, la relación a largo plazo \\(y_{t} = \\theta x_{t} + u_{t}\\); y en la segunda etapa, también por MCO, el modelo en forma de corrección del error, substituyendo los errores de desequilibrio teóricos, \\((y_{t - 1} - \\theta x_{t - 1})\\), por sus análogos estimados, \\(\\Delta y_{t} = \\alpha_{0} + \\beta_{0}\\Delta x_{t} - \\lambda{\\widehat{u}}_{t - 1} + e_{t}\\).\nPara el caso general, donde existen varios regresores como factores explicativos de la variable y, el enfoque de Engle-Granger funciona de forma análoga al procedimiento bi-etápico anterior:\n- En primer lugar, se estima** por MCO la ecuación de largo plazo siguiente:\n\\[\\mathbf{\\ }y_{t} = \\theta_{1} + \\theta_{2}x_{2t} + \\ldots + \\theta_{K}x_{Kt} + u_{t}\\ \\]\ny, a continuación, se calculan los errores estimados, \\({\\widehat{u}}_{t}\\).\n- En la segunda etapa, se estima también por MCO el modelo dinámico de corrección del error (MCE), que será un modelo ARDL en las primeras diferencias de la variable dependiente y las variables explicativas , \\(\\mathrm{\\Delta}y_{t}\\) y \\(\\mathrm{\\Delta}x_{jt}\\), más el término de corrección del error \\(- \\lambda{\\widehat{u}}_{t - 1}\\) y otros regresores z’s (en primeras diferencias o no) que aporten información que permita explicar las variaciones de la variable y en el corto plazo:\n\\[\\mathrm{\\Delta}y_{t} = \\alpha_{0} + \\sum_{i = 1}^{p}{\\alpha_{i}\\mathrm{\\Delta}y_{t - i} +}\\sum_{i = 1}^{q_{1}}{\\beta_{1,i}\\mathrm{\\Delta}x_{1,t - i} +}\\ldots + \\sum_{i = 1}^{q_{K}}{\\beta_{K,i}\\mathrm{\\Delta}x_{K,t - i} -  }\\] \\[\\mathrm{-\\lambda{\\widehat{u}}_{t - 1} + \\gamma_{1}z_{1t} + \\ldots + \\gamma_{m}z_{mt} + e_{t}}\\mathbf{\\ }\\]\nUna condición necesaria para que exista cointegración, es decir, una relación estable a largo plazo entre la variable y y las x’s, es que el coeficiente de ajuste \\(\\lambda\\) sea estadísticamente significativo; si \\(\\lambda = 0\\) entonces no hay ajuste y la relación a largo plazo no tiene sentido, sino sólo la de corto plazo. Solo en el caso de que exista cointegración podrá hablarse de forma fiable de las relaciones a corto y a largo plazo y del correspondiente MCE, que es el que “guía” el movimiento simultáneo de las variables del sistema hacia su posición de equilibrio a largo plazo.\nTécnicamente la forma correcta de determinar si las variables están cointegradas es realizar el correspondiente test de la hipótesis de estacionariedad de los residuos \\({\\widehat{u}}_{t}\\), lo que debe hacerse a través de los llamados contrastes de raíces unitarias. Uno de estos contrastes es el llamado test de Dickey-Fuller aumentado, que consiste en estimar por el método MCO la regresión auxiliar\n\\[\\mathrm{\\Delta}{\\widehat{u}}_{t} = \\phi_{0}{\\widehat{u}}_{t - 1} + \\sum_{i = 1}^{p}{\\phi_{i}\\mathrm{\\Delta}{\\widehat{u}}_{t - i} + \\nu_{t}}\\]\ny comprobar si el estadístico t0 asociado al parámetro \\({\\widehat{\\phi}}_{0}\\) resulta estadísticamente significativo. Para ello deben utilizarse valores críticos o P-valores específicos, puesto que la distribución del estadístico t bajo la hipótesis nula no es la t de Student convencional sino que sigue una distribución no estándar con valores críticos y probabilidades asociadas que dependen del tipo de regresión auxiliar realizada. A modo de ejemplo, el valor crítico al 5% de significación está entre −3.4 y −3.2, mucho más negativo que el valor crítico estándar de la t de Student asociado a la hipótesis nula de que \\(\\phi_{0} = 0\\), cercano a −1.7.\n\n\n3.6.3.10 Modelos con dinámica en el espacio\nSupongamos que, en lugar de partir de un modelo de regresión con autocorrelación espacial de primer orden en los errores, se propone un modelo con retardo espacial en la variable endógena, el llamado modelo SAR:\n\\[\\mathbf{y} = \\rho\\mathbf{Wy} + \\mathbf{X\\beta} + \\mathbf{e}\\]\nsiendo \\(\\mathbf{W}\\) la matriz de pesos espaciales, \\(\\rho\\) el parámetro que mide la intensidad de la correlación espacial en la variable dependiente y \\(\\mathbf{e} \\approx N(\\mathbf{0}\\mathbf{,}\\sigma^{2}\\mathbf{I})\\).\nEn estos casos, igual que ocurre con los modelos espaciales SEM para los errores, debe utilizarse el estimador de máxima verosimilitud, que cumple las propiedades de consistencia, eficiencia y normalidad asintótica; además, en este caso el estimador MCO no solo pierde fiabilidad, sino que además es sesgado e inconsistente, por lo que resulta obligatoria su sustitución por el estimador MV."
  },
  {
    "objectID": "p3c1-teoria.html#información-muestral",
    "href": "p3c1-teoria.html#información-muestral",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.7 Información muestral",
    "text": "3.7 Información muestral\n\n3.7.1 Falta de observaciones\nEs frecuente en el trabajo econométrico encontrarse con el problema de la falta de una o varias observaciones muestrales (missing data) para alguna de las variables del modelo, bien sea la endógena, o alguna(s) de las explicativas. Esta ausencia debe ser de tipo aleatorio, pues en caso contrario estaríamos ante un problema de selección muestral, el cual se tratará con posterioridad.\nEn general, hay que señalar que no se da el mismo tratamiento al problema de falta de información muestral si se trabaja con datos de corte transversal o de series temporales. Entre los diferentes métodos que se han propuesto en la literatura para tratar el mismo podemos mencionar los siguientes:\n\nMCO de la muestra truncada. Las estimaciones se obtienen solamente con las observaciones completas. Esta solución supone pérdida de observaciones y de grados de libertad, pero el estimador MCO sigue teniendo todas las propiedades habituales, siempre y cuando los “huecos” en los datos no sean sistemáticos, sino aleatorios (sin causa específica alguna), y la muestra truncada siga siendo representativa de la población investigada.\nRegresión de orden cero. Se substituyen los valores perdidos de cada de una de las variables por su media (la de las observaciones completas). Si denotamos por (yA, XA) las observaciones completas, por (yB, XB) las observaciones para las cuales faltan los valores de y pero no de las x’s, y por (yC, XC) las observaciones para las cuales faltan los valores de las x’s pero no de y, se procede del siguiente modo: (1) se substituye yB por la media de las observaciones yA e yC, (2) se substituye XC por la media de las observaciones XA y XB y (3) se aplican MCO para todas las observaciones, las completas y las “completadas”.\nRegresión de primer orden. Se realiza la regresión de y sobre las x’s con las observaciones completas (yA, XA) y también de cada x sobre un conjunto de regresores z’s que se considere oportuno, ZA, y se substituyen los valores perdidos por los correspondientes valores de predicción. Por último, se lleva a cabo la regresión con todos los datos, completos y completados.\nOtros métodos de imputación: máxima verosimilitud, variables ficticias, interpolación, etc.\n\nPuede decirse que, en términos generales, no se conocen bien las propiedades estadísticas de los estimadores que se obtienen con los distintos métodos de imputación propuestos en la literatura, aunque se ha demostrado que la mayoría de ellos reportan pocos beneficios, cuando no empeoran las propiedades básicas, como por ejemplo la insesgadez, respecto a la opción de utilizar solo las observaciones completas (muestra truncada).\n\n\n3.7.2 Agregación de datos\nConsideremos el modelo de regresión estándar, \\(y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i}\\). Si la muestra inicial era de n observaciones, a veces ocurre que no se dispone de los datos originales sino de datos elaborados por agregación a partir de la información de origen (por ejemplo, para guardar el anonimato de los informantes, por problemas de coste, etc.), como pueden ser los valores medios o totales correspondientes a g grupos de \\(n_{1},\\ldots,n_{g}\\) observaciones cada uno de ellos.\nEn esta situación no podemos aplicar directamente los resultados conocidos de la estimación MCO, ya que dejan de satisfacerse algunas de las hipótesis básicas.\nSupongamos que disponemos de los valores medios, \\({\\overline{y}}_{i},{\\overline{x}}_{2i},\\ldots,{\\overline{x}}_{Ki}\\text{\\ \\ \\ }i = 1,\\ldots,g\\), en lugar de los datos originales \\(y_{i},x_{2i},\\ldots,x_{Ki}\\text{\\ \\ \\ }i = 1,\\ldots,n\\). En este caso, la ecuación a estimar será\n\\[\\ {\\overline{y}}_{i} = \\beta_{1} + \\beta_{2}{\\overline{x}}_{2i} + \\ldots + \\beta_{K}{\\overline{x}}_{Ki} + {\\overline{e}}_{i}\\ \\]\nque, como puede apreciarse, tiene los mismos parámetros que el modelo original, aunque se tiene que \\(\\ {\\overline{e}}_{i} = \\frac{\\sum_{i}^{}e_{ij}}{n_{i}}\\ \\) y, por tanto, \\(\\ Var\\left( {\\overline{e}}_{i} \\right) = \\frac{\\sigma^{2}}{n_{i}}\\ \\).\nEs decir, que en el modelo con datos agrupados no se satisface la hipótesis de homoscedasticidad, sino que, por el contrario, existe heteroscedasticidad con una forma concreta. Sin embargo, en esta situación particular, el problema puede resolverse fácilmente aplicando el método de mínimos cuadrados ponderados, utilizando como ponderaciones los valores \\(\\ p_{i} = \\sqrt{n_{i}}\\ \\).\n\n\n3.7.3 Multicolinealidad\n\n3.7.3.1 Naturaleza y causas de la multicolinealidad\nSe utiliza el término multicolinealidad exacta para designar la situación que se da cuando las variables explicativas de un modelo de regresión son linealmente dependientes, es decir, ∃λ1,…,λK no todos nulos tales que\n\\[\\lambda_{1}\\mathbf{x}_{1} + \\lambda_{2}\\mathbf{x}_{2} + \\ldots + \\lambda_{K}\\mathbf{x}_{K} = \\mathbf{0}\\]\nComo consecuencia, el rango de la matriz \\(\\mathbf{X}\\) de datos de las variables explicativas (y, por tanto, de la matriz \\(\\mathbf{X}'\\mathbf{X}\\)) es menor que K y, por consiguiente, el sistema \\(\\left( \\mathbf{X}'\\mathbf{X} \\right)\\mathbf{\\beta} = \\mathbf{X}'\\mathbf{y}\\) no tiene solución única [puesto que \\((\\mathbf{X}'\\mathbf{X})^{- 1} =\\frac{1}{det(\\mathbf{X}'\\mathbf{X})}adj(\\mathbf{X}'\\mathbf{X})^{'}\\), si el determinante de la matriz \\(\\mathbf{X}'\\mathbf{X}\\) es cero, no existe la matriz inversa]. En consecuencia, no existe un único estimador MCO y, además, la varianza de las estimaciones será “infinita”.\nSi la dependencia lineal no es exacta, pero se encuentra muy próxima a ella, hablaremos de multicolinealidad aproximada, o simplemente de multicolinealidad, teniéndose entonces que ∃ λ1,…,λK no todos nulos, tales que\n\\[\\lambda_{1}\\mathbf{x}_{1} + \\lambda_{2}\\mathbf{x}_{2} + \\ldots + \\lambda_{K}\\mathbf{x}_{K} \\cong \\mathbf{0}\\]\nEn este caso, en lugar de cumplirse que \\(det(\\mathbf{X}^{\\mathbf{'}}\\mathbf{X}) = 0\\), como en el caso de multicolinealidad exacta, este determinante tendrá valores muy próximos a cero:\n\\[\\det(\\mathbf{X}^{\\mathbf{'}}\\mathbf{X}) \\cong \\mathbf{0}\\]\nComo en la práctica el caso de multicolinealidad exacta no se observa salvo en circunstancias excepcionales (como el caso de la ‘trampa de las variables ficticias’ tratado en el capítulo tres), en lo que sigue trataremos solo el caso aproximado, utilizando para esta situación el término multicolinealidad, a secas.\nEn cuanto a las causas de la multicolinealidad, en general podemos afirmar que la colinealidad es un problema de los datos y no del modelo, siendo la norma —más que la excepción— cuando se trabaja con variables económicas temporales. Algunos de los motivos por los que la multicolinealidad puede aparecer son los siguientes:\n\nComportamiento tendencial en el tiempo de las series económicas.\nSobredeterminación: la misma información se encuentra en diferentes variables explicativas de un mismo modelo que, por tanto, estarán fuertemente correlacionadas.\nMétodos de obtención de la información.\nEspecificación del modelo: aparecen como regresores diferentes potencias de una misma variable explicativa o se usan múltiples variables ficticias.\n\n\n\n3.7.3.2 Consecuencias de la multicolinealidad\nCuando existe multicolinealidad se originan los problemas siguientes:\n\nAunque el estimador MCO siguen siendo insesgado y consistente, existe una pérdida importante de precisión en las estimaciones ya que, al venir la matriz de covarianzas del estimador dada por \\(Cov({\\widehat{\\mathbf{\\beta}}}_{MCO}) = \\sigma^{2}(\\mathbf{X}'\\mathbf{X})^{- 1}\\), las varianzas \\(Var({\\widehat{\\beta}}_{i})\\)y covarianzas \\(Cov({\\widehat{\\beta}}_{i},{\\widehat{\\beta}}_{j})\\) tomarán valores muy elevados, puesto que en el cálculo de la matriz \\((\\mathbf{X}'\\mathbf{X})^{- 1}\\) aparece como divisor el número \\(det(\\mathbf{X}'\\mathbf{X})\\). Por tanto, existirán en general pocos coeficientes significativos (los estadísticos t serán bajos), aunque pueda observarse un R2 elevado. Además, los intervalos de confianza serán anormalmente amplios, lo que implica una sobre-tendencia a aceptar cualquier hipótesis nula.\nExisten, entonces, ‘sesgos’ en el contraste de hipótesis paramétricas, en el sentido de que cada contraste estadístico será menos preciso que si no hubiese colinealidad entre las variables explicativas.\nPequeñas variaciones en los datos pueden dar lugar a grandes variaciones en las estimaciones, es decir, las estimaciones se vuelven muy inestables.\nNo se pueden separar los efectos individuales de las variables y, por tanto, se hace difícil utilizar el modelo como una herramienta para el análisis estructural. Sin embargo, no se ven afectadas las capacidades ni explicativa ni predictiva del modelo.\n\n\n\n3.7.3.3 Detección de la multicolinealidad\nSe puede decir que, en economía, dada la naturaleza no experimental de los datos, siempre existe algún grado de colinealidad entre las variables de un modelo de regresión. Por tanto, el problema de la detección de la multicolinealidad no consiste en analizar su existencia, sino en determinar cuándo su nivel de presencia puede ser suficientemente alto como para perjudicar el proceso inferencial asociado a la estimación de un modelo.\nPueden considerarse como indicios de multicolinealidad los siguientes fenómenos:\n\nPequeñas variaciones en la información muestral dan lugar a grandes fluctuaciones en las estimaciones de los parámetros y en los errores estándar estimados.\nLos coeficientes tienen errores estándar elevados y niveles de significación estadística bajos (t-ratios cercanos a cero), aún cuando todas las variables resulten conjuntamente significativas (test F) y el R2 sea elevado.\nLos coeficientes estimados pueden tomar valores anormales en tamaño o incluso signos opuestos al esperado.\nSe observan altas correlaciones* parciales, \\(r_{ij} = Corr(x_{i},x_{j})\\ \\), entre las variables explicativas del modelo. Se considera que valores superiores a 0.8 para datos de series temporales, o mayores que 0.5 para datos de corte transversal, señalan un nivel de multicolinealidad importante.\nPor otra parte, se puede demostrar que \\[Var({\\widehat{\\beta}}_{j}) = \\frac{{\\widehat{\\sigma}}^{2}}{S_{jj}}\\left( \\frac{1}{1 - R_{j}^{2}} \\right)\\] donde $R_{j}^{2}$ es el coeficiente de determinación de la regresión de la variable xj frente al resto de variables explicativas del modelo y \\(S_{jj} = \\sum_{i}^{}{(x_{ij} - {\\overline{x}}_{j})^{2}}\\). Por tanto, valores altos de los coeficientes \\(R_{j}^{2}\\) están asociados con valores elevados de las varianzas estimadas. Normalmente se utilizan, en lugar de los \\(R_{j}^{2}\\), los llamados factores de inflación de la varianza (FIV), que se definen como \\[FIV_{j} = \\frac{1}{1 - R_{j}^{2}}\\]considerándose como señal de multicolinealidad débil valores de los FIV inferiores a 5, moderada si los FIV están entre 5 y 10, y fuerte si existen valores por encima de 10 (lo que equivale a que los \\(R_{j}^{2}\\) sean superiores a 0.9).\n\n\n\n3.7.3.4 Corrección de multicolinealidad\nEn general, podemos afirmar que la multicolinealidad es la norma, más que la excepción, cuando se trabaja con datos de series temporales. Además, se puede decir que, dada la naturaleza no experimental de los datos económicos, siempre existe algún grado de colinealidad entre las variables explicativas de un modelo de regresión.\nLa cuestión que planteamos en este apartado es saber qué hacer cuando el nivel de multicolinealidad es tan alto como para perjudicar al proceso inferencial asociado a un modelo de regresión.\nPueden considerarse distintas posibilidades:\n\nUso de información a priori o extramuestral (de trabajos empíricos anteriores o de la propia teoría económica). Un ejemplo de este tipo de solución puede ser la incorporación de información transversal en el modelo temporal, o la imposición de restricciones paramétricas en el proceso de estimación. Sin embargo, si las restricciones son falsas, puede generarse aún más ineficiencia que con la sola presencia de la multicolinealidad.\nEliminación de algún regresor fuertemente correlacionado con alguna(s) de las restantes variables explicativas. En este caso, “puede ser peor el remedio que la enfermedad” ya que pueden aparecer problemas de mala especificación funcional derivados de la exclusión de alguna variable relevante (sesgo e inconsistencia, no solo imprecisión).\nTransformar las variables del modelo, por ejemplo, tomando primeras diferencias, ha sido hasta hace pocos años una práctica rutinaria para eliminar la tendencia en las series temporales económicas y, por tanto, para aliviar los problemas de multicolinealidad que provoca su presencia. Sin embargo, esta costumbre genera nuevos problemas como la presencia de autocorrelación en los errores o, lo que es más importante, la pérdida de información valiosa sobre la relación a largo plazo entre las variables del modelo.\nUtilización de métodos de regularización, lo que conduce al estimador ridge (también llamado estimador “cresta”) o al estimador lasso, entre otros.\nEl estimador ridge se obtiene el vector de parámetros que minimiza la función\n\\[{\\ \\mathbf{(}\\mathbf{y}\\mathbf{-}\\mathbf{X\\beta}\\mathbf{)'(}\\mathbf{y}\\mathbf{-}\\mathbf{X\\beta}\\mathbf{)}}{\\  + r\\sum_{j}^{}\\beta_{j}^{2}}\\]\npara algún valor \\(r \\geq 0\\). Gráficamente, el estimador ridge se obtiene expandiendo las elipses centradas en el estimador MCO hasta lograr la intersección con el círculo que representa el espacio de parámetros asociado a la restricción de penalización \\(\\sum_{j}^{}\\beta_{j}^{2} \\leq t^{2}\\) (el valor t juega el mismo papel que \\(r\\)).\nEl vector que resuelve el problema de minimización penalizada propuesto viene dado por la expresión \\[{\\widehat{\\mathbf{\\beta}}}_{ridge} = (\\mathbf{X}'\\mathbf{X} + r\\mathbf{I})^{- 1}\\mathbf{X}'\\mathbf{y}\\]\npudiendo comprobarse que para r = 0 el estimador ridge coincide con el estándar MCO. Aunque \\({\\widehat{\\mathbf{\\beta}}}_{ridge}\\) es esgado, se puede demostrar que su matriz de covarianzas\n\\[Cov({\\widehat{\\mathbf{\\beta}}}_{ridge}) = \\sigma^{2}(\\mathbf{X}'\\mathbf{X} + r\\mathbf{I})^{- 1}\\mathbf{X}'\\mathbf{X}(\\mathbf{X}'\\mathbf{X} + r\\mathbf{I})^{- 1}\\]\n“es menor” que la del estimador MCO, en el sentido de que el error cuadrático medio (ECM) a que da lugar es inferior. Por tanto, el aumento del sesgo puede quedar compensado con la menor varianza si se tiene en cuenta el criterio del error cuadrático medio en lugar del criterio del sesgo.\nEl estimador lasso , \\({\\widehat{\\mathbf{\\beta}}}_{lasso}\\), se obtiene al minimizar la función\n\\[{\\ \\mathbf{(}\\mathbf{y}\\mathbf{-}\\mathbf{X\\beta}\\mathbf{)'(}\\mathbf{y}\\mathbf{-}\\mathbf{X\\beta}\\mathbf{)}}{\\  + r\\sum_{j}^{}\\left| \\beta_{j} \\right|}\\]\npara alguna elección de \\(r \\geq 0\\). En este caso, la solución (que no tiene una fórmula explícita para el problema de optimización planteado) se obtiene en el punto de intersección de las elipses entradas en el estimador MCO con el cuadrado asociado a la restricción \\(\\sum_{j}^{}\\left| \\beta_{j}\\  \\right| \\leq t\\).\nUso de métodos multivariantes de reducción-contracción (shrinkage), en particular el análisis de componentes principales (PCA en inglés) o el método de mínimos cuadrados parciales (PLS en inglés). Estas técnicas consisten en reducir la matriz original de datos \\(\\mathbf{X}\\), de orden \\(n \\times K\\), a una matriz \\(\\mathbf{Z}\\), de orden \\(n \\times M\\) con M &lt; K, en la que las columnas de la nueva matriz sean ortogonales entre sí (multicolinealidad cero). La diferencia entre ellas radica en que mientras el PCA ignora la variable dependiente a la hora de buscar la matriz \\(\\mathbf{Z}\\), el método PLS explícitamente elige las z’s para predecir la variable respuesta y lo mejor posible. Aplicando cualquiera de estos métodos se pasa, por tanto, del modelo original, \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\), a otro modelo, \\(\\mathbf{y} = \\mathbf{Z\\gamma} + \\mathbf{e}\\), en el que ya no existe multicolinealidad. El inconveniente que se plantea es que no resulta fácil en muchas ocasiones la interpretación de las nuevas variables del modelo y menos aún la de los parámetros γ del modelo transformado."
  },
  {
    "objectID": "p3c1-teoria.html#regresores-endógenos-errores-de-medida-yo-simultaneidad-en-las-variables-del-modelo",
    "href": "p3c1-teoria.html#regresores-endógenos-errores-de-medida-yo-simultaneidad-en-las-variables-del-modelo",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.8 Regresores endógenos: errores de medida y/o simultaneidad en las variables del modelo",
    "text": "3.8 Regresores endógenos: errores de medida y/o simultaneidad en las variables del modelo\nHasta el momento se ha supuesto que, a la hora de realizar un trabajo econométrico empírico, se dispone de los verdaderos valores de las variables. Sin embargo, es frecuente que existan, por diferentes motivos (ajenos o intrínsecos a la investigación), errores de medida en las observaciones de las variables que pueden inducir sesgos en las estimaciones MCO que pueden ser altos. Un ejemplo de tal situación es el que produce el empleo de variables aproximadas (proxy) para cuantificar conceptos (variables latentes) sobre los que no se dispone de información numérica (inteligencia, habilidad, nivel de educación, etc.).\n\n3.8.1 Errores de medida en la variable dependiente\nConsideremos, sin pérdida de generalidad, un modelo de regresión teórico dado por \\(y_{i} = \\beta_{1} + \\beta_{2}x_{i} + e_{i}\\). Si medimos la variable y con error, no dispondremos de los verdaderos valores \\(y_{i}\\), sino de los valores observados \\(y_{i}^{*} = y_{i} + u_{i}\\), donde \\(u_{i}\\) es el error de medida. Entonces\n\\[\\left\\{ \\begin{matrix} y_{i} = \\beta_{1} + \\beta_{2}x_{i} + e_{i} \\\\ y_{i}^{*} = y_{i} + u_{i} \\\\ \\end{matrix} \\right.\\ \\]\ny, como consecuencia, el modelo que puede ser estimado será\n\\[y_{i}^{*} = \\beta_{1} + \\beta_{2}x_{i} + v_{i}\\]\ndonde \\(\\nu_{i}^{} = e_{i} + u_{i}\\).\nEn este nuevo modelo los parámetros estructurales son los mismos, pero la perturbación aleatoria, incrementada ahora con el error de medida en y, tendrá una varianza dada por Var(vi)=Var(ei)+Var(ui)+2Cov(ei,ui).\nSi se supone que no existe correlación entre el error de medida y la perturbación, Cov(ei,ui)=0, se tendrá entonces que \\(Var(\\nu_{i}) = \\sigma^{2} + \\sigma_{u}^{2}\\).\nPor tanto, en presencia de errores de medida en la variable dependiente, el estimador MCO sigue siendo insesgado y consistente, si bien las varianzas estimadas serán mayores que cuando no existen estos errores. En consecuencia, los ajustes del modelo serán en general peores y las estimaciones serán más imprecisas que en el caso ideal de ausencia de errores de medición en la variable a explicar.\n\n\n3.8.2 Errores de medida en las variables explicativas\nSi en el modelo de regresión \\(y_{i} = \\beta_{1} + \\beta_{2}x_{i} + e_{i}\\) ahora fuese la variable explicativa x la que se midiese con error, se tendría que \\(x_{i}^{*} = x_{i} + w_{i}\\) y, entonces,\n\\[\\left\\{ \\begin{matrix} y_{i} = \\beta_{1} + \\beta_{2}x_{i} + e_{i} \\\\ x_{i}^{*} = x_{i} + w_{i} \\\\ \\end{matrix} \\right.\\ \\]\nPor tanto, el modelo que se estimará en la práctica es\n\\[y_{i} = \\beta_{1} + \\beta_{2}x_{i}^{*} + v_{i}\\]\ndonde \\(\\nu_{i} = e_{i} - \\beta_{2}w_{i}\\)\nSe tiene pues que \\(Var(\\nu_{i}) = \\sigma^{2} + \\beta_{2}^{2}\\sigma_{w}^{2}\\), por lo que, de nuevo, las varianzas estimadas serán mayores que cuando no existen errores de medida: se tendrá un peor ajuste y una mayor imprecisión en las estimaciones. Pero, además, se cumple que \\(Cov(x_{i}^{*},v_{i}) = Cov(x_{i} + w_{i},e_{i} - \\beta_{2}w_{i}) = - \\beta_{2}\\sigma_{w}^{2} \\neq 0\\), implicando este resultado el incumplimiento de una de las hipótesis básicas del modelo de regresión lineal ya que, siendo ahora la variable explicativa \\(x_{i}^{*}\\) estocástica, no se verifica que la covarianza de esta con el término de error \\(\\nu_{i}\\) sea nula y, por tanto, el estimador MCO será entonces sesgado e inconsistente.\nEn general, si en un modelo de regresión \\(y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + ... + \\beta_{K}x_{Ki} + e_{i}\\) alguna de las variables explicativas se mide con error, se tendrá que \\(x_{ji}^{*} = x_{ji} + w_{ji}\\) y, por tanto, el modelo que realmente se estimará viene dado por\n\\[y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{j}x_{ji}^{*} + \\ldots + \\beta_{K}x_{Ki} + \\nu_{i}\\]\ndonde el término de error tomará la expresión \\(\\nu_{i} = e_{i} - \\beta_{j}w_{ji}\\).\nEn este caso se cumple que \\(Cov(x_{ji}^{*},v_{i}) = - \\beta_{j}\\sigma_{jw}^{2} \\neq 0\\), lo que implica la violación de una de las hipótesis básicas del modelo de regresión lineal ya que, siendo ahora la variable explicativa \\(x_{j}^{*}\\) estocástica, su covarianza con el término de error \\(\\nu_{i}\\) no es nula y, por tanto, el estimador MCO será sesgado e inconsistente.\n\n\n3.8.3 Modelos de múltiples ecuaciones: el problema de la simultaneidad\nUn modelo de ecuaciones simultáneas es un conjunto de ecuaciones de regresión e identidades matemáticas que representan las relaciones de un sistema económico. Este conjunto de relaciones se conoce como forma o ecuaciones estructurales del sistema, ya que recogen de modo directo las relaciones entre las variables del sistema económico bajo estudio.\nUn ejemplo de sistema multiecuacional puede ser un modelo Keynesiano simple para explicar el consumo agregado de una economía cerrada, el cual viene representado por las dos ecuaciones estructurales siguientes (como puede observarse, la segunda es una identidad, sin parámetros a estimar):\n\\[\\left\\{ \\begin{matrix} C_{t} = \\beta_{1} + \\beta_{2}Y_{t} + e_{t} \\\\ Y_{t} = C_{t} + I_{t} \\\\ \\end{matrix} \\right.\\ \\]\ndonde C es el consumo, Y la renta e I la inversión (privada y pública). Las variables C e Y son las variables endógenas del sistema, cuyos valores se determinan de forma conjunta e interdependiente en el modelo, y la variable I es la variable exógena, que se determina fuera del sistema e independientemente de C, Y y del término de error del modelo, e.\nSuponiendo un hipotético equilibrio para C* e Y* en un determinado instante de tiempo t, dado un cierto valor de la inversión, I*, cada vez que se produzcan cambios en la inversión, también se producirán variaciones en la renta de equilibrio Y* y, por tanto, a través de la función de consumo se tendrá un nuevo valor de equilibrio para C*.\nOtro ejemplo de sistema con múltiples ecuaciones viene dado por un modelo básico para el análisis del mercado en equilibrio de un determinado bien, en el que las ecuaciones de demanda y oferta, y la relación de equilibrio, se expresan como\n\\[\\left\\{ \\begin{matrix}\nQ_{t}^{d} = \\beta_{1} + \\beta_{2}P_{t} + \\beta_{3}Y_{t} + e_{1t} \\\\\nQ_{t}^{s} = \\gamma_{1} + \\gamma_{2}P_{t} + \\gamma_{3}PF_{t} + e_{2t} \\\\\nQ_{t}^{d} = Q_{t}^{s} \\\\\n\\end{matrix} \\right.\\ \\]\ndonde Qd, Qs, P, Y y PF son, respectivamente, las cantidades demandada y ofertada, el precio, la renta disponible (o el gasto total) y el precio de los factores de producción.\nEn este modelo, los valores de equilibrio Q* y P* en cada instante de tiempo t se determinan dentro del sistema, de forma simultánea y endógena, mientras que los valores de Y* y PF* se determinan fuera del mismo, exógenamente.\nSupongamos que se intentase aplicar el método de mínimos cuadrados ordinarios para estimar la función Keynesiana de consumo de un país, o para estimar las funciones de demanda y oferta asociadas al mercado en equilibrio de un determinado producto. Aparte del hecho de estar ignorando la información de las identidades macroeconómicas en ambos modelos, lo que ya de por sí supondría una pérdida de eficiencia en el estimador, se puede demostrar que los estimadores MCO de los parámetros estructurales de la función de consumo o de las funciones de demanda y oferta son sesgados e inconsistentes, pues se cumple que \\(\\ Cov\\left( Y_{t},e_{t} \\right) \\neq 0\\ \\) para la función de consumo y \\(\\ Cov\\left( P_{t},e_{1t} \\right) \\neq 0\\ \\) y \\(\\ Cov\\left( P_{t},e_{2t} \\right) \\neq 0\\ \\) para las funciones de demanda y oferta, respectivamente.\n\n\n3.8.4 El caso general de variables explicativas estocásticas correlacionadas con la perturbación\nEl caso de errores de medida en las variables explicativas o la simultaneidad no son sino situaciones particulares del problema general de existencia de variables explicativas estocásticas correlacionadas con el término de error, hablándose entonces de regresores endógenos.\nPuede demostrarse que, en el modelo de regresión \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\), cuando las variables explicativas son estocásticas, si \\(\\mathbf{X}\\) y \\(\\mathbf{e}\\) están correlacionados (por tanto \\(\\ Cov\\left( \\mathbf{X},\\mathbf{e} \\right) \\neq \\mathbf{0}\\ \\)), entonces el estimador MCO será sesgado e inconsistente. Es decir, para cada parámetro estructural \\(\\beta\\) se tiene que \\(E(\\widehat{\\beta}) \\neq \\beta\\) y \\(\\lim_{n \\rightarrow \\infty}{E(\\widehat{\\beta}}) \\neq \\beta\\) y, por tanto, existe un sesgo en la estimación persistente, es decir, no desaparece aunque aumente el tamaño de la muestra.\n\n\n3.8.5 Las regresiones con variables instrumentales\nAnte la situación creada para el estimador MCO cuando los regresores están medidos con error o, de modo más general, cuando existen regresores estocásticos correlacionados con el término de error, se hace necesaria la construcción de un nuevo estimador con buenas propiedades. Un método de estimación que conduce a un estimador consistente para β es el conocido como método de variables instrumentales (VI).\nEn términos intuitivos, este método consiste en ‘substituir’ las variables originales del modelo, \\(\\mathbf{X}\\), por otro conjunto de variables (instrumentos o variables instrumentales), \\(\\mathbf{Z}\\), que serán el nuevo conjunto de variables explicativas, de modo que dichas variables instrumentales cumplan que (a) tengan información común con las variables originales (correlacionadas con ellas) y (b) no estén correlacionadas (al menos asintóticamente) con los errores del modelo.\n\n3.8.5.1 El test de Hausman de endogeneidad\nHausman (1978) propuso una prueba para contrastar la inconsistencia del estimador MCO originada por la correlación contemporánea no nula entre la perturbación y alguno(s) de los regresores incluidos en la ecuación a estimar (problema de endogeneidad). Así, si se parte del modelo de regresión \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\), el test de Hausman intenta contrastar\n\\[H_{0}:\\{ Cov(\\mathbf{X},\\mathbf{e}) = \\mathbf{0}\\}\\ \\ frente\\ a\\ \\ H_{1}:\\{ Cov(\\mathbf{X},\\mathbf{e}) \\neq \\mathbf{0}\\}\\]\nBásicamente, el estadístico propuesto compara las estimaciones MCO con las estimaciones VI para comprobar el grado de inconsistencia de las estimaciones mínimo-cuadráticas:\n\\[H = \\ \\left( {\\widehat{\\mathbf{\\beta}}}_{\\mathbf{VI}}\\mathbf{-}{\\widehat{\\mathbf{\\beta}}}_{\\mathbf{MCO}} \\right)^{'}\\left\\lbrack \\mathbf{Cov}\\left( {\\widehat{\\mathbf{\\beta}}}_{\\mathbf{VI}} \\right)\\mathbf{-}\\mathbf{Cov}\\left( {\\widehat{\\mathbf{\\beta}}}_{\\mathbf{MCO}} \\right) \\right\\rbrack^{\\mathbf{-}\\mathbf{1}}({\\widehat{\\mathbf{\\beta}}}_{\\mathbf{VI}}\\mathbf{-}{\\widehat{\\mathbf{\\beta}}}_{\\mathbf{MCO}})\\]\nBajo la hipótesis nula de ausencia de correlación, \\(H_{0}:\\{ Cov(\\mathbf{X},\\mathbf{e}) = \\mathbf{0}\\}\\), se cumple que \\(H\\overset{as}{\\sim}\\chi_{K_{1}}^{2}\\ \\), siendo \\(K_{1}\\) el número de variables explicativas en la matriz \\(\\mathbf{X}\\) potencialmente correlacionadas con el término de error:\n- Si no se rechaza la hipótesis nula, podremos confiar en la validez de la hipótesis de ausencia de correlación entre las variables explicativas y el término de error y seguir usando el estimador MCO, que mantendrá sus buenas propiedades (MELI, consistente y, además, eficiente si se verifica la hipótesis de normalidad de los errores).\n- Por el contrario, si se rechaza la hipótesis nula, ello implicará la invalidez del estimador MCO (que es sesgado e inconsistente), que debe ser substituido por el estimador VI (que será consistente siempre que se verifiquen las condiciones de relevancia y exogeneidad de los instrumentos).\n\n\n3.8.5.2 El estimador VI de variables instrumentales (mínimos cuadrados en dos etapas, MC2E)\nUn procedimiento que conduce a un estimador consistente para β cuando \\(\\mathbf{X}\\) y \\(\\mathbf{e}\\) están correlacionados es el conocido como método de estimación por variables instrumentales (VI). El método de VI consiste en encontrar una matriz \\(\\mathbf{Z}\\) de orden \\(n \\times L\\) (\\(L \\geq K\\)) que verifique las siguientes condiciones:\n- Relevancia de los instrumentos: las variables contenidas en \\(\\mathbf{Z}\\) están correlacionadas con las de \\(\\mathbf{X}\\): \\(\\ Cov\\left( \\mathbf{X},\\mathbf{Z} \\right) \\neq 0\\ \\).\n- Exogeneidad de los instrumentos: en el límite se debe cumplir que \\(\\ Cov\\left( \\mathbf{Z},\\mathbf{e} \\right) = \\mathbf{0}\\ \\).\nSi se encuentra una matriz \\(\\mathbf{Z}\\) que cumpla tales condiciones, se puede demostrar que el modelo transformado \\(\\mathbf{Z}^{\\mathbf{'}}\\mathbf{y} = \\mathbf{Z}^{\\mathbf{'}}\\mathbf{X\\beta} + \\mathbf{Z}^{\\mathbf{'}}\\mathbf{e}\\) ya no “padece”, al menos asintóticamente, el problema de correlación no nula entre los regresores y el término de error, aunque este último es heteroscedástico, ya que se cumple que \\(Var(\\mathbf{Z}^{\\mathbf{'}}\\mathbf{e}) = \\sigma^{2}(\\mathbf{Z}^{\\mathbf{'}}\\mathbf{Z})\\), por lo cual se requiere el uso del método de mínimos cuadrados ponderados para la estimación del nuevo modelo.\nAhora, la función a minimizar para obtener el correspondiente estimador MCP viene dada por \\(S^{*}(\\mathbf{b}) = (\\mathbf{y} - \\mathbf{Xb})'\\mathbf{P}_{Z}(\\mathbf{y} - \\mathbf{Xb})\\), donde \\(\\mathbf{P}_{Z} = \\mathbf{Z}(\\mathbf{Z}^{\\mathbf{'}}\\mathbf{Z})^{- 1}\\mathbf{Z}^{\\mathbf{'}}\\) es la matriz de ponderaciones. Se puede demostrar que el estimador que se obtiene en este caso, llamado de variables instrumentales (VI), tiene la expresión\n\\[{\\widehat{\\mathbf{\\beta}}}_{VI} = (\\mathbf{X}'\\mathbf{P}_{Z}\\mathbf{X})^{- 1}\\mathbf{X}'\\mathbf{P}_{Z}\\mathbf{y}\\]\ny su matriz de varianzas-covarianzas viene dada por\n\\[\\mathbf{\\ \\ }Cov\\left( {\\widehat{\\mathbf{\\beta}}}_{\\mathbf{VI}} \\right) = \\sigma^{2}\\left( \\mathbf{X}^{'}\\mathbf{P}_{Z}\\mathbf{X} \\right)^{- 1}\\ \\]\ndonde \\(\\sigma^{2}\\) puede estimarse de forma consistente mediante\n\\[{\\widehat{\\sigma}}_{VI}^{2} = (\\mathbf{y} - \\mathbf{X}{\\widehat{\\mathbf{\\beta}}}_{VI})'(\\mathbf{y} - \\mathbf{X}{\\widehat{\\mathbf{\\beta}}}_{VI})/(n - K)\\]\nEl estimador VI, \\(\\ {\\widehat{\\mathbf{\\beta}}}_{VI}\\ \\), sigue siendo sesgado, pero se puede demostrar que es consistente, aunque en general no será eficiente. Por otra parte, también puede demostrarse la distribución asintóticamente normal del mismo, siempre que se cumplan ciertas condiciones sobre el comportamiento de la matriz \\(\\mathbf{Z}\\) de instrumentos.\nEl estimador VI también puede verse como el resultado de aplicar MCO en dos pasos consecutivos razón por la que también se le conoce como estimador de mínimos cuadrados en dos etapas (MC2E):\n\nEn la primera etapa se “regresan” las variables contenidas en la matriz \\(\\mathbf{X}\\) sobre todas las variables instrumentales \\(\\mathbf{Z}\\), \\(\\ \\mathbf{X} = \\mathbf{Z}\\mathbf{\\Pi} + \\mathbf{u}\\ \\), y se calculan los valores ajustados de dichas regresiones, \\(\\ \\widehat{\\mathbf{X}}\\ \\).\nEn la segunda etapa se aplican MCO al modelo transformado \\(\\ \\mathbf{y} = \\widehat{\\mathbf{X}}\\mathbf{\\beta} + \\mathbf{e}\\ \\), cumpliéndose que \\(\\ {\\widehat{\\mathbf{\\beta}}}_{VI} = \\left( {\\widehat{\\mathbf{X}}}^{'}\\widehat{\\mathbf{X}} \\right)^{- 1}\\widehat{\\mathbf{X}}\\mathbf{y}\\ \\).\n\n\n\n3.8.5.3 El test de Sargan de validez de los instrumentos\nBajo la hipótesis nula de que los instrumentos son independientes del término de error, \\(\\ H_{0}:\\left\\{ Cov\\left( \\mathbf{Z},\\mathbf{e} \\right) = \\mathbf{0} \\right\\}\\) (condición de exogeneidad), debería esperarse que la regresión del término de error \\(\\mathbf{e}\\) sobre las variables que componen la matriz \\(\\mathbf{Z}\\) tuviese un ajuste bajo en términos del coeficiente R2; en caso contrario (cuando se acepta \\(\\ H_{1}:\\left\\{ Cov\\left( \\mathbf{Z},\\mathbf{e} \\right) \\neq \\mathbf{0} \\right\\}\\ \\)), este coeficiente de determinación podría ser significativo.\nEl test de Sargan consiste en substituir los errores inobservables \\(\\mathbf{e}\\) por su contrapartida observable \\({\\widehat{\\mathbf{e}}}_{VI}\\), los residuos del modelo \\(\\mathbf{y} = \\mathbf{X\\beta} + \\mathbf{e}\\) estimados por VI, y estimar por MCO la regresión auxiliar\n\\[\\ {\\widehat{\\mathbf{e}}}_{VI} = \\delta_{1}\\mathbf{z}_{1} + \\ldots + \\delta_{L}\\mathbf{z}_{L} + \\mathbf{u}\\ \\]\ncumpliéndose que, bajo la hipótesis nula \\(H_{0}:\\left\\{ Cov\\left( \\mathbf{Z},\\mathbf{e} \\right) = \\mathbf{0} \\right\\}\\), el estadístico\n\\[S = (n - K)R^{2}\\ \\overset{as}{\\sim\\ }\\chi_{r}^{2}\\ \\]\ndonde \\(r = L - K\\) es el número de restricciones de sobre-identificación, que se obtiene restando al número de instrumentos en la matriz \\(\\mathbf{Z}\\), L, el número de variables explicativas en la matriz \\(\\mathbf{X}\\), K. Al valor S se le conoce comúnmente en la literatura econométrica como estadístico J.\n\n\n3.8.5.4 El contraste de Cragg-Donald de debilidad de los instrumentos\nTal como se ha anotado en párrafos anteriores, cuando el estimador MCO no es válido por la presencia de correlación entre alguno(s) de los regresores y el término de error, ha de utilizarse como alternativa el estimador VI, cuyas propiedades dependen en buena medida de una elección correcta de los instrumentos, los cuales deben estar fuertemente correlacionados con los regresores originales y tener una correlación nula con el término de error.\nPor un lado, los estadísticos F asociados a las hipótesis de significación de los parámetros de las variables z’s introducidas para instrumentar a las variables potencialmente endógenas (sin incluir las variables explicativas exógenas) en las regresiones de la primera etapa del método VI, \\(x_{j} = \\pi_{1}^{j}z_{1} + \\ldots + \\pi_{L}^{j}z_{L} + u_{j}\\), permiten examinar la condición de relevancia de los instrumentos, \\(Cov\\left( \\mathbf{X},\\mathbf{Z} \\right) \\neq 0\\): cuanto mayores sean los estadísticos F de significación conjunta de los parámetros π’s, los instrumentos serán más relevantes; y viceversa, cuanto menores sean los estadísticos F, más débiles serán los instrumentos propuestos, puesto que explicarán una pequeña proporción de la variación de cada xj endógena.\nLos estadísticos F de las regresiones auxiliares de la primera son sólo un indicador parcial de la fortaleza o debilidad de los instrumentos elegidos, pero no son un contraste en el sentido estadístico estricto. Cragg y Donald (1993) han propuesto un contraste de identificación débil que generaliza el método de los estadísticos F propuesto anteriormente y que permite detectar situaciones donde los instrumentos seleccionados tienen una correlación baja con los regresores endógenos de la regresión.\nDicho contraste está basado en la búsqueda de la menor correlación canónica (\\(r_{B}\\)) entre los instrumentos ‘externos’ (aquellos no incluidos como variables exógenas en el modelo) y las variables explicativas endógenas, y posteriormente en el cálculo del estadístico\n\\[CD = \\left\\lbrack \\frac{(n - G - L´)}{L´} \\right\\rbrack\\left\\lbrack \\frac{r_{B}^{2}}{\\left( 1 - r_{B}^{2} \\right)} \\right\\rbrack\\]\ndonde n es el tamaño muestral, G el número de regresores exógenos, B el número de regresores endógenos, y L’ es el número de instrumentos externos. Este estadístico no sigue ninguna distribución conocida y, por tanto, deben utilizarse valores críticos específicos (que dependen de los valores B y L’), los cuales han sido tabulados por Stock y Yogo (2005).\nSi no se rechaza la hipótesis nula, es decir, si los instrumentos son débiles, las consecuencias prácticas sobre el estimador VI puede ser importantes, haciendo el mismo poco fiable: por un lado, pueden producirse sesgos en las estimaciones VI en relación con el sesgo del estimador MCO; y, por otro lado, la tasa de rechazo puede verse incrementada, siendo el tamaño real de los contrastes (error tipo I) muy superior al nivel de rechazo nominal elegido a priori (por ejemplo, \\(\\alpha = 0.05\\)).\nEn este sentido, los valores críticos de Stock-Yogo son distintos según que se elija el sesgo relativo máximo o el tamaño del contraste máximo como criterio de valoración de la debilidad o fortaleza de los instrumentos (debe anotarse que no hay valores críticos si \\(L´&lt; 3\\) para el criterio del sesgo relativo máximo y, por tanto, para esos casos sólo podrá valorarse si los instrumentos son débiles valorando la distorsión que se produce en el tamaño real de lo contrastes)."
  },
  {
    "objectID": "p3c1-teoria.html#observaciones-atípicas",
    "href": "p3c1-teoria.html#observaciones-atípicas",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.9 Observaciones atípicas",
    "text": "3.9 Observaciones atípicas\nEn el conjunto de datos disponible para estimar un modelo de regresión podemos encontrarnos, en muchas ocasiones, con observaciones atípicas que pueden corresponder a individuos o acontecimientos anómalos o de especial trascendencia. La característica principal de estas observaciones especiales es que pueden llegar a tener una gran influencia en los resultados de la estimación por MCO del modelo, de tal modo que su inclusión o exclusión en la información muestral puede provocar grandes cambios en las estimaciones de los parámetros, en el ajuste del modelo, en las varianzas estimadas, etc.\nHablaremos de outliers cuando los datos especiales corresponden a observaciones atípicas en los valores de la variable dependiente y de leverages para observaciones con valores anormales en alguna(s) de las variables explicativas del modelo.\n\n3.9.1 Identificación y análisis de la influencia de las observaciones atípicas\n\n3.9.1.1 Detección de observaciones atípicas en las variables explicativas\nPara detectar la presencia de leverages se suelen utilizar los valores hi, definidos por\n\\[\\ h_{i} = \\mathbf{x}_{i}^{'}\\left( \\mathbf{X}^{'}\\mathbf{X} \\right)^{- 1}\\mathbf{x}_{i}\\ \\]\nlos cuales miden la distancia del vector \\(\\mathbf{x}_{1} = \\left( x_{1i},x_{2i},\\ldots,x_{Ki} \\right)\\) al centroide de los datos, \\(\\overline{\\mathbf{x}} = \\left( {\\overline{x}}_{1},{\\overline{x}}_{2},\\ldots,{\\overline{x}}_{K} \\right)\\); por tanto, tenderán a ser altos para aquellas observaciones con valores que son bastante diferentes de las medias de las variables explicativas.\nEn concreto, se puede demostrar que \\(0 \\leq h_{i} \\leq 1\\) y \\(\\sum_{i}^{}h_{i} = K\\) y, por consiguiente, el promedio de los hi es \\(\\overline{h} = \\frac{K}{n}\\). Se considera que un valor crítico adecuado para medir la desviación respecto a este punto central es dos veces dicha cuantía, es decir, se considera que una observación toma valores atípicos para alguna variable explicativa si se cumple que\n\\[\\ h_{i} &gt; 2\\left( \\frac{K}{n} \\right)\\ \\]\n\n\n3.9.1.2 Detección de observaciones atípicas en la variable dependiente\nPara detectar la presencia de outliers pueden utilizarse los llamados residuos estandarizados, que están diseñados para señalar las observaciones que originan valores grandes (en valor absoluto) en los residuos del modelo, es decir, el valor observado de la variable dependiente difiere substancialmente del valor esperado según el modelo de regresión.\nEstos se obtienen re-escalando los residuos MCO del modelo mediante la expresión\n\\[\\ r_{i} = \\frac{{\\widehat{e}}_{i}}{\\widehat{\\sigma}}\\ \\]\nSe puede demostrar que \\(r_{i}\\sim N(0,1)\\) y, por tanto, grandes valores de estos residuos\n\\[\\ \\left| r_{i} \\right| &gt; 2.5\\ \\]\nson indicativos de la presencia de observaciones extremas en la variable dependiente.\n\n\n3.9.1.3 Influencia real de las observaciones atípicas\nPara detectar cómo influyen las observaciones atípicas (outliers o leverages) sobre los resultados MCO de una regresión, se han propuesto en la literatura diferentes estadísticos: DFBETAS, para valorar la repercusión sobre los parámetros estimados; DFFITS, para ver cómo afectan los atípicos a las predicciones; DCOOK, para analizar la influencia conjunta sobre parámetros y predicciones; etc.\nEn particular, para valorar los efectos de las observaciones atípicas sobre los valores ajustados del modelo, se pueden utilizar los estadísticos \\(\\left( \\frac{h_{i}}{1 - h_{i}} \\right){\\widehat{e}}_{i}\\), o una versión escalada de estos valores, los llamados \\(\\ {DFFITS}_{i} = \\sqrt{\\frac{h_{i}}{1 - h_{i}}}{\\widehat{e}}_{i}^{s}\\ \\), donde \\({\\widehat{e}}_{i}^{s} = \\frac{{\\widehat{e}}_{i}}{\\widehat{\\sigma}\\sqrt{1 - h_{i}}}\\) son los llamados residuos estudentizados, de forma que se puede demostrar que una observación es influyente si se cumple que\n\\[\\ \\left| {DFFITS}_{i} \\right| &gt; 2\\sqrt{\\frac{K}{n}}\\ \\]\n\n\n\n3.9.2 Cuestiones que plantea la presencia de observaciones atípicas\n¿Qué problemas acarrea la presencia de observaciones atípicas? En principio, el “único” problema es la falta de robustez de los resultados ante la presencia de dichas observaciones, ya que el estimador MCO mantiene todas sus propiedades.\n¿Qué hacer ante la presencia de observaciones atípicas? Son cuatro las posibilidades:\n\nNo hacer nada con dichas observaciones, manteniéndolas en la muestra, pero siendo conscientes de que su presencia puede condicionar fuertemente los resultados.\nEliminar de la muestra los datos atípicos, lo que supondría eliminar el peligro potencial de su influencia, pero a costa de perder información que puede ser valiosa tanto en términos económicos como estadísticos (menores errores estándar en las estimaciones y, por tanto, mayor eficiencia).\nTratar dichas observaciones de una forma sencilla, por ejemplo, a través de la introducción de variables ficticias que consideren la especificidad de los valores atípicos.\nUtilizar métodos más sofisticados, como los estimadores robustos, las regresiones cuantilíticas o las regresiones con errores no normales (como las distribuciones t con colas “gruesas”).\n\nUno de los estimadores robustos más usados en la literatura econométrica es el denominado estimador de desviaciones absolutas mínimas (MDA), que se obtiene minimizando la suma absoluta de los errores\n\\[\\ \\sum_{i = 1}^{n}\\left| y_{i} - \\beta_{1} - \\beta_{2}x_{2i} - \\ldots - \\beta_{K}x_{Ki} \\right|\\ \\]\nen lugar de la suma de cuadrados \\(\\sum_{i = 1}^{n}\\left( y_{i} - \\beta_{1} - \\beta_{2}x_{2i} - \\ldots - \\beta_{K}x_{Ki} \\right)^{2}\\), como en el caso estándar del estimador MCO. En este caso, se estiman los parámetros de la mediana condicional de y, y no de la media; por tanto, cada parámetro estimado βj medirá el efecto parcial del regresor xj sobre la mediana de y.\nSe puede demostrar que el estimador MDA, que es no lineal, es asintóticamente insesgado, consistente y con una distribución normal para muestras grandes. Además, su varianza asintótica es menor que la del estimador MCO para una amplia clase de distribuciones con “colas densas”. Lógicamente, cuando la distribución de los errores es normal, el estimador MDA es ineficiente, pudiéndose demostrar que su varianza (asintótica) es un 57% mayor que la del estimador MCO."
  },
  {
    "objectID": "p3c1-teoria.html#variable-dependiente-discreta-o-limitada",
    "href": "p3c1-teoria.html#variable-dependiente-discreta-o-limitada",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.10 Variable dependiente discreta o limitada",
    "text": "3.10 Variable dependiente discreta o limitada\n\n3.10.1 Variable dependiente discreta\nLos modelos de variable dependiente discreta son aquellos en que la variable de respuesta, y, toma únicamente valores discretos. Esta situación aparece comúnmente en modelos donde la variable dependiente es de tipo cualitativo (cumplimiento de una propiedad, elección entre varias alternativas, impacto deseado de una medida de política económica, etc.), de tipo ordinal (los resultados de un suceso representan categorías ordenadas siguiendo un cierto rango) o de recuento (el número de veces que ocurre un fenómeno).\nEjemplos de variables discretas u ordenadas son los siguientes:\n\ny = 1 si una familia compra una vivienda en propiedad, y = 0 si la alquila.\ny = 1 si se tiene empleo, y = 0 si no se tiene.\ny = 1 si una empresa tiene beneficios, y = 0 si no los tiene.\ny = 1 si el efecto de una medida económica ha sido el esperado, y = 0 si no lo ha sido.\ny = 1 si elige ir en coche al trabajo, y = 2 si va en autobús, y = 3 si va en tren de cercanías.\nOpinión del consumidor ante un nuevo producto: y = 0 (muy malo), y = 1 (malo), y = 2 (normal), y = 3 (bueno), y = 4 (muy bueno).\ny = n el número de huelgas en un cierto mes del año, o las veces que un paciente acude al médico en una semana.\n\nEn este apartado analizaremos solo los modelos econométricos donde la variable dependiente es del tipo cualitativo y, además, dicotómica, es decir, que toma únicamente dos valores distintos, según se satisfaga o no una determinada propiedad o condición. Para este caso, se expondrán los modelos Logit y Probit, que son los más utilizados para tratar este tipo de casos de elección binaria, aunque previamente expondremos los problemas a los que se enfrenta el modelo clásico si se intenta aplicar a este tipo de variables.\n\n3.10.1.1 El modelo de probabilidad lineal\nCuando se aplica el modelo de regresión lineal estándar \\(y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i}\\) al caso donde la variable dependiente es de tipo dicotómico (1/0), éste recibe el nombre de modelo de probabilidad lineal (MPL). En este caso, la distribución de y condicionada al conjunto de valores observados de las variables explicativas viene dada por\n\\[y_{i} = \\left\\{ \\begin{matrix} \\ 1\\ \\ \\ con\\ \\ \\ \\ \\ \\ P_{i} = P(y = 1) \\\\ \\ \\ \\ \\ \\ \\  0\\ \\ \\ con\\ \\ \\ \\ \\ 1 - P_{i} = P(y = 0) \\\\ \\end{matrix} \\right.\\ \\]\nSe llama modelo de probabilidad lineal porque, si se cumple que \\(E\\left\\lbrack e_{i} \\right\\rbrack = 0\\), la función de regresión poblacional está dada por\n\\[E\\left\\lbrack y_{i} \\right\\rbrack = 1 \\times P_{i} + 0 \\times \\left( 1 - P_{i} \\right) = P_{i}\\]\nluego se tendrá que\n\\[P_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\cdots + \\beta_{K}x_{Ki}\\]\ny, por tanto, el parámetro βj representa el incremento en la probabilidad de que la variable y tome el valor 1 cuando se incrementa la variable xj en una unidad (manteniéndose constante el resto de las variables explicativas), \\(\\frac{\\partial P_{i}}{\\partial x_{j}} = \\beta_{j}\\).\nSi estimamos el modelo MPL por mínimos cuadrados ordinarios tendremos varios inconvenientes: la no normalidad de los errores, la heteroscedasticidad y, lo más importante, la probabilidad estimada de que la variable y tome el valor 1, dada por \\({\\widehat{P}}_{i} = {\\widehat{\\beta}}_{1} + {\\widehat{\\beta}}_{2}x_{2i} + \\ldots + {\\widehat{\\beta}}_{K}x_{Ki}\\), puede no pertenecer al intervalo [0,1] para algunas observaciones de la muestra. Lógicamente, si eso ocurre en una aplicación, el MPL queda invalidado.\n\n\n3.10.1.2 Modelos Logit y Probit\nUna alternativa frente al modelo de probabilidad lineal es construir un modelo donde la probabilidad de que la variable dependiente tome el valor 1 venga dada por una función que obligatoriamente tome valores entre 0 y 1 y que no sea necesariamente lineal en las variables explicativas,\n\\[P_{i} = P\\left\\lbrack y_{i} = 1 \\right\\rbrack = F(\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + x_{Ki}) = F(I_{i})\\]\nLas candidatas naturales para utilizar son la función logística, que origina el modelo Logit, o las funciones de distribución acumulada de variables aleatorias unidimensionales, como la normal tipificada, que da lugar al modelo Probit, u otras funciones como la distribución asimétrica log-Weibull, que da lugar al modelo Gompit.\n\n\n3.10.1.3 El modelo Logit\nLa función logística está dada por \\(\\Lambda(z) = \\frac{1}{1 + e^{- z}}\\), de modo que el modelo Logit tendrá una función de probabilidad dada por\n\\[P_{i} = P\\lbrack y_{i} = 1\\rbrack = \\Lambda(\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}) = \\frac{1}{1 + e^{- (\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki})}}\\]\nEl valor \\(I_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}\\) puede interpretarse como un indicador de utilidad, de modo que la probabilidad de que y tome el valor 1 depende de la utilidad que tenga para el individuo la opción correspondiente. Es inmediato que \\(\\Lambda(0) = 0.5\\), de modo que la preferencia por y = 1 será mayor cuando el indicador sea positivo (\\(I &gt; 0\\)), y viceversa, aunque el incremento de probabilidad no es constante para crecimientos iguales de la utilidad dado que la función logística no es lineal.\nDe hecho, para el modelo Logit se tiene que\n\\[\\frac{\\partial P_{i}}{\\partial x_{j}} = \\beta_{j}\\lambda(\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki})\\]\ndonde \\(\\lambda(z) = \\frac{e^{- z}}{\\left( 1 + e^{- z} \\right){}^{2}}\\) es la “función de densidad” de la curva logística [en el sentido de que se cumple que \\(\\Lambda^{'}(z) = \\lambda(z)\\)].\nPor consiguiente, el efecto marginal no coincide con el valor del parámetro, tal como ocurría en el MPL, sino que depende del valor que tomen las variables explicativas en cada observación: cuando cambia una variable xj, el valor de la función \\(\\lambda\\left( \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} \\right)\\) también varía (ceteris paribus) y, por tanto, el efecto combinado viene dado por el producto \\(\\beta_{j}\\lambda\\left( \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} \\right)\\).\nNotar que, si βj es positivo, también lo será el efecto marginal \\(\\frac{\\partial P_{i}}{\\partial x_{j}}\\) ya que la función \\(\\lambda( z )\\) siempre toma valores positivos. Asimismo, puesto que dicha función toma el máximo valor en z = 0 y en dicho valor se tiene que \\(P = \\Lambda(0) = 0.5\\), el mayor efecto marginal (en valor absoluto), dado el parámetro βj, se produce para aquellas observaciones donde existe indecisión (P = 0.5) entre las dos alternativas posibles, y = 1 o y = 0.\nAdemás, al verificarse la igualdad \\(\\lambda(z) = \\Lambda(z)\\left\\lbrack 1 - \\Lambda(z) \\right\\rbrack\\), se tiene que\n\\[\\frac{\\partial P_{i}}{\\partial x_{j}} = \\beta_{j}P_{i}(1 - P_{i})\\]\nla cual es una función cuadrática en la variable P. Entonces, no solo los efectos marginales son no lineales, sino que el crecimiento de la probabilidad es mayor en la zona central (cerca de P = 0.5), disminuyendo progresivamente conforme nos alejamos hacia la izquierda o hacia la derecha (hacia P = 0 o P = 1, respectivamente).\nPor otra parte, también se tiene que\n\\[\\frac{\\beta_{j}}{\\beta_{k}} = \\frac{\\partial P/\\partial x_{j}}{\\partial P/\\partial x_{k}}\\]\ny, por tanto, la razón de coeficientes estimados proporciona una medida del cambio relativo en las probabilidades cuando se producen variaciones en las variables explicativas.\n\n\n3.10.1.4 El modelo Probit\nEn el modelo Probit, la probabilidad de que y tome el valor 1 viene dada por la función de distribución de una variable aleatoria normal tipificada, \\(\\Phi(z) = \\int_{- \\infty}^{z}{\\frac{1}{\\sqrt{2\\pi}}e^{- \\frac{\\ t^{2}}{2}}}dt\\), es decir\n\\[P_{i} = P\\lbrack y_{i} = 1\\rbrack = \\Phi(\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}) = \\int_{- \\infty}^{\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}}{\\frac{1}{\\sqrt{2\\pi}}e^{- \\frac{\\ t^{2}}{2}}}dt\\]\nPara este modelo, se tiene que\n\\[\\frac{\\partial P_{i}}{\\partial x_{j}} = \\beta_{j}\\varphi(\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki})\\]\ndonde \\(\\phi\\) es la función de densidad de la distribución N(0,1), \\(\\varphi(t) = \\frac{1}{\\sqrt{2\\pi}}e^{- \\frac{\\ t^{2}}{2}}\\). De nuevo, el efecto marginal no coincide con el valor del parámetro, sino que es no lineal y alcanza el máximo valor absoluto para P = 0.5, es decir, en el valor de indecisión entre las dos alternativas.\n\n\n3.10.1.5 Consideraciones especiales en los modelos Logit y Probit\n\n3.10.1.5.1 Estimación\nDado que los modelos Logit y Probit no son lineales, podría utilizarse el método de MCNL para estimarlos. Sin embargo, en general se emplea el método de máxima verosimilitud (MV), que consiste en maximizar el logaritmo de la función de verosimilitud del modelo, que viene dado para los dos modelos en cuestión por la expresión siguiente\n\\[\\log L(\\beta) = \\sum_{i = 1}^{n}\\left\\lbrack y_{i}\\log F(\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}) \\right\\rbrack + \\]\n\\[+ \\sum_{i = 1}^{n}\\left\\lbrack (1 - y_{i})log(1 - F(\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}) \\right\\rbrack\\]\ndonde F(z) es la función de probabilidad correspondiente (logística o normal estándar). El estimador MV garantiza las propiedades de consistencia, eficiencia y normalidad asintótica. En consecuencia, las estimaciones serán fiables siempre y cuando el tamaño de la muestra sea suficientemente elevado.\n\n\n3.10.1.5.2 Predicción\nA partir de las estimaciones del modelo, \\({\\widehat{P}}_{i} = F({\\widehat{\\beta}}_{1} + {\\widehat{\\beta}}_{2}x_{Ki} + \\ldots + {\\widehat{\\beta}}_{K}x_{Ki})\\), los valores de predicción para la variable dependiente y vienen dados por\n\\[{\\widehat{y}}_{i} = \\left\\{ \\begin{matrix}\n\\ 0\\ si\\ \\ {\\widehat{P}}_{i} &lt; 0.5 \\\\\n\\ 1\\ si\\ \\ {\\widehat{P}}_{i} \\geq 0.5 \\\\\n\\end{matrix} \\right.\\ \\]\n\n\n3.10.1.5.3 Grado de ajuste del modelo\nPara todos los modelos de elección binaria, el estadístico R2 definido para el modelo lineal deja de ser una buena medida de la bondad del ajuste proporcionado por el modelo. Un estadístico muy utilizado es el conocido R2 de McFadden, que toma también valores entre 0 y 1 y que se calcula como\n\\[R_{McFadden}^{2} = 1 - \\frac{l(\\widehat{\\mathbf{\\beta}})}{l({\\widehat{\\mathbf{\\beta}}}_{0})}\\]\ndonde \\(l\\left( \\widehat{\\mathbf{\\beta}} \\right)\\) y \\(l\\left( {\\widehat{\\mathbf{\\beta}}}_{0} \\right)\\) son, respectivamente, los valores del logaritmo de la función de verosimilitud del modelo completo y del modelo sin variables explicativas (salvo la constante).\nTambién suelen utilizarse como medida del grado de ajuste del modelo estimado las conocidas tablas de clasificación, en las cuales se representa el porcentaje de predicciones correctas del modelo estimado para los datos de la muestra.\n\n\n3.10.1.5.4 Contraste de hipótesis\nPara los modelos expuestos, Logit y Probit, se tiene que \\(\\widehat{\\mathbf{\\beta}}\\overset{as}{\\sim}N\\left( \\mathbf{\\beta},Cov\\left( \\widehat{\\mathbf{\\beta}} \\right) \\right)\\), donde \\(Cov\\left( \\widehat{\\mathbf{\\beta}} \\right) = \\left( \\mathbf{X}^{'}\\mathbf{DX} \\right)^{- 1}\\) y \\(\\mathbf{D}\\) es una matriz diagonal cuyos elementos tienen diferentes expresiones para cada modelo.\nPor tanto, si el tamaño de muestra es grande, los contrastes de significación individual pueden realizarse mediante los estadísticos z, definidos como \\(z_{j} = \\frac{{\\widehat{\\beta}}_{j}}{se\\left( {\\widehat{\\beta}}_{j} \\right)}\\), pero comparando tales ratios con los valores críticos de la distribución N(0,1) en lugar de los correspondientes a la distribución t de Student que se usan en las regresiones estándar.\nPara contrastes generales del tipo \\(H_{0}:\\left\\{ \\mathbf{R\\beta} = \\mathbf{r} \\right\\}\\) se puede usar el test de Wald (W) o el test de razón de verosimilitudes (LR), que toma la forma\n\\[LR = 2\\left\\lbrack l({\\widehat{\\mathbf{\\beta}}}_{NR}) - l({\\widehat{\\mathbf{\\beta}}}_{R}) \\right\\rbrack\\]\ndonde \\(l\\left( {\\widehat{\\mathbf{\\beta}}}_{NR} \\right)\\) y \\(l\\left( {\\widehat{\\mathbf{\\beta}}}_{R} \\right)\\) son, respectivamente, los valores del logaritmo de la función de verosimilitud del modelo no restringido y restringido. Ambos estadísticos siguen asintóticamente, bajo la hipótesis nula correspondiente, una distribución \\(\\ \\chi_{q}^{2}\\ \\), siendo q el número de restricciones.\n\n\n3.10.1.5.5 Efectos marginales\nComo se ha dicho en la exposición teórica, los efectos marginales de los modelos Logit y Probit no son constantes, sino que dependen de los valores de las variables explicativas.\nEn ocasiones, el investigador puede estar interesado en el cálculo del efecto marginal en la media de las variables explicativas, \\(\\overline{\\mathbf{x}} = \\left( 1,{\\overline{x}}_{2},\\ldots,{\\overline{x}}_{K} \\right)\\), en cuyo caso el valor que habría que utilizar será\n\\[\\frac{\\partial P}{\\partial x_{j}}({\\overline{x}}_{2},\\ldots,{\\overline{x}}_{K}) = \\beta_{j}f(\\beta_{1} + \\beta_{2}{\\overline{x}}_{2} + \\ldots + \\beta_{K}{\\overline{x}}_{K})\\]\ndonde \\(f(z)\\) representa a la función de densidad \\(\\lambda(z)\\) o \\(\\phi(t)\\), según corresponda.\nOtras veces, en lugar de evaluar el efecto marginal en un valor específico, se considera más relevante el efecto marginal promedio, que se define como la media de los efectos marginales calculados en cada punto muestral\n\\[\\overline{\\frac{\\partial P}{\\partial x_{j}}} = \\frac{\\sum_{i = 1}^{n}{\\beta_{j}f(\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki})}}{n} = \\beta_{j}\\overline{f(\\beta_{1} + \\beta_{2}x_{2} + \\ldots + \\beta_{K}x_{K})}\\]\nEste valor representa la respuesta promedio de la probabilidad, para las observaciones de la muestra, ante un cambio en el valor de una determinada variable explicativa.\n\n\n\n\n3.10.2 Variable dependiente limitada\n\n3.10.2.1 Valores censurados: el modelo Tobit\nEn algunas ocasiones, la variable dependiente toma valores limitados porque todos los valores contenidos en un cierto rango se asocian a un único valor límite c que, en general, por conveniencia se supone que es cero. Se dice entonces que dicha variable está censurada.\nLos ejemplos clásicos de este tipo de situaciones son la compra de vivienda o automóviles por parte de los individuos o las familias, donde se observa un gran número de individuos que no gastan cantidad alguna (\\(y_{i} = 0\\)) en dicho bien. En términos microeconómicos, estas observaciones límite describen un comportamiento de solución de esquina, es decir, resultan de un comportamiento optimizador por parte de los agentes económicos, para quienes resulta óptimo gastar una cantidad cero en la compra de vivienda o automóvil.\nCon el modelo de regresión lineal estándar no se puede explicar la diferencia cualitativa que existe entre las observaciones límite (0) y las observaciones normales (\\(y_{i}\\)). De hecho, si se utilizan MCO para estimar modelos de regresión donde la variable dependiente está limitada, los resultados serán sesgados e inconsistentes, empeorando conforme aumenta el número de observaciones censuradas.\nPara tratar estos casos de censura suele utilizarse el modelo Tobit*, propuesto por Tobin (1958), quien lo introdujo por primera vez para analizar la compra de automóviles en el mercado estadounidense.\nEn el modelo Tobit se define una variable latente asociada a “todas” las observaciones muestrales, \\(y_{i}^{*}\\), que cumple la propiedad\n\\[y_{i} = \\left\\{ \\begin{matrix} \\ 0\\ \\ si\\ y_{i}^{*} &lt; 0 \\\\ \\ y_{i}^{*}\\ si\\ y_{i}^{*} \\geq 0 \\\\ \\end{matrix} \\right.\\ \\]\nSi se supone que la variable latente sigue un modelo de regresión lineal estándar\n\\[y_{i}^{*} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i}\\]\nentonces la distribución que sigue la variable \\(y_{i}\\) es\n\\[\\left\\{ \\begin{matrix} \\ P\\lbrack y_{i} = 0\\rbrack = P\\lbrack y_{i}^{*} &lt; 0\\rbrack\\ \\ para\\ las\\ observaciones\\ límite\\ (y_{i} = 0) \\\\ \\ \\ \\ \\ \\ f(y_{i}) = \\varphi(y_{i}^{*})\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ para\\ las\\ observaciones\\ continuas\\ (y_{i} &gt; 0) \\\\ \\end{matrix} \\right.\\ \\]\ncon lo que se pone de manifiesto la diferencia entre los dos tipos de observaciones en el conjunto de datos observado.\nComo se trata de un modelo no lineal, para estimar el modelo Tobit se utiliza habitualmente el método de máxima de verosimilitud, igual que ocurrió con los modelos Logit y Probit. En este caso, la función a maximizar viene dada por\n\\[\\log L(\\mathbf{\\beta},\\sigma) = \\sum_{y_{i} = 0}^{}\\left\\lbrack log(1 - \\Phi(\\frac{\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}}{\\sigma}) \\right\\rbrack + \\] \\[ +  \\sum_{y_{i} &gt; 0}^{}\\left\\lbrack \\log\\varphi(\\frac{\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}}{\\sigma}) \\right\\rbrack\\] Si se cumplen las propiedades estándar en el modelo latente, se puede demostrar que el estimador MV tiene las propiedades de consistencia, eficiencia y normalidad asintótica. También pueden realizarse inferencias utilizando los estadísticos z y LR, en los mismos términos que se expusieron anteriormente para los modelos de elección binaria.\nEn lo referente a los efectos marginales, se tiene en este caso que\n\\[\\frac{\\partial E(y)}{\\partial x_{j}} = \\beta_{j}\\Phi\\left( \\frac{\\beta_{1} + \\beta_{2}x_{2} + \\ldots + \\beta_{K}x_{K}}{\\sigma} \\right)\\]\npor lo que, de nuevo, estos efectos dependen de los valores de las variables explicativas, y ahora además de la desviación estándar residual, σ.\nComo puede observarse, el factor de ajuste que multiplica a los parámetros \\(\\beta_{j}\\) está comprendido entre 0 y 1, ya que la función \\(\\Phi(z)\\) solo toma valores en ese rango, por lo que los efectos marginales serán siempre inferiores (en valor absoluto) a los parámetros del modelo.\nPor otro lado, se pueden calcular los efectos marginales en la media de las variables explicativas\n\\[\\frac{\\partial E(y|{\\overline{x}}_{2},\\ldots,{\\overline{x}}_{K})}{\\partial x_{j}} = \\beta_{j}\\Phi\\left( \\frac{\\beta_{1} + \\beta_{2}{\\overline{x}}_{2} + \\ldots + \\beta_{K}{\\overline{x}}_{K}}{\\sigma} \\right)\\]\no se puede computar el efecto marginal promedio sobre la muestra\n\\[\\overline{\\frac{\\partial E(y)}{\\partial x_{j}}} = \\frac{\\sum_{i = 1}^{n}{\\beta_{j}\\Phi\\left( \\frac{\\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki}}{\\sigma} \\right)}}{n} = \\beta_{j}{\\overline{\\Phi(\\frac{\\beta_{1} + \\beta_{2}x_{2} + \\ldots + \\beta_{K}x_{K}}{\\sigma})}}^{}\\]\n\n\n3.10.2.2 Valores con truncamiento selectivo: el modelo Heckit\nEn algunas situaciones económicas, los datos observados de la variable dependiente se obtienen a partir de un mecanismo de selección muestral que no es aleatorio, por lo que dicha variable se ve sometida a un proceso de truncamiento selectivo.\nPor ejemplo, si se quieren analizar los salarios de la población femenina, con el objeto de explicar los factores diferenciales del mercado laboral de las mujeres frente al de los hombres, hay que tener en cuenta que hace unas décadas una parte importante de la población femenina no participaba en el mercado de trabajo (eran amas de casa, es decir, con un trabajo no remunerado en el mercado), por lo que solo se observaban datos salariales para aquella parte de la población que formaba parte de la fuerza laboral (población activa). Existe, por consiguiente, un problema de truncamiento selectivo en los datos observados, que habrá que tener en cuenta al estimar el modelo econométrico correspondiente.\nIgual que para el caso censurado, con el modelo de regresión lineal estándar no se puede explicar la diferencia cualitativa que existe entre las mujeres amas de casa, que no reciben salario alguno por su trabajo (\\(y_{i} = 0\\)) y las mujeres que forman parte de la población ocupada, para las que se observan sus salarios de mercado \\(y_{i}\\). Si se utilizasen MCO completos para estimar la regresión\n\\(y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i}\\) que explicase los salarios de “toda la población femenina”, los resultados serían sesgados e inconsistentes. Por otra parte, si se aplicasen MCO truncados a dicho modelo, es decir, utilizando solo los datos de las mujeres con trabajo remunerado, los resultados también serían sesgados e inconsistentes, ya que la muestra truncada no sería aleatoria (pues el mecanismo de selección no es exógeno).\nPara tratar este tipo de situaciones en las que existe un truncamiento selectivo de la muestra, la literatura econométrica ha propuesto el uso del denominado modelo Heckit, propueto por Heckman (1979) para resolver el problema de la estimación de una ecuación de salarios para las mujeres casadas.\nEste modelo, también conocido en la literatura como modelo Tobit tipo II, es básicamente un modelo Probit más una regresión truncada. Así, el modelo Heckit se compone de dos ecuaciones. La primera de ellas, la ecuación de selección, que se corresponde con un modelo Probit que determina cuándo se observa la variable de interés, se expresa en términos de una variable de selección \\(s_{i}\\), asociada a “todas” las observaciones muestrales\n\\[s_{i} = \\left\\{ \\begin{matrix} \\ 0\\ \\ si\\ s_{i}^{*} &lt; 0 \\\\ \\ 1\\ si\\ s_{i}^{*} \\geq 0 \\\\ \\end{matrix} \\right.\\ \\]\ndonde la variable latente \\(s_{i}^{*}\\) de preferencias individuales sigue un modelo de regresión lineal estándar\n\\[s_{i}^{*} = \\alpha_{1} + \\alpha_{2}w_{2i} + \\ldots + \\alpha_{M}w_{Mi} + u_{i}\\]\nLa segunda es la llamada ecuación de intensidad, que se corresponde con un modelo de regresión lineal para la variable de interés, \\(y_{i}\\), la cual es válida únicamente para la muestra truncada y, por tanto,\n\\[y_{i} = \\left\\{ \\begin{matrix}\n\\ \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i}\\ \\ si\\ s_{i}^{} = 1 \\\\\n\\ no\\ se\\ observa\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ si\\ s_{i}^{} = 0 \\\\\n\\end{matrix} \\right.\\ \\]\nPuede demostrarse que, teniendo en cuenta el proceso por el que se generan las observaciones de la variable dependiente \\(y_{i}\\), se cumple que\n\\[E(y_{i}|s_{i} = 1) = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + \\beta_{\\lambda}\\lambda_{i}\\]\ndonde la variable \\(\\lambda_{i}\\), conocida como la inversa de la razón de Mills, viene definida por\n\\[\\lambda_{i} = \\frac{\\varphi\\left( \\alpha_{1} + \\alpha_{2}w_{2i} + \\ldots + \\alpha_{M}w_{Mi} \\right)}{\\Phi\\left( \\alpha_{1} + \\alpha_{2}w_{2i} + \\ldots + \\alpha_{M}w_{Mi} \\right)}\\]\nPara estimar el modelo Heckit es frecuente utilizar el método bietápico original propuesto por Heckman, que es un procedimiento condicional aproximado que da lugar a un estimador consistente de los parámetros del modelo. Este método procede como sigue:\n\nEn la primera etapa se usa la muestra completa para estimar el modelo para la variable \\(s_{i}\\) que rige la observación de la variable de interés:\n\n\\[P\\lbrack s_{i} = 1\\rbrack = \\Phi(\\alpha_{1} + \\alpha_{2}w_{2i} + \\ldots + \\alpha_{M}w_{Mi})\\]\n\nEn la segunda etapa se utiliza solo la muestra truncada, compuesta por las observaciones que cumplen la condición \\(s_{i} = 1\\):\n\n\\[y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + \\beta_{\\lambda}{\\widehat{\\lambda}}_{i} + u_{i}\\]\nSin embargo, la forma más eficiente de estimar el modelo Heckit es utilizar el método de máxima de verosimilitud, que estima simultáneamente los parámetros de las dos ecuaciones del modelo.\nEn cuanto al cálculo de los efectos marginales, se tiene en este caso que\n\\[\\frac{\\partial E(y|s = 1)}{\\partial x_{j}} = \\beta_{j} - \\alpha_{j}G(\\lambda)\\]\ndonde la función G viene dada por \\(G\\left( \\lambda_{i} \\right) = \\beta_{\\lambda}\\lambda_{i}\\left( \\lambda_{i} + \\mathbf{w}_{i}^{'}\\mathbf{\\alpha} \\right)\\), siendo \\(\\lambda_{i} = \\frac{\\phi\\left( \\mathbf{w}_{i}^{'}\\mathbf{\\alpha} \\right)}{\\Phi\\left( \\mathbf{w}_{i}^{'}\\mathbf{\\alpha} \\right)}\\) la inversa de la razón de Mills y \\(\\mathbf{w}_{i}^{'}\\mathbf{\\alpha} = \\alpha_{1} + \\alpha_{2}w_{2i} + \\ldots + \\alpha_{M}w_{Mi}\\).\nDesde un punto de vista cualitativo puede apreciarse que, para una variable xj que únicamente aparezca en la ecuación de intensidad (es decir, no se encuentra también entre los regresores w’s de la ecuación de selección), se tiene que \\(\\frac{\\partial E\\left( y_{i} \\middle| s_{i} = 1 \\right)}{\\partial x_{ji}} = \\beta_{j}\\), puesto que \\(\\alpha_{j} = 0\\). Por el contrario, si la variable xj es común a las dos ecuaciones, selección e intensidad, entonces el efecto marginal tomará la forma general \\(\\frac{\\partial E\\left( y_{i} \\middle| s_{i} = 1 \\right)}{\\partial x_{ji}} = \\beta_{j} - \\alpha_{j}G\\left( \\lambda_{i} \\right)\\), y no coincidirá ya con el efecto directo \\(\\beta_{j}\\), puesto que el valor indirecto \\(\\alpha_{j}G\\left( \\lambda_{i} \\right)\\) será distinto de cero en este caso."
  },
  {
    "objectID": "p3c1-teoria.html#paneles-de-datos",
    "href": "p3c1-teoria.html#paneles-de-datos",
    "title": "3  Diagnosis, correcciones y extensiones del modelo de regresión lineal",
    "section": "3.11 Paneles de datos",
    "text": "3.11 Paneles de datos\n\n3.11.1 Regresiones para datos de panel y efectos individuales inobservables\nUn modelo de regresión básico para datos de corte transversal viene dado por la expresión \\(y_{i} = \\beta_{1} + \\beta_{2}x_{2i} + \\ldots + \\beta_{K}x_{Ki} + e_{i}\\) donde \\(i = 1,2,\\ldots,n\\). Cuando cada unidad transversal i se observa durante T períodos, el modelo resultante será\n\\[y_{it} = \\beta_{1} + \\beta_{2}x_{2it} + \\cdots + \\beta_{K}x_{Kit} + e_{it}\\]\npara \\(i = 1,\\ldots,n\\) y \\(t = 1,\\ldots,T\\). Este será el prototipo de un modelo estático para datos de panel.\nLas unidades transversales pueden ser individuos, familias, regiones, países, empresas, etc. En general, se hablará de datos de panel (también llamados datos longitudinales) cuando n es grande (varios cientos o incluso miles) relativo al número de períodos de observación T (normalmente de 2 a 10 períodos en la mayoría de los casos, y raras veces excediendo 20 observaciones temporales).\nPara controlar la presencia de efectos individuales inobservables se supone que \\(\\ e_{it} = \\mu_{i} + \\nu_{it}\\ \\), donde \\(\\mu_{i}\\) recoge la heterogeneidad transversal no observada (diferencias entre unidades) y \\(\\nu_{it}\\) representa el término de perturbación con las propiedades estándar (media cero, varianza constante y no autocorrelacionado, ni entre unidades ni a lo largo del tiempo). Según que se asuma que el efecto \\(\\mu_{i}\\) es un parámetro fijo o una variable aleatoria se tendrá el modelo de efectos fijos o el modelo de efectos aleatorios.\n\n\n3.11.2 Ventajas y limitaciones derivadas del uso de paneles de datos\nEntre las ventajas de emplear datos de panel pueden incluirse las siguientes:\n\nControl de la heterogeneidad individual: los datos transversales o temporales no son capaces, por sí solos, de controlar la heterogeneidad inherente en el comportamiento de los individuos, empresas, regiones o países, corriéndose el riesgo de obtener estimaciones sesgadas cuando se utilizan datos exclusivamente de un tipo o de otro. Sin embargo, a través del uso de datos de panel pueden controlarse estos efectos específicos, transversales o temporales, sean observables o no (generalmente no lo serán).\nProporciona datos con mayor cantidad de información, con mayor grado de variabilidad y con menor nivel de colinealidad entre los regresores; y también aumenta el número de grados de libertad y, por tanto, da lugar a una mayor eficiencia en las estimaciones.\nSon un medio adecuado para estudiar procesos dinámicos de ajuste, ya que a partir de ellos se pueden analizar los cambios en el tiempo de las distribuciones transversales.\nAyudan a identificar y medir efectos que no son detectables con datos puros de corte transversal o de series temporales.\nPermiten construir y contrastar modelos de comportamiento más complejos que con datos más simples.\nPuesto que las unidades transversales de un panel de datos normalmente se refieren a individuos, familias o empresas (más que a países o regiones, para los cuales no se utiliza generalmente el término de panel de datos sino de pool temporal de secciones cruzadas), se evitan los sesgos que resultan cuando se trabaja con variables agregadas.\n\nPor otro lado, entre las limitaciones cabe destacar las siguientes:\n\nProblemas de diseño muestral y de recogida de datos relacionados con inadecuadas tasas de cobertura, falta de respuesta, frecuencia y lapso temporal, período de referencia, etc.\nDistorsiones provocadas por los errores de medida, que pueden aparecer por la falta de respuesta, errores de memoria, respuestas incorrectas deliberadas, etc.\nProblemas de selección muestral tales como no aleatoriedad, autoselección, no respuesta inicial o abandono (sesgo por atrición).\nEn general, escasa dimensión temporal, lo que invalida algunos argumentos asintóticos y hace que la mayor parte de estos recaigan sobre el tamaño del corte transversal.\nDependencia espacial, es decir, correlación entre las unidades transversales.\n\n\n\n3.11.3 Modelo de efectos fijos\nEl modelo de efectos fijos, también conocido como modelo de variables ficticias, toma la forma\n\\[y_{it} = \\alpha_{i} + \\beta_{2}x_{2it} + \\cdots + \\beta_{K}x_{Kit} + \\nu_{it}\\]\npara \\(i = 1,\\ldots,n\\) y \\(t = 1,\\ldots,T\\), donde se ha denotado por \\(\\alpha_{i}\\) al término \\(\\beta_{1} + \\mu_{i}\\), habiéndose considerado los valores \\(\\mathbf{\\mu}_{\\mathbf{i}}\\) como parámetros fijos que deben estimarse.\nAgrupando las T observaciones temporales para cada unidad transversal i se tiene el modelo \\(\\mathbf{y}_{i} = \\mathbf{i}\\alpha_{i} + \\mathbf{X}_{i}\\beta + \\mathbf{v}_{i}\\), y ordenando las unidades transversales se llega al modelo\n\\[\\mathbf{y} = \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\\\ \\end{bmatrix} = \\begin{bmatrix} i & \\mathbf{0} & \\ldots & \\mathbf{0} \\\\ \\mathbf{0} & i & \\ldots & \\mathbf{0} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\\\ \\mathbf{0} & \\mathbf{0} & \\ldots & i \\\\ \\end{bmatrix}\\begin{bmatrix} \\alpha_{1} \\\\ \\alpha_{2} \\\\ \\vdots \\\\ \\alpha_{n} \\\\ \\end{bmatrix} + \\begin{bmatrix} X_{1} \\\\ X_{2} \\\\  \\vdots \\\\ X_{n} \\\\ \\end{bmatrix}\\mathbf{\\beta} + \\begin{bmatrix} v_{1} \\\\ v_{2} \\\\  \\vdots \\\\ v_{n} \\\\ \\end{bmatrix}\\]\nque matricialmente se puede escribir como \\(\\mathbf{y} = \\mathbf{I\\alpha} + \\mathbf{X\\beta} + \\mathbf{v}\\).\nEl modelo de efectos fijos puede estimarse por MCO, regresando la variable endógena \\(y_{it}\\) sobre las variables explicativas \\(x_{kit}\\) y un conjunto de n variables ficticias individuales Dit (Dit = 1 para las T observaciones temporales de cada unidad i, y Dit = 0 para las T observaciones de cada unidad j ≠ i). De forma equivalente, para obtener las estimaciones MCO del vector β puede realizarse la regresión de\n\\(y_{it} - {\\overline{y}}_{i \\cdot}\\) sobre las variables \\(x_{kit} - {\\overline{x}}_{ki \\cdot}\\) (donde \\({\\overline{z}}_{i \\cdot}\\) representa la media temporal de la variable z para cada unidad i) y, seguidamente, estimar los \\(\\alpha_{i}\\) a partir de las relaciones \\({\\widehat{\\alpha}}_{i} = {\\overline{y}}_{i \\cdot} - {\\overline{x}}_{i \\cdot}^{'}\\widehat{\\beta}\\).\nEl estimador que se obtiene se denomina de efectos fijos (EF), o también estimador intra-grupos (within). Suponiendo que los términos de perturbación aleatorios \\(\\nu_{it}\\) cumplen las propiedades estándar y que las variables \\(x_{kit}\\) no están correlacionadas con los mismos, se puede demostrar que \\({\\widehat{\\mathbf{\\beta}}}_{EF}\\) es un estimador insesgado y consistente si se verifica que \\(n \\times T \\rightarrow \\infty\\) (T puede ser fijo y cumplirse que \\(n \\rightarrow \\infty\\)), mientras que \\(\\widehat{\\mathbf{\\alpha}}\\) es insesgado pero no será consistente salvo que se cumpla que \\(T \\rightarrow \\infty\\).\n\n3.11.3.1 Modelo con efectos individuales y efectos temporales fijos\nEl modelo anterior puede extenderse a un modelo de efectos fijos de doble vía en el que aparecen también efectos inobservables temporales\n\\[y_{it} = \\alpha_{i} + \\delta_{t} + \\beta_{2}x_{2it} + \\cdots + \\beta_{K}x_{Kit} + \\nu_{it}\\]\nDesde el punto de vista práctico, para estimar este modelo habría que introducir dos conjuntos de variables ficticias, unas individuales y otras temporales, y el estimador MCO tendría las mismas propiedades anotadas en el epígrafe anterior, siendo distintas para el vector β que para los efectos individuales \\(\\alpha_{i}\\) o \\(\\delta_{t}\\).\n\n\n3.11.3.2 Anotaciones respecto al modelo de efectos fijos\nEn primer lugar, hay que tener en cuenta que el número de grados de libertad en el modelo de efectos fijos es \\(nT - n - T - K\\) o \\(nT - n - K\\), según que se incluyan o no efectos temporales aparte de los individuales. Existe, por tanto, una importante pérdida de grados de libertad cuando n es elevado.\nEl estimador EF no permite estimar el efecto de variables invariantes en el tiempo (\\(x_{it} = x_{i}\\text{\\ ,\\ \\ }\\forall t\\)) tales como el sexo, raza, religión, etc. ya que dichas variables desaparecen con la transformación en desviaciones respecto a la media. Se han propuesto en la literatura varios métodos alternativos que combinan la estimación mediante variables instrumentales con la estimación EF, que evitan el problema anterior.\nPara contrastar la significación estadística de los efectos individuales y/o temporales se realiza un test F conjunto del tipo \\(H_{0}:\\left\\{ \\alpha_{1} = \\alpha_{2} = \\ldots = \\alpha_{n} \\right\\}\\) para el caso del modelo de “una vía” y \\(H_{0}:\\left\\{ \\alpha_{1} = \\alpha_{2} = \\ldots = \\alpha_{n}\\text{\\ ,\\ \\ }\\delta_{1} = \\delta_{2} = \\ldots = \\delta_{T} \\right\\}\\) para el caso general de “doble vía”. Si no se rechaza la hipótesis nula, el modelo correcto sería el clásico, \\(y_{it} = \\beta_{1} + \\beta_{2}x_{2it} + \\ldots + \\beta_{K}x_{Kit} + \\nu_{it}\\), conocido en el contexto de datos de panel como modelo plano.\n\n\n\n3.11.4 Modelo de efectos aleatorios\nEn este modelo, en lugar de admitir que la heterogeneidad inobservable es de tipo determinista (los parámetros \\(\\mu_{i}\\) son fijos), se supone que tiene un carácter aleatorio. Así, se parte de la hipótesis de que \\(\\ \\mu_{i} \\approx IID\\left( 0,\\sigma_{\\mu}^{2} \\right)\\ \\) y \\(\\nu_{it} \\approx IID\\left( 0,\\sigma_{\\nu}^{2} \\right)\\), siendo ambas variables aleatorias independientes entre sí, y se supone de nuevo que las variables explicativas \\(x_{kit}\\) son independientes de los componentes aleatorios \\(\\mu_{i}\\) y \\(\\nu_{it}\\).\nDesde el punto de vista conceptual, el modelo de efectos aleatorios, también llamado modelo de componentes del error (debido a que el término de error se descompone como \\(e_{it} = \\mu_{i} + \\nu_{it}\\)) **es apropiado cuando las n unidades transversales observadas son una muestra (aleatoria) de una población mayor (individuos, familias, empresas, etc.); en este caso cabe esperar que el efecto individual se caracterice mejor por una variable aleatoria, y las inferencias que se realicen serán respecto a la población y no respecto a la muestra aleatoria extraída. Por el contrario, el modelo de efectos fijos es más apropiado cuando el análisis se centra sobre un conjunto específico de n unidades, y la inferencia que se haga será condicional al comportamiento de dicho conjunto particular.\nBajo la hipótesis de efectos aleatorios, el término de error compuesto \\(e_{it} = \\mu_{i} + \\nu_{it}\\) tendrá la estructura\n\\[E\\left\\lbrack e_{it}e_{js} \\right\\rbrack = \\left\\{ \\begin{matrix}\n\\sigma_{\\mu}^{2} + \\sigma_{v}^{2}\\ \\ \\ i = j,\\ t = s \\\\\n\\sigma_{\\mu}^{2}\\ \\ \\ \\ \\ i = j,\\ t \\neq s \\\\\n0\\ \\ i \\neq j \\\\\n\\end{matrix} \\right.\\ \\]\nEntonces, el estimador MCO del modelo \\(y_{it} = \\beta_{1} + \\beta_{2}x_{2it} + \\ldots + \\beta_{K}x_{Kit} + e_{it}\\) no será MELI y la matriz de covarianzas no tendrá la forma estándar \\(\\sigma^{2}\\left( \\mathbf{X}^{'}\\mathbf{X} \\right)^{- 1}\\).\nAgrupando las T observaciones para cada unidad i, \\(\\mathbf{y}_{i} = \\mathbf{X}_{i}\\beta + \\mathbf{e}_{i}\\), se tendrá que\n\\(\\Omega = E\\left\\lbrack \\mathbf{e}_{i}\\mathbf{e}_{i}^{'} \\right\\rbrack = \\sigma_{\\nu}^{2}\\mathbf{I}_{T} + \\sigma_{\\mu}^{2}\\mathbf{i}\\mathbf{i}^{'}\\) y, por tanto, puesto que las unidades i y j son independientes, la matriz de covarianzas para el modelo global con las \\(n \\times T\\) observaciones tendrá la forma\n\\[\\mathbf{V} = \\begin{bmatrix}\n\\mathbf{\\Omega} & \\mathbf{0} & \\ldots & \\mathbf{0} \\\\\n\\mathbf{0} & \\mathbf{\\Omega} & \\ldots & \\ldots \\\\\n\\vdots & \\vdots & \\mathbf{\\Omega} & \\mathbf{0} \\\\\n\\mathbf{0} & \\ldots & \\mathbf{0} & \\mathbf{\\Omega} \\\\\n\\end{bmatrix}\\]\nEn resumen, habrá que utilizar el estimador de mínimos cuadrados generalizados para tener en cuenta la violación de la hipótesis de esfericidad. En este caso concreto, el estimador MCG se obtiene mediante la regresión de la variable \\(y_{it} - \\lambda{\\overline{y}}_{i \\cdot}\\) sobre el vector de regresores \\(x_{kit} - \\lambda{\\overline{x}}_{ki \\cdot}\\), donde \\(\\lambda = 1 - \\sqrt{\\frac{\\sigma_{\\nu}^{2}}{T\\sigma_{\\mu}^{2} + \\sigma_{\\nu}^{2}}}\\ \\). En la práctica, para obtener estimaciones consistentes del parámetro \\(\\lambda\\) generalmente se utiliza como estimación de la varianza \\(\\sigma_{\\nu}^{2}\\) la varianza residual obtenida del estimador EF (within) multiplicada por el factor \\(\\frac{(nT - K)}{(nT - n - K)}\\), y como estimación de la varianza \\(\\sigma_{\\mu}^{2}\\) el valor \\({\\widehat{\\sigma}}_{\\nu}^{2} - \\frac{{\\widehat{\\sigma}}_{b}^{2}}{T}\\), donde \\({\\widehat{\\sigma}}_{b}^{2}\\) es la varianza residual estimada del estimador entre-grupos (between), calculado mediante la regresión MCO de la variable \\({\\overline{y}}_{i \\cdot}\\) sobre los regresores \\({\\overline{x}}_{ki \\cdot}\\ \\). El estimador resultante, llamado de efectos aleatorios (EA), será asintóticamente MELI (cuando se cumpla que \\(n \\times T \\rightarrow \\infty\\)), consistente y se distribuirá normalmente.\n\n3.11.4.1 Anotaciones respecto al modelo de efectos aleatorios\n\nEl modelo de doble vía \\(e_{it} = \\mu_{i} + \\delta_{t} + \\nu_{it}\\) puede analizarse de una forma similar al modelo básico, considerando también los efectos \\(\\delta_{t}\\) como aleatorios y aplicando MCG. Sin embargo, lo más usual es considerar los efectos individuales como aleatorios y los temporales como efectos fijos, estimándose estos últimos mediante la introducción de las correspondientes variables ficticias.\nPara contrastar la validez del modelo de efectos aleatorios puede utilizarse el contraste** propuesto por Breusch y Pagan (1979), que es una prueba de multiplicadores de Lagrange diseñada para contrastar \\(H_{0}:\\left\\{ \\sigma_{\\mu}^{2} = 0 \\right\\}\\) frente a la alternativa \\(H_{1}:\\left\\{ \\sigma_{\\mu}^{2} \\neq 0 \\right\\}\\). El estadístico propuesto, bajo la hipótesis nula, se distribuye asintóticamente como \\(\\lambda_{BP}\\overset{as}{\\sim}\\chi_{1}^{2}\\) .\nPor otra parte, para elegir entre los dos estimadores alternativos propuestos, el modelo de efectos fijos o el modelo de efectos aleatorios, puede utilizarse el test de Hausman, que compara directamente los dos estimadores. Este contraste se basa en el hecho de que, bajo la hipótesis nula \\(H_{0}:E\\left\\lbrack \\mu_{i} \\middle| x_{kit} \\right\\rbrack = 0\\), el estimador EA es asintóticamente más eficiente que el estimador EF; sin embargo, si la hipótesis alternativa \\(H_{1}:E\\left\\lbrack \\mu_{i} \\middle| x_{kit} \\right\\rbrack \\neq 0\\) es cierta, el estimador EF mantendrá la consistencia, pero el estimador EA será sesgado e inconsistente. El estadístico, bajo la hipótesis nula, se distribuye asintóticamente como \\(H\\overset{as}{\\sim}\\chi_{K}^{2}\\). El no rechazo de H0 implicaría decantarse por el modelo de EA, que sería más eficiente que el de EF, mientras que la “aceptación” de H1 supondría inclinarse hacia el modelo de EF, que sería el único estimador consistente en esta situación."
  },
  {
    "objectID": "p3c2-app1.html#código-r",
    "href": "p3c2-app1.html#código-r",
    "title": "Aplicación 3.1 (Evaluación, validación y especificación del MRL): El modelo APT de valoración de activos",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(readxl)\n# Lectura de datos\napt &lt;- read_excel(\"data/APT_MICROSOFT.xls\")\n# Estructura de la base de datos\nstr(apt)\n\ntibble [385 × 10] (S3: tbl_df/tbl/data.frame)\n $ Date     : POSIXct[1:385], format: \"1986-03-01\" \"1986-04-01\" ...\n $ MICROSOFT: num [1:385] 0.0955 0.112 0.1215 0.1068 0.099 ...\n $ SANDP    : num [1:385] 239 236 247 251 236 ...\n $ CPI      : num [1:385] 109 109 109 110 110 ...\n $ INDPRO   : num [1:385] 56.5 56.6 56.7 56.5 56.8 ...\n $ M1SUPPLY : num [1:385] 624 647 646 663 673 ...\n $ CCREDIT  : num [1:385] 607 614 622 628 634 ...\n $ BMINUSA  : num [1:385] 1.5 1.4 1.2 1.21 1.28 ...\n $ USTB3M   : num [1:385] 6.76 6.24 6.33 6.4 6 5.69 5.35 5.32 5.5 5.68 ...\n $ USTB10Y  : num [1:385] 7.78 7.3 7.71 7.8 7.3 7.17 7.45 7.43 7.25 7.11 ...\n\ndim(apt)\n\n[1] 385  10\n\nhead(apt)\n\n# A tibble: 6 × 10\n  Date                MICROSOFT SANDP   CPI INDPRO M1SUPPLY CCREDIT BMINUSA\n  &lt;dttm&gt;                  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 1986-03-01 00:00:00    0.0955  239.  109.   56.5     624.    607.    1.5 \n2 1986-04-01 00:00:00    0.112   236.  109.   56.6     647     614.    1.4 \n3 1986-05-01 00:00:00    0.122   247.  109.   56.7     646.    622.    1.2 \n4 1986-06-01 00:00:00    0.107   251.  110.   56.5     663.    628.    1.21\n5 1986-07-01 00:00:00    0.0990  236.  110.   56.8     673.    634.    1.28\n6 1986-08-01 00:00:00    0.0990  253.  110.   56.7     678.    641.    1.46\n# ℹ 2 more variables: USTB3M &lt;dbl&gt;, USTB10Y &lt;dbl&gt;\n\ntail(apt)\n\n# A tibble: 6 × 10\n  Date                MICROSOFT SANDP   CPI INDPRO M1SUPPLY CCREDIT BMINUSA\n  &lt;dttm&gt;                  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 2017-10-01 00:00:00      83.2 2575.  247.   105.    3582.   3771.    0.72\n2 2017-11-01 00:00:00      84.2 2585.  247.   105.    3581.   3805.    0.7 \n3 2017-12-01 00:00:00      85.5 2674.  247.   106.    3636.   3835.    0.71\n4 2018-01-01 00:00:00      95.0 2824.  248.   105.    3635.   3843.    0.71\n5 2018-02-01 00:00:00      93.8 2714.  249.   106.    3557.   3827.    0.69\n6 2018-03-01 00:00:00      91.3 2641.  250.   107.    3685.   3824.    0.77\n# ℹ 2 more variables: USTB3M &lt;dbl&gt;, USTB10Y &lt;dbl&gt;\n\nsummary(apt[,2:10])\n\n   MICROSOFT            SANDP             CPI            INDPRO      \n Min.   : 0.09549   Min.   : 230.3   Min.   :108.6   Min.   : 56.50  \n 1st Qu.: 2.89453   1st Qu.: 459.3   1st Qu.:147.2   1st Qu.: 69.48  \n Median :25.72000   Median :1104.5   Median :178.8   Median : 93.00  \n Mean   :23.30104   Mean   :1066.0   Mean   :181.1   Mean   : 86.63  \n 3rd Qu.:30.86000   3rd Qu.:1385.6   3rd Qu.:218.2   3rd Qu.:100.72  \n Max.   :95.01000   Max.   :2823.8   Max.   :249.6   Max.   :106.66  \n    M1SUPPLY         CCREDIT          BMINUSA           USTB3M     \n Min.   : 624.3   Min.   : 606.8   Min.   :0.5500   Min.   :0.010  \n 1st Qu.:1069.3   1st Qu.: 886.2   1st Qu.:0.7200   1st Qu.:0.450  \n Median :1191.8   Median :1891.8   Median :0.9000   Median :3.440  \n Mean   :1514.7   Mean   :1897.8   Mean   :0.9746   Mean   :3.297  \n 3rd Qu.:1716.0   3rd Qu.:2620.5   3rd Qu.:1.1300   3rd Qu.:5.290  \n Max.   :3684.7   Max.   :3843.4   Max.   :3.3800   Max.   :9.140  \n    USTB10Y     \n Min.   :1.500  \n 1st Qu.:3.330  \n Median :4.910  \n Mean   :5.075  \n 3rd Qu.:6.740  \n Max.   :9.520  \n\n# Transformación de variables\napt$dspread = c(NA,diff(apt$BMINUSA))\napt$dcredit = c(NA,diff(apt$CCREDIT))\napt$dprod = c(NA,diff(apt$INDPRO))\napt$dmoney = c(NA,diff(apt$M1SUPPLY))\napt$inflation = c(NA,100*diff(log(apt$CPI)))\napt$rterm = c(NA,diff(apt$USTB10Y-apt$USTB3M))\napt$dinflation = c(NA,diff(apt$inflation))\napt$r_msoft = c(NA,100*diff(log(apt$MICROSOFT)))\napt$r_sp = c(NA,100*diff(log(apt$SANDP)))\napt$er_msoft = apt$r_msoft-apt$USTB3M/12\napt$er_sp = apt$r_sp-apt$USTB3M/12\n\n# Formato a la fechas\napt$Date = as.Date(apt$Date)\n# Estimación MCO del modelo APT\nAPT_msft  &lt;-  lm(er_msoft ~ er_sp + dprod + dcredit + dinflation +\n                   dmoney + dspread + rterm, data = apt)\n# Formulación alternativa del modelo de series temporales\n# apt_ts &lt;- ts(apt, start=c(1986,3), end=c(2018,3), frequency = 12)\n# APT_msft_ts  &lt;-  lm(er_msoft ~ er_sp + dprod + dcredit + dinflation +\n# dmoney + dspread + rterm, data = apt_ts)\n# summary(APT_msft_ts)\n#\n# Validación global de las hipótesis básicas del MRL\nlibrary(gvlma)\ngvmodel &lt;- gvlma(APT_msft)\nsummary(gvmodel)\n\n\nCall:\nlm(formula = er_msoft ~ er_sp + dprod + dcredit + dinflation + \n    dmoney + dspread + rterm, data = apt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.075  -4.440  -0.403   4.616  24.480 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.326002   0.475481   2.789  0.00556 ** \ner_sp        1.280799   0.094354  13.574  &lt; 2e-16 ***\ndprod       -0.303032   0.736881  -0.411  0.68113    \ndcredit     -0.025364   0.027149  -0.934  0.35078    \ndinflation   2.194670   1.264299   1.736  0.08341 .  \ndmoney      -0.006871   0.015568  -0.441  0.65919    \ndspread      2.260064   4.140284   0.546  0.58548    \nrterm        4.733069   1.715814   2.758  0.00609 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.845 on 375 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.3452,    Adjusted R-squared:  0.333 \nF-statistic: 28.24 on 7 and 375 DF,  p-value: &lt; 2.2e-16\n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = APT_msft) \n\n                       Value   p-value                   Decision\nGlobal Stat        98.208657 0.000e+00 Assumptions NOT satisfied!\nSkewness            0.002011 9.642e-01    Assumptions acceptable.\nKurtosis           63.503462 1.554e-15 Assumptions NOT satisfied!\nLink Function       1.601550 2.057e-01    Assumptions acceptable.\nHeteroscedasticity 33.101634 8.747e-09 Assumptions NOT satisfied!\n\n# Chequeo general del modelo estimado\nlibrary(performance)\nmodel_performance(APT_msft)\n\n# Indices of model performance\n\nAIC      |     AICc |      BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n------------------------------------------------------------------\n2674.673 | 2675.155 | 2710.205 | 0.345 |     0.333 | 7.762 | 7.845\n\ncheck_model(APT_msft)\n\n\n\n# Especificación del modelo\n# Contraste de significación de variables irrelevantes\nlibrary(car)\nlinearHypothesis(APT_msft,c(\"dprod=0\",\"dcredit=0\",\"dmoney=0\",\"dspread=0\"))\n\nLinear hypothesis test\n\nHypothesis:\ndprod = 0\ndcredit = 0\ndmoney = 0\ndspread = 0\n\nModel 1: restricted model\nModel 2: er_msoft ~ er_sp + dprod + dcredit + dinflation + dmoney + dspread + \n    rterm\n\n  Res.Df   RSS Df Sum of Sq      F Pr(&gt;F)\n1    379 23180                           \n2    375 23078  4    101.88 0.4139 0.7986\n\n# Modelo sin variables no significativas: MCR\nAPT_msft_r  &lt;-  lm(er_msoft ~ er_sp + dinflation + rterm, data = apt)\nsummary(APT_msft_r)\n\n\nCall:\nlm(formula = er_msoft ~ er_sp + dinflation + rterm, data = apt)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.260  -4.330  -0.217   4.496  24.781 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1.0209     0.4010   2.546  0.01129 *  \ner_sp         1.2663     0.0921  13.750  &lt; 2e-16 ***\ndinflation    2.1874     1.2082   1.810  0.07101 .  \nrterm         4.7388     1.7087   2.773  0.00582 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.821 on 379 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.3423,    Adjusted R-squared:  0.3371 \nF-statistic: 65.75 on 3 and 379 DF,  p-value: &lt; 2.2e-16\n\n# Adecuación de la forma funcional: test RESET de Ramsey\nlibrary(lmtest)\nresettest(APT_msft_r, power=2, type=\"fitted\")\n\n\n    RESET test\n\ndata:  APT_msft_r\nRESET = 1.7054, df1 = 1, df2 = 378, p-value = 0.1924\n\nresettest(APT_msft_r, power=2:3, type=\"fitted\")\n\n\n    RESET test\n\ndata:  APT_msft_r\nRESET = 1.373, df1 = 2, df2 = 377, p-value = 0.2546"
  },
  {
    "objectID": "p3c2-app1.html#código-python",
    "href": "p3c2-app1.html#código-python",
    "title": "Aplicación 3.1 (Evaluación, validación y especificación del MRL): El modelo APT de valoración de activos",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.stats.api as sms\nimport statsmodels.stats as smstats\nimport statsmodels.stats.diagnostic as smsdiag\nfrom statsmodels.stats.outliers_influence import reset_ramsey\nfrom statsmodels.compat import lzip\nimport scipy.stats as scs\n\n# Lectura de datos\napt = pd.read_excel('data/APT_MICROSOFT.xls', parse_dates=['Date'], index_col='Date')\n# Estructura de la base de datos\napt.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 385 entries, 1986-03-01 to 2018-03-01\nData columns (total 9 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   MICROSOFT  385 non-null    float64\n 1   SANDP      385 non-null    float64\n 2   CPI        385 non-null    float64\n 3   INDPRO     385 non-null    float64\n 4   M1SUPPLY   385 non-null    float64\n 5   CCREDIT    385 non-null    float64\n 6   BMINUSA    385 non-null    float64\n 7   USTB3M     385 non-null    float64\n 8   USTB10Y    385 non-null    float64\ndtypes: float64(9)\nmemory usage: 30.1 KB\n\napt.head()\n\n            MICROSOFT       SANDP    CPI  ...  BMINUSA  USTB3M  USTB10Y\nDate                                      ...                          \n1986-03-01   0.095486  238.899994  108.8  ...     1.50    6.76     7.78\n1986-04-01   0.111979  235.520004  108.6  ...     1.40    6.24     7.30\n1986-05-01   0.121528  247.350006  108.9  ...     1.20    6.33     7.71\n1986-06-01   0.106771  250.839996  109.5  ...     1.21    6.40     7.80\n1986-07-01   0.098958  236.119995  109.5  ...     1.28    6.00     7.30\n\n[5 rows x 9 columns]\n\napt.tail()\n\n            MICROSOFT        SANDP      CPI  ...  BMINUSA  USTB3M  USTB10Y\nDate                                         ...                          \n2017-11-01  84.169998  2584.840088  246.669  ...     0.70    1.25     2.35\n2017-12-01  85.540001  2673.610107  246.524  ...     0.71    1.34     2.40\n2018-01-01  95.010002  2823.810059  247.867  ...     0.71    1.43     2.58\n2018-02-01  93.769997  2713.830078  248.991  ...     0.69    1.59     2.86\n2018-03-01  91.269997  2640.870117  249.554  ...     0.77    1.73     2.84\n\n[5 rows x 9 columns]\n\napt.describe()\n\n        MICROSOFT        SANDP         CPI  ...     BMINUSA      USTB3M     USTB10Y\ncount  385.000000   385.000000  385.000000  ...  385.000000  385.000000  385.000000\nmean    23.301038  1066.036103  181.062083  ...    0.974623    3.296909    5.075403\nstd     19.255768   602.397165   41.136433  ...    0.382047    2.589801    2.173512\nmin      0.095486   230.300003  108.600000  ...    0.550000    0.010000    1.500000\n25%      2.894531   459.269989  147.200000  ...    0.720000    0.450000    3.330000\n50%     25.719999  1104.489990  178.800000  ...    0.900000    3.440000    4.910000\n75%     30.860001  1385.589966  218.178000  ...    1.130000    5.290000    6.740000\nmax     95.010002  2823.810059  249.554000  ...    3.380000    9.140000    9.520000\n\n[8 rows x 9 columns]\n\n# Transformación de variables\ndef LogDiff(x):\n    x_diff = np.log(x/x.shift(1))\n    return x_diff\napt['dspread'] = apt['BMINUSA'] - apt['BMINUSA'].shift(1)\napt['dcredit'] = apt['CCREDIT'] - apt['CCREDIT'].shift(1)\napt['dprod'] = apt['INDPRO'] - apt['INDPRO'].shift(1)\napt['dmoney'] = apt['M1SUPPLY'] - apt['M1SUPPLY'].shift(1)\napt['inflation'] = 100*LogDiff(apt['CPI'])\napt['rterm'] = (apt['USTB10Y'] - apt['USTB3M']) - (apt['USTB10Y'] - apt['USTB3M']).shift(1)\napt['dinflation'] = apt['inflation'] - apt['inflation'].shift(1)\napt['r_msft'] = 100*LogDiff(apt['MICROSOFT'])\napt['r_sp'] = 100*LogDiff(apt['SANDP'])\napt['er_msoft'] = apt['r_msft'] - apt['USTB3M']/12\napt['er_sp'] = apt['r_sp'] - apt['USTB3M']/12\n# Eliminación de observaciones no disponibles (NA)\napt = apt.dropna()\n# Estimación MCO del modelo APT\nformula = 'er_msoft ~ er_sp + dprod + dcredit + dinflation + dmoney + dspread + rterm'\nAPT_msft = smf.ols(formula, apt).fit()\nprint(APT_msft.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               er_msoft   R-squared:                       0.345\nModel:                            OLS   Adj. R-squared:                  0.333\nMethod:                 Least Squares   F-statistic:                     28.24\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           3.52e-31\nTime:                        09:25:30   Log-Likelihood:                -1328.3\nNo. Observations:                 383   AIC:                             2673.\nDf Residuals:                     375   BIC:                             2704.\nDf Model:                           7                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      1.3260      0.475      2.789      0.006       0.391       2.261\ner_sp          1.2808      0.094     13.574      0.000       1.095       1.466\ndprod         -0.3030      0.737     -0.411      0.681      -1.752       1.146\ndcredit       -0.0254      0.027     -0.934      0.351      -0.079       0.028\ndinflation     2.1947      1.264      1.736      0.083      -0.291       4.681\ndmoney        -0.0069      0.016     -0.441      0.659      -0.037       0.024\ndspread        2.2601      4.140      0.546      0.585      -5.881      10.401\nrterm          4.7331      1.716      2.758      0.006       1.359       8.107\n==============================================================================\nOmnibus:                       21.147   Durbin-Watson:                   2.097\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               63.505\nSkew:                          -0.006   Prob(JB):                     1.62e-14\nKurtosis:                       4.995   Cond. No.                         293.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Especificación del modelo\n# Contraste de significación de variables irrelevantes\nH_0 = 'dprod = dcredit = dmoney = dspread = 0'\nF_test = APT_msft.f_test(H_0)\nprint(F_test)\n\n&lt;F test: F=0.41387855952255137, p=0.7986453783395882, df_denom=375, df_num=4&gt;\n\n# Modelo sin variables no significativas: MCR\nformula = 'er_msoft ~ er_sp + dinflation + rterm'\nAPT_msft_r = smf.ols(formula, apt).fit()\nprint(APT_msft_r.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               er_msoft   R-squared:                       0.342\nModel:                            OLS   Adj. R-squared:                  0.337\nMethod:                 Least Squares   F-statistic:                     65.75\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           2.99e-34\nTime:                        09:25:30   Log-Likelihood:                -1329.2\nNo. Observations:                 383   AIC:                             2666.\nDf Residuals:                     379   BIC:                             2682.\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      1.0209      0.401      2.546      0.011       0.232       1.809\ner_sp          1.2663      0.092     13.750      0.000       1.085       1.447\ndinflation     2.1874      1.208      1.810      0.071      -0.188       4.563\nrterm          4.7388      1.709      2.773      0.006       1.379       8.099\n==============================================================================\nOmnibus:                       21.806   Durbin-Watson:                   2.084\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               67.158\nSkew:                           0.007   Prob(JB):                     2.61e-15\nKurtosis:                       5.051   Cond. No.                         18.7\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Adecuación de la forma funcional: test RESET de Ramsey\nreset_ramsey(APT_msft_r,degree=2)\n\n&lt;class 'statsmodels.stats.contrast.ContrastResults'&gt;\n&lt;F test: F=1.70537226335334, p=0.19238105612636122, df_denom=378, df_num=1&gt;\n\nreset_ramsey(APT_msft_r,degree=3)\n\n&lt;class 'statsmodels.stats.contrast.ContrastResults'&gt;\n&lt;F test: F=1.3730181364024425, p=0.2546050361892768, df_denom=377, df_num=2&gt;"
  },
  {
    "objectID": "p3c2-app2.html#código-r",
    "href": "p3c2-app2.html#código-r",
    "title": "Aplicación 3.2 (Evaluación, validación y especificación del MRL): Ventas en una cadena de supermercados",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(alr4)\nlibrary(gvlma)\nlibrary(performance)\nlibrary(lmtest)\nlibrary(car)\n# Lectura de datos\nVENTAS &lt;- read_csv(\"data/VENTAS_SUPER.csv\")\n# Estructura de la base de datos\nstr(VENTAS)\n\nspc_tbl_ [75 × 3] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ A: num [1:75] 1.3 2.9 0.8 0.7 1.5 1.3 1.8 2.4 0.7 3 ...\n $ P: num [1:75] 5.69 6.49 5.63 6.22 5.02 6.41 5.85 5.41 6.24 6.2 ...\n $ V: num [1:75] 73.2 71.8 62.4 67.4 89.3 70.3 73.2 86.1 81 76.4 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   A = col_double(),\n  ..   P = col_double(),\n  ..   V = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\ndim(VENTAS)\n\n[1] 75  3\n\nhead(VENTAS)\n\n# A tibble: 6 × 3\n      A     P     V\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   1.3  5.69  73.2\n2   2.9  6.49  71.8\n3   0.8  5.63  62.4\n4   0.7  6.22  67.4\n5   1.5  5.02  89.3\n6   1.3  6.41  70.3\n\ntail(VENTAS)\n\n# A tibble: 6 × 3\n      A     P     V\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   2.2  6.02  73.7\n2   1.7  5.73  82.2\n3   0.7  5.11  74.2\n4   0.7  5.71  75.4\n5   2    5.45  81.3\n6   2.2  6.05  75  \n\nsummary(VENTAS)\n\n       A               P               V        \n Min.   :0.500   Min.   :4.830   Min.   :62.40  \n 1st Qu.:1.100   1st Qu.:5.220   1st Qu.:73.20  \n Median :1.800   Median :5.690   Median :76.50  \n Mean   :1.844   Mean   :5.687   Mean   :77.37  \n 3rd Qu.:2.700   3rd Qu.:6.210   3rd Qu.:82.20  \n Max.   :3.100   Max.   :6.490   Max.   :91.20  \n\n# Matriz de diagramas de puntos y gráficas parciales\nscatterplotMatrix(~ V + P + A, data=VENTAS)\n\n\n\nscatterplot(V ~ P, data=VENTAS, \n            smooth=list(smoother=loessLine, var=FALSE, lwd.smooth=3), \n            col=\"blue\", regLine=list(lwd=3))\n\n\n\nscatterplot(V ~ A, data=VENTAS, \n            smooth=list(smoother=loessLine, var=FALSE, lwd.smooth=3), \n            col=\"blue\", regLine=list(lwd=3))\n\n\n\n# Modelo de ventas\nmodelo_ventas_1 &lt;- lm(V ~ P + A, data=VENTAS)\nsummary(modelo_ventas_1)\n\n\nCall:\nlm(formula = V ~ P + A, data = VENTAS)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.4825  -3.1434  -0.3456   2.8754  11.3049 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 118.9136     6.3516  18.722  &lt; 2e-16 ***\nP            -7.9079     1.0960  -7.215 4.42e-10 ***\nA             1.8626     0.6832   2.726  0.00804 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.886 on 72 degrees of freedom\nMultiple R-squared:  0.4483,    Adjusted R-squared:  0.4329 \nF-statistic: 29.25 on 2 and 72 DF,  p-value: 5.041e-10\n\nconfint(modelo_ventas_1, level=.95)\n\n                 2.5 %     97.5 %\n(Intercept) 106.251852 131.575368\nP           -10.092676  -5.723032\nA             0.500659   3.224510\n\n# Gráficos de efectos (Effects plots)\nplot(allEffects(modelo_ventas_1), grid=TRUE, rug=TRUE)\n\n\n\n# Diagnósticos de la regresión\n# Validación global de las hipótesis básicas del MRL\ngvmodel &lt;- gvlma(modelo_ventas_1)\nsummary(gvmodel)\n\n\nCall:\nlm(formula = V ~ P + A, data = VENTAS)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.4825  -3.1434  -0.3456   2.8754  11.3049 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 118.9136     6.3516  18.722  &lt; 2e-16 ***\nP            -7.9079     1.0960  -7.215 4.42e-10 ***\nA             1.8626     0.6832   2.726  0.00804 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.886 on 72 degrees of freedom\nMultiple R-squared:  0.4483,    Adjusted R-squared:  0.4329 \nF-statistic: 29.25 on 2 and 72 DF,  p-value: 5.041e-10\n\n\nASSESSMENT OF THE LINEAR MODEL ASSUMPTIONS\nUSING THE GLOBAL TEST ON 4 DEGREES-OF-FREEDOM:\nLevel of Significance =  0.05 \n\nCall:\n gvlma(x = modelo_ventas_1) \n\n                     Value p-value                Decision\nGlobal Stat        1.63722  0.8021 Assumptions acceptable.\nSkewness           0.06397  0.8003 Assumptions acceptable.\nKurtosis           0.09499  0.7579 Assumptions acceptable.\nLink Function      0.79527  0.3725 Assumptions acceptable.\nHeteroscedasticity 0.68299  0.4086 Assumptions acceptable.\n\n# Chequeo general del modelo estimado\nmodel_performance(modelo_ventas_1)\n\n# Indices of model performance\n\nAIC     |    AICc |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n---------------------------------------------------------------\n455.739 | 456.310 | 465.009 | 0.448 |     0.433 | 4.787 | 4.886\n\ncheck_model(modelo_ventas_1)\n\n\n\n# Especificación del modelo\n# Adecuación de la forma funcional: test RESET de Ramsey\nresettest(modelo_ventas_1, power=2, type=\"fitted\")\n\n\n    RESET test\n\ndata:  modelo_ventas_1\nRESET = 0.76092, df1 = 1, df2 = 71, p-value = 0.386\n\nresettest(modelo_ventas_1, power=2:3, type=\"fitted\")\n\n\n    RESET test\n\ndata:  modelo_ventas_1\nRESET = 0.53369, df1 = 2, df2 = 70, p-value = 0.5888\n\n# Análisis gráfico de la hipótesis de linealidad\n# Residuos estandarizados (Pearson) \nresidualPlots(modelo_ventas_1)\n\n\n\n\n           Test stat Pr(&gt;|Test stat|)   \nP             1.0183         0.312016   \nA            -2.9427         0.004393 **\nTukey test    0.8723         0.383040   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Gráficos de variables añadidas (AV plots)\n# también denominados de regresiones parciales\navPlots(modelo_ventas_1) \n\n\n\n# Gráficos componente+residuos\n# (Component-plus-Residual o Partial-residual plots)\ncrPlots(modelo_ventas_1) \n\n\n\n# Modelo generalizado: especificación cuadrática en A\nmodelo_ventas_2 &lt;- lm(V ~ P + A + I(A^2), data=VENTAS)\nsummary(modelo_ventas_2)\n\n\nCall:\nlm(formula = V ~ P + A + I(A^2), data = VENTAS)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.2553  -3.1430  -0.0117   2.8513  11.8050 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 109.7190     6.7990  16.137  &lt; 2e-16 ***\nP            -7.6400     1.0459  -7.304 3.24e-10 ***\nA            12.1512     3.5562   3.417  0.00105 ** \nI(A^2)       -2.7680     0.9406  -2.943  0.00439 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.645 on 71 degrees of freedom\nMultiple R-squared:  0.5082,    Adjusted R-squared:  0.4875 \nF-statistic: 24.46 on 3 and 71 DF,  p-value: 5.6e-11\n\n# Gráficos de efectos\nplot(Effect(\"P\", modelo_ventas_2))\n\n\n\nplot(Effect(\"A\", modelo_ventas_2))\n\n\n\n# Comparación con el modelo básico\ncompareCoefs(modelo_ventas_1, modelo_ventas_2)\n\nCalls:\n1: lm(formula = V ~ P + A, data = VENTAS)\n2: lm(formula = V ~ P + A + I(A^2), data = VENTAS)\n\n            Model 1 Model 2\n(Intercept)  118.91  109.72\nSE             6.35    6.80\n                           \nP             -7.91   -7.64\nSE             1.10    1.05\n                           \nA             1.863  12.151\nSE            0.683   3.556\n                           \nI(A^2)               -2.768\nSE                    0.941\n                           \n\nanova(modelo_ventas_1, modelo_ventas_2)\n\nAnalysis of Variance Table\n\nModel 1: V ~ P + A\nModel 2: V ~ P + A + I(A^2)\n  Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)   \n1     72 1718.9                                \n2     71 1532.1  1    186.86 8.6594 0.004393 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncompare_performance(modelo_ventas_1, modelo_ventas_2, rank = TRUE)\n\n# Comparison of Model Performance Indices\n\nName            | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | AICc weights | BIC weights | Performance-Score\n--------------------------------------------------------------------------------------------------------------------------\nmodelo_ventas_2 |    lm | 0.508 |     0.487 | 4.520 | 4.645 |       0.965 |        0.960 |       0.896 |           100.00%\nmodelo_ventas_1 |    lm | 0.448 |     0.433 | 4.787 | 4.886 |       0.035 |        0.040 |       0.104 |             0.00%\n\nplot(compare_performance(modelo_ventas_1, modelo_ventas_2, rank = TRUE))\n\n\n\ntest_performance(modelo_ventas_1, modelo_ventas_2)\n\nName            | Model |   BF | Omega2 | p (Omega2) |   LR | p (LR)\n--------------------------------------------------------------------\nmodelo_ventas_1 |    lm |      |        |            |      |       \nmodelo_ventas_2 |    lm | 8.64 |   0.09 |      0.005 | 8.63 |  0.002\nModels were detected as nested (in terms of fixed parameters) and are compared in sequential order.\n\ntest_wald(modelo_ventas_1, modelo_ventas_2)\n\nName            | Model | df | df_diff |    F |     p\n-----------------------------------------------------\nmodelo_ventas_1 |    lm | 72 |         |      |      \nmodelo_ventas_2 |    lm | 71 |    1.00 | 8.66 | 0.004\nModels were detected as nested (in terms of fixed parameters) and are compared in sequential order.\n\ntest_bf(modelo_ventas_1, modelo_ventas_2)\n\nBayes Factors for Model Comparison\n\n                  Model            BF\n[modelo_ventas_2] P + A + I(A^2) 8.64\n\n* Against Denominator: [modelo_ventas_1] P + A\n*   Bayes Factor Type: BIC approximation\n\ntest_vuong(modelo_ventas_1, modelo_ventas_2)\n\nName            | Model | Omega2 | p (Omega2) |   LR | p (LR)\n-------------------------------------------------------------\nmodelo_ventas_1 |    lm |        |            |      |       \nmodelo_ventas_2 |    lm |   0.09 |      0.005 | 8.63 |  0.002\nModels were detected as nested (in terms of fixed parameters) and are compared in sequential order."
  },
  {
    "objectID": "p3c2-app2.html#código-python",
    "href": "p3c2-app2.html#código-python",
    "title": "Aplicación 3.2 (Evaluación, validación y especificación del MRL): Ventas en una cadena de supermercados",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.stats.api as sms\nimport statsmodels.stats as smstats\nimport statsmodels.stats.diagnostic as smsdiag\nfrom statsmodels.stats.outliers_influence import reset_ramsey\nfrom statsmodels.compat import lzip\nimport scipy.stats as scs\n\n# Lectura de datos\nVENTAS = pd.read_csv(\"data/VENTAS_SUPER.csv\")\n# Estructura de la base de datos\nVENTAS.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 75 entries, 0 to 74\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   A       75 non-null     float64\n 1   P       75 non-null     float64\n 2   V       75 non-null     float64\ndtypes: float64(3)\nmemory usage: 1.9 KB\n\nVENTAS.head()\n\n     A     P     V\n0  1.3  5.69  73.2\n1  2.9  6.49  71.8\n2  0.8  5.63  62.4\n3  0.7  6.22  67.4\n4  1.5  5.02  89.3\n\nVENTAS.tail()\n\n      A     P     V\n70  1.7  5.73  82.2\n71  0.7  5.11  74.2\n72  0.7  5.71  75.4\n73  2.0  5.45  81.3\n74  2.2  6.05  75.0\n\nVENTAS.describe()\n\n               A          P          V\ncount  75.000000  75.000000  75.000000\nmean    1.844000   5.687200  77.374667\nstd     0.831677   0.518432   6.488537\nmin     0.500000   4.830000  62.400000\n25%     1.100000   5.220000  73.200000\n50%     1.800000   5.690000  76.500000\n75%     2.700000   6.210000  82.200000\nmax     3.100000   6.490000  91.200000\n\n# Modelo de ventas\nformula = 'V ~ P + A'\nmodelo_ventas_1 = smf.ols(formula, VENTAS).fit()\nprint(modelo_ventas_1.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      V   R-squared:                       0.448\nModel:                            OLS   Adj. R-squared:                  0.433\nMethod:                 Least Squares   F-statistic:                     29.25\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           5.04e-10\nTime:                        09:32:50   Log-Likelihood:                -223.87\nNo. Observations:                  75   AIC:                             453.7\nDf Residuals:                      72   BIC:                             460.7\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept    118.9136      6.352     18.722      0.000     106.252     131.575\nP             -7.9079      1.096     -7.215      0.000     -10.093      -5.723\nA              1.8626      0.683      2.726      0.008       0.501       3.225\n==============================================================================\nOmnibus:                        0.535   Durbin-Watson:                   2.183\nProb(Omnibus):                  0.765   Jarque-Bera (JB):                0.159\nSkew:                          -0.072   Prob(JB):                        0.924\nKurtosis:                       3.174   Cond. No.                         69.5\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Especificación del modelo\n# Adecuación de la forma funcional: test RESET de Ramsey\nreset_ramsey(modelo_ventas_1,degree=2)\n\n&lt;class 'statsmodels.stats.contrast.ContrastResults'&gt;\n&lt;F test: F=0.7609212886079043, p=0.3859807963132884, df_denom=71, df_num=1&gt;\n\nreset_ramsey(modelo_ventas_1,degree=3)\n\n&lt;class 'statsmodels.stats.contrast.ContrastResults'&gt;\n&lt;F test: F=0.5336864235712575, p=0.5888060456090185, df_denom=70, df_num=2&gt;\n\n# Análisis gráfico de la hipótesis de linealidad\n# Gráficos de variables añadidas (AV plots)\nfig = sm.graphics.plot_partregress_grid(modelo_ventas_1)\n\neval_env: 1\neval_env: 1\neval_env: 1\n\nfig.tight_layout(pad=1.0)\nplt.show()\n\n\n\n# Gráficos componente+residuos\nfig = sm.graphics.plot_ccpr_grid(modelo_ventas_1)\nfig.tight_layout(pad=1.0)\nplt.show()\n\n\n\n# Diagnósticos de regresión de una sola variable\nfig = sm.graphics.plot_regress_exog(modelo_ventas_1, \"P\")\n\neval_env: 1\n\nfig.tight_layout(pad=1.0)\nplt.show()\n\n\n\nfig = sm.graphics.plot_regress_exog(modelo_ventas_1, \"A\")\n\neval_env: 1\n\nfig.tight_layout(pad=1.0)\nplt.show()\n\n\n\n# Modelo generalizado: especificación cuadrática en A\nformula = 'V ~ P + A + + I(A**2)'\nmodelo_ventas_2 = smf.ols(formula, VENTAS).fit()\nprint(modelo_ventas_2.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      V   R-squared:                       0.508\nModel:                            OLS   Adj. R-squared:                  0.487\nMethod:                 Least Squares   F-statistic:                     24.46\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           5.60e-11\nTime:                        09:32:53   Log-Likelihood:                -219.55\nNo. Observations:                  75   AIC:                             447.1\nDf Residuals:                      71   BIC:                             456.4\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept    109.7190      6.799     16.137      0.000      96.162     123.276\nP             -7.6400      1.046     -7.304      0.000      -9.726      -5.554\nA             12.1512      3.556      3.417      0.001       5.060      19.242\nI(A ** 2)     -2.7680      0.941     -2.943      0.004      -4.644      -0.892\n==============================================================================\nOmnibus:                        1.004   Durbin-Watson:                   2.043\nProb(Omnibus):                  0.605   Jarque-Bera (JB):                0.455\nSkew:                          -0.088   Prob(JB):                        0.797\nKurtosis:                       3.339   Cond. No.                         101.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "p3c2-app3.html#diferencia-salarial-por-sexo",
    "href": "p3c2-app3.html#diferencia-salarial-por-sexo",
    "title": "Aplicación 3.3 (Estabilidad de los parámetros estructurales): Diferenciación salarial por sexo. Exportaciones españolas.",
    "section": "Diferencia salarial por sexo",
    "text": "Diferencia salarial por sexo\n\nDe nuevo en este ejemplo se usará como especificación econométrica de partida el siguiente modelo log-lineal, que se corresponde con la ecuación de salarios de Mincer:\n\\[\nlog(SALARIO_{i}) = \\beta_1 + \\beta_2  EDUC_{i} +  \\beta_3  EXPER_{i} + e_{i}\n\\]\ndonde \\(SALARIO\\), \\(EDUC\\) y \\(EXPER\\) representan, respectivamente el salario percibido, el nivel de educación y el grado de experiencia de cada uno de los 526 indviduos que componen la base muestral.\n\n\nCódigo R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(car)\n# Lectura de datos\nSAL_SEX &lt;- read_csv(\"data/SAL_SEX.csv\")\ndim(SAL_SEX)\n\n[1] 526   4\n\nstr(SAL_SEX)\n\nspc_tbl_ [526 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ EDUC   : num [1:526] 11 12 11 8 12 16 18 12 12 17 ...\n $ EXPER  : num [1:526] 2 22 2 44 7 9 15 5 26 22 ...\n $ MUJER  : num [1:526] 1 1 0 0 0 0 0 1 1 0 ...\n $ SALARIO: num [1:526] 3.1 3.24 3 6 5.3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   EDUC = col_double(),\n  ..   EXPER = col_double(),\n  ..   MUJER = col_double(),\n  ..   SALARIO = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nhead(SAL_SEX)\n\n# A tibble: 6 × 4\n   EDUC EXPER MUJER SALARIO\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1    11     2     1    3.1 \n2    12    22     1    3.24\n3    11     2     0    3   \n4     8    44     0    6   \n5    12     7     0    5.3 \n6    16     9     0    8.75\n\ntail(SAL_SEX)\n\n# A tibble: 6 × 4\n   EDUC EXPER MUJER SALARIO\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1    12     2     0    5.65\n2    16    14     1   15   \n3    10     2     1    2.27\n4    15    13     0    4.67\n5    16     5     0   11.6 \n6    14     5     1    3.5 \n\n# Distribución de la variable dependiente\nBoxplot(~SALARIO, data=SAL_SEX, main=\"\", ylab=\"SALARIO\", id=list(method = \"none\"))\n\n\n\n# Conversión de variable numérica MUJER (0/1) a cualitativa (factor)\nclass(SAL_SEX$MUJER)\n\n[1] \"numeric\"\n\nSEXO &lt;- factor(SAL_SEX$MUJER, labels=c(\"Hombre\", \"Mujer\"))\nsummary(SEXO)\n\nHombre  Mujer \n   274    252 \n\n# Distribución de la variable dependiente por sexo\nBoxplot(SALARIO~SEXO, data=SAL_SEX, ylab=\"SALARIO\", id=list(method = \"none\"))\n\n\n\n# Ecuación de salarios para la muestra total\nsummary(lm_SAL &lt;- lm(log(SALARIO) ~ EDUC + EXPER , data = SAL_SEX))\n\n\nCall:\nlm(formula = log(SALARIO) ~ EDUC + EXPER, data = SAL_SEX)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05800 -0.30136 -0.04539  0.30601  1.44425 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.216854   0.108595   1.997   0.0464 *  \nEDUC        0.097936   0.007622  12.848  &lt; 2e-16 ***\nEXPER       0.010347   0.001555   6.653 7.24e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4614 on 523 degrees of freedom\nMultiple R-squared:  0.2493,    Adjusted R-squared:  0.2465 \nF-statistic: 86.86 on 2 and 523 DF,  p-value: &lt; 2.2e-16\n\n# Gráficas parciales con diferenciación por sexo\nscatterplot(log(SALARIO) ~ EDUC| SEXO, data=SAL_SEX, smooth=FALSE, \n            boxplots=FALSE, ylab=\"Relación parcial log(Salario)/Educación\")\n\n\n\nscatterplot(log(SALARIO) ~ EXPER| SEXO, data=SAL_SEX, smooth=FALSE, \n            boxplots=FALSE, ylab=\"Relación parcial log(Salario)/Experiencia\")\n\n\n\n# Diferenciación por sexos:\n# ¿existe realmente diferenciación por sexos? (estadísticamente significativa)\n# Hombres\nsummary(lm_SAL_h &lt;- lm(log(SALARIO) ~ EDUC + EXPER , \n                       data = SAL_SEX[which(SAL_SEX$MUJER==0),]))\n\n\nCall:\nlm(formula = log(SALARIO) ~ EDUC + EXPER, data = SAL_SEX[which(SAL_SEX$MUJER == \n    0), ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.20460 -0.29936 -0.01032  0.28558  1.25532 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.249794   0.144264   1.732   0.0845 .  \nEDUC        0.101813   0.009656  10.544  &lt; 2e-16 ***\nEXPER       0.014908   0.002148   6.941 2.87e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4457 on 271 degrees of freedom\nMultiple R-squared:  0.3106,    Adjusted R-squared:  0.3055 \nF-statistic: 61.04 on 2 and 271 DF,  p-value: &lt; 2.2e-16\n\n# Mujeres\nsummary(lm_SAL_m &lt;- lm(log(SALARIO) ~ EDUC + EXPER , \n                       data = SAL_SEX[which(SAL_SEX$MUJER==1),]))\n\n\nCall:\nlm(formula = log(SALARIO) ~ EDUC + EXPER, data = SAL_SEX[which(SAL_SEX$MUJER == \n    1), ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.96983 -0.21953 -0.06965  0.21896  1.22467 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.334836   0.141456   2.367   0.0187 *  \nEDUC        0.082314   0.010458   7.871 1.08e-13 ***\nEXPER       0.004116   0.001894   2.173   0.0307 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.399 on 249 degrees of freedom\nMultiple R-squared:  0.1996,    Adjusted R-squared:  0.1932 \nF-statistic: 31.06 on 2 and 249 DF,  p-value: 9.089e-13\n\n# Comparación de coeficientes estimados\ncompareCoefs(lm_SAL_h, lm_SAL_m)\n\nCalls:\n1: lm(formula = log(SALARIO) ~ EDUC + EXPER, data = \n  SAL_SEX[which(SAL_SEX$MUJER == 0), ])\n2: lm(formula = log(SALARIO) ~ EDUC + EXPER, data = \n  SAL_SEX[which(SAL_SEX$MUJER == 1), ])\n\n            Model 1 Model 2\n(Intercept)   0.250   0.335\nSE            0.144   0.141\n                           \nEDUC        0.10181 0.08231\nSE          0.00966 0.01046\n                           \nEXPER       0.01491 0.00412\nSE          0.00215 0.00189\n                           \n\n# Test de Chow de cambio estructural\nlm_SAL_int &lt;- lm(log(SALARIO) ~ (EDUC + EXPER)*MUJER, data = SAL_SEX)\nanova(lm_SAL, lm_SAL_int)\n\nAnalysis of Variance Table\n\nModel 1: log(SALARIO) ~ EDUC + EXPER\nModel 2: log(SALARIO) ~ (EDUC + EXPER) * MUJER\n  Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    523 111.345                                  \n2    520  93.477  3    17.868 33.133 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Regresión diferenciada por sexos\nsummary(lm_SAL_int)\n\n\nCall:\nlm(formula = log(SALARIO) ~ (EDUC + EXPER) * MUJER, data = SAL_SEX)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.96983 -0.26177 -0.03718  0.25663  1.25532 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.249794   0.137237   1.820 0.069308 .  \nEDUC         0.101813   0.009186  11.084  &lt; 2e-16 ***\nEXPER        0.014908   0.002043   7.296 1.11e-12 ***\nMUJER        0.085042   0.203534   0.418 0.676247    \nEDUC:MUJER  -0.019499   0.014417  -1.352 0.176818    \nEXPER:MUJER -0.010792   0.002868  -3.763 0.000187 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.424 on 520 degrees of freedom\nMultiple R-squared:  0.3698,    Adjusted R-squared:  0.3637 \nF-statistic: 61.03 on 5 and 520 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCódigo Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.stats as smstats\nimport scipy as sp\n# Lectura de datos\nSAL_SEX = pd.read_csv(\"data/SAL_SEX.csv\")\nSAL_SEX.shape\n\n(526, 4)\n\nSAL_SEX.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 526 entries, 0 to 525\nData columns (total 4 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   EDUC     526 non-null    int64  \n 1   EXPER    526 non-null    int64  \n 2   MUJER    526 non-null    int64  \n 3   SALARIO  526 non-null    float64\ndtypes: float64(1), int64(3)\nmemory usage: 16.6 KB\n\nSAL_SEX.head()\n\n   EDUC  EXPER  MUJER  SALARIO\n0    11      2      1     3.10\n1    12     22      1     3.24\n2    11      2      0     3.00\n3     8     44      0     6.00\n4    12      7      0     5.30\n\nSAL_SEX.tail()\n\n     EDUC  EXPER  MUJER  SALARIO\n521    16     14      1    15.00\n522    10      2      1     2.27\n523    15     13      0     4.67\n524    16      5      0    11.56\n525    14      5      1     3.50\n\n# Distribución de la variable dependiente\nplt.figure(1)\nsns.boxplot(x=SAL_SEX[\"SALARIO\"])\nplt.show()\n\n\n\n# Conversión de variable numérica a cualitativa (factor)\nSAL_SEX['SEXO']=SAL_SEX['MUJER'].astype('category')\nSAL_SEX['SEXO']=SAL_SEX['SEXO'].cat.rename_categories(['Hombre', 'Mujer'])\n# Distribución de la variable dependiente por sexo\nplt.figure(2)\nsns.boxplot(x=SAL_SEX[\"SALARIO\"] , y=SAL_SEX[\"SEXO\"])\nplt.show()\n\n\n\n# Ecuación de salarios para la muestra total\nlm_SAL = smf.ols(formula='np.log(SALARIO) ~ EDUC + EXPER', data=SAL_SEX).fit()\nprint(lm_SAL.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        np.log(SALARIO)   R-squared:                       0.249\nModel:                            OLS   Adj. R-squared:                  0.246\nMethod:                 Least Squares   F-statistic:                     86.86\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           2.68e-33\nTime:                        18:34:50   Log-Likelihood:                -338.01\nNo. Observations:                 526   AIC:                             682.0\nDf Residuals:                     523   BIC:                             694.8\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.2169      0.109      1.997      0.046       0.004       0.430\nEDUC           0.0979      0.008     12.848      0.000       0.083       0.113\nEXPER          0.0103      0.002      6.653      0.000       0.007       0.013\n==============================================================================\nOmnibus:                        7.740   Durbin-Watson:                   1.789\nProb(Omnibus):                  0.021   Jarque-Bera (JB):                9.485\nSkew:                           0.165   Prob(JB):                      0.00872\nKurtosis:                       3.569   Cond. No.                         130.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Gráficas parciales con diferenciación por sexo\nSAL_SEX['l_SALARIO']=np.log(SAL_SEX['SALARIO'])\nplt.figure(3)\nsns.lmplot(x=\"EDUC\", y=\"l_SALARIO\", hue=\"SEXO\", data=SAL_SEX);\nplt.show()\n\n\n\nplt.figure(4)\nsns.lmplot(x=\"EXPER\", y=\"l_SALARIO\", hue=\"SEXO\", data=SAL_SEX);\nplt.show()\n\n\n\n# Diferenciación por sexos:\n# ¿existe realmente diferenciación por sexos? (estadísticamente significativa)\n# Hombres\nlm_SAL_h = smf.ols(formula='np.log(SALARIO) ~ EDUC + EXPER', \nsubset=(SAL_SEX['MUJER'] == 0), data=SAL_SEX).fit()\nprint(lm_SAL_h.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        np.log(SALARIO)   R-squared:                       0.311\nModel:                            OLS   Adj. R-squared:                  0.305\nMethod:                 Least Squares   F-statistic:                     61.04\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           1.30e-22\nTime:                        18:34:52   Log-Likelihood:                -165.86\nNo. Observations:                 274   AIC:                             337.7\nDf Residuals:                     271   BIC:                             348.5\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.2498      0.144      1.732      0.084      -0.034       0.534\nEDUC           0.1018      0.010     10.544      0.000       0.083       0.121\nEXPER          0.0149      0.002      6.941      0.000       0.011       0.019\n==============================================================================\nOmnibus:                        0.921   Durbin-Watson:                   1.872\nProb(Omnibus):                  0.631   Jarque-Bera (JB):                0.674\nSkew:                           0.098   Prob(JB):                        0.714\nKurtosis:                       3.143   Cond. No.                         131.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Mujeres\nlm_SAL_m = smf.ols(formula='np.log(SALARIO) ~ EDUC + EXPER', \nsubset=(SAL_SEX['MUJER'] == 1), data=SAL_SEX).fit()\nprint(lm_SAL_m.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        np.log(SALARIO)   R-squared:                       0.200\nModel:                            OLS   Adj. R-squared:                  0.193\nMethod:                 Least Squares   F-statistic:                     31.06\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           9.09e-13\nTime:                        18:34:52   Log-Likelihood:                -124.54\nNo. Observations:                 252   AIC:                             255.1\nDf Residuals:                     249   BIC:                             265.7\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.3348      0.141      2.367      0.019       0.056       0.613\nEDUC           0.0823      0.010      7.871      0.000       0.062       0.103\nEXPER          0.0041      0.002      2.173      0.031       0.000       0.008\n==============================================================================\nOmnibus:                       17.664   Durbin-Watson:                   2.103\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               56.098\nSkew:                           0.007   Prob(JB):                     6.58e-13\nKurtosis:                       5.311   Cond. No.                         133.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Regresión diferenciada por sexos\nlm_SAL_int = smf.ols(formula='np.log(SALARIO) ~ (EDUC + EXPER)*MUJER', \ndata=SAL_SEX).fit()\nprint(lm_SAL_int.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        np.log(SALARIO)   R-squared:                       0.370\nModel:                            OLS   Adj. R-squared:                  0.364\nMethod:                 Least Squares   F-statistic:                     61.03\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           5.27e-50\nTime:                        18:34:52   Log-Likelihood:                -292.01\nNo. Observations:                 526   AIC:                             596.0\nDf Residuals:                     520   BIC:                             621.6\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n-------------------------------------------------------------------------------\nIntercept       0.2498      0.137      1.820      0.069      -0.020       0.519\nEDUC            0.1018      0.009     11.084      0.000       0.084       0.120\nEXPER           0.0149      0.002      7.296      0.000       0.011       0.019\nMUJER           0.0850      0.204      0.418      0.676      -0.315       0.485\nEDUC:MUJER     -0.0195      0.014     -1.352      0.177      -0.048       0.009\nEXPER:MUJER    -0.0108      0.003     -3.763      0.000      -0.016      -0.005\n==============================================================================\nOmnibus:                       12.139   Durbin-Watson:                   1.802\nProb(Omnibus):                  0.002   Jarque-Bera (JB):               22.040\nSkew:                           0.063   Prob(JB):                     1.64e-05\nKurtosis:                       3.995   Cond. No.                         333.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Test de Chow de cambio estructural\nsm.stats.anova_lm(lm_SAL,lm_SAL_int) \n\n   df_resid         ssr  df_diff    ss_diff          F        Pr(&gt;F)\n0     523.0  111.344709      0.0        NaN        NaN           NaN\n1     520.0   93.476534      3.0  17.868174  33.132916  1.306612e-19"
  },
  {
    "objectID": "p3c2-app3.html#exportaciones-españolas",
    "href": "p3c2-app3.html#exportaciones-españolas",
    "title": "Aplicación 3.3 (Estabilidad de los parámetros estructurales): Diferenciación salarial por sexo. Exportaciones españolas.",
    "section": "Exportaciones españolas",
    "text": "Exportaciones españolas\n\nTanto la teoría económica como la experiencia econométrica internacional nos señalan que las exportaciones de bienes y servicios de un país dependen de dos variables básicas, un indicador de actividad económica mundial y un indicador de precios relativos. Para estimar una ecuación de exportaciones para el caso español, se han tomado series de datos para el período 1970-1997 de las siguientes variables: las exportaciones reales de bienes y servicios, excluido el turismo (\\(XGS\\)); el índice anual del producto interior bruto real mundial (\\(WGDP\\)); y el tipo de cambio efectivo real respecto al conjunto de las diez monedas principales, corregido por la relación de precios de exportación de España respecto a la media ponderada de los precios de exportación de los principales países (\\(REER\\)).\n\nEl modelo de regresión que se usará como soporte del ejemplo es entonces el siguiente:\n\\[\nlog(XGS_{t}) = \\beta_1 + \\beta_2  log(WGDP_{t}) +  \\beta_3  log(REER_{t}) + e_{t}\n\\]\n\nCódigo R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(car)\n# Lectura de datos\nEXP_ESP &lt;- read_delim(\"data/EXP_ESP_Y.csv\", delim = \";\")\n# División de la muestra entre preUE (1970-1985) y postUE (1986-1997)\nY1986 = match(as.Date(\"1986-01-01\"), EXP_ESP$date)\nY1986\n\n[1] 17\n\n# Variables numérica y cualitativa de subperíodos\nUE &lt;- factor(c(rep(0, 16), rep(1, 12)), labels=c(\"preUE\", \"postUE\"))\nUE\n\n [1] preUE  preUE  preUE  preUE  preUE  preUE  preUE  preUE  preUE  preUE \n[11] preUE  preUE  preUE  preUE  preUE  preUE  postUE postUE postUE postUE\n[21] postUE postUE postUE postUE postUE postUE postUE postUE\nLevels: preUE postUE\n\nclass(UE)\n\n[1] \"factor\"\n\nEXP_ESP$D1986 &lt;- as.numeric(UE)-1\nEXP_ESP$D1986\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n\nclass(EXP_ESP$D1986)\n\n[1] \"numeric\"\n\n# Formato de series temporales\nEXP_ESP_ts &lt;- ts(EXP_ESP[,2:5], start=c(1970), end = c(1997), frequency = 1)\nplot(EXP_ESP_ts)\n\n\n\n# Ecuación de exportaciones para el período completo (1970-1997)\nlm_X_ESP &lt;- lm(log(XGS) ~ log(WGDP) + log(REER), data = EXP_ESP_ts)\nsummary(lm_X_ESP)\n\n\nCall:\nlm(formula = log(XGS) ~ log(WGDP) + log(REER), data = EXP_ESP_ts)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.08302 -0.04419 -0.02013  0.03883  0.14376 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.24239    0.84432  -0.287    0.776    \nlog(WGDP)    2.04618    0.06235  32.820   &lt;2e-16 ***\nlog(REER)   -0.34878    0.21480  -1.624    0.117    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06663 on 25 degrees of freedom\nMultiple R-squared:  0.9853,    Adjusted R-squared:  0.9841 \nF-statistic: 836.6 on 2 and 25 DF,  p-value: &lt; 2.2e-16\n\n# Gráficas parciales con diferenciación por subperíodos\nscatterplot(log(XGS) ~ log(WGDP)| D1986, data=EXP_ESP_ts, \n            smooth=FALSE, boxplots=FALSE, \n            ylab=\"Relación parcial Exportaciones/PIB mundial (logs)\")\n\n\n\nscatterplot(log(XGS) ~ log(REER)| D1986, data=EXP_ESP_ts, \n            smooth=FALSE, boxplots=FALSE, \n            ylab=\"Relación parcial Exportaciones/Tipo de cambio (logs)\")\n\n\n\n# Diferenciación por subperíodos\n# PreUE\npreUE &lt;- window(EXP_ESP_ts, start=1970, end = 1985)\nlm_X_ESP_preUE &lt;- lm(log(XGS) ~ log(WGDP) + log(REER) , data = preUE)\nsummary(lm_X_ESP_preUE)\n\n\nCall:\nlm(formula = log(XGS) ~ log(WGDP) + log(REER), data = preUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.085980 -0.029433  0.003653  0.027247  0.084831 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.5078     1.6493   1.520   0.1523    \nlog(WGDP)     1.8144     0.0846  21.447 1.57e-11 ***\nlog(REER)    -0.6945     0.3187  -2.179   0.0483 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05124 on 13 degrees of freedom\nMultiple R-squared:  0.9763,    Adjusted R-squared:  0.9727 \nF-statistic: 267.8 on 2 and 13 DF,  p-value: 2.725e-11\n\n# PostUE\npostUE &lt;- window(EXP_ESP_ts, start=1986, end = 1997)\nlm_X_ESP_postUE &lt;- lm(log(XGS) ~ log(WGDP) + log(REER) , data = postUE)\nsummary(lm_X_ESP_postUE)\n\n\nCall:\nlm(formula = log(XGS) ~ log(WGDP) + log(REER), data = postUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.052680 -0.032117  0.005373  0.029904  0.037074 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -1.6788     0.8889  -1.889  0.09153 .  \nlog(WGDP)     2.6425     0.1032  25.610 1.02e-09 ***\nlog(REER)    -0.7220     0.1933  -3.735  0.00466 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03661 on 9 degrees of freedom\nMultiple R-squared:  0.9871,    Adjusted R-squared:  0.9842 \nF-statistic: 344.6 on 2 and 9 DF,  p-value: 3.133e-09\n\n# Comparación de coeficientes estimados\ncompareCoefs(lm_X_ESP_preUE,lm_X_ESP_postUE)\n\nCalls:\n1: lm(formula = log(XGS) ~ log(WGDP) + log(REER), data = preUE)\n2: lm(formula = log(XGS) ~ log(WGDP) + log(REER), data = postUE)\n\n            Model 1 Model 2\n(Intercept)   2.508  -1.679\nSE            1.649   0.889\n                           \nlog(WGDP)    1.8144  2.6425\nSE           0.0846  0.1032\n                           \nlog(REER)    -0.694  -0.722\nSE            0.319   0.193\n                           \n\n# ¿Existe diferenciación estadísticamente significativa por períodos?\n# Test de Chow de cambio estructural\n# Método 1 (ANOVA)\nlm_X_EXP_int &lt;- lm(log(XGS) ~ (log(WGDP) + log(REER))*D1986, \n                   data = EXP_ESP_ts)\nsummary(lm_X_EXP_int)\n\n\nCall:\nlm(formula = log(XGS) ~ (log(WGDP) + log(REER)) * D1986, data = EXP_ESP_ts)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.085980 -0.030598  0.004582  0.029904  0.084831 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.50775    1.47498   1.700   0.1032    \nlog(WGDP)        1.81445    0.07566  23.982  &lt; 2e-16 ***\nlog(REER)       -0.69447    0.28504  -2.436   0.0234 *  \nD1986           -4.18659    1.84754  -2.266   0.0336 *  \nlog(WGDP):D1986  0.82803    0.14968   5.532 1.47e-05 ***\nlog(REER):D1986 -0.02750    0.37389  -0.074   0.9420    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04583 on 22 degrees of freedom\nMultiple R-squared:  0.9939,    Adjusted R-squared:  0.9925 \nF-statistic: 713.6 on 5 and 22 DF,  p-value: &lt; 2.2e-16\n\nanova(lm_X_ESP, lm_X_EXP_int)\n\nAnalysis of Variance Table\n\nModel 1: log(XGS) ~ log(WGDP) + log(REER)\nModel 2: log(XGS) ~ (log(WGDP) + log(REER)) * D1986\n  Res.Df      RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     25 0.110991                                  \n2     22 0.046204  3  0.064787 10.283 0.0001978 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Método 2 (librería structchange)\nlibrary(strucchange)\nsctest(log(XGS) ~ log(WGDP) + log(REER), data=EXP_ESP_ts, \n       type = \"Chow\", point = Y1986-1)\n\n\n    Chow test\n\ndata:  log(XGS) ~ log(WGDP) + log(REER)\nF = 10.283, p-value = 0.0001978\n\n# Contrastes tipo Chow basados en estimaciones recursivas\n# [se elimina un % de observaciones en los extremmos]\nsbtest &lt;- Fstats(log(XGS) ~ log(WGDP) + log(REER), data = EXP_ESP_ts, \n                 from = 0.15, to = 0.85)\nsbtest[[\"Fstats\"]]\n\nTime Series:\nStart = 1973 \nEnd = 1992 \nFrequency = 1 \n [1] 26.94858 40.37538 52.72550 53.14715 43.28653 41.27132 51.76225 53.52206\n [9] 43.97098 39.04442 33.07102 30.47271 30.84853 32.31100 37.23453 41.05085\n[17] 41.68393 41.71401 38.20854 33.80421\n\nplot(sbtest, alpha = 0.05)\n\n\n\n# Test de Chow (1960) [versión Chi2]\n# [punto de ruptura conocido: 17 - 4 (15% suprimidos a la izquierda) ]\nChow_F &lt;- sbtest$Fstats[Y1986-4] \nChow_F \n\n[1] 30.84853\n\n# Se puede comprobar que CHOW=Chow_F/K\n# Chow_F tiene una distribución asintótica Chi^2 mientras que\n# CHOW tiene una distribución exacta F_K,T-2*K\npval &lt;-  1-pchisq(Chow_F,sbtest$nreg) \npval\n\n[1] 9.148179e-07\n\n# Contrastes de Andrews (1993) y Andrews y Ploberger (1994): supF, aveF, expF\n# [punto de ruptura desconocido]\nsctest(sbtest, type = \"supF\")\n\n\n    supF test\n\ndata:  sbtest\nsup.F = 53.522, p-value = 2.556e-10\n\nsctest(sbtest, type = \"aveF\")\n\n\n    aveF test\n\ndata:  sbtest\nave.F = 40.323, p-value = 1.043e-13\n\nsctest(sbtest, type = \"expF\")\n\n\n    expF test\n\ndata:  sbtest\nexp.F = 24.845, p-value = 0.0007622\n\n# Test CUSUM (Brown, Durbin y Evans, 1975)\nplot(efp(log(XGS) ~ log(WGDP) + log(REER), data = EXP_ESP_ts))\n\n\n\n# Regresión diferenciada por tramos temporales\nsummary(lm(log(XGS) ~ (log(WGDP) + log(REER))*D1986, data=EXP_ESP_ts))\n\n\nCall:\nlm(formula = log(XGS) ~ (log(WGDP) + log(REER)) * D1986, data = EXP_ESP_ts)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.085980 -0.030598  0.004582  0.029904  0.084831 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.50775    1.47498   1.700   0.1032    \nlog(WGDP)        1.81445    0.07566  23.982  &lt; 2e-16 ***\nlog(REER)       -0.69447    0.28504  -2.436   0.0234 *  \nD1986           -4.18659    1.84754  -2.266   0.0336 *  \nlog(WGDP):D1986  0.82803    0.14968   5.532 1.47e-05 ***\nlog(REER):D1986 -0.02750    0.37389  -0.074   0.9420    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04583 on 22 degrees of freedom\nMultiple R-squared:  0.9939,    Adjusted R-squared:  0.9925 \nF-statistic: 713.6 on 5 and 22 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCódigo Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sp\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.stats as smstats\n# Lectura de datos\nEXP_ESP = pd.read_csv(\"data/EXP_ESP_Y.csv\", sep=\";\", \nparse_dates=['date'], index_col='date')\ndate = pd.date_range(start = '1970', periods = len(EXP_ESP.index), freq = 'Y')\nEXP_ESP.index = date\nEXP_ESP.index\n\nDatetimeIndex(['1970-12-31', '1971-12-31', '1972-12-31', '1973-12-31',\n               '1974-12-31', '1975-12-31', '1976-12-31', '1977-12-31',\n               '1978-12-31', '1979-12-31', '1980-12-31', '1981-12-31',\n               '1982-12-31', '1983-12-31', '1984-12-31', '1985-12-31',\n               '1986-12-31', '1987-12-31', '1988-12-31', '1989-12-31',\n               '1990-12-31', '1991-12-31', '1992-12-31', '1993-12-31',\n               '1994-12-31', '1995-12-31', '1996-12-31', '1997-12-31'],\n              dtype='datetime64[ns]', freq='A-DEC')\n\nEXP_ESP.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 28 entries, 1970-12-31 to 1997-12-31\nFreq: A-DEC\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   XGS     28 non-null     float64\n 1   REER    28 non-null     float64\n 2   WGDP    28 non-null     float64\ndtypes: float64(3)\nmemory usage: 896.0 bytes\n\nEXP_ESP.head()\n\n                    XGS        REER        WGDP\n1970-12-31  2225.123047  100.495876  104.200000\n1971-12-31  2541.091064  101.909402  109.410000\n1972-12-31  2881.596924  107.146269  115.646370\n1973-12-31  3169.757080  108.713460  123.972908\n1974-12-31  3138.059082  108.003898  127.072231\n\nEXP_ESP.tail()\n\n                  XGS        REER        WGDP\n1993-12-31   9579.586  114.520445  225.825635\n1994-12-31  11181.767  109.674712  235.084486\n1995-12-31  12299.895  116.021269  243.782612\n1996-12-31  13604.854  121.631204  253.777699\n1997-12-31  15611.863  116.142901  264.436363\n\n# Variables numérica y cualitativa de subperíodos\nEXP_ESP['D1986'] = np.where(EXP_ESP.index &gt; '1985-12-31', 1, 0)\nEXP_ESP['UE']=EXP_ESP['D1986'].astype('category')\nEXP_ESP['UE']=EXP_ESP['UE'].cat.rename_categories(['preUE', 'postUE'])\n# Ecuación de exportaciones para el período completo (1970-1997)\nlm_X_ESP = smf.ols(formula='np.log(XGS) ~ np.log(WGDP) + np.log(REER)', \ndata=EXP_ESP).fit()\nprint(lm_X_ESP.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            np.log(XGS)   R-squared:                       0.985\nModel:                            OLS   Adj. R-squared:                  0.984\nMethod:                 Least Squares   F-statistic:                     836.6\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           1.26e-23\nTime:                        18:34:54   Log-Likelihood:                 37.697\nNo. Observations:                  28   AIC:                            -69.39\nDf Residuals:                      25   BIC:                            -65.40\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept       -0.2424      0.844     -0.287      0.776      -1.981       1.497\nnp.log(WGDP)     2.0462      0.062     32.820      0.000       1.918       2.175\nnp.log(REER)    -0.3488      0.215     -1.624      0.117      -0.791       0.094\n==============================================================================\nOmnibus:                        2.960   Durbin-Watson:                   0.290\nProb(Omnibus):                  0.228   Jarque-Bera (JB):                2.618\nSkew:                           0.693   Prob(JB):                        0.270\nKurtosis:                       2.434   Cond. No.                         485.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Gráficas parciales con diferenciación por subperíodos\nEXP_ESP['l_XGS']=np.log(EXP_ESP['XGS'])\nEXP_ESP['l_WGDP']=np.log(EXP_ESP['WGDP'])\nEXP_ESP['l_REER']=np.log(EXP_ESP['REER'])\nplt.figure(5)\nsns.lmplot(x=\"l_WGDP\", y=\"l_XGS\", hue=\"UE\", data=EXP_ESP);\nplt.show()\n\n\n\nplt.figure(6)\nsns.lmplot(x=\"l_REER\", y=\"l_XGS\", hue=\"UE\", data=EXP_ESP);\nplt.show()\n\n\n\n# Diferenciación por subperíodos\n# PreUE\nlm_X_ESP_preUE = smf.ols(formula='np.log(XGS) ~ np.log(WGDP) + np.log(REER)', \nsubset=(EXP_ESP['D1986'] == 0), data=EXP_ESP).fit()\nprint(lm_X_ESP_preUE.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            np.log(XGS)   R-squared:                       0.976\nModel:                            OLS   Adj. R-squared:                  0.973\nMethod:                 Least Squares   F-statistic:                     267.8\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           2.72e-11\nTime:                        18:34:56   Log-Likelihood:                 26.496\nNo. Observations:                  16   AIC:                            -46.99\nDf Residuals:                      13   BIC:                            -44.68\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept        2.5077      1.649      1.520      0.152      -1.055       6.071\nnp.log(WGDP)     1.8144      0.085     21.447      0.000       1.632       1.997\nnp.log(REER)    -0.6945      0.319     -2.179      0.048      -1.383      -0.006\n==============================================================================\nOmnibus:                        0.094   Durbin-Watson:                   0.755\nProb(Omnibus):                  0.954   Jarque-Bera (JB):                0.314\nSkew:                           0.078   Prob(JB):                        0.855\nKurtosis:                       2.331   Cond. No.                         899.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# PostUE\nlm_X_ESP_postUE = smf.ols(formula='np.log(XGS) ~ np.log(WGDP) + np.log(REER)', \nsubset=(EXP_ESP['D1986'] == 1), data=EXP_ESP).fit()\nprint(lm_X_ESP_postUE.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            np.log(XGS)   R-squared:                       0.987\nModel:                            OLS   Adj. R-squared:                  0.984\nMethod:                 Least Squares   F-statistic:                     344.6\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           3.13e-09\nTime:                        18:34:56   Log-Likelihood:                 24.386\nNo. Observations:                  12   AIC:                            -42.77\nDf Residuals:                       9   BIC:                            -41.32\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept       -1.6788      0.889     -1.889      0.092      -3.690       0.332\nnp.log(WGDP)     2.6425      0.103     25.610      0.000       2.409       2.876\nnp.log(REER)    -0.7220      0.193     -3.735      0.005      -1.159      -0.285\n==============================================================================\nOmnibus:                        3.241   Durbin-Watson:                   1.134\nProb(Omnibus):                  0.198   Jarque-Bera (JB):                1.223\nSkew:                          -0.318   Prob(JB):                        0.543\nKurtosis:                       1.572   Cond. No.                         620.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Regresión diferenciada por tramos temporales\nlm_X_ESP_int = smf.ols(formula='np.log(XGS) ~ (np.log(WGDP) + np.log(REER))*D1986', \ndata=EXP_ESP).fit()\nprint(lm_X_ESP_int.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            np.log(XGS)   R-squared:                       0.994\nModel:                            OLS   Adj. R-squared:                  0.992\nMethod:                 Least Squares   F-statistic:                     713.6\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           1.46e-23\nTime:                        18:34:56   Log-Likelihood:                 49.966\nNo. Observations:                  28   AIC:                            -87.93\nDf Residuals:                      22   BIC:                            -79.94\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n======================================================================================\n                         coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------------\nIntercept              2.5077      1.475      1.700      0.103      -0.551       5.567\nnp.log(WGDP)           1.8144      0.076     23.982      0.000       1.658       1.971\nnp.log(REER)          -0.6945      0.285     -2.436      0.023      -1.286      -0.103\nD1986                 -4.1866      1.848     -2.266      0.034      -8.018      -0.355\nnp.log(WGDP):D1986     0.8280      0.150      5.532      0.000       0.518       1.138\nnp.log(REER):D1986    -0.0275      0.374     -0.074      0.942      -0.803       0.748\n==============================================================================\nOmnibus:                        0.097   Durbin-Watson:                   0.854\nProb(Omnibus):                  0.953   Jarque-Bera (JB):                0.319\nSkew:                           0.000   Prob(JB):                        0.853\nKurtosis:                       2.477   Cond. No.                     2.08e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 2.08e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n# Test de Chow de cambio estructural\nsm.stats.anova_lm(lm_X_ESP,lm_X_ESP_int) \n\n   df_resid       ssr  df_diff   ss_diff          F    Pr(&gt;F)\n0      25.0  0.110991      0.0       NaN        NaN       NaN\n1      22.0  0.046204      3.0  0.064787  10.282842  0.000198"
  },
  {
    "objectID": "p3c2-app4.html#código-r",
    "href": "p3c2-app4.html#código-r",
    "title": "Aplicación 3.4 (No normalidad de los errores y observaciones atípicas): Muestra de datos con observaciones atípicas simuladas",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(car)\nlibrary(lmtest)\nlibrary(quantreg)\nlibrary(MASS)\nlibrary(moments)\nlibrary(tseries)\n# Lectura de datos\nATIP &lt;- read_csv(\"data/ATIP.csv\")\nsummary(ATIP)\n\n       X               Y        \n Min.   :1.500   Min.   :2.500  \n 1st Qu.:2.550   1st Qu.:3.275  \n Median :4.000   Median :4.050  \n Mean   :4.109   Mean   :4.318  \n 3rd Qu.:4.975   3rd Qu.:5.025  \n Max.   :9.500   Max.   :8.000  \n\n# Gráficas\n# Diagrama de puntos\nggplot(ATIP, aes(x=X, y=Y)) + geom_point() + \n  labs(title=\"Diagrama de puntos\", x=\"X\", y=\"Y\")\n\n\n\n# Modelo de regresión lineal\nsummary(lm_YX &lt;- lm(Y ~ X, data = ATIP))\n\n\nCall:\nlm(formula = Y ~ X, data = ATIP)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6674 -0.3891 -0.0534  0.4355  3.6163 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.9087     0.6128   4.746 0.000123 ***\nX             0.3430     0.1331   2.577 0.017987 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.297 on 20 degrees of freedom\nMultiple R-squared:  0.2493,    Adjusted R-squared:  0.2118 \nF-statistic: 6.643 on 1 and 20 DF,  p-value: 0.01799\n\nplot(Y ~ X , data=ATIP)\nabline(lm_YX)\n\n\n\n# ¿Qué pasa si se eliminan las tres observaciones atípicas?\nlmtr_YX &lt;- lm(Y ~ X, data = ATIP[1:19,])\ncompareCoefs(lm_YX,lmtr_YX)\n\nCalls:\n1: lm(formula = Y ~ X, data = ATIP)\n2: lm(formula = Y ~ X, data = ATIP[1:19, ])\n\n            Model 1 Model 2\n(Intercept)   2.909   1.869\nSE            0.613   0.196\n                           \nX            0.3430  0.6109\nSE           0.1331  0.0522\n                           \n\n# Distribución de los errores del modelo\npar(mfrow=c(1,1))\nhist(lm_YX$residuals, main = \"\")\nbox()\n\n\n\ndensityPlot(residuals(lm_YX))\n\n\n\nqqnorm(residuals(lm_YX))\nqqline(residuals(lm_YX))\n\n\n\nqqPlot(lm_YX, distribution=\"norm\")\n\n\n\n\n[1] 20 22\n\n# Contrastes de normalidad\nr &lt;- resid(lm_YX)\nrbar &lt;- mean(r)\nsdr &lt;- sd(r)\nhist(lm_YX$residuals, col=\"grey\", freq=FALSE, \n     main=\"Distribución de los residuos\", \n     ylab=\"Densidad estimada\", xlab=\"residuos\")\ncurve(dnorm(x, rbar, sdr), col=2, add=TRUE, ylab=\"Density\", xlab=\"r\")\n\n\n\n# Librería moments\nskewness(lm_YX$residuals)\n\n[1] 0.06517037\n\nkurtosis(lm_YX$residuals)\n\n[1] 7.089934\n\nagostino.test(lm_YX$residuals)\n\n\n    D'Agostino skewness test\n\ndata:  lm_YX$residuals\nskew = 0.06517, z = 0.15162, p-value = 0.8795\nalternative hypothesis: data have a skewness\n\nanscombe.test(lm_YX$residuals)\n\n\n    Anscombe-Glynn kurtosis test\n\ndata:  lm_YX$residuals\nkurt = 7.0899, z = 3.0186, p-value = 0.002539\nalternative hypothesis: kurtosis is not equal to 3\n\njarque.test(lm_YX$residuals)\n\n\n    Jarque-Bera Normality Test\n\ndata:  lm_YX$residuals\nJB = 15.349, p-value = 0.0004645\nalternative hypothesis: greater\n\n# librería tseries\njarque.bera.test(lm_YX$residuals)\n\n\n    Jarque Bera Test\n\ndata:  lm_YX$residuals\nX-squared = 15.349, df = 2, p-value = 0.0004645\n\nshapiro.test(lm_YX$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  lm_YX$residuals\nW = 0.81712, p-value = 0.0009388\n\nks.test(lm_YX$residuals, pnorm)\n\n\n    Exact one-sample Kolmogorov-Smirnov test\n\ndata:  lm_YX$residuals\nD = 0.21393, p-value = 0.2309\nalternative hypothesis: two-sided\n\n# Detección de observaciones atípicas\n# Observaciones atípicas en las variables explicativas \n# (leverages &lt;-&gt; apalancamiento)\nhat &lt;- hatvalues(lm_YX)\nsummary(hat)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.04554 0.05003 0.05962 0.09091 0.08104 0.35138 \n\nwhich(hat &gt; 2 * mean(hat))\n\n21 22 \n21 22 \n\nplot(hat)\nabline(h = mean(hat), col = 4)\nabline(h = 2 * mean(hat), col = 2)\nid &lt;- which(hat &gt; 2 * mean(hat))\ntext(id, hat[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)\n\n\n\n# Observaciones atípicas en la variable dependiente \n# (outliers)\nslm_YX &lt;- summary(lm_YX)\n# Residuos estandarizados\nr &lt;- lm_YX$residuals/slm_YX$sigma\nsummary(r)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-2.82713 -0.29991 -0.04119  0.00000  0.33574  2.78778 \n\ndensityPlot(r)\n\n\n\nwhich(abs(r) &gt; 2.5)\n\n20 22 \n20 22 \n\nplot(r)\nabline(h = c(0,-2.5, 2.5), col = 4)\nid &lt;- which(abs(r) &gt; 2.5)\ntext(id, r[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)\n\n\n\n# Residuos estudentizados (internamente)\nrs &lt;- rstandard(lm_YX)\nsummary(rs)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-3.51034 -0.31701 -0.04312 -0.01662  0.34508  2.85396 \n\ndensityPlot(rs)\n\n\n\nwhich(abs(rs) &gt; 2)\n\n20 22 \n20 22 \n\nplot(rs)\nabline(h = c(0,-2, 2)*sd(rs), col = 4)\nid &lt;- which(abs(r) &gt; 2*sd(rs))\ntext(id, r[id], rownames(ATIP)[id], pos = 1, xpd = TRUE)\n\n\n\n# Residuos estudentizados (externamente)\nrt &lt;- rstudent(lm_YX)\nrt\n\n           1            2            3            4            5            6 \n-0.339443573 -0.801621429 -0.074710153 -0.524455394 -0.523575574 -0.129761631 \n           7            8            9           10           11           12 \n-0.496849799 -0.002665832  0.048211719 -0.084207435 -0.009354414 -0.191969037 \n          13           14           15           16           17           18 \n 0.321112299 -0.220966280  0.395595340  0.369165231  0.342764870  0.083323817 \n          19           20           21           22 \n 0.393951873  3.613064780  1.858685559 -5.522252312 \n\ndensityPlot(rt)\n\n\n\nqqPlot(lm_YX)\n\n\n\n\n[1] 20 22\n\noutlierTest(lm_YX)\n\n    rstudent unadjusted p-value Bonferroni p\n22 -5.522252         2.5102e-05   0.00055224\n20  3.613065         1.8525e-03   0.04075600\n\n# Medidas de diagnóstico específicas\n# Obs. influyentes: DFBETAS_i, DFFITS_i, COVRATIO_i, DCOOK_i y h_i\n# NOTA: la columna inf señala observaciones inusuales para al menos una medida\ninfluence.measures(lm_YX)\n\nInfluence measures of\n     lm(formula = Y ~ X, data = ATIP) :\n\n      dfb.1_     dfb.X     dffit cov.r   cook.d    hat inf\n1  -0.121055  0.096704 -0.123628 1.240 8.00e-03 0.1171    \n2  -0.268656  0.209618 -0.276825 1.160 3.90e-02 0.1065    \n3  -0.022687  0.016968 -0.023821 1.220 2.99e-04 0.0923    \n4  -0.148489  0.107322 -0.158632 1.175 1.31e-02 0.0838    \n5  -0.132415  0.089762 -0.146611 1.161 1.12e-02 0.0727    \n6  -0.032817  0.022246 -0.036336 1.193 6.94e-04 0.0727    \n7  -0.115812  0.074339 -0.132456 1.157 9.12e-03 0.0664    \n8  -0.000569  0.000341 -0.000679 1.180 2.42e-07 0.0608    \n9   0.009826 -0.005654  0.012007 1.176 7.59e-05 0.0584    \n10 -0.013126  0.005397 -0.019188 1.165 1.94e-04 0.0494    \n11 -0.001193  0.000304 -0.002065 1.162 2.24e-06 0.0465    \n12 -0.017270 -0.001833 -0.041933 1.156 9.24e-04 0.0455    \n13  0.025883  0.006439  0.070382 1.149 2.59e-03 0.0458    \n14 -0.011611 -0.011406 -0.049612 1.158 1.29e-03 0.0480    \n15  0.009670  0.032970  0.092688 1.150 4.48e-03 0.0520    \n16  0.005558  0.034690  0.088036 1.154 4.05e-03 0.0538    \n17  0.001936  0.035862  0.083319 1.159 3.63e-03 0.0558    \n18 -0.000315  0.009609  0.020672 1.175 2.25e-04 0.0580    \n19 -0.012690  0.058166  0.104569 1.167 5.71e-03 0.0658    \n20  0.291228  0.072449  0.791915 0.408 1.96e-01 0.0458   *\n21 -0.917055  1.276478  1.368027 1.223 8.33e-01 0.3514   *\n22  2.724619 -3.792484 -4.064480 0.252 3.34e+00 0.3514   *\n\nS(influence.measures(lm_YX))\n\nPotentially influential observations of\n     lm(formula = Y ~ X, data = ATIP) :\n\n   dfb.1_  dfb.X   dffit   cov.r   cook.d  hat    \n20  0.29    0.07    0.79    0.41_*  0.20    0.05  \n21 -0.92    1.28_*  1.37_*  1.22    0.83_*  0.35_*\n22  2.72_* -3.79_* -4.06_*  0.25_*  3.34_*  0.35_*\n\ninfluenceIndexPlot(lm_YX, vars=c(\"hat\", \"Studentized\",\"Cook\"))\n\n\n\ninfluencePlot(lm_YX, xlab=\"Hat values\")\n\n\n\n\n     StudRes       Hat     CookD\n20  3.613065 0.0458382 0.1956463\n21  1.858686 0.3513751 0.8334543\n22 -5.522252 0.3513751 3.3376919\n\n# Medidas individuales\nhat &lt;- hatvalues(lm_YX)\ndfbetas &lt;-  dfbetas(lm_YX)\ndffits &lt;-  dffits(lm_YX)\ndcook &lt;-  cooks.distance(lm_YX)\nhat ; dfbetas ; dffits; dcook\n\n         1          2          3          4          5          6          7 \n0.11711229 0.10654749 0.09227928 0.08381979 0.07270953 0.07270953 0.06635534 \n         8          9         10         11         12         13         14 \n0.06084327 0.05840303 0.04935980 0.04646022 0.04554154 0.04583820 0.04799135 \n        15         16         17         18         19         20         21 \n0.05203927 0.05380964 0.05579054 0.05798197 0.06581944 0.04583820 0.35137515 \n        22 \n0.35137515 \n\n\n     (Intercept)             X\n1  -0.1210550547  0.0967044410\n2  -0.2686558904  0.2096182664\n3  -0.0226869829  0.0169684103\n4  -0.1484894369  0.1073215817\n5  -0.1324152881  0.0897623911\n6  -0.0328174664  0.0222464815\n7  -0.1158120753  0.0743388221\n8  -0.0005691882  0.0003412440\n9   0.0098255572 -0.0056536588\n10 -0.0131259608  0.0053971790\n11 -0.0011927906  0.0003037916\n12 -0.0172701507 -0.0018327463\n13  0.0258829797  0.0064389476\n14 -0.0116105156 -0.0114064102\n15  0.0096704719  0.0329704531\n16  0.0055580652  0.0346902377\n17  0.0019363561  0.0358623130\n18 -0.0003147545  0.0096088290\n19 -0.0126898190  0.0581659541\n20  0.2912279682  0.0724492173\n21 -0.9170553069  1.2764784676\n22  2.7246194301 -3.7924844977\n\n\n            1             2             3             4             5 \n-0.1236277852 -0.2768249321 -0.0238207591 -0.1586322104 -0.1466111950 \n            6             7             8             9            10 \n-0.0363357436 -0.1324561839 -0.0006785315  0.0120070906 -0.0191879700 \n           11            12            13            14            15 \n-0.0020648467 -0.0419330580  0.0703816904 -0.0496120344  0.0926875935 \n           16            17            18            19            20 \n 0.0880362600  0.0833186873  0.0206721685  0.1045694572  0.7919148784 \n           21            22 \n 1.3680269444 -4.0644798251 \n\n\n           1            2            3            4            5            6 \n7.995633e-03 3.901319e-02 2.985589e-04 1.305531e-02 1.115217e-02 6.942722e-04 \n           7            8            9           10           11           12 \n9.115586e-03 2.423183e-07 7.586978e-05 1.937057e-04 2.243985e-06 9.236723e-04 \n          13           14           15           16           17           18 \n2.593076e-03 1.292129e-03 4.484635e-03 4.050098e-03 3.631232e-03 2.248329e-04 \n          19           20           21           22 \n5.708514e-03 1.956463e-01 8.334543e-01 3.337692e+00 \n\nmax(hatvalues(lm_YX))\n\n[1] 0.3513751\n\nwhich.max(hatvalues(lm_YX))\n\n21 \n21 \n\nmax(abs(dffits(lm_YX)))\n\n[1] 4.06448\n\nwhich.max(abs(dffits(lm_YX)))\n\n22 \n22 \n\nmax(cooks.distance(lm_YX))\n\n[1] 3.337692\n\nwhich.max(cooks.distance(lm_YX))\n\n22 \n22 \n\n# Gráficos de variable añadida, buscando casos influyentes\navPlots(lm_YX, id=list(cex=0.60, method=\"mahal\")) \n\n\n\n# Estimación robusta\n# Regresiones cuartilíticas\n# tau=0.5\nsummary(qr_YX &lt;- rq(Y ~ X, data = ATIP))\n\n\nCall: rq(formula = Y ~ X, data = ATIP)\n\ntau: [1] 0.5\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.13750      1.47445  2.67331 \nX           0.57500      0.32363  0.74276 \n\n# Comparación de regresiones\nplot(Y ~ X , data=ATIP)\nabline(lm_YX)\nabline(qr_YX, lty=2)\nlegend(\"topleft\", c(\"Regresión MCO\", \"Regresión DAM\"), \n       lty = c(1, 2), bty = \"n\")\n\n\n\n# tau secuencial\nS(qr_YX &lt;- rq(Y ~ X, data = ATIP, tau=seq(0.1,0.9,0.1)))\n\n\nCall: rq(formula = Y ~ X, tau = seq(0.1, 0.9, 0.1), data = ATIP)\n\ntau: [1] 0.1\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept)  3.09375      2.61079  3.14417\nX           -0.06250     -0.06703  0.57699\n\nCall: rq(formula = Y ~ X, tau = seq(0.1, 0.9, 0.1), data = ATIP)\n\ntau: [1] 0.2\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept)  1.90000      1.40106  3.50461\nX            0.50000     -0.08789  0.70048\n\nCall: rq(formula = Y ~ X, tau = seq(0.1, 0.9, 0.1), data = ATIP)\n\ntau: [1] 0.3\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept)  1.68000      1.29958  2.92467\nX            0.60000     -0.00927  0.70201\n\nCall: rq(formula = Y ~ X, tau = seq(0.1, 0.9, 0.1), data = ATIP)\n\ntau: [1] 0.4\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 1.72500      1.37760  2.70125 \nX           0.65000      0.24673  0.70275 \n\nCall: rq(formula = Y ~ X, tau = seq(0.1, 0.9, 0.1), data = ATIP)\n\ntau: [1] 0.5\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.13750      1.47445  2.67331 \nX           0.57500      0.32363  0.74276 \n\nCall: rq(formula = Y ~ X, tau = seq(0.1, 0.9, 0.1), data = ATIP)\n\ntau: [1] 0.6\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.10000      1.53990  2.44895 \nX           0.60000      0.43072  0.74284 \n\nCall: rq(formula = Y ~ X, tau = seq(0.1, 0.9, 0.1), data = ATIP)\n\ntau: [1] 0.7\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.07353      1.93579  2.41902 \nX           0.61765      0.51567  0.63299 \n\nCall: rq(formula = Y ~ X, tau = seq(0.1, 0.9, 0.1), data = ATIP)\n\ntau: [1] 0.8\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.15385      2.06883  2.49759 \nX           0.61538      0.53634  1.04264 \n\nCall: rq(formula = Y ~ X, tau = seq(0.1, 0.9, 0.1), data = ATIP)\n\ntau: [1] 0.9\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.30000      2.03634  6.40464 \nX           0.60000      0.60000  2.06745 \n\nplot(summary(qr_YX), level=0.95)\n\n\n\n# tau discreto\nS(qr_YX &lt;- rq(Y ~ X, tau = c(0.25, 0.50, 0.75), data = ATIP))\n\n\nCall: rq(formula = Y ~ X, tau = c(0.25, 0.5, 0.75), data = ATIP)\n\ntau: [1] 0.25\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept)  1.79000      1.39508  3.01749\nX            0.55000     -0.10318  0.70372\n\nCall: rq(formula = Y ~ X, tau = c(0.25, 0.5, 0.75), data = ATIP)\n\ntau: [1] 0.5\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.13750      1.47445  2.67331 \nX           0.57500      0.32363  0.74276 \n\nCall: rq(formula = Y ~ X, tau = c(0.25, 0.5, 0.75), data = ATIP)\n\ntau: [1] 0.75\n\nCoefficients:\n            coefficients lower bd upper bd\n(Intercept) 2.09848      2.03503  2.39653 \nX           0.62121      0.52358  0.65685 \n\nplot(qr_YX)\n\n\n\n# Estimadores M y MM\nsummary(rlm_YX &lt;- rlm(Y ~ X, data = ATIP, method=\"MM\")) # Estim. M: method=\"M\"\n\n\nCall: rlm(formula = Y ~ X, data = ATIP, method = \"MM\")\nResiduals:\n     Min       1Q   Median       3Q      Max \n-5.36813 -0.29629  0.02774  0.25640  3.46961 \n\nCoefficients:\n            Value   Std. Error t value\n(Intercept)  1.7703  0.1499    11.8097\nX            0.6419  0.0326    19.7167\n\nResidual standard error: 0.3874 on 20 degrees of freedom\n\nplot(Y ~ X , data=ATIP)\nabline(lm_YX)\nabline(rlm_YX, lty=2)\nlegend(\"topleft\", c(\"Regresión MCO\", \"Regresión MM\"), lty = c(1, 2), bty = \"n\")"
  },
  {
    "objectID": "p3c2-app4.html#código-python",
    "href": "p3c2-app4.html#código-python",
    "title": "Aplicación 3.4 (No normalidad de los errores y observaciones atípicas): Muestra de datos con observaciones atípicas simuladas",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.stats.api as sms\nimport statsmodels.formula.api as smf\nfrom statsmodels.compat import lmap\nfrom statsmodels.compat import lzip\nfrom scipy import stats\n\n# Lectura de datos\nATIP  = pd.read_csv(\"data/ATIP.csv\")\nATIP .describe().round(2)\n\n           X      Y\ncount  22.00  22.00\nmean    4.11   4.32\nstd     2.13   1.46\nmin     1.50   2.50\n25%     2.55   3.28\n50%     4.00   4.05\n75%     4.97   5.02\nmax     9.50   8.00\n\n# Gráficas\n# Diagrama de puntos\nplt.figure(1)\nsns.scatterplot(x=\"X\", y=\"Y\", data=ATIP);\nplt.show()\n\n\n\n# Modelo de regresión lineal\nformula = 'Y ~ X'\nlm_YX = smf.ols(formula, ATIP).fit()\nprint(lm_YX.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      Y   R-squared:                       0.249\nModel:                            OLS   Adj. R-squared:                  0.212\nMethod:                 Least Squares   F-statistic:                     6.643\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):             0.0180\nTime:                        09:37:21   Log-Likelihood:                -35.893\nNo. Observations:                  22   AIC:                             75.79\nDf Residuals:                      20   BIC:                             77.97\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      2.9087      0.613      4.746      0.000       1.630       4.187\nX              0.3430      0.133      2.577      0.018       0.065       0.621\n==============================================================================\nOmnibus:                        9.135   Durbin-Watson:                   1.408\nProb(Omnibus):                  0.010   Jarque-Bera (JB):               15.349\nSkew:                           0.065   Prob(JB):                     0.000464\nKurtosis:                       7.090   Cond. No.                         10.6\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\nplt.figure(2)\nsns.lmplot(x=\"X\", y=\"Y\", data=ATIP);\nplt.show()\n\n\n\n# Contrastes de normalidad\n# Test de Jarque-Bera \nname = [\"Jarque-Bera\", \"Chi^2 two-tail prob.\", \"Skew\", \"Kurtosis\"]\ntest = sms.jarque_bera(lm_YX.resid)\nlzip(name, test)\n\n[('Jarque-Bera', 15.349166421968405), ('Chi^2 two-tail prob.', 0.00046448410913513467), ('Skew', 0.0651703702648101), ('Kurtosis', 7.089933554345362)]\n\n# Test Omni\nname = [\"Chi^2\", \"Two-tail probability\"]\ntest = sms.omni_normtest(lm_YX.resid)\nlzip(name, test)\n\n[('Chi^2', 9.134967773529176), ('Two-tail probability', 0.01038405433188652)]\n\n# Detección de observaciones atípicas\nplt.figure(3)\nfig = sm.graphics.influence_plot(lm_YX, criterion=\"cooks\")\nfig.tight_layout(pad=1.0)\nplt.show()\n\n\n\n# Outliers\ninfl = lm_YX.get_influence()\nstudent = infl.summary_frame()[\"student_resid\"]\nprint(student)\n\n0    -0.339444\n1    -0.801621\n2    -0.074710\n3    -0.524455\n4    -0.523576\n5    -0.129762\n6    -0.496850\n7    -0.002666\n8     0.048212\n9    -0.084207\n10   -0.009354\n11   -0.191969\n12    0.321112\n13   -0.220966\n14    0.395595\n15    0.369165\n16    0.342765\n17    0.083324\n18    0.393952\n19    3.613065\n20    1.858686\n21   -5.522252\nName: student_resid, dtype: float64\n\nprint(student.loc[np.abs(student) &gt; 2])\n\n19    3.613065\n21   -5.522252\nName: student_resid, dtype: float64\n\n# Leverages\nh_bar = 2 * (lm_YX.df_model + 1) / lm_YX.nobs\nhat_diag = infl.summary_frame()[\"hat_diag\"]\nprint(hat_diag)\n\n0     0.117112\n1     0.106547\n2     0.092279\n3     0.083820\n4     0.072710\n5     0.072710\n6     0.066355\n7     0.060843\n8     0.058403\n9     0.049360\n10    0.046460\n11    0.045542\n12    0.045838\n13    0.047991\n14    0.052039\n15    0.053810\n16    0.055791\n17    0.057982\n18    0.065819\n19    0.045838\n20    0.351375\n21    0.351375\nName: hat_diag, dtype: float64\n\nhat_diag.loc[hat_diag &gt; h_bar]\n\n20    0.351375\n21    0.351375\nName: hat_diag, dtype: float64\n\n# Medidas de influencias de las observaciones atípicas\nprint(infl.summary_frame().loc[ATIP.index[19]])\n\ndfb_Intercept      0.291228\ndfb_X              0.072449\ncooks_d            0.195646\nstandard_resid     2.853961\nhat_diag           0.045838\ndffits_internal    0.625534\nstudent_resid      3.613065\ndffits             0.791915\nName: 19, dtype: float64\n\nprint(infl.summary_frame().loc[ATIP.index[20]])\n\ndfb_Intercept     -0.917055\ndfb_X              1.276478\ncooks_d            0.833454\nstandard_resid     1.754152\nhat_diag           0.351375\ndffits_internal    1.291088\nstudent_resid      1.858686\ndffits             1.368027\nName: 20, dtype: float64\n\nprint(infl.summary_frame().loc[ATIP.index[21]])\n\ndfb_Intercept      2.724619\ndfb_X             -3.792484\ncooks_d            3.337692\nstandard_resid    -3.510342\nhat_diag           0.351375\ndffits_internal   -2.583676\nstudent_resid     -5.522252\ndffits            -4.064480\nName: 21, dtype: float64\n\n# Estimaciones robustas\n# Regresión cuartilítica\nformula = 'Y ~ X'\nqr_YX  = smf.quantreg(formula, ATIP)\nDAM = qr_YX.fit(q=0.5)\nprint(DAM.summary())\n\n                         QuantReg Regression Results                          \n==============================================================================\nDep. Variable:                      Y   Pseudo R-squared:               0.4004\nModel:                       QuantReg   Bandwidth:                      0.8651\nMethod:                 Least Squares   Sparsity:                        1.464\nDate:                Wed, 15 Nov 2023   No. Observations:                   22\nTime:                        09:37:22   Df Residuals:                       20\n                                        Df Model:                            1\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      2.1375      0.346      6.181      0.000       1.416       2.859\nX              0.5750      0.075      7.657      0.000       0.418       0.732\n==============================================================================\n\n# Comparación de resultados para diferentes cuartiles con MCO\nquantiles = np.arange(0.1, 1, 0.1)\ndef fit_model(q): res = qr_YX.fit(q=q); return [q, res.params[\"Intercept\"], res.params[\"X\"]] + res.conf_int().loc[\"X\"].tolist()\nmodels = [fit_model(x) for x in quantiles]\nmodels = pd.DataFrame(models, columns=[\"q\", \"a\", \"b\", \"lb\", \"ub\"])\nfrom statsmodels.formula.api import ols\nols = smf.ols(\"Y ~ X\", ATIP).fit()\nols_ci = ols.conf_int().loc[\"X\"].tolist()\nols = dict(a=ols.params[\"Intercept\"], b=ols.params[\"X\"], lb=ols_ci[0], ub=ols_ci[1])\nprint(models)\n\n     q         a         b        lb        ub\n0  0.1  3.093749 -0.062499       NaN       NaN\n1  0.2  1.899998  0.500000       NaN       NaN\n2  0.3  1.680000  0.600000  0.427153  0.772847\n3  0.4  1.725000  0.650000  0.502502  0.797498\n4  0.5  2.137492  0.575002  0.418354  0.731651\n5  0.6  2.100000  0.600000  0.443285  0.756715\n6  0.7  2.073525  0.617650  0.451179  0.784121\n7  0.8  2.153834  0.615386       NaN       NaN\n8  0.9  2.299994  0.600001       NaN       NaN\n\nprint(ols)\n\n{'a': 2.908677678041684, 'b': 0.3430209190606518, 'lb': 0.06539606119633479, 'ub': 0.6206457769249688}\n\n# Gráfica asociada\nplt.figure(4)\nn = models.shape[0]\np1 = plt.plot(models.q, models.b, color=\"black\", label=\"Reg.cuart.\")\np2 = plt.plot(models.q, models.ub, linestyle=\"dotted\", color=\"black\")\np3 = plt.plot(models.q, models.lb, linestyle=\"dotted\", color=\"black\")\np4 = plt.plot(models.q, [ols[\"b\"]] * n, color=\"red\", label=\"MCO\")\np5 = plt.plot(models.q, [ols[\"lb\"]] * n, linestyle=\"dotted\", color=\"red\")\np6 = plt.plot(models.q, [ols[\"ub\"]] * n, linestyle=\"dotted\", color=\"red\")\nplt.ylabel(r\"$\\beta_{X}$\")\nplt.xlabel(\"Cuartiles de la distribución condicional\")\nplt.legend()\nplt.show()\n\n\n\n# Estimadores M y MM\nfrom statsmodels.formula.api import rlm\nrlm_YX = rlm(\"Y ~ X\", ATIP).fit()\nprint(rlm_YX.summary())\n\n                    Robust linear Model Regression Results                    \n==============================================================================\nDep. Variable:                      Y   No. Observations:                   22\nModel:                            RLM   Df Residuals:                       20\nMethod:                          IRLS   Df Model:                            1\nNorm:                          HuberT                                         \nScale Est.:                       mad                                         \nCov Type:                          H1                                         \nDate:                Wed, 15 Nov 2023                                         \nTime:                        09:37:23                                         \nNo. Iterations:                    15                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      1.9357      0.171     11.348      0.000       1.601       2.270\nX              0.5977      0.037     16.137      0.000       0.525       0.670\n==============================================================================\n\nIf the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore ."
  },
  {
    "objectID": "p3c2-app5.html#código-r",
    "href": "p3c2-app5.html#código-r",
    "title": "Aplicación 3.5 (Regresiones heteroscedásticas): Función de demanda con varianza no constante",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(car)\nlibrary(skedastic)\nlibrary(lmtest)\nlibrary(sandwich)\n# Lectura de datos\nDEM_HET &lt;- read_csv(\"data/DEM_HET.csv\")\ndim(DEM_HET)\n\n[1] 30  5\n\nsummary(DEM_HET)\n\n       PA               PB               PC               QA        \n Min.   : 89.15   Min.   : 51.04   Min.   : 85.85   Min.   : 93.01  \n 1st Qu.:102.52   1st Qu.: 74.72   1st Qu.:103.85   1st Qu.: 99.65  \n Median :111.77   Median : 81.49   Median :130.84   Median :105.93  \n Mean   :109.02   Mean   : 81.91   Mean   :127.68   Mean   :109.59  \n 3rd Qu.:114.53   3rd Qu.: 90.13   3rd Qu.:145.07   3rd Qu.:117.28  \n Max.   :124.85   Max.   :111.66   Max.   :182.04   Max.   :140.97  \n       Y        \n Min.   :100.0  \n 1st Qu.:139.5  \n Median :188.4  \n Mean   :180.6  \n 3rd Qu.:221.0  \n Max.   :254.9  \n\n# Estimación MCO\nmodelo_MCO &lt;- lm(log(QA) ~ log(PA) + log(PB) + log(PC)+ log(Y), \n                 data = DEM_HET)\nsummary(modelo_MCO)\n\n\nCall:\nlm(formula = log(QA) ~ log(PA) + log(PB) + log(PC) + log(Y), \n    data = DEM_HET)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.11826 -0.04692 -0.01407  0.03830  0.20191 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.2747     1.2052   3.547 0.001570 ** \nlog(PA)      -0.8901     0.2157  -4.126 0.000358 ***\nlog(PB)       0.5542     0.1300   4.262 0.000252 ***\nlog(PC)      -0.3491     0.1831  -1.906 0.068154 .  \nlog(Y)        0.7440     0.1352   5.503 1.02e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.07619 on 25 degrees of freedom\nMultiple R-squared:  0.6643,    Adjusted R-squared:  0.6106 \nF-statistic: 12.37 on 4 and 25 DF,  p-value: 1.105e-05\n\n# Chequeo de la hipótesis de homoscedasticidad\n# Contrastes estándar (automáticos): Z's -&gt; variables explicativas del modelo\n# Test de White\nwhite(modelo_MCO)\n\n# A tibble: 1 × 5\n  statistic p.value parameter method       alternative\n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      \n1      7.90   0.443         8 White's Test greater    \n\nwhite(modelo_MCO, interactions=TRUE)\n\n# A tibble: 1 × 5\n  statistic p.value parameter method       alternative\n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      \n1      12.9   0.535        14 White's Test greater    \n\n# Test de Glejser\nglejser(modelo_MCO)\n\n# A tibble: 1 × 4\n  statistic p.value parameter alternative\n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      \n1      6.65   0.156         4 greater    \n\n# Test de Breusch-Pagan\nbreusch_pagan(modelo_MCO)\n\n# A tibble: 1 × 5\n  statistic p.value parameter method                alternative\n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                 &lt;chr&gt;      \n1      4.38   0.357         4 Koenker (studentised) greater    \n\n# Contrastes específicos: Z's seleccionadas\n# Test de Breusch-Pagan (manual)\nDEM_HET$resid2 = resid(modelo_MCO)^2\n# Análisis gráfico\nggplot(DEM_HET, aes(x = log(Y), y = resid2)) +\n    geom_point(color = \"blue\") +\n    geom_smooth(method='lm', formula = y~x, se = TRUE, \n                color = \"blue\", linetype = \"dashed\") +\n    xlab(\"Y (log)\") + \n    ylab(\"resid2\") +\n    theme_minimal()\n\n\n\n# Regresión auxiliar\nsummary(modelo_resid2 &lt;- lm(resid2 ~ log(Y), data=DEM_HET))\n\n\nCall:\nlm(formula = resid2 ~ log(Y), data = DEM_HET)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.007864 -0.004221 -0.002092  0.001574  0.032720 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -0.05395    0.02832  -1.905   0.0671 .\nlog(Y)       0.01139    0.00548   2.078   0.0469 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.008199 on 28 degrees of freedom\nMultiple R-squared:  0.1337,    Adjusted R-squared:  0.1027 \nF-statistic:  4.32 on 1 and 28 DF,  p-value: 0.04695\n\nN &lt;- nobs(modelo_resid2)\np &lt;- 1 # Número Z's de la regresión auxiliar, sin incluir la constante\nsm_resid2 &lt;- summary(modelo_resid2)\nR2_m_resid2 &lt;- sm_resid2$r.squared\nBP &lt;- N*R2_m_resid2\n# Contraste Chi-cuadrado\npval &lt;- 1-pchisq(BP, p)\nBP ; pval \n\n[1] 4.009848\n\n\n[1] 0.04523524\n\n# Test de Breusch-Pagan (automático)\nbptest(modelo_MCO, varformula = ~ log(Y), data=DEM_HET) \n\n\n    studentized Breusch-Pagan test\n\ndata:  modelo_MCO\nBP = 4.0098, df = 1, p-value = 0.04524\n\n# Test de Breusch-Pagan robusto (variante de Koenker)\nbptest(modelo_MCO, varformula = ~ log(Y), data=DEM_HET, studentize = FALSE)\n\n\n    Breusch-Pagan test\n\ndata:  modelo_MCO\nBP = 6.2053, df = 1, p-value = 0.01274\n\n# Corrección básica de la heteroscedasticidad: \n# Matriz de covarianzas robusta (MCO-HC)\n# Corrección de White (librería sandwich)\ncoeftest(modelo_MCO, vcov. = vcovHC(modelo_MCO,type=\"HC1\"))\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  4.27468    0.89931  4.7533 7.062e-05 ***\nlog(PA)     -0.89012    0.13561 -6.5639 7.083e-07 ***\nlog(PB)      0.55419    0.08331  6.6521 5.704e-07 ***\nlog(PC)     -0.34909    0.15058 -2.3182   0.02891 *  \nlog(Y)       0.74395    0.11879  6.2627 1.494e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Otra versión, con idéntico resultado (librería car)\ncoeftest(modelo_MCO, vcov.=hccm(modelo_MCO, type = \"hc1\")) \n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  4.27468    0.89931  4.7533 7.062e-05 ***\nlog(PA)     -0.89012    0.13561 -6.5639 7.083e-07 ***\nlog(PB)      0.55419    0.08331  6.6521 5.704e-07 ***\nlog(PC)     -0.34909    0.15058 -2.3182   0.02891 *  \nlog(Y)       0.74395    0.11879  6.2627 1.494e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Corrección avanzada: mínimos cuadrados ponderados (MCP)\n# Regresión auxiliar para el logaritmo de la varianza estimada\nsummary(modelo_l_resid2 &lt;- lm(log(resid2) ~ log(Y), data=DEM_HET))\n\n\nCall:\nlm(formula = log(resid2) ~ log(Y), data = DEM_HET)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.5616 -0.6447  0.1990  1.7185  3.2886 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  -26.658      7.565  -3.524  0.00148 **\nlog(Y)         3.846      1.464   2.628  0.01379 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.19 on 28 degrees of freedom\nMultiple R-squared:  0.1978,    Adjusted R-squared:  0.1692 \nF-statistic: 6.905 on 1 and 28 DF,  p-value: 0.01379\n\n# Estimación de la varianza residual (no constante)\nsigma2 &lt;- exp(fitted(modelo_l_resid2))\n# MCO con ponderaciones: MCP (FGLS)\nsummary(modelo_MCP &lt;- lm(log(QA) ~ log(PA) + log(PB) + log(PC)+ log(Y), \n                         weights = 1/sigma2, data = DEM_HET))\n\n\nCall:\nlm(formula = log(QA) ~ log(PA) + log(PB) + log(PC) + log(Y), \n    data = DEM_HET, weights = 1/sigma2)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-5.2922 -0.9431 -0.1967  1.4063  3.8662 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.48077    0.87248   5.136 2.62e-05 ***\nlog(PA)     -0.90716    0.14931  -6.076 2.38e-06 ***\nlog(PB)      0.54594    0.10265   5.318 1.64e-05 ***\nlog(PC)     -0.24882    0.12394  -2.007   0.0556 .  \nlog(Y)       0.63130    0.08844   7.138 1.76e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.026 on 25 degrees of freedom\nMultiple R-squared:  0.7734,    Adjusted R-squared:  0.7372 \nF-statistic: 21.33 on 4 and 25 DF,  p-value: 9.299e-08"
  },
  {
    "objectID": "p3c2-app5.html#código-python",
    "href": "p3c2-app5.html#código-python",
    "title": "Aplicación 3.5 (Regresiones heteroscedásticas): Función de demanda con varianza no constante",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.stats.api as sms\nimport statsmodels.stats as smstats\nimport statsmodels.stats.diagnostic as smsdiag\n\n# Lectura de datos\nDEM_HET = pd.read_csv('data/DEM_HET.csv')\nDEM_HET.describe()\n\n               PA          PB          PC          QA           Y\ncount   30.000000   30.000000   30.000000   30.000000   30.000000\nmean   109.024334   81.911667  127.679001  109.594333  180.644667\nstd      8.747229   12.729947   24.977371   13.852708   46.540796\nmin     89.150002   51.040001   85.849998   93.010002  100.000000\n25%    102.519999   74.720001  103.850002   99.652502  139.475002\n50%    111.770000   81.489998  130.834999  105.930000  188.370003\n75%    114.527502   90.132498  145.067497  117.282501  221.032501\nmax    124.849998  111.660004  182.039993  140.970001  254.949997\n\n# Estimación MCO\nmodelo1 = smf.ols(formula = \"np.log(QA) ~ np.log(PA) + np.log(PB) + np.log(PC) + np.log(Y)\", data = DEM_HET)\nmodelo_MCO = modelo1.fit()\nprint(modelo_MCO.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:             np.log(QA)   R-squared:                       0.664\nModel:                            OLS   Adj. R-squared:                  0.611\nMethod:                 Least Squares   F-statistic:                     12.37\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           1.10e-05\nTime:                        09:38:46   Log-Likelihood:                 37.403\nNo. Observations:                  30   AIC:                            -64.81\nDf Residuals:                      25   BIC:                            -57.80\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      4.2747      1.205      3.547      0.002       1.792       6.757\nnp.log(PA)    -0.8901      0.216     -4.126      0.000      -1.334      -0.446\nnp.log(PB)     0.5542      0.130      4.262      0.000       0.286       0.822\nnp.log(PC)    -0.3491      0.183     -1.906      0.068      -0.726       0.028\nnp.log(Y)      0.7440      0.135      5.503      0.000       0.466       1.022\n==============================================================================\nOmnibus:                        8.115   Durbin-Watson:                   2.471\nProb(Omnibus):                  0.017   Jarque-Bera (JB):                6.392\nSkew:                           0.989   Prob(JB):                       0.0409\nKurtosis:                       4.095   Cond. No.                         840.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Contrastes de heteroscedasticidad\nname = ['LM statistic', 'Chi^2 p-val', 'F statistic', 'F p-val']\n# Test de White\nW_test = smsdiag.het_white(modelo_MCO.resid, modelo_MCO.model.exog)\nprint(pd.DataFrame([np.round(W_test, 8)], columns=name))\n\n   LM statistic  Chi^2 p-val  F statistic   F p-val\n0     12.888845     0.535294     0.807045  0.653204\n\n# Test de Breusch-Pagan\nBP_test = smsdiag.het_breuschpagan(modelo_MCO.resid, modelo_MCO.model.exog)\nprint(pd.DataFrame([np.round(BP_test, 8)], columns=name))\n\n   LM statistic  Chi^2 p-val  F statistic   F p-val\n0      4.382204     0.356744     1.069131  0.392569\n\n# Estimación MCO-HC\nmodelo1 = smf.ols(formula = \"np.log(QA) ~ np.log(PA) + np.log(PB) + np.log(PC) + np.log(Y)\", data = DEM_HET)\n# HC1 -&gt; corrige la fórmula de White por grados de libertad\nmodelo_MCO_HC1 = modelo1.fit(cov_type='HC1')\nprint(modelo_MCO_HC1.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:             np.log(QA)   R-squared:                       0.664\nModel:                            OLS   Adj. R-squared:                  0.611\nMethod:                 Least Squares   F-statistic:                     26.61\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           1.09e-08\nTime:                        09:38:46   Log-Likelihood:                 37.403\nNo. Observations:                  30   AIC:                            -64.81\nDf Residuals:                      25   BIC:                            -57.80\nDf Model:                           4                                         \nCovariance Type:                  HC1                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      4.2747      0.899      4.753      0.000       2.512       6.037\nnp.log(PA)    -0.8901      0.136     -6.564      0.000      -1.156      -0.624\nnp.log(PB)     0.5542      0.083      6.652      0.000       0.391       0.717\nnp.log(PC)    -0.3491      0.151     -2.318      0.020      -0.644      -0.054\nnp.log(Y)      0.7440      0.119      6.263      0.000       0.511       0.977\n==============================================================================\nOmnibus:                        8.115   Durbin-Watson:                   2.471\nProb(Omnibus):                  0.017   Jarque-Bera (JB):                6.392\nSkew:                           0.989   Prob(JB):                       0.0409\nKurtosis:                       4.095   Cond. No.                         840.\n==============================================================================\n\nNotes:\n[1] Standard Errors are heteroscedasticity robust (HC1)\n\n# HC2 -&gt; corrige la fórmula de White por grados de libertad y tamaño muestral pequeño\nmodelo_MCO_HC2 = modelo1.fit(cov_type='HC2') \nprint(modelo_MCO_HC2.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:             np.log(QA)   R-squared:                       0.664\nModel:                            OLS   Adj. R-squared:                  0.611\nMethod:                 Least Squares   F-statistic:                     25.98\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           1.38e-08\nTime:                        09:38:46   Log-Likelihood:                 37.403\nNo. Observations:                  30   AIC:                            -64.81\nDf Residuals:                      25   BIC:                            -57.80\nDf Model:                           4                                         \nCovariance Type:                  HC2                                         \n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      4.2747      0.904      4.727      0.000       2.502       6.047\nnp.log(PA)    -0.8901      0.138     -6.470      0.000      -1.160      -0.620\nnp.log(PB)     0.5542      0.085      6.488      0.000       0.387       0.722\nnp.log(PC)    -0.3491      0.151     -2.308      0.021      -0.646      -0.053\nnp.log(Y)      0.7440      0.119      6.275      0.000       0.512       0.976\n==============================================================================\nOmnibus:                        8.115   Durbin-Watson:                   2.471\nProb(Omnibus):                  0.017   Jarque-Bera (JB):                6.392\nSkew:                           0.989   Prob(JB):                       0.0409\nKurtosis:                       4.095   Cond. No.                         840.\n==============================================================================\n\nNotes:\n[1] Standard Errors are heteroscedasticity robust (HC2)\n\n# Estimación MCP (FGLS)\n# Análisis gráfico\nDEM_HET['resid2'] = (modelo_MCO.resid)**2\nsns.regplot(x=np.log(DEM_HET['Y']), y = DEM_HET['resid2'])\nplt.show()\n\n\n\n# Regresión auxiliar para el logaritmo de la varianza estimada\nreg_aux_resid2 = smf.ols(formula = \"np.log(resid2) ~ np.log(Y)\", data = DEM_HET)\nmodelo_l_resid2 = reg_aux_resid2.fit()\nprint(modelo_l_resid2.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:         np.log(resid2)   R-squared:                       0.198\nModel:                            OLS   Adj. R-squared:                  0.169\nMethod:                 Least Squares   F-statistic:                     6.905\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):             0.0138\nTime:                        09:38:47   Log-Likelihood:                -65.049\nNo. Observations:                  30   AIC:                             134.1\nDf Residuals:                      28   BIC:                             136.9\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept    -26.6579      7.565     -3.524      0.001     -42.154     -11.161\nnp.log(Y)      3.8463      1.464      2.628      0.014       0.848       6.845\n==============================================================================\nOmnibus:                        3.869   Durbin-Watson:                   2.164\nProb(Omnibus):                  0.144   Jarque-Bera (JB):                2.972\nSkew:                          -0.771   Prob(JB):                        0.226\nKurtosis:                       3.035   Cond. No.                         101.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Estimación de la varianza residual (no constante)\nsigma2 = np.exp(modelo_l_resid2.fittedvalues)\nw=list(1/sigma2)\n# MCO con ponderaciones (FGLS)\nmodelo2 = smf.wls(formula = \"np.log(QA) ~ np.log(PA) + np.log(PB) + np.log(PC) + np.log(Y)\", weights = w , data = DEM_HET)\nmodelo_MCP = modelo2.fit()\nprint(modelo_MCP.summary())\n\n                            WLS Regression Results                            \n==============================================================================\nDep. Variable:             np.log(QA)   R-squared:                       0.773\nModel:                            WLS   Adj. R-squared:                  0.737\nMethod:                 Least Squares   F-statistic:                     21.33\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           9.30e-08\nTime:                        09:38:47   Log-Likelihood:                 41.087\nNo. Observations:                  30   AIC:                            -72.17\nDf Residuals:                      25   BIC:                            -65.17\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      4.4808      0.872      5.136      0.000       2.684       6.278\nnp.log(PA)    -0.9072      0.149     -6.076      0.000      -1.215      -0.600\nnp.log(PB)     0.5459      0.103      5.318      0.000       0.335       0.757\nnp.log(PC)    -0.2488      0.124     -2.007      0.056      -0.504       0.006\nnp.log(Y)      0.6313      0.088      7.138      0.000       0.449       0.813\n==============================================================================\nOmnibus:                        2.395   Durbin-Watson:                   2.584\nProb(Omnibus):                  0.302   Jarque-Bera (JB):                1.170\nSkew:                          -0.196   Prob(JB):                        0.557\nKurtosis:                       3.884   Cond. No.                         899.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
  },
  {
    "objectID": "p3c2-app6.html#código-r",
    "href": "p3c2-app6.html#código-r",
    "title": "Aplicación 3.6 (Regresiones con volatilidad variable en el tiempo): Relación entre los precios de los carburantes y el precio del petroleo",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(zoo)\nlibrary(dynlm)\nlibrary(nlWaldTest)\nlibrary(FinTS)\nlibrary(tseries)\nlibrary(rugarch)\n# Lectura de datos\nGASOL_CRUDO &lt;- read_csv(\"data/GASOL_CRUDO.csv\")\nGASOL_CRUDO_ts &lt;- read.zoo(GASOL_CRUDO)\n# Gráfica de las series temporales\nplot(GASOL_CRUDO_ts)\n\n\n\n# Modelo dinámico para el precio de la gasolina (precio minorista)\ndyn_model &lt;- dynlm (log(PGASOL) ~ D2008JD + time + \n                      L(log(PGASOL), 1:2) + L(log(PCRUDO),0:2), \n                    data=GASOL_CRUDO_ts)\nsummary(dyn_model)\n\n\nTime series regression with \"zoo\" data:\nStart = 2000-01-15, End = 2013-07-13\n\nCall:\ndynlm(formula = log(PGASOL) ~ D2008JD + time + L(log(PGASOL), \n    1:2) + L(log(PCRUDO), 0:2), data = GASOL_CRUDO_ts)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.296134 -0.027702  0.002138  0.029019  0.289684 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -8.127e-02  6.474e-02  -1.255 0.209773    \nD2008JD              -3.358e-02  1.332e-02  -2.520 0.011949 *  \ntime                  7.733e-05  2.371e-05   3.261 0.001162 ** \nL(log(PGASOL), 1:2)1  5.176e-01  3.600e-02  14.378  &lt; 2e-16 ***\nL(log(PGASOL), 1:2)2  3.003e-01  3.508e-02   8.560  &lt; 2e-16 ***\nL(log(PCRUDO), 0:2)0  1.524e-01  4.029e-02   3.781 0.000169 ***\nL(log(PCRUDO), 0:2)1  1.117e-01  5.185e-02   2.154 0.031616 *  \nL(log(PCRUDO), 0:2)2 -1.304e-01  4.205e-02  -3.100 0.002012 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06243 on 697 degrees of freedom\nMultiple R-squared:  0.9663,    Adjusted R-squared:  0.966 \nF-statistic:  2858 on 7 and 697 DF,  p-value: &lt; 2.2e-16\n\n# Estimación de efectos parciales a corto y largo plazo\nnlConfint(dyn_model, c(\"b[6]\",\"(b[6]+b[7]+b[8])/(1-b[4]-b[5])\"))\n\n                                   value      2.5 %    97.5 %\nb[6]                           0.1523516 0.07338349 0.2313197\n(b[6]+b[7]+b[8])/(1-b[4]-b[5]) 0.7338844 0.60592473 0.8618440\n\nnlWaldtest(dyn_model, \"b[6]\")\n\n\n    Wald Chi-square test of a restriction on model parameters\n\ndata:  dyn_model\nChisq = 14.298, df = 1, p-value = 0.000156\n\nnlWaldtest(dyn_model, \"(b[6]+b[7]+b[8])/(1-b[4]-b[5])\")\n\n\n    Wald Chi-square test of a restriction on model parameters\n\ndata:  dyn_model\nChisq = 126.36, df = 1, p-value &lt; 2.2e-16\n\n# Contraste de heteroscedasticidad autoregresiva condicional (efectos ARCH)\nresid &lt;- as.zoo(dyn_model$residuals)\nplot(resid)\n\n\n\nplot(resid^2)\n\n\n\nsummary(dynlm(I(dyn_model$residuals^2) ~ L(I(dyn_model$residuals^2), 1:1)))\n\n\nTime series regression with \"numeric\" data:\nStart = 1(1), End = 704(1)\n\nCall:\ndynlm(formula = I(dyn_model$residuals^2) ~ L(I(dyn_model$residuals^2), \n    1:1))\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.019284 -0.002994 -0.002524 -0.000487  0.084493 \n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      0.0029745  0.0003589   8.289 5.82e-16 ***\nL(I(dyn_model$residuals^2), 1:1) 0.2166995  0.0365381   5.931 4.73e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.008756 on 702 degrees of freedom\nMultiple R-squared:  0.04771,   Adjusted R-squared:  0.04636 \nF-statistic: 35.17 on 1 and 702 DF,  p-value: 4.731e-09\n\nArchTest(dyn_model$residuals, lag = 1)\n\n\n    ARCH LM-test; Null hypothesis: no ARCH effects\n\ndata:  dyn_model$residuals\nChi-squared = 33.591, df = 1, p-value = 6.8e-09\n\nsummary(dynlm(I(dyn_model$residuals^2) ~ L(I(dyn_model$residuals^2), 1:2)))\n\n\nTime series regression with \"numeric\" data:\nStart = 1(1), End = 703(1)\n\nCall:\ndynlm(formula = I(dyn_model$residuals^2) ~ L(I(dyn_model$residuals^2), \n    1:2))\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.016743 -0.002748 -0.002240 -0.000395  0.083559 \n\nCoefficients:\n                                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                       0.0025408  0.0003727   6.818 2.00e-11 ***\nL(I(dyn_model$residuals^2), 1:2)1 0.1909697  0.0373769   5.109 4.18e-07 ***\nL(I(dyn_model$residuals^2), 1:2)2 0.1413477  0.0370799   3.812  0.00015 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.008671 on 700 degrees of freedom\nMultiple R-squared:  0.06865,   Adjusted R-squared:  0.06599 \nF-statistic:  25.8 on 2 and 700 DF,  p-value: 1.547e-11\n\nArchTest(dyn_model$residuals, lag = 2)\n\n\n    ARCH LM-test; Null hypothesis: no ARCH effects\n\ndata:  dyn_model$residuals\nChi-squared = 48.261, df = 2, p-value = 3.313e-11\n\n# Modelo GARCH para los errores del modelo\n# Librería tseries\nresid.ARCH &lt;- garch(resid,c(0,2), trace=FALSE)\nsummary(resid.ARCH)\n\n\nCall:\ngarch(x = resid, order = c(0, 2), trace = FALSE)\n\nModel:\nGARCH(0,2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-5.13757 -0.48437  0.04168  0.51027  5.64979 \n\nCoefficient(s):\n    Estimate  Std. Error  t value Pr(&gt;|t|)    \na0 1.892e-03   9.665e-05   19.573  &lt; 2e-16 ***\na1 2.324e-01   5.917e-02    3.928 8.57e-05 ***\na2 3.742e-01   4.906e-02    7.628 2.40e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nDiagnostic Tests:\n    Jarque Bera Test\n\ndata:  Residuals\nX-squared = 643.78, df = 2, p-value &lt; 2.2e-16\n\n\n    Box-Ljung test\n\ndata:  Squared.Residuals\nX-squared = 0.00054561, df = 1, p-value = 0.9814\n\nhhat_1 &lt;- as.zoo(resid.ARCH$fitted.values[,1]^2)\nplot(hhat_1)\n\n\n\n# Librería rugarch\nresid_GARCH_spec &lt;-  ugarchspec(\n  mean.model = list(armaOrder=c(0,0), include.mean = FALSE),\n  variance.model = list(model=\"sGARCH\", garchOrder=c(2,0)),\n  distribution.model =\"norm\")\nresid_GARCH_fit &lt;- ugarchfit(spec = resid_GARCH_spec, data = resid)\nshow(resid_GARCH_fit)\n\n\n*---------------------------------*\n*          GARCH Model Fit        *\n*---------------------------------*\n\nConditional Variance Dynamics   \n-----------------------------------\nGARCH Model : sGARCH(2,0)\nMean Model  : ARFIMA(0,0,0)\nDistribution    : norm \n\nOptimal Parameters\n------------------------------------\n        Estimate  Std. Error  t value Pr(&gt;|t|)\nomega   0.001892    0.000187  10.1387  0.0e+00\nalpha1  0.232407    0.057631   4.0327  5.5e-05\nalpha2  0.374224    0.085864   4.3583  1.3e-05\n\nRobust Standard Errors:\n        Estimate  Std. Error  t value Pr(&gt;|t|)\nomega   0.001892    0.000488   3.8799 0.000105\nalpha1  0.232407    0.057430   4.0468 0.000052\nalpha2  0.374224    0.159605   2.3447 0.019043\n\nLogLikelihood : 1009.718 \n\nInformation Criteria\n------------------------------------\n                    \nAkaike       -2.8559\nBayes        -2.8365\nShibata      -2.8560\nHannan-Quinn -2.8484\n\nWeighted Ljung-Box Test on Standardized Residuals\n------------------------------------\n                        statistic  p-value\nLag[1]                      6.347 0.011758\nLag[2*(p+q)+(p+q)-1][2]     7.360 0.009566\nLag[4*(p+q)+(p+q)-1][5]     9.434 0.012845\nd.o.f=0\nH0 : No serial correlation\n\nWeighted Ljung-Box Test on Standardized Squared Residuals\n------------------------------------\n                        statistic   p-value\nLag[1]                   0.003479 9.530e-01\nLag[2*(p+q)+(p+q)-1][5] 11.673463 3.392e-03\nLag[4*(p+q)+(p+q)-1][9] 35.350902 1.454e-08\nd.o.f=2\n\nWeighted ARCH LM Tests\n------------------------------------\n            Statistic Shape Scale   P-Value\nARCH Lag[3]   0.06681 0.500 2.000 7.960e-01\nARCH Lag[5]  33.44106 1.440 1.667 8.336e-09\nARCH Lag[7]  43.09372 2.315 1.543 5.252e-11\n\nNyblom stability test\n------------------------------------\nJoint Statistic:  3.9216\nIndividual Statistics:             \nomega  3.7505\nalpha1 0.9287\nalpha2 0.8884\n\nAsymptotic Critical Values (10% 5% 1%)\nJoint Statistic:         0.846 1.01 1.35\nIndividual Statistic:    0.35 0.47 0.75\n\nSign Bias Test\n------------------------------------\n                   t-value   prob sig\nSign Bias          0.98942 0.3228    \nNegative Sign Bias 0.09161 0.9270    \nPositive Sign Bias 0.99225 0.3214    \nJoint Effect       1.35262 0.7167    \n\n\nAdjusted Pearson Goodness-of-Fit Test:\n------------------------------------\n  group statistic p-value(g-1)\n1    20     57.87    8.379e-06\n2    30     71.21    2.066e-05\n3    40     73.38    7.103e-04\n4    50     92.38    1.774e-04\n\n\nElapsed time : 0.09360504 \n\nhhat_2 &lt;- as.zoo(resid_GARCH_fit@fit$sigma^2)\nplot.ts(hhat_2) # ts.plot(resid_GARCH_fit@fit$sigma^2)\n\n\n\n# Modo interactivo: permite seleccionar el tipo de gráfica\n# plot(resid_GARCH_fit)\nplot(resid_GARCH_fit, which=1)\n\n\n\nplot(resid_GARCH_fit, which=3)"
  },
  {
    "objectID": "p3c2-app6.html#código-python",
    "href": "p3c2-app6.html#código-python",
    "title": "Aplicación 3.6 (Regresiones con volatilidad variable en el tiempo): Relación entre los precios de los carburantes y el precio del petroleo",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.stats.api as sms\nimport statsmodels.stats.diagnostic as smsdiag\nfrom statsmodels.compat import lzip\nfrom arch import arch_model\n# Lectura de datos y asignación del índice temporal\nGASOL_CRUDO_ts = pd.read_csv(\"data/GASOL_CRUDO.csv\", parse_dates=['date'], index_col='date')\nGASOL_CRUDO_ts.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 707 entries, 2000-01-01 to 2013-07-13\nData columns (total 4 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   D2008JD  707 non-null    int64  \n 1   PCRUDO   707 non-null    float64\n 2   PGASOL   707 non-null    float64\n 3   time     707 non-null    int64  \ndtypes: float64(2), int64(2)\nmemory usage: 27.6 KB\n\nGASOL_CRUDO_ts.head()\n\n            D2008JD  PCRUDO  PGASOL  time\ndate                                     \n2000-01-01        0  226.18    29.2     1\n2000-01-08        0  229.43    31.4     2\n2000-01-15        0  263.68    26.6     3\n2000-01-22        0  256.43    30.9     4\n2000-01-29        0  253.18    32.1     5\n\nGASOL_CRUDO_ts.index\n\nDatetimeIndex(['2000-01-01', '2000-01-08', '2000-01-15', '2000-01-22',\n               '2000-01-29', '2000-02-05', '2000-02-12', '2000-02-19',\n               '2000-02-26', '2000-03-04',\n               ...\n               '2013-05-11', '2013-05-18', '2013-05-25', '2013-06-01',\n               '2013-06-08', '2013-06-15', '2013-06-22', '2013-06-29',\n               '2013-07-06', '2013-07-13'],\n              dtype='datetime64[ns]', name='date', length=707, freq=None)\n\n# Asignación del formato semanal (opcional)\ndate_w = pd.date_range(start = '2000', periods = len(GASOL_CRUDO_ts.index), freq = 'W')\nGASOL_CRUDO_ts.index = date_w\nGASOL_CRUDO_ts.index\n\nDatetimeIndex(['2000-01-02', '2000-01-09', '2000-01-16', '2000-01-23',\n               '2000-01-30', '2000-02-06', '2000-02-13', '2000-02-20',\n               '2000-02-27', '2000-03-05',\n               ...\n               '2013-05-12', '2013-05-19', '2013-05-26', '2013-06-02',\n               '2013-06-09', '2013-06-16', '2013-06-23', '2013-06-30',\n               '2013-07-07', '2013-07-14'],\n              dtype='datetime64[ns]', length=707, freq='W-SUN')\n\n# Gráfica de las series temporales\nplt.figure(1)\nfig, ax = plt.subplots(4, 1, sharex = True)\nax[0].plot(GASOL_CRUDO_ts.D2008JD)\nax[0].set_ylabel('D2008JD')\nax[1].plot(GASOL_CRUDO_ts.PCRUDO)\nax[1].set_ylabel('PCRUDO')\nax[2].plot(GASOL_CRUDO_ts.PGASOL)\nax[2].set_ylabel('PGASOL')\nax[3].plot(GASOL_CRUDO_ts.time)\nax[3].set_ylabel('time')\nplt.show()\n\n\n\n# Modelo dinámico para el precio de la gasolina (precio minorista)\nGASOL_CRUDO_ts['l_PGASOL'] = np.log(GASOL_CRUDO_ts['PGASOL'])\nGASOL_CRUDO_ts['l_PCRUDO'] = np.log(GASOL_CRUDO_ts['PCRUDO'])\nformula = 'l_PGASOL ~ D2008JD + time + l_PGASOL.shift(1) + l_PGASOL.shift(2) + l_PCRUDO + l_PCRUDO.shift(1) + l_PCRUDO.shift(2)'\ndyn_model = smf.ols(formula, data = GASOL_CRUDO_ts)\nlm_dyn_model = dyn_model.fit()\nprint(lm_dyn_model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               l_PGASOL   R-squared:                       0.966\nModel:                            OLS   Adj. R-squared:                  0.966\nMethod:                 Least Squares   F-statistic:                     2858.\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):               0.00\nTime:                        09:40:53   Log-Likelihood:                 959.11\nNo. Observations:                 705   AIC:                            -1902.\nDf Residuals:                     697   BIC:                            -1866.\nDf Model:                           7                                         \nCovariance Type:            nonrobust                                         \n=====================================================================================\n                        coef    std err          t      P&gt;|t|      [0.025      0.975]\n-------------------------------------------------------------------------------------\nIntercept            -0.0813      0.065     -1.255      0.210      -0.208       0.046\nD2008JD              -0.0336      0.013     -2.520      0.012      -0.060      -0.007\ntime               7.733e-05   2.37e-05      3.261      0.001    3.08e-05       0.000\nl_PGASOL.shift(1)     0.5176      0.036     14.378      0.000       0.447       0.588\nl_PGASOL.shift(2)     0.3003      0.035      8.560      0.000       0.231       0.369\nl_PCRUDO              0.1524      0.040      3.781      0.000       0.073       0.231\nl_PCRUDO.shift(1)     0.1117      0.052      2.154      0.032       0.010       0.213\nl_PCRUDO.shift(2)    -0.1304      0.042     -3.100      0.002      -0.213      -0.048\n==============================================================================\nOmnibus:                       88.212   Durbin-Watson:                   1.949\nProb(Omnibus):                  0.000   Jarque-Bera (JB):              384.370\nSkew:                          -0.482   Prob(JB):                     3.43e-84\nKurtosis:                       6.487   Cond. No.                     1.15e+04\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.15e+04. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n# Estimación de efectos parciales a corto y largo plazo\nb = lm_dyn_model.params[0:]\n# Multiplicador de corto plazo\nb[5].round(3)\n\n0.152\n\n# Multiplicador de largo plazo\n((b[5]+b[6]+b[7])/(1-b[3]-b[4])).round(3)\n\n0.734\n\n# Contraste de heteroscedasticidad autoregresiva condicional (efectos ARCH)\nresiduals = lm_dyn_model.resid\nplt.figure(5)\nplt.plot(residuals, label='Residuos')\nplt.xlabel('Semana')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\nplt.figure(6)\nplt.plot(residuals**2, label='Residuos al cuadrado')\nplt.xlabel('Semana')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n\n\n# Test de Engle\nname = ['LM statistic', 'Chi^2 p-val', 'F statistic', 'F p-val']\nE_test_1 = smsdiag.het_arch(residuals, nlags=1)\nlzip(name,E_test_1)\n\n[('LM statistic', 33.59125111341629), ('Chi^2 p-val', 6.79978851875406e-09), ('F statistic', 35.17415057721384), ('F p-val', 4.731167717319399e-09)]\n\nprint(pd.DataFrame([np.round(E_test_1, 3)], columns=name))\n\n   LM statistic  Chi^2 p-val  F statistic  F p-val\n0        33.591          0.0       35.174      0.0\n\nE_test_2 = smsdiag.het_arch(residuals, nlags=2)\nlzip(name,E_test_2)\n\n[('LM statistic', 48.26143118405129), ('Chi^2 p-val', 3.312557106655711e-11), ('F statistic', 25.79884814936918), ('F p-val', 1.5467136016750854e-11)]\n\nprint(pd.DataFrame([np.round(E_test_2, 3)], columns=name))\n\n   LM statistic  Chi^2 p-val  F statistic  F p-val\n0        48.261          0.0       25.799      0.0\n\n# Modelo GARCH para los errores del modelo\ngarch_model = arch_model(residuals, mean='Zero', vol='GARCH', p=2, q=0, dist='normal')\nmv_garch_model = garch_model.fit()\n\nIteration:      1,   Func. Count:      5,   Neg. LLF: -440.3038423896095\nIteration:      2,   Func. Count:     13,   Neg. LLF: -848.4746617760027\nIteration:      3,   Func. Count:     18,   Neg. LLF: -40.92526664364976\nIteration:      4,   Func. Count:     23,   Neg. LLF: -997.1901354377039\nIteration:      5,   Func. Count:     28,   Neg. LLF: 4501163.304429701\nIteration:      6,   Func. Count:     33,   Neg. LLF: -991.4353946793708\nIteration:      7,   Func. Count:     38,   Neg. LLF: -1009.757502482586\nIteration:      8,   Func. Count:     42,   Neg. LLF: -1009.9254909725157\nIteration:      9,   Func. Count:     46,   Neg. LLF: -1009.9299853001154\nIteration:     10,   Func. Count:     50,   Neg. LLF: -1009.9303155884547\nIteration:     11,   Func. Count:     54,   Neg. LLF: -1009.9303168451199\nIteration:     12,   Func. Count:     57,   Neg. LLF: -1009.9303168451216\nOptimization terminated successfully    (Exit mode 0)\n            Current function value: -1009.9303168451199\n            Iterations: 12\n            Function evaluations: 57\n            Gradient evaluations: 12\n\nprint(mv_garch_model)\n\n                        Zero Mean - ARCH Model Results                        \n==============================================================================\nDep. Variable:                   None   R-squared:                       0.000\nMean Model:                 Zero Mean   Adj. R-squared:                  0.001\nVol Model:                       ARCH   Log-Likelihood:                1009.93\nDistribution:                  Normal   AIC:                          -2013.86\nMethod:            Maximum Likelihood   BIC:                          -2000.19\n                                        No. Observations:                  705\nDate:                Wed, Nov 15 2023   Df Residuals:                      705\nTime:                        09:40:53   Df Model:                            0\n                              Volatility Model                              \n============================================================================\n                 coef    std err          t      P&gt;|t|      95.0% Conf. Int.\n----------------------------------------------------------------------------\nomega      1.8836e-03  3.690e-04      5.105  3.309e-07 [1.160e-03,2.607e-03]\nalpha[1]       0.2349  6.195e-02      3.792  1.494e-04     [  0.114,  0.356]\nalpha[2]       0.3902      0.155      2.518  1.181e-02   [8.646e-02,  0.694]\n============================================================================\n\nCovariance estimator: robust\n\nfig = mv_garch_model.plot()\nplt.show()"
  },
  {
    "objectID": "p3c2-app7.html#caso-univariante-especificación-ardl-tipos-de-interés-en-españa-en-la-década-de-1980",
    "href": "p3c2-app7.html#caso-univariante-especificación-ardl-tipos-de-interés-en-españa-en-la-década-de-1980",
    "title": "Aplicación 3.7 (Autocorrelación y regresiones dinámicas): Modelos ARDL y VAR",
    "section": "Caso univariante (especificación ARDL): Tipos de interés en España en la década de 1980",
    "text": "Caso univariante (especificación ARDL): Tipos de interés en España en la década de 1980\nEn esta primera aplicación se estimará un modelo de regresión uniecuacional con autocorrelación en los errores y se propondrán soluciones al problema."
  },
  {
    "objectID": "p3c2-app7.html#caso-multivariante-especificación-var-evolución-temporal-de-los-tipos-de-cambio",
    "href": "p3c2-app7.html#caso-multivariante-especificación-var-evolución-temporal-de-los-tipos-de-cambio",
    "title": "Aplicación 3.7 (Autocorrelación y regresiones dinámicas): Modelos ARDL y VAR",
    "section": "Caso multivariante (especificación VAR): Evolución temporal de los tipos de cambio",
    "text": "Caso multivariante (especificación VAR): Evolución temporal de los tipos de cambio\nEn esta segunda aplicación se estimará un modelo vectorial autorregresivo para explicar la evolución en el tiempo de tres tipos de cambio."
  },
  {
    "objectID": "p3c2-app8a.html",
    "href": "p3c2-app8a.html",
    "title": "Aplicación 3.8a (Dependencia espacial - Geometría: polígonos): Estadísticas ‘morales’ en Francia en 1830",
    "section": "",
    "text": "En esta aplicación se analizarán con técnicas modernas de análisis estadístico espacial algunas de las cuestiones abordadas en el estudio fundacional de las ciencias sociales de André-Michel Guerry sobre la delincuencia, el suicidio, la alfabetización y otras “estadísticas morales” en la Francia de 1830.\nReferencia original: Guerry, A.M. (1833). “Essai sur la statistique morale de la France”, París: Crochard.\nFuente de los datos: https://geodacenter.github.io/data-and-lab/Guerry/\nInformación complementaria: https://www.datavis.ca/gallery/guerry/\nPara una introducción asequible al análisis de datos espaciales puede consultarse el libro de Moraga, P. (2023): “Spatial Statistics for Data Science: Theory and Practice with R”, Chapman & Hall/CRC: https://www.paulamoraga.com/book-spatial/.\nPara una revisión completa sobre los principales métodos y técnicas utilizados en ciencia de datos espaciales en R y Python las referencias básicas son los libros de Pebesma, E. y Bivand, R. (2023): “Spatial Data Science: With Applications in R”, Chapman & Hall/CRC: https://r-spatial.org/book/, y Rey, S., Arribas-Bel, D. y Wolf, L. (2023): “Geographic Data Science with Python”, Chapman & Hall/CRC: https://geographicdata.science/book/.\n\n\nCódigo R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(sf) # https://r-spatial.github.io/sf/\n\n# Lectura de datos\nGuerry &lt;- st_read(\"data/GUERRY_FRANCE.shp\")\n\nReading layer `GUERRY_FRANCE' from data source \n  `/Users/JulianRamajo/Documentos/RStudio/Quarto-Book/data/GUERRY_FRANCE.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 85 features and 29 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 47680 ymin: 1703258 xmax: 1031401 ymax: 2677441\nProjected CRS: NTF (Paris) / Lambert zone II\n\nclass(Guerry)\n\n[1] \"sf\"         \"data.frame\"\n\nstr(Guerry)\n\nClasses 'sf' and 'data.frame':  85 obs. of  30 variables:\n $ CODE_DE  : chr  \"01\" \"02\" \"03\" \"04\" ...\n $ COUNT    : num  1 1 1 1 1 1 1 1 1 1 ...\n $ AVE_ID_  : num  49 812 1418 1603 1802 ...\n $ dept     : num  1 2 3 4 5 7 8 9 10 11 ...\n $ Region   : chr  \"E\" \"N\" \"C\" \"E\" ...\n $ Dprtmnt  : chr  \"Ain\" \"Aisne\" \"Allier\" \"Basses-Alpes\" ...\n $ Crm_prs  : num  28870 26226 26747 12935 17488 ...\n $ Crm_prp  : num  15890 5521 7925 7289 8174 ...\n $ Litercy  : num  37 51 13 46 69 27 67 18 59 34 ...\n $ Donatns  : num  5098 8901 10973 2733 6962 ...\n $ Infants  : num  33120 14572 17044 23018 23076 ...\n $ Suicids  : num  35039 12831 114121 14238 16171 ...\n $ MainCty  : num  2 2 2 1 1 1 2 1 2 2 ...\n $ Wealth   : num  73 22 61 76 83 84 33 72 14 17 ...\n $ Commerc  : num  58 10 66 49 65 1 4 60 3 35 ...\n $ Clergy   : num  11 82 68 5 10 28 50 39 42 15 ...\n $ Crm_prn  : num  71 4 46 70 22 76 53 74 77 80 ...\n $ Infntcd  : num  60 82 42 12 23 47 85 28 54 35 ...\n $ Dntn_cl  : num  69 36 76 37 64 67 49 63 9 27 ...\n $ Lottery  : num  41 38 66 80 79 70 31 75 28 50 ...\n $ Desertn  : num  55 82 16 32 35 19 62 22 86 63 ...\n $ Instrct  : num  46 24 85 29 7 62 9 77 15 48 ...\n $ Prsttts  : num  13 327 34 2 1 1 83 3 207 1 ...\n $ Distanc  : num  218.4 65.9 161.9 351.4 320.3 ...\n $ Area     : num  5762 7369 7340 6925 5549 ...\n $ Pop1831  : num  346 513 298 156 129 ...\n $ TopCrm   : num  1 1 1 0 0 0 1 0 0 0 ...\n $ TopLit   : num  0 1 0 1 1 0 1 0 1 0 ...\n $ TopWealth: num  1 0 1 1 1 1 0 1 0 0 ...\n $ geometry :sfc_MULTIPOLYGON of length 85; first list element: List of 1\n  ..$ :List of 1\n  .. ..$ : num [1:498, 1:2] 801150 800669 800688 800780 800589 ...\n  ..- attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:29] \"CODE_DE\" \"COUNT\" \"AVE_ID_\" \"dept\" ...\n\nGuerry\n\nSimple feature collection with 85 features and 29 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 47680 ymin: 1703258 xmax: 1031401 ymax: 2677441\nProjected CRS: NTF (Paris) / Lambert zone II\nFirst 10 features:\n   CODE_DE COUNT AVE_ID_ dept Region      Dprtmnt Crm_prs Crm_prp Litercy\n1       01     1      49    1      E          Ain   28870   15890      37\n2       02     1     812    2      N        Aisne   26226    5521      51\n3       03     1    1418    3      C       Allier   26747    7925      13\n4       04     1    1603    4      E Basses-Alpes   12935    7289      46\n5       05     1    1802    5      E Hautes-Alpes   17488    8174      69\n6       07     1    2249    7      S      Ardeche    9474   10263      27\n7       08     1   35395    8      N     Ardennes   35203    8847      67\n8       09     1    2526    9      S       Ariege    6173    9597      18\n9       10     1   34410   10      E         Aube   19602    4086      59\n10      11     1    2807   11      S         Aude   15647   10431      34\n   Donatns Infants Suicids MainCty Wealth Commerc Clergy Crm_prn Infntcd\n1     5098   33120   35039       2     73      58     11      71      60\n2     8901   14572   12831       2     22      10     82       4      82\n3    10973   17044  114121       2     61      66     68      46      42\n4     2733   23018   14238       1     76      49      5      70      12\n5     6962   23076   16171       1     83      65     10      22      23\n6     3188   42117   52547       1     84       1     28      76      47\n7     6400   16106   26198       2     33       4     50      53      85\n8     3542   22916  123625       1     72      60     39      74      28\n9     3608   18642   10989       2     14       3     42      77      54\n10    2582   20225   66498       2     17      35     15      80      35\n   Dntn_cl Lottery Desertn Instrct Prsttts Distanc Area Pop1831 TopCrm TopLit\n1       69      41      55      46      13 218.372 5762  346.03      1      0\n2       36      38      82      24     327  65.945 7369  513.00      1      1\n3       76      66      16      85      34 161.927 7340  298.26      1      0\n4       37      80      32      29       2 351.399 6925  155.90      0      1\n5       64      79      35       7       1 320.280 5549  129.10      0      1\n6       67      70      19      62       1 279.413 5529  340.73      0      0\n7       49      31      62       9      83 105.694 5229  289.62      1      1\n8       63      75      22      77       3 385.313 4890  253.12      0      0\n9        9      28      86      15     207  83.244 6004  246.36      0      1\n10      27      50      63      48       1 370.949 6139  270.13      0      0\n   TopWealth                       geometry\n1          1 MULTIPOLYGON (((801150 2092...\n2          0 MULTIPOLYGON (((729326 2521...\n3          1 MULTIPOLYGON (((710830 2137...\n4          1 MULTIPOLYGON (((882701 1920...\n5          1 MULTIPOLYGON (((886504 1922...\n6          1 MULTIPOLYGON (((747008 1925...\n7          0 MULTIPOLYGON (((818893 2514...\n8          1 MULTIPOLYGON (((509103 1747...\n9          0 MULTIPOLYGON (((775400 2345...\n10         0 MULTIPOLYGON (((626230 1810...\n\n# Análisis exploratorio básico (EDA)\nsummary(Guerry)\n\n   CODE_DE              COUNT          AVE_ID_           dept      \n Length:85          Min.   :1.000   Min.   :   49   Min.   : 1.00  \n Class :character   1st Qu.:1.000   1st Qu.: 8612   1st Qu.:24.00  \n Mode  :character   Median :1.000   Median :16732   Median :45.00  \n                    Mean   :1.059   Mean   :17701   Mean   :45.08  \n                    3rd Qu.:1.000   3rd Qu.:26842   3rd Qu.:66.00  \n                    Max.   :4.000   Max.   :36521   Max.   :89.00  \n    Region            Dprtmnt             Crm_prs         Crm_prp     \n Length:85          Length:85          Min.   : 5883   Min.   : 1368  \n Class :character   Class :character   1st Qu.:14790   1st Qu.: 5990  \n Mode  :character   Mode  :character   Median :18785   Median : 7624  \n                                       Mean   :19961   Mean   : 7881  \n                                       3rd Qu.:26221   3rd Qu.: 9190  \n                                       Max.   :37014   Max.   :20235  \n    Litercy         Donatns         Infants         Suicids          MainCty \n Min.   :12.00   Min.   : 1246   Min.   : 2660   Min.   :  3460   Min.   :1  \n 1st Qu.:25.00   1st Qu.: 3446   1st Qu.:14281   1st Qu.: 15400   1st Qu.:2  \n Median :38.00   Median : 4964   Median :17044   Median : 26198   Median :2  \n Mean   :39.14   Mean   : 6723   Mean   :18983   Mean   : 36517   Mean   :2  \n 3rd Qu.:52.00   3rd Qu.: 9242   3rd Qu.:21981   3rd Qu.: 45180   3rd Qu.:2  \n Max.   :74.00   Max.   :27830   Max.   :62486   Max.   :163241   Max.   :3  \n     Wealth         Commerc          Clergy         Crm_prn         Infntcd  \n Min.   : 1.00   Min.   : 1.00   Min.   : 2.00   Min.   : 1.00   Min.   : 1  \n 1st Qu.:22.00   1st Qu.:21.00   1st Qu.:23.00   1st Qu.:22.00   1st Qu.:23  \n Median :44.00   Median :42.00   Median :44.00   Median :43.00   Median :44  \n Mean   :43.58   Mean   :42.33   Mean   :43.93   Mean   :43.06   Mean   :44  \n 3rd Qu.:65.00   3rd Qu.:63.00   3rd Qu.:65.00   3rd Qu.:64.00   3rd Qu.:65  \n Max.   :86.00   Max.   :86.00   Max.   :86.00   Max.   :86.00   Max.   :86  \n    Dntn_cl         Lottery         Desertn         Instrct     \n Min.   : 1.00   Min.   : 1.00   Min.   : 1.00   Min.   : 1.00  \n 1st Qu.:22.00   1st Qu.:22.00   1st Qu.:23.00   1st Qu.:23.00  \n Median :43.00   Median :43.00   Median :44.00   Median :42.00  \n Mean   :43.02   Mean   :43.04   Mean   :43.91   Mean   :43.34  \n 3rd Qu.:64.00   3rd Qu.:64.00   3rd Qu.:65.00   3rd Qu.:65.00  \n Max.   :86.00   Max.   :86.00   Max.   :86.00   Max.   :86.00  \n    Prsttts          Distanc           Area          Pop1831     \n Min.   :   0.0   Min.   :  0.0   Min.   :  762   Min.   :129.1  \n 1st Qu.:   6.0   1st Qu.:119.7   1st Qu.: 5361   1st Qu.:283.8  \n Median :  34.0   Median :199.2   Median : 6040   Median :346.3  \n Mean   : 143.5   Mean   :204.1   Mean   : 6117   Mean   :380.8  \n 3rd Qu.: 117.0   3rd Qu.:283.8   3rd Qu.: 6815   3rd Qu.:445.2  \n Max.   :4744.0   Max.   :403.4   Max.   :10000   Max.   :989.9  \n     TopCrm           TopLit         TopWealth               geometry \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   MULTIPOLYGON :85  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   epsg:27572   : 0  \n Median :0.0000   Median :0.0000   Median :0.0000   +proj=lcc ...: 0  \n Mean   :0.3294   Mean   :0.3294   Mean   :0.3294                     \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000                     \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000                     \n\n# Gráficas: representación de datos espaciales\nplot(Guerry['Crm_prs'])\n\n\n\nlibrary(mapview)\nmapview(Guerry, zcol = \"Crm_prs\")\n\n\n\n\n\n# ESTADÍSTICA ESPACIAL: ANÁLISIS EXPLORATORIO DE DATOS ESPACIALES (ESDA)\n\n# Librería rgeoda (https://geodacenter.github.io/rgeoda/)\nlibrary(rgeoda)\n# Matriz de pesos espaciales \n# (www.paulamoraga.com/book-spatial/spatial-neighborhood-matrices.html)\nWq &lt;- queen_weights(Guerry)\nsummary(Wq)\n\n                     name              value\n1 number of observations:                 85\n2          is symmetric:                TRUE\n3               sparsity: 0.0581314878892734\n4        # min neighbors:                  2\n5        # max neighbors:                  8\n6       # mean neighbors:   4.94117647058824\n7     # median neighbors:                  5\n8           has isolates:              FALSE\n\n# Estadísticos de autocorrelación espacial para la variable Crm_prs\nLISA_Crm_prs &lt;- local_moran(Wq, Guerry['Crm_prs'])\nLISA_Crm_prs\n\nReference class object of class \"LISA\"\nField \"gda_lisa\":\nAn object of class \"p_LISA\"\nSlot \"pointer\":\n&lt;pointer: 0x7fd1fa0cc2a0&gt;\n\nField \"p_vals\":\n [1] 0.197 0.013 0.023 0.068 0.111 0.045 0.281 0.048 0.183 0.004 0.002 0.052\n[13] 0.106 0.002 0.266 0.267 0.017 0.401 0.091 0.123 0.219 0.281 0.206 0.035\n[25] 0.371 0.301 0.119 0.001 0.011 0.189 0.463 0.024 0.014 0.272 0.021 0.423\n[37] 0.067 0.426 0.061 0.458 0.125 0.145 0.433 0.145 0.197 0.011 0.187 0.130\n[49] 0.017 0.197 0.002 0.210 0.092 0.080 0.471 0.077 0.032 0.331 0.061 0.037\n[61] 0.154 0.170 0.309 0.036 0.158 0.205 0.059 0.183 0.003 0.048 0.342 0.100\n[73] 0.358 0.443 0.290 0.075 0.034 0.026 0.060 0.005 0.310 0.122 0.064 0.494\n[85] 0.126\nField \"c_vals\":\n [1] 0 1 1 0 0 2 0 2 0 2 2 0 0 2 0 0 1 0 0 0 0 0 0 2 0 0 0 2 2 0 0 2 1 0 3 0 0 0\n[39] 0 0 0 0 0 0 0 2 0 0 3 0 1 0 0 0 0 0 1 0 0 1 0 0 0 2 0 0 0 0 1 1 0 0 0 0 0 0\n[77] 2 2 0 2 0 0 0 0 0\nField \"lisa_vals\":\n [1]  0.516120231  0.818275138  0.794086560  0.733161543  0.228467334\n [6]  0.829040272  0.615280448  1.627415446 -0.019525625  0.687081885\n[11]  1.707896579  0.821748275 -0.213568315  0.291316827 -0.184833414\n[16] -0.047198613  0.249972417  0.054411195  0.862095943  0.835368441\n[21]  0.538432168 -0.050446242 -0.681022658  0.678851849 -0.105369231\n[26]  0.038567922  1.116236578  1.168138859  0.162030880  0.069037225\n[31]  0.021522359  1.000255304  0.276308094  0.423159405 -0.101271972\n[36]  0.015647332  0.554846307 -0.027584417  0.111200075 -0.082994402\n[41]  0.281817532 -0.048962443 -0.015839144  0.830286100 -0.160743989\n[46]  1.597607483  0.396712769  0.862342357 -0.466396879  0.262343383\n[51]  1.424738721 -0.379247703  0.388066026  0.316231271  0.068795845\n[56]  0.405538158  0.977019076  0.202610060  0.714533504  0.601447598\n[61] -0.177594467  0.229608404  0.284505927  2.247991283  0.532787318\n[66]  1.039424040 -0.129846379  0.136565215  1.033851456  1.238521154\n[71]  0.296054062 -0.167632280 -0.041663121  0.036396148 -0.055081083\n[76]  1.166507105  0.773315084  0.523682291  0.851277285  0.884651013\n[81]  0.025497212 -0.326497225 -0.306819894  0.001277301 -0.125219240\nField \"nn_vals\":\n [1] 4 6 6 4 3 7 3 3 5 5 7 3 3 6 5 5 6 6 7 3 6 7 2 5 6 6 2 6 6 6 4 4 6 6 5 6 5 4\n[39] 6 7 5 4 7 6 6 5 8 4 6 6 5 4 5 4 2 6 3 6 6 2 6 3 3 2 4 2 4 5 7 6 2 3 8 6 5 5\n[77] 5 6 3 6 4 6 6 6 5\nField \"labels\":\n[1] \"Not significant\" \"High-High\"       \"Low-Low\"         \"Low-High\"       \n[5] \"High-Low\"        \"Undefined\"       \"Isolated\"       \nField \"colors\":\n[1] \"#eeeeee\" \"#FF0000\" \"#0000FF\" \"#a7adf9\" \"#f4ada8\" \"#464646\" \"#999999\"\n\nlisa_colors &lt;- lisa_colors(LISA_Crm_prs)\nlisa_labels &lt;- lisa_labels(LISA_Crm_prs)\nlisa_clusters &lt;- lisa_clusters(LISA_Crm_prs)\n\nplot(st_geometry(Guerry), \n     col=sapply(lisa_clusters, function(x){return(lisa_colors[[x+1]])}), \n     border = \"#333333\", lwd=0.2)\ntitle(main = \"Mapa de Moran local de Crm_prs\")\nlegend('bottomleft', legend = lisa_labels, fill = lisa_colors, border = \"#eeeeee\")\n\n\n\nlisa_p &lt;- lisa_pvalues(LISA_Crm_prs)\np_labels &lt;- c(\"Not significant\", \"p &lt;= 0.05\", \"p &lt;= 0.01\", \"p &lt;= 0.001\")\np_colors &lt;- c(\"#eeeeee\", \"#84f576\", \"#53c53c\", \"#348124\")\nplot(st_geometry(Guerry), \n     col=sapply(lisa_p, function(x){\n       if (x &lt;= 0.001) return(p_colors[4])\n       else if (x &lt;= 0.01) return(p_colors[3])\n       else if (x &lt;= 0.05) return (p_colors[2])\n       else return(p_colors[1])\n       }), \n     border = \"#333333\", lwd=0.2)\ntitle(main = \"Mapa de signicación local de Crm_prs\")\nlegend('bottomleft', legend = p_labels, fill = p_colors, border = \"#eeeeee\")\n\n\n\n# Librería spdep (https://r-spatial.github.io/spdep/)\n# [Ver también la librería sfdep: https://sfdep.josiahparry.com/]\nlibrary(spdep)\n\n# Cálculo de los vecinos de cada región\nnb &lt;- spdep::poly2nb(Guerry, queen = TRUE)\nnb\n\nNeighbour list object:\nNumber of regions: 85 \nNumber of nonzero links: 420 \nPercentage nonzero weights: 5.813149 \nAverage number of links: 4.941176 \n\nplot(st_geometry(Guerry), border = \"lightgrey\")\nplot.nb(nb, st_geometry(Guerry), add = TRUE)\n\n\n\n# ¿Cómo funciona al nivel individual la lista nb?\nhead(nb)\n\n[[1]]\n[1] 36 37 67 69\n\n[[2]]\n[1]  7 49 57 58 73 76\n\n[[3]]\n[1] 17 21 40 56 61 69\n\n[[4]]\n[1]  5 24 79 80\n\n[[5]]\n[1]  4 24 36\n\n[[6]]\n[1] 24 28 36 40 41 46 80\n\nid &lt;- 1 # id de la región\nGuerry$neighbors &lt;- \"Otros\"\nGuerry$neighbors[id] &lt;- \"Región\"\nGuerry$neighbors[nb[[id]]] &lt;- \"Vecinos\"\nggplot(Guerry) + geom_sf(aes(fill = neighbors)) + theme_bw() +\n    scale_fill_manual(values = c(\"white\",\"gray30\", \"gray\"))\n\n\n\n# Construcción de la matriz W de pesos espaciales\nWnb &lt;- spdep::nb2listw(nb, style = \"W\")\nWnb\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 85 \nNumber of nonzero links: 420 \nPercentage nonzero weights: 5.813149 \nAverage number of links: 4.941176 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0      S1       S2\nW 85 7225 85 37.2761 347.6683\n\nhead(Wnb$weights)\n\n[[1]]\n[1] 0.25 0.25 0.25 0.25\n\n[[2]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[3]]\n[1] 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667 0.1666667\n\n[[4]]\n[1] 0.25 0.25 0.25 0.25\n\n[[5]]\n[1] 0.3333333 0.3333333 0.3333333\n\n[[6]]\n[1] 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571 0.1428571\n\nm &lt;- listw2mat(Wnb)\nlattice::levelplot(t(m))\n\n\n\n# Cálculo de los estadísticos de autocorrelación espacial\n\n# I de Moran global\nmoran.plot(Guerry$Crm_prs, Wnb)\n\n\n\ngmoran &lt;- moran.test(Guerry$Crm_prs, Wnb,\n                     alternative = \"greater\")\ngmoran\n\n\n    Moran I test under randomisation\n\ndata:  Guerry$Crm_prs  \nweights: Wnb    \n\nMoran I statistic standard deviate = 6.0484, p-value = 7.316e-10\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.411459718      -0.011904762       0.004899501 \n\ngmoranMC &lt;- moran.mc(Guerry$Crm_prs, Wnb, nsim = 999)\ngmoranMC\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  Guerry$Crm_prs \nweights: Wnb  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.41146, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\nhist(gmoranMC$res)\nabline(v = gmoranMC$statistic, col = \"red\")\n\n\n\n# I de Moran local (LISAs)\nlmoran &lt;- localmoran(Guerry$Crm_prs, Wnb, alternative = \"greater\")\nhead(lmoran)\n\n         Ii         E.Ii     Var.Ii      Z.Ii Pr(z &gt; E(Ii))\n1 0.5222645 -0.017946035 0.36097297 0.8991367   0.184289928\n2 0.8280165 -0.008874730 0.11710297 2.4455980   0.007230607\n3 0.8035400 -0.010412142 0.13717616 2.1976551   0.013986846\n4 0.7418897 -0.011161277 0.22605294 1.5838690   0.056611763\n5 0.2311872 -0.001382714 0.03818002 1.1902425   0.116975548\n6 0.8389098 -0.024865805 0.27314951 1.6527255   0.049193373\n\ntail(lmoran)\n\n             Ii          E.Ii      Var.Ii        Z.Ii Pr(z &gt; E(Ii))\n80  0.895182573 -0.0092176169 0.121585312  2.59370206   0.004747436\n81  0.025800751 -0.0001695898 0.003472936  0.44068598   0.329720173\n82 -0.330384096 -0.0055421769 0.073375477 -1.19921375   0.884777578\n83 -0.310472511 -0.0031036125 0.041190939 -1.51446442   0.935045954\n84  0.001292507 -0.0002866396 0.003815012  0.02556668   0.489801481\n85 -0.126709946 -0.0008641164 0.013969946 -1.06473485   0.856502032\n\nlibrary(tmap)\ntmap_mode(\"view\")\nGuerry$lmI &lt;- lmoran[, \"Ii\"]\nGuerry$lmZ &lt;- lmoran[, \"Z.Ii\"]\nGuerry$lmpval &lt;- lmoran[, \"Pr(z &gt; E(Ii))\"]\np1 &lt;- tm_shape(Guerry) +\n  tm_polygons(col = \"Crm_prs\", title = \"Crm_prs\", style = \"quantile\") +\n  tm_layout(legend.outside = TRUE)\np2 &lt;- tm_shape(Guerry) +\n  tm_polygons(col = \"lmI\", title = \"I de Moran local\",\n              style = \"quantile\") +\n  tm_layout(legend.outside = TRUE)\np3 &lt;- tm_shape(Guerry) +\n  tm_polygons(col = \"lmZ\", title = \"Z-score\",\n              breaks = c(-Inf, 1.65, Inf)) +\n  tm_layout(legend.outside = TRUE)\np4 &lt;- tm_shape(Guerry) +\n  tm_polygons(col = \"lmpval\", title = \"p-valor\",\n              breaks = c(-Inf, 0.05, Inf)) +\n  tm_layout(legend.outside = TRUE)\ntmap_arrange(p1, p2, p3, p4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(Guerry) + tm_polygons(col = \"lmZ\",\ntitle = \"I de Moran local\", style = \"fixed\",\nbreaks = c(-Inf, -1.96, 1.96, Inf),\nlabels = c(\"SAC negativa\", \"SAC no significativa\", \"SAC positiva\"),\npalette =  c(\"blue\", \"white\", \"red\")) +\ntm_layout(legend.outside = TRUE)\n\n\n\n\n\nlmoran2 &lt;- localmoran(Guerry$Crm_prs, Wnb, alternative = \"two.sided\")\nhead(lmoran2)\n\n         Ii         E.Ii     Var.Ii      Z.Ii Pr(z != E(Ii))\n1 0.5222645 -0.017946035 0.36097297 0.8991367     0.36857986\n2 0.8280165 -0.008874730 0.11710297 2.4455980     0.01446121\n3 0.8035400 -0.010412142 0.13717616 2.1976551     0.02797369\n4 0.7418897 -0.011161277 0.22605294 1.5838690     0.11322353\n5 0.2311872 -0.001382714 0.03818002 1.1902425     0.23395110\n6 0.8389098 -0.024865805 0.27314951 1.6527255     0.09838675\n\ntail(lmoran2)\n\n             Ii          E.Ii      Var.Ii        Z.Ii Pr(z != E(Ii))\n80  0.895182573 -0.0092176169 0.121585312  2.59370206    0.009494873\n81  0.025800751 -0.0001695898 0.003472936  0.44068598    0.659440345\n82 -0.330384096 -0.0055421769 0.073375477 -1.19921375    0.230444843\n83 -0.310472511 -0.0031036125 0.041190939 -1.51446442    0.129908092\n84  0.001292507 -0.0002866396 0.003815012  0.02556668    0.979602961\n85 -0.126709946 -0.0008641164 0.013969946 -1.06473485    0.286995936\n\nGuerry$lmpval2 &lt;- lmoran2[, 5] # columna 5 contiene p-valores\nmp &lt;- moran.plot(as.vector(scale(Guerry$Crm_prs)), Wnb)\n\n\n\n# Mapa LISA\nGuerry$quadrant &lt;- NA\n# Cuadrante HH (high-high)\nGuerry[(mp$x &gt;= 0 & mp$wx &gt;= 0) & (Guerry$lmpval2 &lt;= 0.05), \"quadrant\"]&lt;- 1\n# Cuadrante LL (low-low)\nGuerry[(mp$x &lt;= 0 & mp$wx &lt;= 0) & (Guerry$lmpval2 &lt;= 0.05), \"quadrant\"]&lt;- 2\n# Cuadrante HL (high-low)\nGuerry[(mp$x &gt;= 0 & mp$wx &lt;= 0) & (Guerry$lmpval2 &lt;= 0.05), \"quadrant\"]&lt;- 3\n# Cuadrante LH (low-high)\nGuerry[(mp$x &lt;= 0 & mp$wx &gt;= 0) & (Guerry$lmpval2 &lt;= 0.05), \"quadrant\"]&lt;- 4\n# Cuadrante NS (no significavo)\nGuerry[(Guerry$lmpval2 &gt; 0.05), \"quadrant\"] &lt;- 5\n\ntm_shape(Guerry) + tm_fill(col = \"quadrant\", title = \"\",\nbreaks = c(1, 2, 3, 4, 5, 6),\npalette =  c(\"red\", \"blue\", \"lightpink\", \"skyblue2\", \"white\"),\nlabels = c(\"HH\", \"LL\", \"HL\",\n           \"LH\", \"NS\")) +\ntm_legend(text.size = 1)  + tm_borders(alpha = 0.5) +\ntm_layout(frame = FALSE,  title = \"Clusters\")  +\ntm_layout(legend.outside = TRUE)\n\n\n\n\n\n# ECONOMETRÍA ESPACIAL: ANÁLISIS CONFIRMATORIO DE DATOS ESPACIALES\n\n# Modelos econométricos para explicar la variable Crm_prs\n\n# Regresión estándar (modelo lineal)\nCrm_LM &lt;- lm(Crm_prs ~ Region + Litercy + Donatns + Infants + Suicids,\n              data = Guerry)\nsummary(Crm_LM)\n\n\nCall:\nlm(formula = Crm_prs ~ Region + Litercy + Donatns + Infants + \n    Suicids, data = Guerry)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11260.7  -4301.5   -571.8   3783.8  14837.0 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.641e+04  3.425e+03   7.709 3.97e-11 ***\nRegionE     -3.068e+02  2.876e+03  -0.107    0.915    \nRegionN      2.469e+03  2.804e+03   0.881    0.381    \nRegionS     -1.090e+04  2.260e+03  -4.822 7.14e-06 ***\nRegionW      3.813e+02  2.290e+03   0.167    0.868    \nLitercy     -8.997e+01  6.347e+01  -1.417    0.160    \nDonatns     -1.896e-01  1.591e-01  -1.191    0.237    \nInfants      4.693e-03  9.099e-02   0.052    0.959    \nSuicids     -1.814e-03  2.480e-02  -0.073    0.942    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6196 on 76 degrees of freedom\nMultiple R-squared:  0.348, Adjusted R-squared:  0.2794 \nF-statistic: 5.071 on 8 and 76 DF,  p-value: 4.542e-05\n\n# Regresiones espaciales\nlibrary(spatialreg)\n\n# Retardo espacial de la variable dependiente (SLM) [estimación S2SLS]\nCrm_SLM &lt;- stsls(Crm_prs ~ Region + Litercy + Donatns + Infants + Suicids,\n                 data = Guerry,\n                 listw = Wnb)\nsummary(Crm_SLM)\n\n\nCall:stsls(formula = Crm_prs ~ Region + Litercy + Donatns + Infants + \n    Suicids, data = Guerry, listw = Wnb)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-11360.90  -3999.21   -609.53   3214.41  15225.47 \n\nCoefficients: \n               Estimate  Std. Error t value Pr(&gt;|t|)\nRho          7.5420e-01  2.5326e-01  2.9779 0.002902\n(Intercept)  8.0208e+03  6.9631e+03  1.1519 0.249359\nRegionE     -7.8425e+02  2.7086e+03 -0.2895 0.772166\nRegionN      7.2377e+01  2.7564e+03  0.0263 0.979052\nRegionS     -5.1597e+03  2.8685e+03 -1.7988 0.072057\nRegionW      3.8961e+02  2.1527e+03  0.1810 0.856382\nLitercy     -3.0311e+01  6.2948e+01 -0.4815 0.630148\nDonatns     -2.2687e-01  1.5015e-01 -1.5109 0.130809\nInfants      6.3493e-03  8.5547e-02  0.0742 0.940836\nSuicids      7.0054e-03  2.3501e-02  0.2981 0.765637\n\nResidual variance (sigma squared): 33939000, (sigma: 5825.7)\n\n# Retardo espacial de los errores (SEM) [estimación GMM]\nCrm_SEM &lt;- GMerrorsar(Crm_prs ~ Region + Litercy + Donatns + Infants + Suicids,\n                      data =Guerry,\n                      listw = Wnb)\nsummary(Crm_SEM)\n\n\nCall:GMerrorsar(formula = Crm_prs ~ Region + Litercy + Donatns + Infants + \n    Suicids, data = Guerry, listw = Wnb)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-11791.83  -4256.49   -222.09   4263.67  15003.03 \n\nType: GM SAR estimator\nCoefficients: (GM standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)  2.5396e+04  3.4824e+03  7.2927 3.038e-13\nRegionE     -1.0359e+03  2.9313e+03 -0.3534    0.7238\nRegionN      1.0069e+03  2.8768e+03  0.3500    0.7263\nRegionS     -1.0528e+04  2.4549e+03 -4.2885 1.799e-05\nRegionW     -1.8482e+02  2.4744e+03 -0.0747    0.9405\nLitercy     -6.0066e+01  6.2947e+01 -0.9542    0.3400\nDonatns     -1.8220e-01  1.5174e-01 -1.2007    0.2299\nInfants      1.2229e-02  8.3868e-02  0.1458    0.8841\nSuicids     -2.2536e-03  2.4192e-02 -0.0932    0.9258\n\nLambda: 0.26267 (standard error): 0.4347 (z-value): 0.60427\nResidual variance (sigma squared): 32698000, (sigma: 5718.2)\nGM argmin sigma squared: 32424000\nNumber of observations: 85 \nNumber of parameters estimated: 11 \n\n# Modelo combinado (SAC -&gt; SLM + SEM) [estimación GS2SLS]\nCrm_SAC &lt;- gstsls(Crm_prs ~ Region + Litercy + Donatns + Infants + Suicids,\n                      data =Guerry,\n                      listw = Wnb)\nsummary(Crm_SAC)\n\n\nCall:gstsls(formula = Crm_prs ~ Region + Litercy + Donatns + Infants + \n    Suicids, data = Guerry, listw = Wnb)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-10239.24  -4103.09   -218.59   3323.59  14042.87 \n\nType: GM SARAR estimator\nCoefficients: (GM standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\nRho_Wy       8.9782e-01  1.8980e-01  4.7304 2.241e-06\n(Intercept)  5.6147e+03  5.3284e+03  1.0537   0.29201\nRegionE      4.2234e+02  1.9800e+03  0.2133   0.83109\nRegionN      1.2128e+03  2.0200e+03  0.6004   0.54825\nRegionS     -3.0187e+03  2.2400e+03 -1.3477   0.17777\nRegionW      8.3674e+02  1.4787e+03  0.5658   0.57150\nLitercy     -5.6247e+01  4.8205e+01 -1.1668   0.24328\nDonatns     -2.1237e-01  1.2320e-01 -1.7238   0.08475\nInfants     -1.5936e-02  7.4019e-02 -0.2153   0.82954\nSuicids      6.8299e-03  1.8064e-02  0.3781   0.70536\n\nLambda: -0.60748\nResidual variance (sigma squared): 27852000, (sigma: 5277.5)\nGM argmin sigma squared: 25561000\nNumber of observations: 85 \nNumber of parameters estimated: 12 \n\n# Versiones estimadas por máxima verosimilitud\nCrm_SLM_2 &lt;- lagsarlm(Crm_prs ~ Region + Litercy + Donatns + Infants + Suicids,\n                 data = Guerry,\n                 listw = Wnb)\nsummary(Crm_SLM_2)\n\n\nCall:lagsarlm(formula = Crm_prs ~ Region + Litercy + Donatns + Infants + \n    Suicids, data = Guerry, listw = Wnb)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-9815.314 -4306.668   -55.825  4260.298 15031.038 \n\nType: lag \nCoefficients: (numerical Hessian approximate standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  1.7222e+04  4.6919e+03  3.6706 0.000242\nRegionE     -5.4531e+02  2.7258e+03 -0.2001 0.841439\nRegionN      1.2718e+03  2.7965e+03  0.4548 0.649259\nRegionS     -8.0315e+03  2.2666e+03 -3.5434 0.000395\nRegionW      3.8544e+02  2.0742e+03  0.1858 0.852581\nLitercy     -6.0168e+01  5.6138e+01 -1.0718 0.283815\nDonatns     -2.0823e-01  1.4136e-01 -1.4730 0.140757\nInfants      5.5205e-03  5.5539e-02  0.0994 0.920823\nSuicids      2.5915e-03  2.3303e-02  0.1112 0.911451\n\nRho: 0.37673, LR test value: 6.9655, p-value: 0.0083095\nApproximate (numerical Hessian) standard error: 0.13328\n    z-value: 2.8265, p-value: 0.0047054\nWald statistic: 7.9893, p-value: 0.0047054\n\nLog likelihood: -854.5647 for lag model\nML residual variance (sigma squared): 30596000, (sigma: 5531.3)\nNumber of observations: 85 \nNumber of parameters estimated: 11 \nAIC: 1731.1, (AIC for lm: 1736.1)\n\nCrm_SEM_2 &lt;- errorsarlm(Crm_prs ~  Region + Litercy + Donatns + Infants + Suicids,\n                       data = Guerry,\n                       listw = Wnb,\n                       Durbin = FALSE)\nsummary(Crm_SEM_2)\n\n\nCall:errorsarlm(formula = Crm_prs ~ Region + Litercy + Donatns + Infants + \n    Suicids, data = Guerry, listw = Wnb, Durbin = FALSE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-10770.31  -4238.89   -658.43   3347.89  15369.79 \n\nType: error \nCoefficients: (asymptotic standard errors) \n               Estimate  Std. Error z value  Pr(&gt;|z|)\n(Intercept)  2.5012e+04  3.5727e+03  7.0008 2.544e-12\nRegionE     -1.2123e+03  2.9929e+03 -0.4051    0.6854\nRegionN      4.8363e+02  2.9448e+03  0.1642    0.8695\nRegionS     -1.0329e+04  2.5682e+03 -4.0219 5.773e-05\nRegionW     -3.7700e+02  2.5848e+03 -0.1459    0.8840\nLitercy     -4.9483e+01  6.3640e+01 -0.7775    0.4368\nDonatns     -1.8187e-01  1.5155e-01 -1.2001    0.2301\nInfants      1.3675e-02  8.2765e-02  0.1652    0.8688\nSuicids     -1.8978e-03  2.4299e-02 -0.0781    0.9377\n\nLambda: 0.34269, LR test value: 3.6061, p-value: 0.057569\nApproximate (numerical Hessian) standard error: 0.16651\n    z-value: 2.058, p-value: 0.039586\nWald statistic: 4.2356, p-value: 0.039586\n\nLog likelihood: -856.2444 for error model\nML residual variance (sigma squared): 32024000, (sigma: 5659)\nNumber of observations: 85 \nNumber of parameters estimated: 11 \nAIC: NA (not available for weighted model), (AIC for lm: 1736.1)\n\nCrm_SAC_2 &lt;- sacsarlm(Crm_prs ~ Region + Litercy + Donatns + Infants + Suicids,\n                      data = Guerry,\n                      listw = Wnb)\nsummary(Crm_SAC_2)\n\n\nCall:sacsarlm(formula = Crm_prs ~ Region + Litercy + Donatns + Infants + \n    Suicids, data = Guerry, listw = Wnb)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-9518.93 -4094.65  -415.92  3955.99 14639.10 \n\nType: sac \nCoefficients: (numerical Hessian approximate standard errors) \n               Estimate  Std. Error z value Pr(&gt;|z|)\n(Intercept)  1.4668e+04  4.8636e+03  3.0159 0.002562\nRegionE     -5.6833e-01         NaN     NaN      NaN\nRegionN      1.7593e+03  1.4607e+03  1.2044 0.228419\nRegionS     -6.8264e+03  2.1260e+03 -3.2108 0.001323\nRegionW      6.9736e+02  1.4631e+03  0.4766 0.633613\nLitercy     -6.9346e+01  2.3895e+01 -2.9021 0.003707\nDonatns     -2.1431e-01  1.3310e-01 -1.6102 0.107357\nInfants     -3.1417e-03         NaN     NaN      NaN\nSuicids      4.3722e-03  1.9408e-02  0.2253 0.821758\n\nRho: 0.5054\nApproximate (numerical Hessian) standard error: 0.17131\n    z-value: 2.9502, p-value: 0.0031756\nLambda: -0.2419\nApproximate (numerical Hessian) standard error: 0.27179\n    z-value: -0.89001, p-value: 0.37346\n\nLR test value: 7.5349, p-value: 0.023111\n\nLog likelihood: -854.28 for sac model\nML residual variance (sigma squared): 29141000, (sigma: 5398.3)\nNumber of observations: 85 \nNumber of parameters estimated: 12 \nAIC: 1732.6, (AIC for lm: 1736.1)\n\n\n\n\nCódigo Python\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\n\nGuerry  = gpd.read_file('data/GUERRY_FRANCE.shp')\nGuerry.info()\n\n&lt;class 'geopandas.geodataframe.GeoDataFrame'&gt;\nRangeIndex: 85 entries, 0 to 84\nData columns (total 30 columns):\n #   Column     Non-Null Count  Dtype   \n---  ------     --------------  -----   \n 0   CODE_DE    85 non-null     object  \n 1   COUNT      85 non-null     float64 \n 2   AVE_ID_    85 non-null     float64 \n 3   dept       85 non-null     int64   \n 4   Region     85 non-null     object  \n 5   Dprtmnt    85 non-null     object  \n 6   Crm_prs    85 non-null     int64   \n 7   Crm_prp    85 non-null     int64   \n 8   Litercy    85 non-null     int64   \n 9   Donatns    85 non-null     int64   \n 10  Infants    85 non-null     int64   \n 11  Suicids    85 non-null     int64   \n 12  MainCty    85 non-null     int64   \n 13  Wealth     85 non-null     int64   \n 14  Commerc    85 non-null     int64   \n 15  Clergy     85 non-null     int64   \n 16  Crm_prn    85 non-null     int64   \n 17  Infntcd    85 non-null     int64   \n 18  Dntn_cl    85 non-null     int64   \n 19  Lottery    85 non-null     int64   \n 20  Desertn    85 non-null     int64   \n 21  Instrct    85 non-null     int64   \n 22  Prsttts    85 non-null     int64   \n 23  Distanc    85 non-null     float64 \n 24  Area       85 non-null     int64   \n 25  Pop1831    85 non-null     float64 \n 26  TopCrm     85 non-null     float64 \n 27  TopLit     85 non-null     float64 \n 28  TopWealth  85 non-null     float64 \n 29  geometry   85 non-null     geometry\ndtypes: float64(7), geometry(1), int64(19), object(3)\nmemory usage: 20.0+ KB\n\nGuerry\n\n   CODE_DE  COUNT  ...  TopWealth                                           geometry\n0       01    1.0  ...        1.0  POLYGON ((801150.000 2092615.000, 800669.000 2...\n1       02    1.0  ...        0.0  POLYGON ((729326.000 2521619.000, 729320.000 2...\n2       03    1.0  ...        1.0  POLYGON ((710830.000 2137350.000, 711746.000 2...\n3       04    1.0  ...        1.0  POLYGON ((882701.000 1920024.000, 882408.000 1...\n4       05    1.0  ...        1.0  POLYGON ((886504.000 1922890.000, 885733.000 1...\n..     ...    ...  ...        ...                                                ...\n80      85    1.0  ...        0.0  MULTIPOLYGON (((243055.000 2197885.000, 243019...\n81      86    1.0  ...        1.0  POLYGON ((450395.000 2119945.000, 450065.000 2...\n82      87    1.0  ...        1.0  POLYGON ((515230.000 2049895.000, 514990.000 2...\n83      88    1.0  ...        1.0  POLYGON ((951144.000 2383215.000, 953082.000 2...\n84      89    1.0  ...        0.0  POLYGON ((650260.000 2358330.000, 651712.000 2...\n\n[85 rows x 30 columns]\n\nGuerry.plot('Crm_prs', legend = True)\nplt.show()\n\n\n\n# ESTADÍSTICA ESPACIAL: ANÁLISIS EXPLORATORIO DE DATOS ESPACIALES (ESDA)\n\n# Librería pygeoda (https://geodacenter.github.io/pygeoda/)\nimport pygeoda\n\nGuerry_geoda = pygeoda.open(Guerry)\nGuerry_geoda\n\ngeoda object:\n     Number of observations: 85\n     Number of fields: 30\n     Geometry type(s): ('MultiPolygon', 'Polygon')\n             field name:      field type (numpy.dtype):\n                 CODE_DE                         object\n                   COUNT                        float64\n                 AVE_ID_                        float64\n                    dept                          int64\n                  Region                         object\n                 Dprtmnt                         object\n                 Crm_prs                          int64\n                 Crm_prp                          int64\n                 Litercy                          int64\n                 Donatns                          int64\n                 Infants                          int64\n                 Suicids                          int64\n                 MainCty                          int64\n                  Wealth                          int64\n                 Commerc                          int64\n                  Clergy                          int64\n                 Crm_prn                          int64\n                 Infntcd                          int64\n                 Dntn_cl                          int64\n                 Lottery                          int64\n                 Desertn                          int64\n                 Instrct                          int64\n                 Prsttts                          int64\n                 Distanc                        float64\n                    Area                          int64\n                 Pop1831                        float64\n                  TopCrm                        float64\n                  TopLit                        float64\n               TopWealth                        float64\n                geometry                       geometry\n\n# Matriz de pesos espaciales\nWq = pygeoda.queen_weights(Guerry_geoda)\n\n# Estadísticos de autocorrelación espacial para la variable Crm_prs\nLISA_Crm_prs = pygeoda.local_moran(Wq, Guerry_geoda['Crm_prs'])\nprint(LISA_Crm_prs)\n\nlisa object:\n\n    lisa_values(): [0.516120231288079, 0.8182751384950308, 0.7940865596945419, 0.733161543045998, 0.22846733444978454, 0.8290402723708735, 0.6152804476793944, 1.627415445739334, -0.019525625137996896, 0.6870818854535427, ...]\n    lisa_pvalues(): [0.197, 0.013, 0.023, 0.068, 0.111, 0.045, 0.281, 0.048, 0.183, 0.004, ...]\n    lisa_num_nbrs(): [4, 6, 6, 4, 3, 7, 3, 3, 5, 5, ...]\n    lisa_clusters(): [0, 1, 1, 0, 0, 2, 0, 2, 0, 2, ...]\n    lisa_labels(): ('Not significant', 'High-High', 'Low-Low', 'Low-High', 'High-Low', 'Undefined', 'Isolated')\n    lisa_colors(): ('#eeeeee', '#FF0000', '#0000FF', '#a7adf9', '#f4ada8', '#464646', '#999999')\n\nfig, ax = plt.subplots(figsize = (10,10))\nlisa_colors = LISA_Crm_prs.lisa_colors()\nlisa_labels = LISA_Crm_prs.lisa_labels()\nGuerry['LISA'] = LISA_Crm_prs.lisa_clusters()\nfor ctype, data in Guerry.groupby('LISA'):\n    color = lisa_colors[ctype]\n    lbl = lisa_labels[ctype]\n    data.plot(color = color,\n        ax = ax,\n        label = lbl,\n        edgecolor = 'black',\n        linewidth = 0.2)\nlisa_legend = [matplotlib.lines.Line2D([0], [0], color=color, lw=2) for color in lisa_colors]\nax.legend(lisa_legend, lisa_labels,loc='lower left', fontsize=12, frameon=True)\nax.set(title='Mapa de Moran local de Crm_prs')\nax.set_axis_off()\nplt.show()\n\n\n\nGuerry['LISA_PVAL'] = LISA_Crm_prs.lisa_pvalues()\nfig, ax = plt.subplots(figsize = (10,10))\nGuerry.plot(color='#eeeeee', ax=ax, edgecolor = 'black', linewidth = 0.2)\nGuerry[Guerry['LISA_PVAL'] &lt;= 0.05].plot(color=\"#84f576\", ax=ax)\nGuerry[Guerry['LISA_PVAL'] &lt;= 0.01].plot(color=\"#53c53c\", ax=ax)\nGuerry[Guerry['LISA_PVAL'] &lt;= 0.001].plot(color=\"#348124\", ax=ax)\nax.set(title='Mapa de significación local de Crm_prs')\nax.set_axis_off()\nplt.show()\n\n\n\n# Librería PySAL (http://pysal.org/)\nimport libpysal\nimport esda\nfrom esda.moran import Moran, Moran_Local\nimport splot\nfrom splot.esda import moran_scatterplot, plot_moran, lisa_cluster, plot_local_autocorrelation\nfrom splot.libpysal import plot_spatial_weights\nfrom libpysal.weights import Queen, Rook, KNN\n\n# Construcción de la matriz W de pesos espaciales\nWnb = Queen.from_dataframe(Guerry)\nWnb.transform = 'r'\nplot_spatial_weights(Wnb, Guerry)\nplt.show()\n\n\n\nWnb.neighbors[0]\n\n[66, 35, 68, 36]\n\nWnb.neighbors[1]\n\n[48, 6, 72, 57, 56, 75]\n\nWnb.neighbors[2]\n\n[16, 68, 20, 55, 39, 60]\n\nWnb.neighbors[3]\n\n[4, 79, 78, 23]\n\nWnb.neighbors[4]\n\n[35, 3, 23]\n\nWnb.neighbors[5]\n\n[35, 23, 39, 40, 27, 45, 79]\n\n# Cálculo de los estadísticos de autocorrelación espacial\n\n# I de Moran global\ngmoran = Moran(Guerry['Crm_prs'], Wnb)\nprint(gmoran.I)\n\n0.41145971831297995\n\nprint(gmoran.p_sim)\n\n0.001\n\nmoran_scatterplot(gmoran, aspect_equal=True, zstandard=True)\nplt.show()\n\n\n\n# I de Moran local (LISAs)\nlmoran = Moran_Local(Guerry['Crm_prs'], Wnb, permutations = 999, seed=12345)\nlmoran.p_sim\n\narray([0.185, 0.008, 0.013, 0.045, 0.111, 0.048, 0.294, 0.045, 0.193,\n       0.002, 0.001, 0.046, 0.13 , 0.001, 0.3  , 0.266, 0.011, 0.427,\n       0.071, 0.113, 0.248, 0.3  , 0.221, 0.032, 0.347, 0.292, 0.138,\n       0.001, 0.006, 0.166, 0.43 , 0.012, 0.009, 0.243, 0.02 , 0.417,\n       0.066, 0.412, 0.063, 0.432, 0.11 , 0.143, 0.438, 0.113, 0.17 ,\n       0.009, 0.16 , 0.134, 0.034, 0.218, 0.004, 0.229, 0.086, 0.094,\n       0.465, 0.079, 0.039, 0.307, 0.063, 0.035, 0.135, 0.192, 0.322,\n       0.037, 0.165, 0.206, 0.07 , 0.201, 0.008, 0.054, 0.34 , 0.116,\n       0.357, 0.479, 0.281, 0.081, 0.033, 0.029, 0.06 , 0.003, 0.334,\n       0.123, 0.073, 0.498, 0.168])\n\nmoran_scatterplot(lmoran, p=0.05, zstandard =False) # p-valor=0.05\nplt.show()\n\n\n\nlisa_cluster(lmoran, Guerry, p=0.05)\nplt.show()\n\n\n\n# ECONOMETRÍA ESPACIAL: ANÁLISIS CONFIRMATORIO DE DATOS ESPACIALES\n\n# Modelos econométricos para explicar la variable Crm_prs\n\n# Regresión estándar (modelo lineal)\n# Librería statsmodels (https://www.statsmodels.org/stable/)\nimport statsmodels.formula.api as smf\nmodel = smf.ols(formula = \"Crm_prs ~ Region + Litercy + Donatns + Infants + Suicids\", data = Guerry)\nCrm_LM = model.fit()\nprint(Crm_LM.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                Crm_prs   R-squared:                       0.348\nModel:                            OLS   Adj. R-squared:                  0.279\nMethod:                 Least Squares   F-statistic:                     5.071\nDate:                Tue, 07 Nov 2023   Prob (F-statistic):           4.54e-05\nTime:                        07:06:42   Log-Likelihood:                -858.05\nNo. Observations:                  85   AIC:                             1734.\nDf Residuals:                      76   BIC:                             1756.\nDf Model:                           8                                         \nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n-------------------------------------------------------------------------------\nIntercept    2.641e+04   3425.318      7.709      0.000    1.96e+04    3.32e+04\nRegion[T.E]  -306.8258   2875.815     -0.107      0.915   -6034.507    5420.855\nRegion[T.N]  2468.9607   2803.985      0.881      0.381   -3115.660    8053.582\nRegion[T.S]  -1.09e+04   2260.121     -4.822      0.000   -1.54e+04   -6396.349\nRegion[T.W]   381.2855   2289.660      0.167      0.868   -4178.968    4941.539\nLitercy       -89.9681     63.471     -1.417      0.160    -216.381      36.445\nDonatns        -0.1896      0.159     -1.191      0.237      -0.507       0.127\nInfants         0.0047      0.091      0.052      0.959      -0.177       0.186\nSuicids        -0.0018      0.025     -0.073      0.942      -0.051       0.048\n==============================================================================\nOmnibus:                        2.467   Durbin-Watson:                   1.777\nProb(Omnibus):                  0.291   Jarque-Bera (JB):                2.198\nSkew:                           0.291   Prob(JB):                        0.333\nKurtosis:                       2.469   Cond. No.                     3.15e+05\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 3.15e+05. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n# Librería spreg (https://pysal.org/spreg/)\nimport spreg\nGuerry[\"Region_E\"] = (Guerry.Region == \"E\").astype(int)\nGuerry[\"Region_N\"] = (Guerry.Region == \"N\").astype(int)\nGuerry[\"Region_S\"] = (Guerry.Region == \"S\").astype(int)\nGuerry[\"Region_W\"] = (Guerry.Region == \"W\").astype(int)\n\n# Método OLS\nvariable_names = [\"Region_E\",\"Region_N\",\"Region_S\",\"Region_W\",\"Litercy\", \"Donatns\", \"Infants\", \"Suicids\",]\nspreg_LM = spreg.OLS(\n    # Variable dependiente\n    Guerry[[\"Crm_prs\"]].values,\n    # Variables explicativas \n    Guerry[variable_names].values,\n    # Nombre variable dependiente\n    name_y=\"Crm_prs\",\n    # Nombre variables explicativas \n    name_x=variable_names,\n)\nprint(spreg_LM.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: ORDINARY LEAST SQUARES\n-----------------------------------------\nData set            :     unknown\nWeights matrix      :        None\nDependent Variable  :     Crm_prs                Number of Observations:          85\nMean dependent var  :  19960.9412                Number of Variables   :           9\nS.D. dependent var  :   7299.2418                Degrees of Freedom    :          76\nR-squared           :      0.3480\nAdjusted R-squared  :      0.2794\nSum squared residual:2917886368.231                F-statistic           :      5.0710\nSigma-square        :38393241.687                Prob(F-statistic)     :   4.542e-05\nS.E. of regression  :    6196.228                Log likelihood        :    -858.047\nSigma-square ML     :34328074.920                Akaike info criterion :    1734.095\nS.E of regression ML:   5859.0165                Schwarz criterion     :    1756.079\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     t-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT    26405.2972444    3425.3179913       7.7088601       0.0000000\n            Region_E    -306.8257944    2875.8146118      -0.1066918       0.9153146\n            Region_N    2468.9606968    2803.9854963       0.8805184       0.3813545\n            Region_S    -10897.7695922    2260.1207644      -4.8217643       0.0000071\n            Region_W     381.2854636    2289.6603054       0.1665249       0.8681861\n             Litercy     -89.9680663      63.4709882      -1.4174676       0.1604331\n             Donatns      -0.1896216       0.1591457      -1.1914967       0.2371663\n             Infants       0.0046933       0.0909868       0.0515818       0.9589972\n             Suicids      -0.0018138       0.0247967      -0.0731487       0.9418799\n------------------------------------------------------------------------------------\n\nREGRESSION DIAGNOSTICS\nMULTICOLLINEARITY CONDITION NUMBER           13.689\n\nTEST ON NORMALITY OF ERRORS\nTEST                             DF        VALUE           PROB\nJarque-Bera                       2           2.198           0.3331\n\nDIAGNOSTICS FOR HETEROSKEDASTICITY\nRANDOM COEFFICIENTS\nTEST                             DF        VALUE           PROB\nBreusch-Pagan test                8           7.506           0.4831\nKoenker-Bassett test              8          10.218           0.2501\n================================ END OF REPORT =====================================\n\n# Modelo con retardo espacial (SLM) [estimación STLS: MC2E-espacial]\nspreg_SLM = spreg.GM_Lag(\n    # Variable dependiente\n    Guerry[[\"Crm_prs\"]].values,\n    # Variables explicativas \n    Guerry[variable_names].values,\n    # Nombre variable dependiente\n    name_y=\"Crm_prs\",\n    # Nombre variables explicativas \n    name_x=variable_names,\n    # Matriz W\n    w=Wnb, \n)\nprint(spreg_SLM.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: SPATIAL TWO STAGE LEAST SQUARES\n--------------------------------------------------\nData set            :     unknown\nWeights matrix      :     unknown\nDependent Variable  :     Crm_prs                Number of Observations:          85\nMean dependent var  :  19960.9412                Number of Variables   :          10\nS.D. dependent var  :   7299.2418                Degrees of Freedom    :          75\nPseudo R-squared    :      0.4333\nSpatial Pseudo R-squared:  0.3954\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     z-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT    9377.1977272    7551.3236721       1.2417952       0.2143121\n            Region_E    -749.0286259    2541.9933591      -0.2946619       0.7682522\n            Region_N     249.1940455    2631.7810455       0.0946865       0.9245639\n            Region_S    -5583.0610318    2938.9518231      -1.8996776       0.0574754\n            Region_W     388.9926618    2018.8162748       0.1926835       0.8472068\n             Litercy     -34.7121514      60.3013006      -0.5756452       0.5648551\n             Donatns      -0.2241173       0.1410189      -1.5892707       0.1119993\n             Infants       0.0062271       0.0802263       0.0776191       0.9381310\n             Suicids       0.0063547       0.0221141       0.2873598       0.7738369\n           W_Crm_prs       0.6985582       0.2839292       2.4603257       0.0138811\n------------------------------------------------------------------------------------\nInstrumented: W_Crm_prs\nInstruments: W_Donatns, W_Infants, W_Litercy, W_Region_E, W_Region_N,\n             W_Region_S, W_Region_W, W_Suicids\n================================ END OF REPORT =====================================\n\n# Modelo con errores espaciales (SEM) [estimación GMM]\nspreg_SEM = spreg.GM_Error(    # spreg.GM_Error_Het permite heteroscedasticidad\n    # Variable dependiente\n    Guerry[[\"Crm_prs\"]].values,\n    # Variables explicativas \n    Guerry[variable_names].values,\n    # Nombre variable dependiente\n    name_y=\"Crm_prs\",\n    # Nombre variables explicativas \n    name_x=variable_names,\n    # Matriz W\n    w=Wnb, \n)\nprint(spreg_SEM.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: SPATIALLY WEIGHTED LEAST SQUARES\n---------------------------------------------------\nData set            :     unknown\nWeights matrix      :     unknown\nDependent Variable  :     Crm_prs                Number of Observations:          85\nMean dependent var  :  19960.9412                Number of Variables   :           9\nS.D. dependent var  :   7299.2418                Degrees of Freedom    :          76\nPseudo R-squared    :      0.3283\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     z-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT    24096.2470449    3841.9929573       6.2718093       0.0000000\n            Region_E    -1424.1591860    3147.9263956      -0.4524118       0.6509723\n            Region_N    -637.0231106    3118.1809283      -0.2042932       0.8381244\n            Region_S    -9751.8508349    2848.4549540      -3.4235580       0.0006181\n            Region_W    -790.5662288    2861.6333204      -0.2762640       0.7823453\n             Litercy     -26.7123720      65.5442400      -0.4075472       0.6836061\n             Donatns      -0.1859657       0.1523064      -1.2209973       0.2220870\n             Infants       0.0156033       0.0810433       0.1925299       0.8473272\n             Suicids      -0.0003321       0.0246271      -0.0134856       0.9892404\n              lambda       0.4997085    \n------------------------------------------------------------------------------------\n================================ END OF REPORT =====================================\n\n# Modelo combinado (SAC -&gt; SLM + SEM) [estimación GMM]\nspreg_SAC = spreg.GM_Combo(\n    # Variable dependiente\n    Guerry[[\"Crm_prs\"]].values,\n    # Variables explicativas \n    Guerry[variable_names].values,\n    # Nombre variable dependiente\n    name_y=\"Crm_prs\",\n    # Nombre variables explicativas \n    name_x=variable_names,\n    # Matriz W\n    w=Wnb, \n)\nprint(spreg_SAC.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: SPATIALLY WEIGHTED TWO STAGE LEAST SQUARES\n-------------------------------------------------------------\nData set            :     unknown\nWeights matrix      :     unknown\nDependent Variable  :     Crm_prs                Number of Observations:          85\nMean dependent var  :  19960.9412                Number of Variables   :          10\nS.D. dependent var  :   7299.2418                Degrees of Freedom    :          75\nPseudo R-squared    :      0.4232\nSpatial Pseudo R-squared:  0.4115\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     z-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT    7996.0179257    6490.6551810       1.2319277       0.2179761\n            Region_E     801.5538728    1729.0192611       0.4635887       0.6429424\n            Region_N    1802.3527315    1881.9004563       0.9577301       0.3381989\n            Region_S    -3592.1010985    2588.8838370      -1.3875096       0.1652864\n            Region_W    1007.5858682    1283.3390004       0.7851284       0.4323783\n             Litercy     -70.9927265      45.0860522      -1.5746051       0.1153476\n             Donatns      -0.2068418       0.1102454      -1.8761937       0.0606287\n             Infants      -0.0261162       0.0668118      -0.3908914       0.6958775\n             Suicids       0.0063271       0.0158486       0.3992237       0.6897284\n           W_Crm_prs       0.8135936       0.2449130       3.3219692       0.0008938\n              lambda      -0.8013415    \n------------------------------------------------------------------------------------\nInstrumented: W_Crm_prs\nInstruments: W_Donatns, W_Infants, W_Litercy, W_Region_E, W_Region_N,\n             W_Region_S, W_Region_W, W_Suicids\n================================ END OF REPORT =====================================\n\n# Versiones estimadas por máxima verosimilitud\n# Modelo con retardo espacial (SLM)\nspreg_SLM_2 = spreg.ML_Lag(\n    # Variable dependiente\n    Guerry[[\"Crm_prs\"]].values,\n    # Variables explicativas \n    Guerry[variable_names].values,\n    # Nombre variable dependiente\n    name_y=\"Crm_prs\",\n    # Nombre variables explicativas \n    name_x=variable_names,\n    # Matriz W\n    w=Wnb, \n)\nprint(spreg_SLM_2.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: MAXIMUM LIKELIHOOD SPATIAL LAG (METHOD = FULL)\n-----------------------------------------------------------------\nData set            :     unknown\nWeights matrix      :     unknown\nDependent Variable  :     Crm_prs                Number of Observations:          85\nMean dependent var  :  19960.9412                Number of Variables   :          10\nS.D. dependent var  :   7299.2418                Degrees of Freedom    :          75\nPseudo R-squared    :      0.4201\nSpatial Pseudo R-squared:  0.3818\nSigma-square ML     :30595830.661                Log likelihood        :    -854.565\nS.E of regression   :    5531.350                Akaike info criterion :    1729.129\n                                                 Schwarz criterion     :    1753.556\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     z-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT    17221.9890457    4183.6343033       4.1165140       0.0000385\n            Region_E    -545.3071871    2574.1750950      -0.2118376       0.8322337\n            Region_N    1271.8334856    2503.9367003       0.5079336       0.6114999\n            Region_S    -8031.5303711    2246.9419353      -3.5744272       0.0003510\n            Region_W     385.4419801    2048.1286644       0.1881923       0.8507259\n             Litercy     -60.1683757      56.8203818      -1.0589224       0.2896351\n             Donatns      -0.2082252       0.1421283      -1.4650513       0.1429069\n             Infants       0.0055205       0.0813506       0.0678601       0.9458970\n             Suicids       0.0025915       0.0222660       0.1163874       0.9073455\n           W_Crm_prs       0.3767347       0.1246775       3.0216737       0.0025138\n------------------------------------------------------------------------------------\n================================ END OF REPORT =====================================\n\n# Modelo con errores espaciales (SEM)\nspreg_SEM_2 = spreg.ML_Error( \n    # Variable dependiente\n    Guerry[[\"Crm_prs\"]].values,\n    # Variables explicativas \n    Guerry[variable_names].values,\n    # Nombre variable dependiente\n    name_y=\"Crm_prs\",\n    # Nombre variables explicativas \n    name_x=variable_names,\n    # Matriz W\n    w=Wnb, \n)\nprint(spreg_SEM_2.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: MAXIMUM LIKELIHOOD SPATIAL ERROR (METHOD = FULL)\n-------------------------------------------------------------------\nData set            :     unknown\nWeights matrix      :     unknown\nDependent Variable  :     Crm_prs                Number of Observations:          85\nMean dependent var  :  19960.9412                Number of Variables   :           9\nS.D. dependent var  :   7299.2418                Degrees of Freedom    :          76\nPseudo R-squared    :      0.3422\nSigma-square ML     :32024233.391                Log likelihood        :    -856.244\nS.E of regression   :    5658.996                Akaike info criterion :    1730.489\n                                                 Schwarz criterion     :    1752.473\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     z-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT    25011.5705265    3572.6578259       7.0008301       0.0000000\n            Region_E    -1212.3323541    2992.9372008      -0.4050644       0.6854302\n            Region_N     483.6259084    2944.7665791       0.1642323       0.8695482\n            Region_S    -10328.8382346    2568.1528508      -4.0218939       0.0000577\n            Region_W    -377.0018738    2584.8041732      -0.1458532       0.8840373\n             Litercy     -49.4832464      63.6403426      -0.7775453       0.4368371\n             Donatns      -0.1818720       0.1515524      -1.2000598       0.2301161\n             Infants       0.0136754       0.0827652       0.1652308       0.8687623\n             Suicids      -0.0018978       0.0242990      -0.0781012       0.9377475\n              lambda       0.3426854       0.1367094       2.5066708       0.0121874\n------------------------------------------------------------------------------------\n================================ END OF REPORT ====================================="
  },
  {
    "objectID": "p3c2-app8b.html#código-r",
    "href": "p3c2-app8b.html#código-r",
    "title": "Aplicación 3.8b (Dependencia espacial - Geometría: puntos): Precio de la vivienda en el condado de Lucas [Ohio, Estados Unidos]",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(viridis)\nlibrary(sf)\nlibrary(geojsonsf)\nlibrary(spdep)\nlibrary(spatialreg)\n\n# Lectura de datos (house {spData} -&gt; Lucas county OH housing)\nhouse &lt;- geojson_sf(\"data/LUCAS_USA.geojson\")\nclass(house)\n\n[1] \"sf\"         \"data.frame\"\n\nstr(house)\n\nClasses 'sf' and 'data.frame':  25357 obs. of  25 variables:\n $ TLA       : num  3273 920 1956 1430 2208 ...\n $ s1993     : num  0 0 1 0 0 1 0 1 0 0 ...\n $ price     : num  303000 92000 90000 330000 185000 ...\n $ frontage  : num  177 100 192 200 241 154 320 362 500 220 ...\n $ s1998     : num  0 0 0 0 0 0 0 0 0 0 ...\n $ garage    : chr  \"attached\" \"detached\" \"attached\" \"no garage\" ...\n $ stories   : chr  \"one+half\" \"one\" \"two\" \"one+half\" ...\n $ syear     : chr  \"1996\" \"1997\" \"1993\" \"1997\" ...\n $ baths     : num  3 1 1 1 2 1 1 2 1 1 ...\n $ halfbaths : num  1 0 0 0 1 0 0 1 0 0 ...\n $ geometry  :sfc_POINT of length 25357; first list element:  'XY' num  -83.9 41.4\n $ wall      : chr  \"partbrk\" \"metlvnyl\" \"stucdrvt\" \"wood\" ...\n $ garagesqft: num  625 308 480 0 528 1200 360 672 624 780 ...\n $ s1996     : num  1 0 0 0 0 0 0 0 1 1 ...\n $ depth     : num  0 0 0 217 0 1420 0 0 990 0 ...\n $ rooms     : num  12 4 7 7 7 5 4 6 7 6 ...\n $ s1995     : num  0 0 0 0 1 0 1 0 0 0 ...\n $ beds      : num  4 2 3 4 3 1 2 3 3 2 ...\n $ lotsize   : num  53496 37900 52900 43560 225800 ...\n $ sdate     : num  960423 970421 931101 971223 950807 ...\n $ yrbuilt   : num  1978 1957 1937 1887 1978 ...\n $ avalue    : num  306514 84628 126514 199228 192514 ...\n $ s1994     : num  0 0 0 0 0 0 0 0 0 0 ...\n $ s1997     : num  0 1 0 1 0 0 0 0 0 0 ...\n $ age       : num  0.21 0.42 0.62 1.12 0.21 0.1 0.72 0.09 1.22 0.63 ...\n - attr(*, \"sf_column\")= chr \"geometry\"\n\nhouse\n\nSimple feature collection with 25357 features and 24 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -83.88239 ymin: 41.4169 xmax: -83.23993 ymax: 41.73226\nGeodetic CRS:  WGS 84\nFirst 10 features:\n    TLA s1993  price frontage s1998    garage  stories syear baths halfbaths\n1  3273     0 303000      177     0  attached one+half  1996     3         1\n2   920     0  92000      100     0  detached      one  1997     1         0\n3  1956     1  90000      192     0  attached      two  1993     1         0\n4  1430     0 330000      200     0 no garage one+half  1997     1         0\n5  2208     0 185000      241     0  attached      two  1995     2         1\n6  1232     1 100000      154     0  detached      one  1993     1         0\n7   832     0  43065      320     0  detached      one  1995     1         0\n8  3011     1 305000      362     0  attached one+half  1993     2         1\n9  1034     0  56493      500     0  detached      one  1996     1         0\n10  960     0  50000      220     0  detached      one  1996     1         0\n                     geometry     wall garagesqft s1996 depth rooms s1995 beds\n1   POINT (-83.87964 41.4169)  partbrk        625     1     0    12     0    4\n2   POINT (-83.87716 41.4172) metlvnyl        308     0     0     4     0    2\n3  POINT (-83.87271 41.41773) stucdrvt        480     0     0     7     0    3\n4   POINT (-83.8667 41.42522)     wood          0     0   217     7     0    4\n5  POINT (-83.83824 41.42928)  partbrk        528     0     0     7     1    3\n6  POINT (-83.86964 41.42953)     wood       1200     0  1420     5     0    1\n7   POINT (-83.84248 41.4297)     wood        360     0     0     4     1    2\n8  POINT (-83.83147 41.43122)  partbrk        672     0     0     6     0    3\n9  POINT (-83.86598 41.43207)     wood        624     1   990     7     0    3\n10    POINT (-83.84 41.43282)     wood        780     1     0     6     0    2\n   lotsize  sdate yrbuilt avalue s1994 s1997  age\n1    53496 960423    1978 306514     0     0 0.21\n2    37900 970421    1957  84628     0     1 0.42\n3    52900 931101    1937 126514     0     0 0.62\n4    43560 971223    1887 199228     0     1 1.12\n5   225800 950807    1978 192514     0     0 0.21\n6   214100 931101    1989 107914     0     0 0.10\n7    23500 951031    1927  49028     0     0 0.72\n8   324900 931229    1990 263400     0     0 0.09\n9   354200 960222    1877  76600     0     0 1.22\n10   37000 960607    1936  50714     0     0 0.63\n\n# Análisis exploratorio básico (EDA)\nsummary(house)\n\n      TLA           s1993            price           frontage     \n Min.   : 120   Min.   :0.0000   Min.   :  2000   Min.   :  0.00  \n 1st Qu.:1070   1st Qu.:0.0000   1st Qu.: 41900   1st Qu.: 40.00  \n Median :1318   Median :0.0000   Median : 65500   Median : 50.00  \n Mean   :1462   Mean   :0.1286   Mean   : 79018   Mean   : 64.27  \n 3rd Qu.:1682   3rd Qu.:0.0000   3rd Qu.: 97000   3rd Qu.: 75.00  \n Max.   :7616   Max.   :1.0000   Max.   :875000   Max.   :810.00  \n     s1998           garage            stories             syear          \n Min.   :0.0000   Length:25357       Length:25357       Length:25357      \n 1st Qu.:0.0000   Class :character   Class :character   Class :character  \n Median :0.0000   Mode  :character   Mode  :character   Mode  :character  \n Mean   :0.1727                                                           \n 3rd Qu.:0.0000                                                           \n Max.   :1.0000                                                           \n     baths         halfbaths               geometry         wall          \n Min.   :0.000   Min.   :0.0000   POINT        :25357   Length:25357      \n 1st Qu.:1.000   1st Qu.:0.0000   epsg:4326    :    0   Class :character  \n Median :1.000   Median :0.0000   +proj=long...:    0   Mode  :character  \n Mean   :1.242   Mean   :0.3412                                           \n 3rd Qu.:1.000   3rd Qu.:1.0000                                           \n Max.   :7.000   Max.   :3.0000                                           \n   garagesqft         s1996            depth            rooms       \n Min.   :   0.0   Min.   :0.0000   Min.   :   0.0   Min.   : 1.000  \n 1st Qu.: 280.0   1st Qu.:0.0000   1st Qu.: 105.0   1st Qu.: 5.000  \n Median : 396.0   Median :0.0000   Median : 120.0   Median : 6.000  \n Mean   : 369.5   Mean   :0.1908   Mean   : 119.1   Mean   : 6.115  \n 3rd Qu.: 484.0   3rd Qu.:0.0000   3rd Qu.: 140.0   3rd Qu.: 7.000  \n Max.   :5755.0   Max.   :1.0000   Max.   :1587.0   Max.   :20.000  \n     s1995             beds          lotsize           sdate       \n Min.   :0.0000   Min.   :0.000   Min.   :   702   Min.   :930104  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:  4700   1st Qu.:941025  \n Median :0.0000   Median :3.000   Median :  6800   Median :960520  \n Mean   :0.1629   Mean   :2.987   Mean   : 13332   Mean   :957704  \n 3rd Qu.:0.0000   3rd Qu.:3.000   3rd Qu.: 11100   3rd Qu.:970818  \n Max.   :1.0000   Max.   :9.000   Max.   :429100   Max.   :981005  \n    yrbuilt         avalue           s1994            s1997       \n Min.   :1835   Min.   :  1714   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:1924   1st Qu.: 38514   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1950   Median : 59800   Median :0.0000   Median :0.0000  \n Mean   :1945   Mean   : 73641   Mean   :0.1467   Mean   :0.1984  \n 3rd Qu.:1964   3rd Qu.: 91114   3rd Qu.:0.0000   3rd Qu.:0.0000  \n Max.   :1998   Max.   :788114   Max.   :1.0000   Max.   :1.0000  \n      age        \n Min.   :0.0100  \n 1st Qu.:0.3500  \n Median :0.4900  \n Mean   :0.5366  \n 3rd Qu.:0.7500  \n Max.   :1.6400  \n\n# Análisis exploratorio para datos espaciales (ESDA)\n\n# Gráficas: representación de datos espaciales\nggplot(house) + geom_sf(aes(col = price)) + scale_color_viridis() + theme_bw()\n\n\n\nlibrary(leaflet)\npal &lt;- colorNumeric(palette = \"viridis\", domain = house$price)\nleaflet(house) %&gt;% addTiles() %&gt;%\n    addCircles(lng = st_coordinates(house)[, 1],\n               lat = st_coordinates(house)[, 2],\n               color = ~pal(price)) %&gt;%\n    addLegend(pal = pal, values = ~price, position = \"bottomright\")\n\n\n\n\n# Información sobre las coordenadas (longitud y latitud) de los datos\n# coords &lt;- coordinates(house_sf)\ncoords &lt;- st_coordinates(house)\n# Construcción de matrices de pesos espaciales: \n# Vecinos más próximos (k=6, mediana de vecinos)\nknn6 &lt;- knearneigh(coords, k=6) \nnb6nn &lt;- knn2nb(knn6)\n# Gráficos de vecinos\nplot(st_geometry(house)) \nplot(nb6nn, coords, add=TRUE, col=\"red\")\n\n\n\n# Matriz espacial W estandarizada por filas\nWnb6nn &lt;- nb2listw(neighbours=nb6nn, style=\"W\")\nWnb6nn\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 25357 \nNumber of nonzero links: 152142 \nPercentage nonzero weights: 0.02366211 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\nWeights style: W \nWeights constants summary:\n      n        nn    S0       S1       S2\nW 25357 642977449 25357 7570.944 104462.6\n\n# Estadísticos de autocorrelación espacial\n# Globales\nmoran.test(house$price, listw=Wnb6nn)\n\n\n    Moran I test under randomisation\n\ndata:  house$price  \nweights: Wnb6nn    \n\nMoran I statistic standard deviate = 226.75, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     7.777479e-01     -3.943840e-05      1.176627e-05 \n\nmoran.plot(house$price, listw=Wnb6nn)\n\n\n\n# Locales (LISAs)\nLocalI &lt;- as.data.frame(localmoran(house$price, listw=Wnb6nn))\nstr(LocalI)\n\n'data.frame':   25357 obs. of  5 variables:\n $ Ii            : num  3.875 0.353 0.273 1.586 0.921 ...\n $ E.Ii          : num  -5.56e-04 -1.87e-06 -1.34e-06 -6.98e-04 -1.24e-04 ...\n $ Var.Ii        : num  2.34795 0.00789 0.00565 2.94771 0.52591 ...\n $ Z.Ii          : num  2.529 3.972 3.627 0.924 1.27 ...\n $ Pr(z != E(Ii)): num  1.14e-02 7.12e-05 2.87e-04 3.56e-01 2.04e-01 ...\n\nhouse_LocalI &lt;- bind_cols(house,LocalI)\nplot(house_LocalI[\"Z.Ii\"])\n\n\n\nplot(house_LocalI[\"Pr(z != E(Ii))\"])\n\n\n\n# Modelos econométricos espaciales\nform &lt;- formula(log(price) ~ age + log(lotsize) + rooms)\n# Modelo lineal (LM) [estimación MCO]\nm1_LM &lt;- lm(formula=form, data=house)\nsummary(m1_LM)\n\n\nCall:\nlm(formula = form, data = house)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2148 -0.2090  0.0662  0.2914  2.8415 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   8.793591   0.042969  204.65   &lt;2e-16 ***\nage          -1.475724   0.012249 -120.47   &lt;2e-16 ***\nlog(lotsize)  0.244074   0.004395   55.53   &lt;2e-16 ***\nrooms         0.135360   0.002383   56.79   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4791 on 25353 degrees of freedom\nMultiple R-squared:  0.6057,    Adjusted R-squared:  0.6057 \nF-statistic: 1.298e+04 on 3 and 25353 DF,  p-value: &lt; 2.2e-16\n\n# Modelo con retardo espacial (SLM)\nm2_SLM &lt;- stsls(formula=form, data=house, listw=Wnb6nn)\nsummary(m2_SLM)\n\n\nCall:stsls(formula = form, data = house, listw = Wnb6nn)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-2.474539 -0.140669  0.041546  0.203977  2.414065 \n\nCoefficients: \n               Estimate Std. Error t value  Pr(&gt;|t|)\nRho           0.5238190  0.0085133  61.529 &lt; 2.2e-16\n(Intercept)   4.0433688  0.0830646  48.677 &lt; 2.2e-16\nage          -0.7479265  0.0147058 -50.859 &lt; 2.2e-16\nlog(lotsize)  0.1158118  0.0037650  30.760 &lt; 2.2e-16\nrooms         0.0925783  0.0018369  50.400 &lt; 2.2e-16\n\nResidual variance (sigma squared): 0.11678, (sigma: 0.34174)\n\n# Modelo con errores espaciales (SEM)\nm3_SEM &lt;- GMerrorsar(formula=form, data=house, listw=Wnb6nn)\nsummary(m3_SEM)\n\n\nCall:GMerrorsar(formula = form, data = house, listw = Wnb6nn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.15072 -0.20516  0.10807  0.33411  2.54157 \n\nType: GM SAR estimator\nCoefficients: (GM standard errors) \n               Estimate Std. Error z value  Pr(&gt;|z|)\n(Intercept)   8.8153942  0.0483589 182.291 &lt; 2.2e-16\nage          -0.8687533  0.0137399 -63.228 &lt; 2.2e-16\nlog(lotsize)  0.2266407  0.0051131  44.326 &lt; 2.2e-16\nrooms         0.1027348  0.0020207  50.842 &lt; 2.2e-16\n\nLambda: 0.68971 (standard error): 0.011167 (z-value): 61.765\nResidual variance (sigma squared): 0.11915, (sigma: 0.34518)\nGM argmin sigma squared: 0.11951\nNumber of observations: 25357 \nNumber of parameters estimated: 6 \n\n# Modelo combinado (SAC -&gt; SLM + SEM)\nm4_SAC &lt;- gstsls(formula=form, data=house, listw=Wnb6nn)\nsummary(m4_SAC)\n\n\nCall:gstsls(formula = form, data = house, listw = Wnb6nn)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-2.385331 -0.136218  0.034588  0.189469  2.532176 \n\nType: GM SARAR estimator\nCoefficients: (GM standard errors) \n               Estimate Std. Error z value  Pr(&gt;|z|)\nRho_Wy        0.5181163  0.0089184  58.095 &lt; 2.2e-16\n(Intercept)   3.8960079  0.0893889  43.585 &lt; 2.2e-16\nage          -0.7048022  0.0140979 -49.993 &lt; 2.2e-16\nlog(lotsize)  0.1338316  0.0043795  30.559 &lt; 2.2e-16\nrooms         0.0965855  0.0018600  51.929 &lt; 2.2e-16\n\nLambda: 0.35507\nResidual variance (sigma squared): 0.10716, (sigma: 0.32736)\nGM argmin sigma squared: 0.10757\nNumber of observations: 25357 \nNumber of parameters estimated: 7"
  },
  {
    "objectID": "p3c2-app8b.html#código-python",
    "href": "p3c2-app8b.html#código-python",
    "title": "Aplicación 3.8b (Dependencia espacial - Geometría: puntos): Precio de la vivienda en el condado de Lucas [Ohio, Estados Unidos]",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport geopandas as gpd\nimport libpysal\nfrom libpysal  import weights\nimport esda\nfrom esda.moran import Moran, Moran_Local\nimport splot\nfrom splot.esda import moran_scatterplot, plot_moran, lisa_cluster, plot_local_autocorrelation\nfrom splot.libpysal import plot_spatial_weights\nimport statsmodels.formula.api as smf\nimport spreg\n\n# Lectura de datos\nhouse = gpd.read_file(\"data/LUCAS_USA.geojson\")\nhouse.head(5)\n\n    price  yrbuilt   stories  ...  syear   age                    geometry\n0  303000     1978  one+half  ...   1996  0.21  POINT (-83.87964 41.41690)\n1   92000     1957       one  ...   1997  0.42  POINT (-83.87716 41.41720)\n2   90000     1937       two  ...   1993  0.62  POINT (-83.87271 41.41773)\n3  330000     1887  one+half  ...   1997  1.12  POINT (-83.86670 41.42522)\n4  185000     1978       two  ...   1995  0.21  POINT (-83.83824 41.42928)\n\n[5 rows x 25 columns]\n\n# Análisis exploratorio básico (EDA)\nhouse.describe().round(2)\n\n           price   yrbuilt       TLA  ...    s1997     s1998       age\ncount   25357.00  25357.00  25357.00  ...  25357.0  25357.00  25357.00\nmean    79017.94   1945.34   1462.25  ...      0.2      0.17      0.54\nstd     59655.02     27.88    613.12  ...      0.4      0.38      0.28\nmin      2000.00   1835.00    120.00  ...      0.0      0.00      0.01\n25%     41900.00   1924.00   1070.00  ...      0.0      0.00      0.35\n50%     65500.00   1950.00   1318.00  ...      0.0      0.00      0.49\n75%     97000.00   1964.00   1682.00  ...      0.0      0.00      0.75\nmax    875000.00   1998.00   7616.00  ...      1.0      1.00      1.64\n\n[8 rows x 20 columns]\n\n# Análisis exploratorio para datos espaciales (ESDA)\n\n# Mapas básicos\nhouse.plot('price', legend = True)\nplt.show()\n\n\n\n# Vecinos geográficos y matriz de pesos espaciales \nWnb6nn = weights.KNN.from_dataframe(house, k=6)\n# Estandarización por filas (Row-standardized W)\nWnb6nn.transform = 'r'\nplot_spatial_weights(Wnb6nn, house)\nplt.show()\n\n\n\n# Estadísticos de autocorrelación espacial\n# Dependencia espacial global\nglobalMoran = Moran(house['price'], Wnb6nn)\nprint(globalMoran.I)\n\n0.7777478528962092\n\nprint(globalMoran.p_sim)\n\n0.001\n\nmoran_scatterplot(globalMoran, aspect_equal=True, zstandard=True)\nplt.show()\n\n\n\n# Dependencia espacial local\nlocalMoran = Moran_Local(house['price'], Wnb6nn, permutations = 999, seed=12345)\nlocalMoran.p_sim\n\narray([0.018, 0.003, 0.005, ..., 0.312, 0.119, 0.046])\n\nmoran_scatterplot(localMoran, p=0.05, zstandard =False) # Nota: p-valor=0.05\nplt.show()\n\n\n\nlisa_cluster(localMoran, house, p=0.05)\nplt.show()\n\n\n\n# Modelos econométricos espaciales\n# Operaciones con variables\nhouse['l_price']=house['price'].map(lambda x:np.log(x))\nhouse['l_lotsize']=house['lotsize'].map(lambda x:np.log(x))\nvariable_names = ['age', 'l_lotsize', 'rooms']\n# Modelo lineal (LM)\nm1_LM = spreg.OLS(\n    # Var. dep.\n    house[['l_price']].values, \n    # Var. expl.\n    house[variable_names].values,\n    # \n    name_y='l_price', \n    # \n    name_x=variable_names\n)\nprint(m1_LM.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: ORDINARY LEAST SQUARES\n-----------------------------------------\nData set            :     unknown\nWeights matrix      :        None\nDependent Variable  :     l_price                Number of Observations:       25357\nMean dependent var  :     11.0203                Number of Variables   :           4\nS.D. dependent var  :      0.7629                Degrees of Freedom    :       25353\nR-squared           :      0.6057\nAdjusted R-squared  :      0.6057\nSum squared residual:    5818.903                F-statistic           :  12983.3074\nSigma-square        :       0.230                Prob(F-statistic)     :           0\nS.E. of regression  :       0.479                Log likelihood        :  -17317.995\nSigma-square ML     :       0.229                Akaike info criterion :   34643.990\nS.E of regression ML:      0.4790                Schwarz criterion     :   34676.554\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     t-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT       8.7935911       0.0429690     204.6496305       0.0000000\n                 age      -1.4757244       0.0122493    -120.4742831       0.0000000\n           l_lotsize       0.2440741       0.0043952      55.5317466       0.0000000\n               rooms       0.1353600       0.0023835      56.7912500       0.0000000\n------------------------------------------------------------------------------------\n\nREGRESSION DIAGNOSTICS\nMULTICOLLINEARITY CONDITION NUMBER           37.126\n\nTEST ON NORMALITY OF ERRORS\nTEST                             DF        VALUE           PROB\nJarque-Bera                       2       14610.253           0.0000\n\nDIAGNOSTICS FOR HETEROSKEDASTICITY\nRANDOM COEFFICIENTS\nTEST                             DF        VALUE           PROB\nBreusch-Pagan test                3        3911.303           0.0000\nKoenker-Bassett test              3        1566.036           0.0000\n================================ END OF REPORT =====================================\n\n# Modelo con retardo espacial (SLM)\nm2_SLM = spreg.GM_Lag(\n    # Var. dep.\n    house[['l_price']].values, \n    # Var. expl.\n    house[variable_names].values,\n    # Matriz W\n    w=Wnb6nn, \n    # \n    name_y='l_price', \n    # \n    name_x=variable_names\n)\nprint(m2_SLM.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: SPATIAL TWO STAGE LEAST SQUARES\n--------------------------------------------------\nData set            :     unknown\nWeights matrix      :     unknown\nDependent Variable  :     l_price                Number of Observations:       25357\nMean dependent var  :     11.0203                Number of Variables   :           5\nS.D. dependent var  :      0.7629                Degrees of Freedom    :       25352\nPseudo R-squared    :      0.8023\nSpatial Pseudo R-squared:  0.6334\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     z-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT       4.0742195       0.0838232      48.6049183       0.0000000\n                 age      -0.7526533       0.0148120     -50.8137599       0.0000000\n           l_lotsize       0.1166448       0.0037808      30.8515814       0.0000000\n               rooms       0.0928562       0.0018419      50.4119119       0.0000000\n           W_l_price       0.5204171       0.0086013      60.5045621       0.0000000\n------------------------------------------------------------------------------------\nInstrumented: W_l_price\nInstruments: W_age, W_l_lotsize, W_rooms\n================================ END OF REPORT =====================================\n\n# Modelo con errores espaciales (SEM)\nm3_SEM = spreg.GM_Error(\n    # Var. dep.\n    house[['l_price']].values, \n    # Var. expl.\n    house[variable_names].values,\n    # Matriz W\n    w=Wnb6nn, \n    #  \n    name_y='l_price', \n    # \n    name_x=variable_names\n)\nprint(m3_SEM.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: SPATIALLY WEIGHTED LEAST SQUARES\n---------------------------------------------------\nData set            :     unknown\nWeights matrix      :     unknown\nDependent Variable  :     l_price                Number of Observations:       25357\nMean dependent var  :     11.0203                Number of Variables   :           4\nS.D. dependent var  :      0.7629                Degrees of Freedom    :       25353\nPseudo R-squared    :      0.5976\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     z-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT       8.8153993       0.0461171     191.1525709       0.0000000\n                 age      -0.8687492       0.0131030     -66.3016384       0.0000000\n           l_lotsize       0.2266399       0.0048760      46.4802668       0.0000000\n               rooms       0.1027347       0.0019270      53.3138424       0.0000000\n              lambda       0.6897112    \n------------------------------------------------------------------------------------\n================================ END OF REPORT =====================================\n\n# Modelo combinado (SAC -&gt; SLM + SEM)\nm4_SAC = spreg.GM_Combo(\n    # Var. dep.\n    house[['l_price']].values, \n    # Var. expl.\n    house[variable_names].values,\n    # Matriz W\n    w=Wnb6nn, \n    # \n    name_y='l_price', \n    # \n    name_x=variable_names\n)\nprint(m4_SAC.summary)\n\nREGRESSION\n----------\nSUMMARY OF OUTPUT: SPATIALLY WEIGHTED TWO STAGE LEAST SQUARES\n-------------------------------------------------------------\nData set            :     unknown\nWeights matrix      :     unknown\nDependent Variable  :     l_price                Number of Observations:       25357\nMean dependent var  :     11.0203                Number of Variables   :           5\nS.D. dependent var  :      0.7629                Degrees of Freedom    :       25352\nPseudo R-squared    :      0.8013\nSpatial Pseudo R-squared:  0.6295\n\n------------------------------------------------------------------------------------\n            Variable     Coefficient       Std.Error     z-Statistic     Probability\n------------------------------------------------------------------------------------\n            CONSTANT       3.9075801       0.0896641      43.5802146       0.0000000\n                 age      -0.7057344       0.0141011     -50.0480675       0.0000000\n           l_lotsize       0.1344617       0.0043901      30.6285971       0.0000000\n               rooms       0.0966978       0.0018608      51.9669274       0.0000000\n           W_l_price       0.5165339       0.0089432      57.7572867       0.0000000\n              lambda       0.3593850    \n------------------------------------------------------------------------------------\nInstrumented: W_l_price\nInstruments: W_age, W_l_lotsize, W_rooms\n================================ END OF REPORT ====================================="
  },
  {
    "objectID": "p3c2-app9.html#código-r",
    "href": "p3c2-app9.html#código-r",
    "title": "Aplicación 3.9 (Información muestral - Falta de observaciones): Exclusión social en el comportamiento de las aseguradoras de Chicago",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\n# Lectura de datos\n# library(faraway)\n# help(chredlin, package=\"faraway\")\nchmiss &lt;- read.csv(\"data/SEGUROS_CHICAGO.csv\", header=TRUE, row.names=\"zip\") \n# Versión tidyverse: read_csv(\"SEGUROS_CHICAGO.csv\") %&gt;% \n# column_to_rownames(., var = \"zip\")\nchmiss\n\n      race fire theft  age involact income\n60626 10.0  6.2    29 60.4       NA 11.744\n60640 22.2  9.5    44 76.5      0.1  9.323\n60613 19.6 10.5    36   NA      1.2  9.948\n60657 17.3  7.7    37   NA      0.5 10.656\n60614 24.5  8.6    53 81.4      0.7  9.730\n60610 54.0 34.1    68 52.6      0.3  8.231\n60611  4.9 11.0    75 42.6      0.0 21.480\n60625  7.1  6.9    18 78.5      0.0 11.104\n60618  5.3  7.3    31 90.1       NA 10.694\n60647 21.5 15.1    NA 89.8      1.1  9.631\n60622 43.1 29.1    34 82.7      1.9  7.995\n60631  1.1  2.2    14 40.2      0.0 13.722\n60646   NA  5.7    11 27.9      0.0 16.250\n60656  1.7  2.0    11  7.7      0.0 13.686\n60630  1.6  2.5    22 63.8      0.0 12.405\n60634  1.5  3.0    NA 51.2      0.0 12.198\n60641  1.8  5.4    27 85.1      0.0 11.600\n60635  1.0  2.2     9 44.4      0.0 12.765\n60639  2.5  7.2    29 84.2      0.2 11.084\n60651   NA 15.1    30 89.8      0.8 10.510\n60644 59.8 16.5    40   NA      0.8  9.784\n60624 94.4 18.4    32 72.9      1.8  7.342\n60612 86.2 36.2    41 63.1      1.8  6.565\n60607 50.2   NA   147 83.0      0.9  7.459\n60623 74.2 18.5    22 78.3      1.9  8.014\n60608 55.5   NA    29 79.0      1.5  8.177\n60616   NA 12.2    46 48.0      0.6  8.212\n60632  4.4  5.6    23 71.5      0.3 11.230\n60609 46.2 21.8     4 73.1      1.3     NA\n60653 99.7 21.6    31 65.0      0.9  5.583\n60615 73.5  9.0    39 75.4      0.4  8.564\n60638 10.7  3.6    15 20.8      0.0 12.102\n60629  1.5  5.0    32 61.8       NA 11.876\n60636 48.8 28.6    27 78.1      1.4  9.742\n60621 98.9 17.4    NA 68.6      2.2  7.520\n60637 90.6 11.3    34 73.4      0.8  7.388\n60652  1.4  3.4    17  2.0      0.0 13.842\n60620 71.2 11.9    46   NA      0.9 11.040\n60619 94.1 10.5    42 55.9      0.9 10.332\n60649 66.1 10.7    NA 67.5      0.4 10.908\n60617   NA 10.8    34 58.0      0.9 11.156\n60655  1.0  4.8    19 15.2      0.0 13.323\n60643 42.5 10.4    25 40.8      0.5 12.960\n60628 35.1 15.6    28 57.8      1.0     NA\n60627 47.4  7.0     3 11.4      0.2 10.080\n60633 34.0  7.1    23 49.2      0.3 11.428\n60645  3.1  4.9    27   NA      0.0 13.731\n\nsummary(chmiss)\n\n      race            fire           theft             age       \n Min.   : 1.00   Min.   : 2.00   Min.   :  3.00   Min.   : 2.00  \n 1st Qu.: 3.75   1st Qu.: 5.60   1st Qu.: 22.00   1st Qu.:48.30  \n Median :24.50   Median : 9.50   Median : 29.00   Median :64.40  \n Mean   :35.61   Mean   :11.42   Mean   : 32.65   Mean   :59.97  \n 3rd Qu.:57.65   3rd Qu.:15.10   3rd Qu.: 38.00   3rd Qu.:78.25  \n Max.   :99.70   Max.   :36.20   Max.   :147.00   Max.   :90.10  \n NA's   :4       NA's   :2       NA's   :4        NA's   :5      \n    involact          income      \n Min.   :0.0000   Min.   : 5.583  \n 1st Qu.:0.0000   1st Qu.: 8.564  \n Median :0.5000   Median :10.694  \n Mean   :0.6477   Mean   :10.736  \n 3rd Qu.:0.9250   3rd Qu.:12.102  \n Max.   :2.2000   Max.   :21.480  \n NA's   :3        NA's   :2       \n\n# Detección de datos perdidos\n# Por filas (casos)\nrowSums(is.na(chmiss))\n\n60626 60640 60613 60657 60614 60610 60611 60625 60618 60647 60622 60631 60646 \n    1     0     1     1     0     0     0     0     1     1     0     0     1 \n60656 60630 60634 60641 60635 60639 60651 60644 60624 60612 60607 60623 60608 \n    0     0     1     0     0     0     1     1     0     0     1     0     1 \n60616 60632 60609 60653 60615 60638 60629 60636 60621 60637 60652 60620 60619 \n    1     0     1     0     0     0     1     0     1     0     0     1     0 \n60649 60617 60655 60643 60628 60627 60633 60645 \n    1     1     0     0     1     0     0     1 \n\nimage(is.na(chmiss),axes=FALSE)\naxis(2, at=0:5/5, labels=colnames(chmiss),las=2)\naxis(1, at=0:46/46, labels=row.names(chmiss),las=2)\n\n\n\n# Por columnas (variables)\ncolSums(is.na(chmiss))\n\n    race     fire    theft      age involact   income \n       4        2        4        5        3        2 \n\nlibrary(mi)\nmd &lt;- missing_data.frame(chmiss)\nimage(md)\n\n\n\nsummary(md@patterns)\n\n nothing involact      age    theft     race     fire   income \n      27        3        5        4        4        2        2 \n\n# Tratamiento de datos perdidos\n# Omisión de observaciones (opción por defecto en R): \n# Resultados con datos completos\nmod_1 &lt;- lm(involact ~ race+fire+theft+age+log(income), chmiss)\nsummary(mod_1)\n\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income), \n    data = chmiss)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.59598 -0.19593 -0.05729  0.13641  0.63481 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.407202   1.419160  -1.696 0.104621    \nrace         0.011129   0.003443   3.232 0.003994 ** \nfire         0.045003   0.010696   4.208 0.000395 ***\ntheft       -0.016062   0.005550  -2.894 0.008678 ** \nage          0.009129   0.003443   2.652 0.014926 *  \nlog(income)  0.844261   0.531601   1.588 0.127196    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3392 on 21 degrees of freedom\n  (20 observations deleted due to missingness)\nMultiple R-squared:  0.7899,    Adjusted R-squared:  0.7399 \nF-statistic: 15.79 on 5 and 21 DF,  p-value: 1.688e-06\n\n# Imputación simple\n# Uso de la media para predecir los datos faltantes de los regresores\n(cmeans &lt;- colMeans(chmiss,na.rm=TRUE))\n\n      race       fire      theft        age   involact     income \n35.6093023 11.4244444 32.6511628 59.9690476  0.6477273 10.7358667 \n\nimput_1 &lt;- chmiss\nfor(i in c(1:4,6)) imput_1[is.na(chmiss[,i]),i] &lt;- cmeans[i] # Sólo var. expl.\nmod_2 &lt;- lm(involact ~ race+fire+theft+age+log(income), imput_1)\nsummary(mod_2)\n\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income), \n    data = imput_1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.00582 -0.15772 -0.00159  0.22214  0.80666 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  0.529635   1.087923   0.487  0.62917   \nrace         0.006975   0.002845   2.452  0.01893 * \nfire         0.028208   0.009541   2.956  0.00532 **\ntheft       -0.003310   0.002745  -1.206  0.23541   \nage          0.006244   0.003160   1.976  0.05543 . \nlog(income) -0.315826   0.390255  -0.809  0.42339   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3845 on 38 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.6813,    Adjusted R-squared:  0.6394 \nF-statistic: 16.25 on 5 and 38 DF,  p-value: 1.461e-08\n\n# Uso de regresiones para predecir los datos faltantes \n# de las variables explicativas\nmod_race &lt;- lm(race ~ fire+theft+age+income,chmiss)\nchmiss[is.na(chmiss$race),]\n\n      race fire theft  age involact income\n60646   NA  5.7    11 27.9      0.0 16.250\n60651   NA 15.1    30 89.8      0.8 10.510\n60616   NA 12.2    46 48.0      0.6  8.212\n60617   NA 10.8    34 58.0      0.9 11.156\n\npredict(mod_race,chmiss[is.na(chmiss$race),])\n\n    60646     60651     60616     60617 \n-17.84722  26.35970  70.39441  32.62029 \n\n# Como la predicción para la zona 60646 es negativa, \n# se puede usar la transformación logit ( log(y/(1-y)) ) \n# para evitar que las predicciones se salgan del intervalo [0,1] \n# y luego aplicar la transformación inversa a la predicción\nlibrary(faraway)\nmod_race_2 &lt;- lm(logit(race/100) ~ fire+theft+age+income,chmiss)\nilogit(predict(mod_race_2,chmiss[is.na(chmiss$race),]))*100\n\n     60646      60651      60616      60617 \n 0.4190909 14.7320193 84.2653995 21.3121261 \n\nmod_fire &lt;- lm(fire ~ race+theft+age+income,chmiss)\nchmiss[is.na(chmiss$fire),]\n\n      race fire theft age involact income\n60607 50.2   NA   147  83      0.9  7.459\n60608 55.5   NA    29  79      1.5  8.177\n\npredict(mod_fire,chmiss[is.na(chmiss$fire),])\n\n   60607    60608 \n50.23688 15.40465 \n\nmod_theft &lt;- lm(theft ~ race+fire+age+income,chmiss)\nchmiss[is.na(chmiss$theft),]\n\n      race fire theft  age involact income\n60647 21.5 15.1    NA 89.8      1.1  9.631\n60634  1.5  3.0    NA 51.2      0.0 12.198\n60621 98.9 17.4    NA 68.6      2.2  7.520\n60649 66.1 10.7    NA 67.5      0.4 10.908\n\npredict(mod_theft,chmiss[is.na(chmiss$theft),])\n\n   60647    60634    60621    60649 \n35.82849 20.86813 35.39362 38.04624 \n\nmod_age &lt;- lm(age ~ race+fire+theft+income,chmiss)\nchmiss[is.na(chmiss$age),]\n\n      race fire theft age involact income\n60613 19.6 10.5    36  NA      1.2  9.948\n60657 17.3  7.7    37  NA      0.5 10.656\n60644 59.8 16.5    40  NA      0.8  9.784\n60620 71.2 11.9    46  NA      0.9 11.040\n60645  3.1  4.9    27  NA      0.0 13.731\n\npredict(mod_age,chmiss[is.na(chmiss$age),])\n\n   60613    60657    60644    60620    60645 \n74.11181 71.75477 64.29939 59.13367 45.83281 \n\nmod_income &lt;- lm(income ~ race+fire+theft+age,chmiss)\nchmiss[is.na(chmiss$income),]\n\n      race fire theft  age involact income\n60609 46.2 21.8     4 73.1      1.3     NA\n60628 35.1 15.6    28 57.8      1.0     NA\n\npredict(mod_income,chmiss[is.na(chmiss$income),])\n\n    60609     60628 \n 6.338472 10.190580 \n\n# Generación de valores para los datos perdidos por variable\nimput_2  &lt;- chmiss\nimput_2$race[is.na(chmiss$race)] &lt;- \n  ilogit(predict(mod_race_2,chmiss[is.na(chmiss$race),]))*100\nimput_2$fire[is.na(chmiss$fire)] &lt;- \n  predict(mod_fire,chmiss[is.na(chmiss$fire),])\nimput_2$theft[is.na(chmiss$theft)] &lt;-  \n  predict(mod_theft,chmiss[is.na(chmiss$theft),])\nimput_2$age[is.na(chmiss$age)] &lt;-  \n  predict(mod_age,chmiss[is.na(chmiss$age),])\nimput_2$income[is.na(chmiss$income)] &lt;-  \n  predict(mod_income,chmiss[is.na(chmiss$income),])\n#\nmod_3 &lt;- lm(involact ~ race+fire+theft+age+log(income), imput_2)\nsummary(mod_3)\n\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income), \n    data = imput_2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7475 -0.1841 -0.0582  0.2203  0.8484 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.329475   1.212672  -1.096 0.279839    \nrace         0.009550   0.002627   3.635 0.000820 ***\nfire         0.039664   0.009974   3.977 0.000303 ***\ntheft       -0.012791   0.003615  -3.539 0.001080 ** \nage          0.009848   0.003071   3.207 0.002723 ** \nlog(income)  0.408210   0.443478   0.920 0.363132    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3581 on 38 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.7235,    Adjusted R-squared:  0.6872 \nF-statistic: 19.89 on 5 and 38 DF,  p-value: 1.067e-09\n\n# Imputación múltiple \n# Enfoque AMELIA (https://cran.r-project.org/web/packages/Amelia/index.html)\nlibrary(Amelia)\nimput_3 &lt;- amelia(chmiss, m=10)\n\n-- Imputation 1 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30 31 32 33 34\n\n-- Imputation 2 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30 31\n\n-- Imputation 3 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60\n 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80\n 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100\n 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200\n 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220\n 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240\n 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n 261 262 263 264 265 266\n\n-- Imputation 4 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13\n\n-- Imputation 5 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30 31\n\n-- Imputation 6 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23\n\n-- Imputation 7 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n 41 42 43 44\n\n-- Imputation 8 --\n\n  1  2  3  4  5  6  7  8\n\n-- Imputation 9 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38\n\n-- Imputation 10 --\n\n  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n 21 22 23 24 25 26 27 28 29 30\n\nsummary(imput_3)\n\n\nAmelia output with 10 imputed datasets.\nReturn code:  1 \nMessage:  Normal EM convergence. \n\nChain Lengths:\n--------------\nImputation 1:  34\nImputation 2:  31\nImputation 3:  266\nImputation 4:  13\nImputation 5:  31\nImputation 6:  23\nImputation 7:  44\nImputation 8:  8\nImputation 9:  38\nImputation 10:  30\n\nRows after Listwise Deletion:  27 \nRows after Imputation:  47 \nPatterns of missingness in the data:  7 \n\nFraction Missing for original variables: \n-----------------------------------------\n\n         Fraction Missing\nrace           0.08510638\nfire           0.04255319\ntheft          0.08510638\nage            0.10638298\ninvolact       0.06382979\nincome         0.04255319\n\nbetas &lt;- NULL\nse_betas &lt;- NULL\nfor(i in 1:imput_3$m){\n  lmod &lt;- lm(involact ~ race+fire+theft+age+log(income), imput_3$imputations[[i]])\n  betas &lt;- rbind(betas ,coef(lmod))\n  se_betas &lt;- rbind(se_betas ,coef(summary(lmod))[,2])\n}\n# Estimaciones, desviaciones estándar estimadas y estadísticos t \n# (individuales y combinadas)\nbetas; se_betas\n\n      (Intercept)        race       fire         theft         age log(income)\n [1,]  -1.5525609 0.009937092 0.03870088 -0.0152888859 0.009631753  0.53071044\n [2,]  -1.9319807 0.009453789 0.04440711 -0.0160375613 0.009757833  0.68863489\n [3,]   0.2448739 0.007705441 0.03085692 -0.0009555429 0.003740203 -0.19107621\n [4,]  -1.3467722 0.009217949 0.04388865 -0.0142605811 0.008672619  0.44003774\n [5,]  -0.3409742 0.008060194 0.03501345 -0.0064161551 0.007061484  0.01934436\n [6,]  -1.1078476 0.008859360 0.04097190 -0.0113665740 0.007393054  0.36141559\n [7,]  -0.7420008 0.008563633 0.03355230 -0.0108660509 0.009499151  0.19525780\n [8,]  -0.5892517 0.007141891 0.03708851 -0.0087319441 0.008875525  0.12364921\n [9,]  -1.1094510 0.008858619 0.03494759 -0.0091012285 0.008898799  0.32620447\n[10,]  -2.2949774 0.011578763 0.04380959 -0.0183111733 0.011214960  0.80341878\n\n\n      (Intercept)        race        fire       theft         age log(income)\n [1,]   1.2433354 0.002496593 0.008429839 0.003644478 0.002822203   0.4603116\n [2,]   1.1233633 0.002063869 0.008161911 0.003113964 0.002497281   0.4180875\n [3,]   1.1425459 0.002893534 0.009577713 0.002689867 0.003029610   0.4140592\n [4,]   1.1266954 0.002299525 0.009287729 0.003372176 0.002712483   0.4170345\n [5,]   0.9521167 0.002407655 0.008675438 0.002243288 0.002676973   0.3432152\n [6,]   1.2043357 0.002573586 0.009052202 0.002993047 0.002627159   0.4432011\n [7,]   1.1022682 0.002430982 0.009130116 0.003280169 0.002702264   0.4048608\n [8,]   1.0496255 0.002455072 0.009714593 0.002891184 0.002693610   0.3847180\n [9,]   1.1039016 0.002453714 0.007685852 0.002389084 0.002596267   0.4039217\n[10,]   1.0582906 0.002222866 0.008224091 0.003496879 0.002532884   0.3936320\n\n(cr &lt;- mi.meld(q=betas,se=se_betas))\n\n$q.mi\n     (Intercept)        race       fire       theft         age log(income)\n[1,]   -1.077094 0.008937673 0.03832369 -0.01113357 0.008474538   0.3297597\n\n$se.mi\n     (Intercept)        race       fire       theft        age log(income)\n[1,]    1.367296 0.002767024 0.01015424 0.006197655 0.00344035      0.5193\n\n(cr$q.mi/cr$se.mi)\n\n     (Intercept)     race     fire     theft      age log(income)\n[1,]  -0.7877547 3.230067 3.774156 -1.796416 2.463278   0.6350081\n\n# Enfoque MICE (https://cran.r-project.org/web/packages/mice/)\nlibrary(mice)\n# Patrón de datos perdidos\nmd.pattern(chmiss)\n\n\n\n\n   fire income involact race theft age   \n27    1      1        1    1     1   1  0\n5     1      1        1    1     1   0  1\n4     1      1        1    1     0   1  1\n4     1      1        1    0     1   1  1\n3     1      1        0    1     1   1  1\n2     1      0        1    1     1   1  1\n2     0      1        1    1     1   1  1\n      2      2        3    4     4   5 20\n\n# Imputación simple con la media de los datos completos\nimp_4_0 &lt;- mice(chmiss, method = \"mean\", m = 1, maxit = 1)\n\n\n iter imp variable\n  1   1  race  fire  theft  age  involact  income\n\nimput_1_2 &lt;- complete(imp_4_0) # Se obtiene el mismo resultado que \n# en el fichero imput_1, pera también se imputan\nsummary(with(imput_1_2, lm(involact ~ race+fire+theft+age+log(income))))\n\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.99102 -0.18765  0.01174  0.21644  0.82392 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  0.628604   1.075959   0.584  0.56227   \nrace         0.006248   0.002765   2.259  0.02923 * \nfire         0.027110   0.009419   2.878  0.00632 **\ntheft       -0.003339   0.002716  -1.229  0.22599   \nage          0.006754   0.003044   2.219  0.03209 * \nlog(income) -0.345200   0.386098  -0.894  0.37650   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.381 on 41 degrees of freedom\nMultiple R-squared:  0.6624,    Adjusted R-squared:  0.6212 \nF-statistic: 16.09 on 5 and 41 DF,  p-value: 9.149e-09\n\n# Imputación por el método de regresión (1):\n# Predicción simple\nimp_4_1 &lt;- mice(chmiss, method = \"norm.predict\", m = 1, maxit = 1) \n\n\n iter imp variable\n  1   1  race  fire  theft  age  involact  income\n\nimput_2_1 &lt;- complete(imp_4_1) # Comparar con el fichero imput_2\n# Imputación por el método de regresión (2):\n# Predicción estocástica (se añade un error aleatorio)\nimp_4_2 &lt;- mice(chmiss, method = \"norm.nob\", m = 1, maxit = 1) \n\n\n iter imp variable\n  1   1  race  fire  theft  age  involact  income\n\nimput_2_2 &lt;- complete(imp_4_2) # Comparar con el fichero imput_2\n# Imputación por el método de regresión (3):\n# Predicción usando booostrap\nimp_4_3 &lt;- mice(chmiss, method = \"norm.boot\", m = 1, maxit = 1) \n\n\n iter imp variable\n  1   1  race  fire  theft  age  involact  income\n\nimput_2_3 &lt;- complete(imp_4_3) # Comparar con el fichero imput_2\n# MICE: Multiple Imputation Chained Equation\nimp_4 &lt;- mice(chmiss, m = 10, print=F)\nsummary(imp_4)\n\nClass: mids\nNumber of multiple imputations:  10 \nImputation methods:\n    race     fire    theft      age involact   income \n   \"pmm\"    \"pmm\"    \"pmm\"    \"pmm\"    \"pmm\"    \"pmm\" \nPredictorMatrix:\n         race fire theft age involact income\nrace        0    1     1   1        1      1\nfire        1    0     1   1        1      1\ntheft       1    1     0   1        1      1\nage         1    1     1   0        1      1\ninvolact    1    1     1   1        0      1\nincome      1    1     1   1        1      0\n\nclass(imp_4) # mids: multiply imputed data set\n\n[1] \"mids\"\n\nattributes(imp_4)\n\n$names\n [1] \"data\"            \"imp\"             \"m\"               \"where\"          \n [5] \"blocks\"          \"call\"            \"nmis\"            \"method\"         \n [9] \"predictorMatrix\" \"visitSequence\"   \"formulas\"        \"post\"           \n[13] \"blots\"           \"ignore\"          \"seed\"            \"iteration\"      \n[17] \"lastSeedValue\"   \"chainMean\"       \"chainVar\"        \"loggedEvents\"   \n[21] \"version\"         \"date\"           \n\n$class\n[1] \"mids\"\n\n# Para ver los datos imputados de una variable\nimp_4$imp # Todas las imputaciones\n\n$race\n         1    2    3    4    5    6    7    8    9   10\n60646  1.5  1.1  4.4  1.8  1.6  7.1  7.1  1.0  1.8  1.0\n60651 17.3 66.1 59.8 17.3 34.0 22.2 42.5 47.4 73.5 71.2\n60616 54.0 90.6 35.1 90.6 74.2 21.5 55.5 71.2 54.0 54.0\n60617 48.8 71.2 19.6 71.2 21.5 59.8 24.5 71.2 66.1 73.5\n\n$fire\n         1    2    3    4    5    6    7    8    9   10\n60607 36.2 17.4 18.5 18.4 29.1 17.4 29.1 18.5 29.1 29.1\n60608 10.5 18.4 18.4 18.5 10.5 21.6  8.6 10.5 34.1 21.6\n\n$theft\n       1  2  3  4  5  6  7  8  9 10\n60647 18 37 32 23 46 34 42 27 44 46\n60634 14 14 27  9 22 22 14 23 32 42\n60621 29 14 11 27 11 11 36 14 19  3\n60649 41 31 75 41 31 37 18 27 41 27\n\n$age\n         1    2    3    4    5    6    7    8    9   10\n60613 68.6 82.7 72.9 82.7 83.0 63.1 81.4 63.1 79.0 63.1\n60657 63.1 90.1 78.1 89.8 90.1 78.1 71.5 65.0 65.0 57.8\n60644 65.0 61.8 63.8 85.1 76.5 71.5 71.5 73.4 65.0 90.1\n60620 63.8 78.1 55.9 61.8 90.1 84.2 90.1 73.1 60.4 72.9\n60645 78.5 40.2 11.4 40.2 44.4 49.2 44.4  7.7 20.8 15.2\n\n$involact\n        1   2   3   4   5 6   7   8   9  10\n60626 0.0 0.3 0.3 0.0 0.0 0 0.0 0.3 0.3 0.0\n60618 0.3 0.9 0.3 0.2 0.5 0 0.2 0.7 1.2 0.2\n60629 0.0 0.3 0.0 0.0 0.0 0 0.0 0.0 0.0 0.0\n\n$income\n           1     2      3      4      5      6      7     8     9    10\n60609  7.388 9.631 10.332 10.908 10.510  9.631 11.040 8.212 9.742 7.388\n60628 11.156 9.948  7.459 10.694 11.084 11.156  8.212 9.323 9.948 9.323\n\n# Imputaciones para una variable: \n# cambiar race por otra variable para ver el resultado\nimp_4$imp$race \n\n         1    2    3    4    5    6    7    8    9   10\n60646  1.5  1.1  4.4  1.8  1.6  7.1  7.1  1.0  1.8  1.0\n60651 17.3 66.1 59.8 17.3 34.0 22.2 42.5 47.4 73.5 71.2\n60616 54.0 90.6 35.1 90.6 74.2 21.5 55.5 71.2 54.0 54.0\n60617 48.8 71.2 19.6 71.2 21.5 59.8 24.5 71.2 66.1 73.5\n\n# Para guardar los datos completos de una imputación\nimp_4_m_1 &lt;- complete(imp_4,1) # cambiar 1 por cualquier valor entre 1 y 10\n#\n# Inspección de la calidad de las imputaciones\n# Convergencia del algoritmo (iterative Markov Chain Monte Carlo)\nplot(imp_4)\n\n\n\n\n\n\n# Gráfica conjunta\nstripplot(imp_4)\n\n\n\n# Gráfica individual\nstripplot(imp_4, involact, pch = 20, xlab = \"Imputation number\")\n\n\n\nstripplot(imp_4, race, pch = 20, xlab = \"Imputation number\")\n\n\n\nstripplot(imp_4, fire, pch = 20, xlab = \"Imputation number\")\n\n\n\nstripplot(imp_4, theft, pch = 20, xlab = \"Imputation number\")\n\n\n\nstripplot(imp_4, age, pch = 20, xlab = \"Imputation number\")\n\n\n\nstripplot(imp_4, income, pch = 20, xlab = \"Imputation number\")\n\n\n\n# Distribución de los datos completos y los completados\nxyplot(imp_4,involact ~ race+fire+theft+age+income)\n\n\n\ndensityplot(imp_4)\n\n\n\n# Ajuste de los modelos con los datos completados (m modelos)\nfit &lt;- with(imp_4, lm(involact ~ race+fire+theft+age+log(income)))\n# Pool y resumen de resultados\nfit # Resultado de la regresión para cada conjunto de datos imputados (m=10 en el ejemplo)\n\ncall :\nwith.mids(data = imp_4, expr = lm(involact ~ race + fire + theft + \n    age + log(income)))\n\ncall1 :\nmice(data = chmiss, m = 10, printFlag = F)\n\nnmis :\n    race     fire    theft      age involact   income \n       4        2        4        5        3        2 \n\nanalyses :\n[[1]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n  -0.599910     0.009319     0.036267    -0.009063     0.007314     0.127509  \n\n\n[[2]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n   0.121086     0.005899     0.033715    -0.005583     0.007738    -0.167841  \n\n\n[[3]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n   0.230438     0.006959     0.033557    -0.005745     0.005959    -0.177621  \n\n\n[[4]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n  -0.437711     0.007982     0.035852    -0.005749     0.007089     0.037169  \n\n\n[[5]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n  -0.243150     0.007204     0.036488    -0.008048     0.007791    -0.019826  \n\n\n[[6]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n   0.095326     0.007493     0.035017    -0.005226     0.005428    -0.139136  \n\n\n[[7]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n   0.168600     0.007552     0.031955    -0.006110     0.006584    -0.173716  \n\n\n[[8]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n   0.373117     0.006646     0.030627    -0.005362     0.006434    -0.237995  \n\n\n[[9]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n  -0.092063     0.006544     0.032811    -0.007120     0.007919    -0.065382  \n\n\n[[10]]\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nCoefficients:\n(Intercept)         race         fire        theft          age  log(income)  \n   0.131407     0.006564     0.037846    -0.007256     0.005088    -0.123178  \n\n# Para ver el resultado de una regresión concreta (la primera por ejemplo)\nsummary(fit$analyses[[1]])\n\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.87720 -0.15182 -0.05708  0.20480  0.76808 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.599910   1.088705  -0.551 0.584603    \nrace         0.009319   0.002555   3.648 0.000739 ***\nfire         0.036267   0.009371   3.870 0.000382 ***\ntheft       -0.009063   0.002895  -3.131 0.003209 ** \nage          0.007314   0.002783   2.628 0.012024 *  \nlog(income)  0.127509   0.396047   0.322 0.749122    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3506 on 41 degrees of freedom\nMultiple R-squared:  0.728, Adjusted R-squared:  0.6949 \nF-statistic: 21.95 on 5 and 41 DF,  p-value: 1.244e-10\n\n# Pool de resultados de regresión\nsummary(pool(fit))\n\n         term     estimate   std.error   statistic       df      p.value\n1 (Intercept) -0.025286073 1.092690052 -0.02314112 34.53745 0.9816708904\n2        race  0.007216278 0.002705433  2.66732786 31.55176 0.0119609194\n3        fire  0.034413473 0.009405569  3.65883993 36.04671 0.0008041661\n4       theft -0.006526315 0.002962423 -2.20303287 26.95465 0.0363243930\n5         age  0.006734236 0.002916411  2.30908328 31.93569 0.0275622318\n6 log(income) -0.094001521 0.397330269 -0.23658283 34.56589 0.8143768712\n\n# Comparación de los resultados a posteriori, con la muestra completa\ndata(chredlin, package=\"faraway\")\nmod_full &lt;- lm(involact ~ race+fire+theft+age+log(income), chredlin)\nsummary(mod_full)\n\n\nCall:\nlm(formula = involact ~ race + fire + theft + age + log(income), \n    data = chredlin)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.85393 -0.16922 -0.03088  0.17890  0.81228 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.185540   1.100255  -1.078 0.287550    \nrace         0.009502   0.002490   3.817 0.000449 ***\nfire         0.039856   0.008766   4.547 4.76e-05 ***\ntheft       -0.010295   0.002818  -3.653 0.000728 ***\nage          0.008336   0.002744   3.038 0.004134 ** \nlog(income)  0.345762   0.400123   0.864 0.392540    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3345 on 41 degrees of freedom\nMultiple R-squared:  0.7517,    Adjusted R-squared:  0.7214 \nF-statistic: 24.83 on 5 and 41 DF,  p-value: 2.009e-11"
  },
  {
    "objectID": "p3c2-app9.html#código-python",
    "href": "p3c2-app9.html#código-python",
    "title": "Aplicación 3.9 (Información muestral - Falta de observaciones): Exclusión social en el comportamiento de las aseguradoras de Chicago",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n# Lectura de datos\nchmiss = pd.read_csv(\"data/SEGUROS_CHICAGO.csv\", index_col=0)\nchmiss.describe().round(2)\n\n        race   fire   theft    age  involact  income\ncount  43.00  45.00   43.00  42.00     44.00   45.00\nmean   35.61  11.42   32.65  59.97      0.65   10.74\nstd    33.26   8.36   23.12  23.62      0.64    2.79\nmin     1.00   2.00    3.00   2.00      0.00    5.58\n25%     3.75   5.60   22.00  48.30      0.00    8.56\n50%    24.50   9.50   29.00  64.40      0.50   10.69\n75%    57.65  15.10   38.00  78.25      0.92   12.10\nmax    99.70  36.20  147.00  90.10      2.20   21.48\n\n# Detección de datos perdidos\n# Por filas (casos)\nchmiss.isna().sum(axis=1)\n\nzip\n60626    1\n60640    0\n60613    1\n60657    1\n60614    0\n60610    0\n60611    0\n60625    0\n60618    1\n60647    1\n60622    0\n60631    0\n60646    1\n60656    0\n60630    0\n60634    1\n60641    0\n60635    0\n60639    0\n60651    1\n60644    1\n60624    0\n60612    0\n60607    1\n60623    0\n60608    1\n60616    1\n60632    0\n60609    1\n60653    0\n60615    0\n60638    0\n60629    1\n60636    0\n60621    1\n60637    0\n60652    0\n60620    1\n60619    0\n60649    1\n60617    1\n60655    0\n60643    0\n60628    1\n60627    0\n60633    0\n60645    1\ndtype: int64\n\nplt.imshow(~chmiss.isna(), aspect='auto')\nplt.xlabel(\"variables\")\nplt.ylabel(\"cases\")\nplt.gray()\nplt.show()\n\n\n\n# Por columnas (variables)\nchmiss.isna().sum(axis=0)\n\nrace        4\nfire        2\ntheft       4\nage         5\ninvolact    3\nincome      2\ndtype: int64\n\n# Tratamiento de datos perdidos\n# Omisión de los datos perdidos: resultados con datos completos\nmod_1 = smf.ols(formula='involact ~ race + fire + theft + age + np.log(income)', data=chmiss).fit()\nprint(mod_1.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               involact   R-squared:                       0.790\nModel:                            OLS   Adj. R-squared:                  0.740\nMethod:                 Least Squares   F-statistic:                     15.79\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           1.69e-06\nTime:                        09:50:31   Log-Likelihood:                -5.7253\nNo. Observations:                  27   AIC:                             23.45\nDf Residuals:                      21   BIC:                             31.23\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n==================================================================================\n                     coef    std err          t      P&gt;|t|      [0.025      0.975]\n----------------------------------------------------------------------------------\nIntercept         -2.4072      1.419     -1.696      0.105      -5.359       0.544\nrace               0.0111      0.003      3.232      0.004       0.004       0.018\nfire               0.0450      0.011      4.208      0.000       0.023       0.067\ntheft             -0.0161      0.006     -2.894      0.009      -0.028      -0.005\nage                0.0091      0.003      2.652      0.015       0.002       0.016\nnp.log(income)     0.8443      0.532      1.588      0.127      -0.261       1.950\n==============================================================================\nOmnibus:                        1.216   Durbin-Watson:                   2.453\nProb(Omnibus):                  0.545   Jarque-Bera (JB):                0.935\nSkew:                           0.441   Prob(JB):                        0.626\nKurtosis:                       2.768   Cond. No.                     1.89e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.89e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n# Imputación simple: uso de la media para predecir los datos faltantes de los regresores\ncmeans = chmiss.mean(axis=0)\ncmeans\n\nrace        35.609302\nfire        11.424444\ntheft       32.651163\nage         59.969048\ninvolact     0.647727\nincome      10.735867\ndtype: float64\n\nimput_1 = chmiss.copy()\nimput_1.race.fillna(cmeans['race'],inplace=True)\nimput_1.fire.fillna(cmeans['fire'],inplace=True)\nimput_1.theft.fillna(cmeans['theft'],inplace=True)\nimput_1.age.fillna(cmeans['age'],inplace=True)\nimput_1.income.fillna(cmeans['income'],inplace=True)\nmod_2 = smf.ols(formula='involact ~ race + fire + theft + age + np.log(income)', data=imput_1).fit()\nprint(mod_2.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:               involact   R-squared:                       0.681\nModel:                            OLS   Adj. R-squared:                  0.639\nMethod:                 Least Squares   F-statistic:                     16.25\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           1.46e-08\nTime:                        09:50:31   Log-Likelihood:                -17.153\nNo. Observations:                  44   AIC:                             46.31\nDf Residuals:                      38   BIC:                             57.01\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n==================================================================================\n                     coef    std err          t      P&gt;|t|      [0.025      0.975]\n----------------------------------------------------------------------------------\nIntercept          0.5296      1.088      0.487      0.629      -1.673       2.732\nrace               0.0070      0.003      2.452      0.019       0.001       0.013\nfire               0.0282      0.010      2.956      0.005       0.009       0.048\ntheft             -0.0033      0.003     -1.206      0.235      -0.009       0.002\nage                0.0062      0.003      1.976      0.055      -0.000       0.013\nnp.log(income)    -0.3158      0.390     -0.809      0.423      -1.106       0.474\n==============================================================================\nOmnibus:                        1.687   Durbin-Watson:                   2.026\nProb(Omnibus):                  0.430   Jarque-Bera (JB):                0.817\nSkew:                          -0.219   Prob(JB):                        0.665\nKurtosis:                       3.504   Cond. No.                     1.68e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.68e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n# Imputación múltiple: enfoque MICE \n# (https://www.statsmodels.org/stable/imputation.html)\n# NOTA: la librería statsmodels incluye el método MICE, pero no es \n# exactamente el mismo que el usado en R\nimport statsmodels.imputation.mice as smimice\nimp = smimice.MICEData(chmiss)\nformula = 'involact ~ race + fire + theft + age + np.log(income)'\nmod_3 = smimice.MICE(formula, sm.OLS, imp)\nresults = mod_3.fit(10, 10)\nprint(results.summary())\n\n                           Results: MICE\n====================================================================\nMethod:                   MICE           Sample size:           47  \nModel:                    OLS            Scale                  0.14\nDependent variable:       involact       Num. imputations       10  \n--------------------------------------------------------------------\n                Coef.  Std.Err.    t    P&gt;|t|   [0.025 0.975]  FMI  \n--------------------------------------------------------------------\nIntercept       0.1845   1.1791  0.1565 0.8756 -2.1264 2.4954 0.1010\nrace            0.0072   0.0028  2.5197 0.0117  0.0016 0.0127 0.0684\nfire            0.0310   0.0095  3.2505 0.0012  0.0123 0.0497 0.0660\ntheft          -0.0036   0.0038 -0.9531 0.3405 -0.0111 0.0038 0.5374\nage             0.0060   0.0033  1.8094 0.0704 -0.0005 0.0124 0.2466\nnp.log(income) -0.1791   0.4260 -0.4205 0.6741 -1.0141 0.6558 0.0996\n===================================================================="
  },
  {
    "objectID": "p3c2-app10.html#código-r",
    "href": "p3c2-app10.html#código-r",
    "title": "Aplicación 3.10 (Información muestral - Multicolinealidad): Análisis de la rentabilidad empresarial",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(car)\nlibrary(corrplot)\nlibrary(broom)\nlibrary(cowplot)\nlibrary(mctest)\n# Lectura de datos\nRENTAB_EMP &lt;- read_delim(\"data/RENTAB_EMP.csv\", \";\", \n                         escape_double = FALSE, trim_ws = TRUE)\nsummary(RENTAB_EMP)\n\n     RENTAB              AT               VT               R1        \n Min.   :-0.5000   Min.   : 30.27   Min.   :  1.00   Min.   :0.0000  \n 1st Qu.: 0.0875   1st Qu.: 55.56   1st Qu.: 62.80   1st Qu.:0.1500  \n Median : 0.1400   Median : 75.57   Median : 83.52   Median :0.2400  \n Mean   : 0.1450   Mean   :100.51   Mean   :117.43   Mean   :0.3048  \n 3rd Qu.: 0.2100   3rd Qu.:101.02   3rd Qu.:125.21   3rd Qu.:0.3950  \n Max.   : 0.5700   Max.   :518.01   Max.   :539.15   Max.   :1.7800  \n       R2              R3                R4               R5         \n Min.   :0.000   Min.   :-1.2800   Min.   : 0.290   Min.   : 0.1400  \n 1st Qu.:1.135   1st Qu.: 0.0900   1st Qu.: 1.135   1st Qu.: 0.5775  \n Median :1.535   Median : 0.1600   Median : 1.375   Median : 0.7550  \n Mean   :1.668   Mean   : 0.1817   Mean   : 1.615   Mean   : 1.0049  \n 3rd Qu.:2.040   3rd Qu.: 0.2500   3rd Qu.: 1.715   3rd Qu.: 0.9775  \n Max.   :5.440   Max.   : 1.4700   Max.   :12.980   Max.   :12.9800  \n       R6               R7               R8               R9        \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2100   1st Qu.:0.1700   1st Qu.:0.3200   1st Qu.:0.1575  \n Median :0.2800   Median :0.2750   Median :0.4750   Median :0.3950  \n Mean   :0.3242   Mean   :0.2624   Mean   :0.4946   Mean   :0.5109  \n 3rd Qu.:0.4200   3rd Qu.:0.3600   3rd Qu.:0.6225   3rd Qu.:0.6000  \n Max.   :0.9400   Max.   :0.7400   Max.   :1.1600   Max.   :4.2100  \n      R10       \n Min.   :-1.28  \n 1st Qu.: 0.10  \n Median : 0.20  \n Mean   : 0.21  \n 3rd Qu.: 0.33  \n Max.   : 1.47  \n\n# Regresión MCO para explicar las variaciones en la rentabilidad de las empresas\nlm_1 &lt;- lm(RENTAB ~ log(VT) + R1 + R2 + R3 + R4 + R5 + R6 + R7 + R8 + R9 + R10, \n           data=RENTAB_EMP)\nS(lm_1)\n\nCall: lm(formula = RENTAB ~ log(VT) + R1 + R2 + R3 + R4 + R5 + R6 + R7 + R8 +\n         R9 + R10, data = RENTAB_EMP)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  0.10571    0.07189   1.470  0.14606   \nlog(VT)      0.03038    0.01435   2.118  0.03785 * \nR1           0.04870    0.05438   0.895  0.37368   \nR2           0.01309    0.01086   1.206  0.23205   \nR3           0.44367    0.16199   2.739  0.00786 **\nR4          -0.05617    0.05032  -1.116  0.26818   \nR5          -0.01200    0.05376  -0.223  0.82402   \nR6          -0.26587    0.09783  -2.718  0.00833 **\nR7          -0.01899    0.12382  -0.153  0.87855   \nR8          -0.08293    0.06315  -1.313  0.19351   \nR9          -0.01248    0.01215  -1.027  0.30818   \nR10          0.12626    0.12275   1.029  0.30730   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 0.07114 on 68 degrees of freedom\nMultiple R-squared: 0.7634\nF-statistic: 19.95 on 11 and 68 DF,  p-value: &lt; 2.2e-16 \n    AIC     BIC \n-182.86 -151.90 \n\n# Detección de la multicolinealidad\n# Análisis global\nmctest::omcdiag(lm_1)\n\n\nCall:\nmctest::omcdiag(mod = lm_1)\n\n\nOverall Multicollinearity Diagnostics\n\n                       MC Results detection\nDeterminant |X'X|:         0.0000         1\nFarrar Chi-Square:       868.1514         1\nRed Indicator:             0.3669         0\nSum of Lambda Inverse:   254.5917         1\nTheil's Method:            0.3297         0\nCondition Number:         53.2324         1\n\n1 --&gt; COLLINEARITY is detected by the test \n0 --&gt; COLLINEARITY is not detected by the test\n\n# Matríz de correlaciones de las variables explicativas (sin incluir la constante)\nattach(RENTAB_EMP)\nX &lt;- data.frame(log(VT), R1, R2, R3, R4, R5, R6, R7, R8, R9, R10)\ncor(X)\n\n            log.VT.          R1          R2          R3         R4          R5\nlog.VT.  1.00000000  0.04455432  0.37937815 -0.26986714 -0.5403307 -0.58688804\nR1       0.04455432  1.00000000  0.13959301 -0.71176219 -0.2434206 -0.23104458\nR2       0.37937815  0.13959301  1.00000000 -0.28660226 -0.2767741 -0.30332163\nR3      -0.26986714 -0.71176219 -0.28660226  1.00000000  0.6020270  0.62075909\nR4      -0.54033073 -0.24342056 -0.27677409  0.60202699  1.0000000  0.97447873\nR5      -0.58688804 -0.23104458 -0.30332163  0.62075909  0.9744787  1.00000000\nR6       0.16832365 -0.02100811 -0.16872501  0.12042353 -0.2363989 -0.16929931\nR7       0.17615205  0.13428960  0.33451829 -0.29984891 -0.1207788 -0.30299567\nR8       0.15785850  0.01106237 -0.09166777  0.09333641 -0.2430305 -0.19754376\nR9       0.02387962 -0.16507346  0.04319976 -0.05465976 -0.0545034 -0.07882045\nR10     -0.17346991 -0.67446971 -0.28226733  0.96910077  0.5496828  0.56385554\n                 R6          R7           R8           R9        R10\nlog.VT.  0.16832365  0.17615205  0.157858498  0.023879622 -0.1734699\nR1      -0.02100811  0.13428960  0.011062374 -0.165073458 -0.6744697\nR2      -0.16872501  0.33451829 -0.091667765  0.043199761 -0.2822673\nR3       0.12042353 -0.29984891  0.093336407 -0.054659764  0.9691008\nR4      -0.23639892 -0.12077879 -0.243030466 -0.054503402  0.5496828\nR5      -0.16929931 -0.30299567 -0.197543764 -0.078820446  0.5638555\nR6       1.00000000 -0.41733008  0.865538114 -0.003837950  0.1375172\nR7      -0.41733008  1.00000000 -0.291781677  0.093247877 -0.3058542\nR8       0.86553811 -0.29178168  1.000000000  0.002774409  0.1110367\nR9      -0.00383795  0.09324788  0.002774409  1.000000000 -0.0399822\nR10      0.13751716 -0.30585425  0.111036662 -0.039982201  1.0000000\n\n# Mapa de calor asociado\ncorrplot(cor(X))\n\n\n\n# Factores de inflación de la varianza (VIF)\nvif(lm_1)\n\n  log(VT)        R1        R2        R3        R4        R5        R6        R7 \n 2.207711  3.182916  1.512578 30.241277 82.054917 97.964824  4.848121  5.376679 \n       R8        R9       R10 \n 4.231952  1.139049 21.831647 \n\nvif(lm_1) &gt; 10 # multicolinealidad alta: se coresponde con un VIF&gt;10, es decir, Rj^2&gt;0.90\n\nlog(VT)      R1      R2      R3      R4      R5      R6      R7      R8      R9 \n  FALSE   FALSE   FALSE    TRUE    TRUE    TRUE   FALSE   FALSE   FALSE   FALSE \n    R10 \n   TRUE \n\nsqrt(vif(lm_1))\n\n log(VT)       R1       R2       R3       R4       R5       R6       R7 \n1.485837 1.784073 1.229869 5.499207 9.058417 9.897718 2.201845 2.318767 \n      R8       R9      R10 \n2.057171 1.067262 4.672435 \n\nsqrt(vif(lm_1)) &gt; 2 # cota alternativa: se coresponde con un VIF&gt;4, es decir, Rj^2&gt;0.75\n\nlog(VT)      R1      R2      R3      R4      R5      R6      R7      R8      R9 \n  FALSE   FALSE   FALSE    TRUE    TRUE    TRUE    TRUE    TRUE    TRUE   FALSE \n    R10 \n   TRUE \n\nmctest::imcdiag(lm_1, method = \"VIF\", vif=10)\n\n\nCall:\nmctest::imcdiag(mod = lm_1, method = \"VIF\", vif = 10)\n\n\n VIF Multicollinearity Diagnostics\n\n            VIF detection\nlog(VT)  2.2077         0\nR1       3.1829         0\nR2       1.5126         0\nR3      30.2413         1\nR4      82.0549         1\nR5      97.9648         1\nR6       4.8481         0\nR7       5.3767         0\nR8       4.2320         0\nR9       1.1390         0\nR10     21.8316         1\n\nMulticollinearity may be due to R3 R4 R5 R10 regressors\n\n1 --&gt; COLLINEARITY is detected by the test \n0 --&gt; COLLINEARITY is not detected by the test\n\n===================================\n\nmctest::imcdiag(lm_1, method = \"VIF\", vif=4)\n\n\nCall:\nmctest::imcdiag(mod = lm_1, method = \"VIF\", vif = 4)\n\n\n VIF Multicollinearity Diagnostics\n\n            VIF detection\nlog(VT)  2.2077         0\nR1       3.1829         0\nR2       1.5126         0\nR3      30.2413         1\nR4      82.0549         1\nR5      97.9648         1\nR6       4.8481         1\nR7       5.3767         1\nR8       4.2320         1\nR9       1.1390         0\nR10     21.8316         1\n\nMulticollinearity may be due to R3 R4 R5 R6 R7 R8 R10 regressors\n\n1 --&gt; COLLINEARITY is detected by the test \n0 --&gt; COLLINEARITY is not detected by the test\n\n===================================\n\n# Corrección del problema de la multicolinealidad\n# Método de componentes principales (PCA)\n# Estándar de R\nPCA_X &lt;- prcomp(X, scale. = TRUE)\nsummary(PCA_X)\n\nImportance of components:\n                          PC1    PC2    PC3     PC4     PC5     PC6     PC7\nStandard deviation     1.9979 1.5319 1.2094 1.00242 0.86701 0.78755 0.67507\nProportion of Variance 0.3629 0.2134 0.1330 0.09135 0.06834 0.05638 0.04143\nCumulative Proportion  0.3629 0.5762 0.7092 0.80054 0.86888 0.92527 0.96669\n                           PC8     PC9    PC10    PC11\nStandard deviation     0.46950 0.34571 0.14512 0.07318\nProportion of Variance 0.02004 0.01086 0.00191 0.00049\nCumulative Proportion  0.98673 0.99760 0.99951 1.00000\n\ndim(PCA_X$rotation)\n\n[1] 11 11\n\nPCA_X$rotation\n\n                 PC1           PC2        PC3         PC4          PC5\nlog.VT.  0.272060602  0.1982069074  0.4137599  0.27338881 -0.032304569\nR1       0.292893420 -0.1054146400 -0.5368550  0.05752372  0.299295872\nR2       0.236359706 -0.1167409339  0.3529184  0.27420521  0.681183843\nR3      -0.448679443  0.1211005503  0.2645271  0.13400463  0.004135074\nR4      -0.414177415 -0.2384492414 -0.1248104  0.01139264  0.352103394\nR5      -0.431076419 -0.1854722032 -0.1956456  0.01139931  0.328588874\nR6      -0.003530123  0.6054335323 -0.1327187 -0.04116143  0.207472602\nR7       0.204139683 -0.3241050981  0.3000028  0.01593913  0.151842982\nR8       0.019537592  0.5803512575 -0.1050323 -0.03170302  0.323402183\nR9       0.028624268  0.0009420534  0.2983959 -0.89643584  0.206023991\nR10     -0.427505522  0.1471314431  0.2907247  0.14830202 -0.016321539\n                PC6          PC7         PC8          PC9          PC10\nlog.VT.  0.17716306  0.756295804  0.15358288 -0.069431887  0.0828318547\nR1      -0.02188778  0.336050204 -0.62819485  0.049231609  0.0994317039\nR2       0.34049854 -0.380180298 -0.03598096  0.057757622 -0.0305511302\nR3      -0.07878078 -0.048317314 -0.33385219  0.052457420  0.7459489740\nR4      -0.08306651  0.291671522  0.30090099 -0.010916327 -0.1388159574\nR5       0.09672745  0.208752961  0.22940019 -0.017212079  0.0894993785\nR6      -0.13436411  0.007200247  0.16414896  0.724294420 -0.0366804587\nR7      -0.83747856  0.044284228  0.02093318  0.122181942  0.0058947245\nR8      -0.29746686 -0.082064324  0.06607274 -0.668168262  0.0006368832\nR9       0.13845613  0.152737278 -0.14365962  0.002383958  0.0308049128\nR10     -0.05149352  0.086539317 -0.52295219  0.016339284 -0.6294993375\n                PC11\nlog.VT.  0.032788772\nR1      -0.040656254\nR2      -0.026721787\nR3      -0.129933035\nR4      -0.655753035\nR5       0.720784665\nR6       0.009277156\nR7       0.145732844\nR8       0.012204574\nR9      -0.002250226\nR10      0.093030098\n\ndim(PCA_X$x)\n\n[1] 80 11\n\n# plot(PCA_X)\n# Estilo tidyverse\nPCA_X %&gt;% tidy(matrix = \"eigenvalues\")\n\n# A tibble: 11 × 4\n      PC std.dev percent cumulative\n   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n 1     1  2.00   0.363        0.363\n 2     2  1.53   0.213        0.576\n 3     3  1.21   0.133        0.709\n 4     4  1.00   0.0914       0.801\n 5     5  0.867  0.0683       0.869\n 6     6  0.788  0.0564       0.925\n 7     7  0.675  0.0414       0.967\n 8     8  0.470  0.0200       0.987\n 9     9  0.346  0.0109       0.998\n10    10  0.145  0.00191      1.00 \n11    11  0.0732 0.00049      1    \n\nPCA_X %&gt;% tidy(matrix = \"rotation\")\n\n# A tibble: 121 × 3\n   column     PC   value\n   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 log.VT.     1  0.272 \n 2 log.VT.     2  0.198 \n 3 log.VT.     3  0.414 \n 4 log.VT.     4  0.273 \n 5 log.VT.     5 -0.0323\n 6 log.VT.     6  0.177 \n 7 log.VT.     7  0.756 \n 8 log.VT.     8  0.154 \n 9 log.VT.     9 -0.0694\n10 log.VT.    10  0.0828\n# ℹ 111 more rows\n\nPCA_X %&gt;%\n  tidy(matrix = \"eigenvalues\") %&gt;%\n  ggplot(aes(PC, percent)) +\n  geom_col(fill = \"#56B4E9\", alpha = 0.8) +\n  scale_x_continuous(breaks = 1:11) +\n  scale_y_continuous(labels = scales::percent_format(), expand = expansion(mult = c(0, 0.01))) +\n  theme_minimal_hgrid(12)\n\n\n\nPCA_X %&gt;%\n  augment(RENTAB_EMP) %&gt;% \n  ggplot(aes(.fittedPC1, .fittedPC2)) + geom_point(size = 1.5) +\n  theme_half_open(12) + background_grid()\n\n\n\narrow_style &lt;- arrow(angle = 20, ends = \"first\", type = \"closed\", length = grid::unit(8, \"pt\"))\nPCA_X %&gt;%\n  tidy(matrix = \"rotation\") %&gt;%\n  pivot_wider(names_from = \"PC\", names_prefix = \"PC\", values_from = \"value\") %&gt;%\n  ggplot(aes(PC1, PC2)) +\n  geom_segment(xend = 0, yend = 0, arrow = arrow_style) +\n  geom_text(aes(label = column),hjust = 1, nudge_x = -0.02, color = \"#904C2F\") +\n  xlim(-1.25, .5) + ylim(-.5, 1) +\n  coord_fixed() + \n  theme_minimal_grid(12)\n\n\n\n# Significado de la variables explicativas (factores)\nround(PCA_X$rotation[,1],2)\n\nlog.VT.      R1      R2      R3      R4      R5      R6      R7      R8      R9 \n   0.27    0.29    0.24   -0.45   -0.41   -0.43    0.00    0.20    0.02    0.03 \n    R10 \n  -0.43 \n\nround(PCA_X$rotation[,2],2)\n\nlog.VT.      R1      R2      R3      R4      R5      R6      R7      R8      R9 \n   0.20   -0.11   -0.12    0.12   -0.24   -0.19    0.61   -0.32    0.58    0.00 \n    R10 \n   0.15 \n\nround(PCA_X$rotation[,3],2)\n\nlog.VT.      R1      R2      R3      R4      R5      R6      R7      R8      R9 \n   0.41   -0.54    0.35    0.26   -0.12   -0.20   -0.13    0.30   -0.11    0.30 \n    R10 \n   0.29 \n\nround(PCA_X$rotation[,4],2)\n\nlog.VT.      R1      R2      R3      R4      R5      R6      R7      R8      R9 \n   0.27    0.06    0.27    0.13    0.01    0.01   -0.04    0.02   -0.03   -0.90 \n    R10 \n   0.15 \n\n# Regresión con los cuatros primeros factores (explicatividad &gt; 80%)\nlm_2 &lt;- lm(RENTAB ~ PCA_X$x[,1:4])\nS(lm_2)\n\nCall: lm(formula = RENTAB ~ PCA_X$x[, 1:4])\n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        0.145000   0.010487  13.827  &lt; 2e-16 ***\nPCA_X$x[, 1:4]PC1 -0.017070   0.005282  -3.232 0.001829 ** \nPCA_X$x[, 1:4]PC2  0.004465   0.006888   0.648 0.518813    \nPCA_X$x[, 1:4]PC3  0.069539   0.008725   7.970 1.36e-11 ***\nPCA_X$x[, 1:4]PC4  0.042087   0.010527   3.998 0.000148 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard deviation: 0.09379 on 75 degrees of freedom\nMultiple R-squared: 0.5465\nF-statistic: 22.59 on 4 and 75 DF,  p-value: 2.853e-12 \n   AIC    BIC \n-144.8 -130.5 \n\n# Método de mínimos cuadrados parciales (PLS)\nlibrary(pls)\nlm_3 &lt;- plsr(RENTAB ~ log(VT) + R1 + R2 + R3 + R4 + R5 + R6 + R7 + R8 + R9 + R10, data=RENTAB_EMP, ncomp=11, validation=\"CV\")\nsummary(lm_3)\n\nData:   X dimension: 80 11 \n    Y dimension: 80 1\nFit method: kernelpls\nNumber of components considered: 11\n\nVALIDATION: RMSEP\nCross-validated using 10 random segments.\n       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps\nCV          0.1366   0.1307   0.1332  0.09562  0.08442  0.08419  0.08374\nadjCV       0.1366   0.1319   0.1321  0.09578  0.08434  0.08381  0.08323\n       7 comps  8 comps  9 comps  10 comps  11 comps\nCV     0.07970  0.07788  0.07901   0.08063   0.07998\nadjCV  0.07901  0.07728  0.07826   0.07974   0.07915\n\nTRAINING: % variance explained\n        1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps\nX         51.18    76.48    83.97    89.74    93.94    98.39    99.18    99.83\nRENTAB    15.42    42.25    60.72    68.54    71.15    72.83    75.04    75.55\n        9 comps  10 comps  11 comps\nX         99.92     99.95    100.00\nRENTAB    76.10     76.34     76.34\n\nexplvar(lm_3)\n\n     Comp 1      Comp 2      Comp 3      Comp 4      Comp 5      Comp 6 \n51.17860789 25.30497881  7.48641359  5.77426812  4.19405115  4.45405962 \n     Comp 7      Comp 8      Comp 9     Comp 10     Comp 11 \n 0.78918833  0.64755300  0.08611158  0.03076461  0.05400330 \n\nplsCV &lt;- RMSEP(lm_3, estimate=\"CV\")\nplot(plsCV,main=\"\")\n\n\n\n#\nplot(lm_3, ncomp = 3, asp = 1, line = TRUE)\n\n\n\nplot(lm_3, plottype = \"scores\", comps = 1:3)\n\n\n\nplot(lm_3, plottype = \"correlation\")\n\n\n\nplot(lm_3, plottype = \"coef\", comps = 1:3, legendpos = \"bottomright\")\n\n\n\n# Método Ridge\n# Librería MASS\nlibrary(MASS)\nlm_4_1 &lt;- lm.ridge(RENTAB ~ log(VT) + R1 + R2 + R3 + R4 + R5 + R6 + R7 + R8 + R9 + R10, data=RENTAB_EMP) # lambda por defecto\nlm_4_1\n\n                log(VT)          R1          R2          R3          R4 \n 0.10571279  0.03038112  0.04869529  0.01309305  0.44366809 -0.05617409 \n         R5          R6          R7          R8          R9         R10 \n-0.01200199 -0.26587009 -0.01899122 -0.08292600 -0.01247702  0.12626126 \n\nlm_4_2 &lt;- lm.ridge(RENTAB ~ log(VT) + R1 + R2 + R3 + R4 + R5 + R6 + R7 + R8 + R9 + R10, data=RENTAB_EMP, lambda = 0.05)\nlm_4_2\n\n                log(VT)          R1          R2          R3          R4 \n 0.10688010  0.03007276  0.04770882  0.01324266  0.43832445 -0.05458838 \n         R5          R6          R7          R8          R9         R10 \n-0.01347270 -0.26493944 -0.02167037 -0.08309377 -0.01259580  0.12961973 \n\n# Librería glmnet\nlibrary(glmnet)\n# Variables dependiente e independientes del modelo\ndata &lt;- data.frame(cbind(log(RENTAB_EMP$VT),RENTAB_EMP$R1,RENTAB_EMP$R2,RENTAB_EMP$R3,\n                         RENTAB_EMP$R4, RENTAB_EMP$R5, RENTAB_EMP$R6, RENTAB_EMP$R7, \n                         RENTAB_EMP$R8,RENTAB_EMP$R9,RENTAB_EMP$R10, RENTAB_EMP$RENTAB))\nnames(data)=c(\"l_VT\",\"R1\",\"R2\",\"R3\",\"R4\",\"R5\",\"R6\",\"R7\",\"R8\",\"R9\",\"R10\",\"RENTAB\")\nx_vars &lt;- data.matrix(data[, 1:11])\ny_var &lt;- data[, \"RENTAB\"]\n# Ajuste del modelo estimado\nfit_ridge &lt;- glmnet(x_vars,y_var,alpha=0)\nplot(fit_ridge, label=TRUE)\n\n\n\nplot(fit_ridge, label=TRUE, xvar=\"lambda\")\n\n\n\nplot(fit_ridge, label=TRUE, xvar=\"dev\")\n\n\n\n# print(fit_ridge)\ncoef(fit_ridge,s=0.05) # Parámetros estimados para un lambda s=X concreto\n\n12 x 1 sparse Matrix of class \"dgCMatrix\"\n                      s1\n(Intercept)  0.102977226\nl_VT         0.025000806\nR1          -0.075172389\nR2           0.012333111\nR3           0.151997456\nR4          -0.017950737\nR5          -0.015006687\nR6          -0.123045293\nR7          -0.008468321\nR8          -0.064861131\nR9          -0.016092669\nR10          0.145855543\n\n# Selección del lambda óptimo (criterio CV)\ncvfit_ridge = cv.glmnet(x_vars, y_var, alpha=0)\nplot(cvfit_ridge)\n\n\n\ncvfit_ridge$lambda.min\n\n[1] 0.007624277\n\ncoef(cvfit_ridge, s = \"lambda.min\")\n\n12 x 1 sparse Matrix of class \"dgCMatrix\"\n                      s1\n(Intercept)  0.121951806\nl_VT         0.025781421\nR1          -0.008253952\nR2           0.014837128\nR3           0.266768030\nR4          -0.033884567\nR5          -0.023383628\nR6          -0.213247120\nR7          -0.033015845\nR8          -0.083680623\nR9          -0.016531917\nR10          0.200411207\n\n# Método LASSO\n# Librería lars\nlibrary(lars)\nlm_5 &lt;- lars(as.matrix(data[,-12]),data$RENTAB)\nplot(lm_5)\n\n\n\ncv_lars_mod &lt;- cv.lars(as.matrix(data[,-12]),data$RENTAB)\n\n\n\nmin &lt;- cv_lars_mod$index[which.min(cv_lars_mod$cv)]  # El valor min se utiliza en el paso siguiente\npredict(lm_5,s=min,type=\"coef\",mode=\"fraction\")$coef  # Estimaciones LASSO\n\n         l_VT            R1            R2            R3            R4 \n 2.891714e-02  0.000000e+00  1.141969e-02  3.323789e-01 -5.932980e-02 \n           R5            R6            R7            R8            R9 \n-1.059601e-05 -2.461453e-01  0.000000e+00 -6.696321e-02 -1.279233e-02 \n          R10 \n 1.601890e-01 \n\n# Librería glmnet\n# Ajuste del modelo\nfit_lasso &lt;- glmnet(x_vars,y_var,alpha=1)\nplot(fit_lasso, label=TRUE)\n\n\n\nplot(fit_lasso, label=TRUE, xvar=\"lambda\")\n\n\n\nplot(fit_lasso, label=TRUE, xvar=\"dev\")\n\n\n\n# print(fit_lasso)\ncoef(fit_lasso,s=0.0006) # Parámetros estimados para un lambda s=X concreto\n\n12 x 1 sparse Matrix of class \"dgCMatrix\"\n                      s1\n(Intercept)  0.108891392\nl_VT         0.030205635\nR1           0.029525284\nR2           0.012279829\nR3           0.400132893\nR4          -0.062166241\nR5          -0.002863428\nR6          -0.258235110\nR7           .          \nR8          -0.077647231\nR9          -0.012925727\nR10          0.142347892\n\n# Selección del lambda óptimo (criterio CV)\ncvfit_lasso = cv.glmnet(x_vars, y_var, alpha=1)\nplot(cvfit_lasso)\n\n\n\ncvfit_lasso$lambda.min\n\n[1] 0.00243921\n\ncoef(cvfit_lasso, s = \"lambda.min\")\n\n12 x 1 sparse Matrix of class \"dgCMatrix\"\n                     s1\n(Intercept)  0.11612149\nl_VT         0.02875096\nR1           .         \nR2           0.01120782\nR3           0.32599021\nR4          -0.05861917\nR5           .         \nR6          -0.24400022\nR7           .         \nR8          -0.06577122\nR9          -0.01236173\nR10          0.16233954\n\n# NOTA FINAL: Hay que estandarizar las variables antes de aplicar \n# los modelos lm.ridge y lars (glmnet estandariza las variables \n# X e y por defecto para la familia Gaussiana de modelos)\nlibrary(caret)\npreProcValues &lt;- preProcess(data[,-12], method = c(\"center\", \"scale\"))\ndataTransformed &lt;- predict(preProcValues, data)\nx_vars &lt;- data.matrix(dataTransformed[, 1:11])\ny_var &lt;- dataTransformed[, \"RENTAB\"]"
  },
  {
    "objectID": "p3c2-app10.html#código-python",
    "href": "p3c2-app10.html#código-python",
    "title": "Aplicación 3.10 (Información muestral - Multicolinealidad): Análisis de la rentabilidad empresarial",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.stats as smstats\n# Lectura de datos\nRENTAB_EMP = pd.read_csv(\"data/RENTAB_EMP.csv\", sep=\";\")\nRENTAB_EMP.describe().round(2)\n\n       RENTAB      AT      VT     R1     R2  ...     R6     R7     R8     R9    R10\ncount   80.00   80.00   80.00  80.00  80.00  ...  80.00  80.00  80.00  80.00  80.00\nmean     0.14  100.51  117.43   0.30   1.67  ...   0.32   0.26   0.49   0.51   0.21\nstd      0.14   84.96   94.19   0.26   0.91  ...   0.18   0.15   0.26   0.70   0.30\nmin     -0.50   30.27    1.00   0.00   0.00  ...   0.00   0.00   0.00   0.00  -1.28\n25%      0.09   55.56   62.80   0.15   1.13  ...   0.21   0.17   0.32   0.16   0.10\n50%      0.14   75.57   83.52   0.24   1.53  ...   0.28   0.28   0.48   0.39   0.20\n75%      0.21  101.02  125.21   0.39   2.04  ...   0.42   0.36   0.62   0.60   0.33\nmax      0.57  518.01  539.15   1.78   5.44  ...   0.94   0.74   1.16   4.21   1.47\n\n[8 rows x 13 columns]\n\n# Regresión MCO para explicar las variaciones en la rentabilidad de las empresas\nformula = 'RENTAB ~ np.log(RENTAB_EMP.VT) + R1 + R2 + R3 + R4 + R5 + R6 + R7 + R8 + R9 + R10'\nlm_1 = smf.ols(formula, RENTAB_EMP).fit()\nprint(lm_1.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 RENTAB   R-squared:                       0.763\nModel:                            OLS   Adj. R-squared:                  0.725\nMethod:                 Least Squares   F-statistic:                     19.95\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           3.37e-17\nTime:                        09:52:35   Log-Likelihood:                 104.43\nNo. Observations:                  80   AIC:                            -184.9\nDf Residuals:                      68   BIC:                            -156.3\nDf Model:                          11                                         \nCovariance Type:            nonrobust                                         \n=========================================================================================\n                            coef    std err          t      P&gt;|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------------\nIntercept                 0.1057      0.072      1.470      0.146      -0.038       0.249\nnp.log(RENTAB_EMP.VT)     0.0304      0.014      2.118      0.038       0.002       0.059\nR1                        0.0487      0.054      0.895      0.374      -0.060       0.157\nR2                        0.0131      0.011      1.206      0.232      -0.009       0.035\nR3                        0.4437      0.162      2.739      0.008       0.120       0.767\nR4                       -0.0562      0.050     -1.116      0.268      -0.157       0.044\nR5                       -0.0120      0.054     -0.223      0.824      -0.119       0.095\nR6                       -0.2659      0.098     -2.718      0.008      -0.461      -0.071\nR7                       -0.0190      0.124     -0.153      0.879      -0.266       0.228\nR8                       -0.0829      0.063     -1.313      0.194      -0.209       0.043\nR9                       -0.0125      0.012     -1.027      0.308      -0.037       0.012\nR10                       0.1263      0.123      1.029      0.307      -0.119       0.371\n==============================================================================\nOmnibus:                       19.322   Durbin-Watson:                   1.961\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               60.988\nSkew:                           0.620   Prob(JB):                     5.71e-14\nKurtosis:                       7.094   Cond. No.                         141.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Detección de la multicolinealidad\nRENTAB_EMP['l_VT'] = np.log(RENTAB_EMP['VT'])\nX = RENTAB_EMP.iloc[:,3:]\nX.head()\n\n             R1    R2    R3    R4    R5  ...    R7    R8            R9   R10  l_VT\n0  4.600000e-01  0.64  0.25  1.53  0.18  ...  0.74  0.12  7.000000e-02  0.25  4.11\n1  1.680000e-39  1.79  0.33  1.73  1.26  ...  0.27  0.15  3.000000e-01  0.33  4.25\n2  2.400000e-01  0.36  0.20  0.44  0.39  ...  0.01  0.97  5.700000e-01  0.50  4.44\n3  4.500000e-01  1.86  0.21  1.23  0.69  ...  0.29  0.52  1.530000e-39  0.23  4.71\n4  9.100000e-01  1.26  0.12  1.76  0.90  ...  0.33  0.54  3.100000e-01  0.21  4.85\n\n[5 rows x 11 columns]\n\nX = X[['l_VT', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'R9', 'R10']]\nX.head()\n\n   l_VT            R1    R2    R3    R4  ...    R6    R7    R8            R9   R10\n0  4.11  4.600000e-01  0.64  0.25  1.53  ...  0.10  0.74  0.12  7.000000e-02  0.25\n1  4.25  1.680000e-39  1.79  0.33  1.73  ...  0.12  0.27  0.15  3.000000e-01  0.33\n2  4.44  2.400000e-01  0.36  0.20  0.44  ...  0.94  0.01  0.97  5.700000e-01  0.50\n3  4.71  4.500000e-01  1.86  0.21  1.23  ...  0.29  0.29  0.52  1.530000e-39  0.23\n4  4.85  9.100000e-01  1.26  0.12  1.76  ...  0.26  0.33  0.54  3.100000e-01  0.21\n\n[5 rows x 11 columns]\n\n# Matriz de correlaciones de las variables explicativas (sin incluir la constante)\nX.corr().round(2)\n\n      l_VT    R1    R2    R3    R4    R5    R6    R7    R8    R9   R10\nl_VT  1.00  0.04  0.38 -0.27 -0.54 -0.59  0.17  0.18  0.16  0.02 -0.17\nR1    0.04  1.00  0.14 -0.71 -0.24 -0.23 -0.02  0.13  0.01 -0.17 -0.67\nR2    0.38  0.14  1.00 -0.29 -0.28 -0.30 -0.17  0.33 -0.09  0.04 -0.28\nR3   -0.27 -0.71 -0.29  1.00  0.60  0.62  0.12 -0.30  0.09 -0.05  0.97\nR4   -0.54 -0.24 -0.28  0.60  1.00  0.97 -0.24 -0.12 -0.24 -0.05  0.55\nR5   -0.59 -0.23 -0.30  0.62  0.97  1.00 -0.17 -0.30 -0.20 -0.08  0.56\nR6    0.17 -0.02 -0.17  0.12 -0.24 -0.17  1.00 -0.42  0.87 -0.00  0.14\nR7    0.18  0.13  0.33 -0.30 -0.12 -0.30 -0.42  1.00 -0.29  0.09 -0.31\nR8    0.16  0.01 -0.09  0.09 -0.24 -0.20  0.87 -0.29  1.00  0.00  0.11\nR9    0.02 -0.17  0.04 -0.05 -0.05 -0.08 -0.00  0.09  0.00  1.00 -0.04\nR10  -0.17 -0.67 -0.28  0.97  0.55  0.56  0.14 -0.31  0.11 -0.04  1.00\n\n# Mapa de calor asociado\nsns.heatmap(X.corr(), vmin=-0.25, vmax=0.25, center=0, annot=True, fmt='.2f', mask=~np.tri(X.corr().shape[1], k=-1, dtype=bool), cbar=False)\nplt.show()\n\n\n\n# Factores de inflación de la varianza (VIF)\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfor i in range(1, lm_1.model.exog.shape[1]): print(variance_inflation_factor(lm_1.model.exog, i))\n\n2.2077109198999\n3.18291599820826\n1.512577893955147\n30.24127699986962\n82.05491709403677\n97.96482402421886\n4.84812107446913\n5.37667914104877\n4.231952446138941\n1.1390486096554169\n21.83164722834848\n\n# Corrección del problema de la multicolinealidad\n# Método de componentes principales (PCA)\n# Reescalamiento de la matriz de datos\nfrom sklearn.preprocessing import scale\nXs = pd.DataFrame(scale(X))\nXs.head().round(2)\n\n     0     1     2     3     4     5     6     7     8     9     10\n0 -0.48  0.59 -1.14  0.25 -0.06 -0.56 -1.25  3.21 -1.45 -0.63  0.13\n1 -0.31 -1.17  0.14  0.55  0.08  0.17 -1.14  0.05 -1.33 -0.30  0.40\n2 -0.08 -0.25 -1.45  0.07 -0.82 -0.42  3.44 -1.69  1.83  0.08  0.96\n3  0.25  0.56  0.21  0.10 -0.27 -0.22 -0.19  0.19  0.10 -0.73  0.07\n4  0.42  2.32 -0.45 -0.23  0.10 -0.07 -0.36  0.45  0.18 -0.29 -0.00\n\n# Método PCA de la librería sklearn\nfrom sklearn.decomposition import PCA\npca = PCA()\npca.fit(Xs)\n\nPCA()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PCAPCA()\n\n# Importancia de componentes\n# Desviaciones estándar (SDs) de los componentes principales\n(np.sqrt(pca.explained_variance_)).round(2)\n\narray([2.01, 1.54, 1.22, 1.01, 0.87, 0.79, 0.68, 0.47, 0.35, 0.15, 0.07])\n\n# Proporción de varianza explicada\n((pca.explained_variance_ratio_)*100).round(2)\n\narray([36.29, 21.34, 13.3 ,  9.13,  6.83,  5.64,  4.14,  2.  ,  1.09,\n        0.19,  0.05])\n\n# Proporción de varianza explicada acumulada\nnp.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n\narray([ 36.29,  57.63,  70.93,  80.06,  86.89,  92.53,  96.67,  98.67,\n        99.76,  99.95, 100.  ])\n\n# Matriz de rotación de los factores\nrotmat = pca.components_\nrotmat.shape\n\n(11, 11)\n\n# Regresión con los cuatros primeros factores (explicatividad &gt; 80%)\n# Interpretación de los factores en base al peso de las variables explicativas\n# NOTA: ¡ojo!, la dirección de los factores es diferente en Python y R\nrotmat[:4,:].round(2)\n\narray([[-0.27, -0.29, -0.24,  0.45,  0.41,  0.43,  0.  , -0.2 , -0.02,\n        -0.03,  0.43],\n       [ 0.2 , -0.11, -0.12,  0.12, -0.24, -0.19,  0.61, -0.32,  0.58,\n         0.  ,  0.15],\n       [-0.41,  0.54, -0.35, -0.26,  0.12,  0.2 ,  0.13, -0.3 ,  0.11,\n        -0.3 , -0.29],\n       [-0.27, -0.06, -0.27, -0.13, -0.01, -0.01,  0.04, -0.02,  0.03,\n         0.9 , -0.15]])\n\n# Factores estimados \npcscores = pca.fit_transform(scale(X))\npcscores.shape\n\n(80, 11)\n\n# Significado de la variables explicativas (factores)\npcscores[:10,:4] # 10 primeras filas\n\narray([[-0.48476918, -2.49283728, -0.39472381, -0.3512601 ],\n       [ 0.93811472, -1.35991854, -0.97998487, -0.38150241],\n       [ 0.67552246,  4.29920846,  1.0625268 ,  0.59921591],\n       [-0.42992425, -0.02737519,  0.14504884, -0.84046623],\n       [-0.8673304 , -0.40998562,  1.21063028, -0.36802165],\n       [ 0.36178714,  1.34224494, -0.1398588 , -0.84104517],\n       [ 0.22239636, -0.47982591, -0.64142878, -1.38659957],\n       [ 0.45846275,  1.60237168, -0.2593763 , -0.47149437],\n       [ 1.13591873, -2.08010949,  0.10255167,  0.08266445],\n       [-0.37084354, -1.34285341, -0.74458391, -0.10889674]])\n\n# Regresión con los factores estimados\nXfact = sm.add_constant(pcscores[:,:4])\nlm_2 = sm.OLS(RENTAB_EMP.RENTAB, Xfact).fit()\nprint(lm_2.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 RENTAB   R-squared:                       0.546\nModel:                            OLS   Adj. R-squared:                  0.522\nMethod:                 Least Squares   F-statistic:                     22.59\nDate:                Wed, 15 Nov 2023   Prob (F-statistic):           2.85e-12\nTime:                        09:52:37   Log-Likelihood:                 78.398\nNo. Observations:                  80   AIC:                            -146.8\nDf Residuals:                      75   BIC:                            -134.9\nDf Model:                           4                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.1450      0.010     13.827      0.000       0.124       0.166\nx1             0.0170      0.005      3.232      0.002       0.007       0.027\nx2             0.0044      0.007      0.648      0.519      -0.009       0.018\nx3            -0.0691      0.009     -7.970      0.000      -0.086      -0.052\nx4            -0.0418      0.010     -3.998      0.000      -0.063      -0.021\n==============================================================================\nOmnibus:                       14.061   Durbin-Watson:                   1.644\nProb(Omnibus):                  0.001   Jarque-Bera (JB):               19.535\nSkew:                           0.751   Prob(JB):                     5.73e-05\nKurtosis:                       4.899   Cond. No.                         2.00\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Método Ridge\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\ny = np.asarray(RENTAB_EMP.RENTAB)  # y = RENTAB_EMP['RENTAB'] \n# Modelo baselina (sin regularización)\nregression = LinearRegression()\nregression.fit(X,y)\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegressionLinearRegression()\n\nMSE_lm_3_0 = (mean_squared_error(y_true=y,y_pred=regression.predict(X)))\nprint(MSE_lm_3_0)\n\n0.004301953862928571\n\ncoef_dict_regression = {}\nfor coef, feat in zip(regression.coef_, X.columns):\n  coef_dict_regression[feat] = coef\ncoef_dict_regression\n\n{'l_VT': 0.03038112251462276, 'R1': 0.048695294678163685, 'R2': 0.01309305040362247, 'R3': 0.44366808519367923, 'R4': -0.05617409325560271, 'R5': -0.012001985053930637, 'R6': -0.2658700929867994, 'R7': -0.018991219082772903, 'R8': -0.08292599521003328, 'R9': -0.01247702324614546, 'R10': 0.12626125534648275}\n\n# Regularización ridge\n# ridge = Ridge(normalize=True)\nridge = Ridge()\nsearch = GridSearchCV(estimator=ridge, param_grid={'alpha':np.logspace(-4,4,50)}, scoring='neg_mean_squared_error', n_jobs=1, refit=True, cv=10)\nsearch.fit(X,y)\n\nGridSearchCV(cv=10, estimator=Ridge(), n_jobs=1,\n             param_grid={'alpha': array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n       4.09491506e-02, 5.96362332e-02, 8.68511...\n       3.72759372e+00, 5.42867544e+00, 7.90604321e+00, 1.15139540e+01,\n       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n       6.86648845e+03, 1.00000000e+04])},\n             scoring='neg_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=10, estimator=Ridge(), n_jobs=1,\n             param_grid={'alpha': array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n       4.09491506e-02, 5.96362332e-02, 8.68511...\n       3.72759372e+00, 5.42867544e+00, 7.90604321e+00, 1.15139540e+01,\n       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n       6.86648845e+03, 1.00000000e+04])},\n             scoring='neg_mean_squared_error')estimator: RidgeRidge()RidgeRidge()\n\nprint(search.best_params_)\n\n{'alpha': 1.2067926406393288}\n\nprint(abs(search.best_score_))\n\n0.011260323137152676\n\n# ridge = Ridge(normalize=True, alpha=1.207)\nridge = Ridge(alpha=1.20679)\nridge.fit(X,y)\n\nRidge(alpha=1.20679)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RidgeRidge(alpha=1.20679)\n\nMSE_lm_3 = (mean_squared_error(y_true=y,y_pred=ridge.predict(X)))\nprint(MSE_lm_3)\n\n0.004956562993708741\n\ncoef_dict_ridge = {}\nfor coef, feat in zip(ridge.coef_, X.columns):\n  coef_dict_ridge[feat] = coef\ncoef_dict_ridge\n\n{'l_VT': 0.025696965854039352, 'R1': -0.05055888236269989, 'R2': 0.015510840375677041, 'R3': 0.18429520974819244, 'R4': -0.04364232422236836, 'R5': -0.005030634957126601, 'R6': -0.11319102431052548, 'R7': 0.008823233166415131, 'R8': -0.10215993405656096, 'R9': -0.020001297300887597, 'R10': 0.20082345795451428}\n\n# Gráfica\nn_alphas = 50\nalphas = np.logspace(-4, 4, n_alphas)\ncoefs = []\nfor a in alphas:\n    # ridge = Ridge(alpha=a, fit_intercept=False, normalize=True)\n    ridge = Ridge(alpha=a, fit_intercept=False)\n    ridge.fit(X, y)\n    coefs.append(ridge.coef_)\n\nRidge(alpha=10000.0, fit_intercept=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RidgeRidge(alpha=10000.0, fit_intercept=False)\n\nax = plt.gca()\nax.plot(alphas, coefs)\nax.set_xscale('log')\nax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n\n(25118.864315095823, 3.9810717055349695e-05)\n\nplt.xlabel('alpha')\nplt.ylabel('weights')\nplt.title('Coeficientes ridge en función del parámetros de regularización')\nplt.axis('tight')\n\n(25118.864315095823, 3.9810717055349695e-05, -0.29356456116968355, 0.54463682355373)\n\nplt.show()\n\n\n\n# Regresión LASSO\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nlasso = Lasso()\nsearch = GridSearchCV(estimator=lasso, param_grid={'alpha':np.logspace(-4,4,50)}, scoring='neg_mean_squared_error', n_jobs=1, refit=True, cv=10)\nsearch.fit(X,y)\n\nGridSearchCV(cv=10, estimator=Lasso(), n_jobs=1,\n             param_grid={'alpha': array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n       4.09491506e-02, 5.96362332e-02, 8.68511...\n       3.72759372e+00, 5.42867544e+00, 7.90604321e+00, 1.15139540e+01,\n       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n       6.86648845e+03, 1.00000000e+04])},\n             scoring='neg_mean_squared_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=10, estimator=Lasso(), n_jobs=1,\n             param_grid={'alpha': array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n       4.09491506e-02, 5.96362332e-02, 8.68511...\n       3.72759372e+00, 5.42867544e+00, 7.90604321e+00, 1.15139540e+01,\n       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n       6.86648845e+03, 1.00000000e+04])},\n             scoring='neg_mean_squared_error')estimator: LassoLasso()LassoLasso()\n\nprint(search.best_params_)\n\n{'alpha': 0.0009540954763499944}\n\nprint(abs(search.best_score_))\n\n0.010415430553402948\n\nlasso = Lasso(alpha=0.00095)\nlasso.fit(X,y)\n\nLasso(alpha=0.00095)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LassoLasso(alpha=0.00095)\n\nMSE_lm_4 = (mean_squared_error(y_true=y,y_pred=lasso.predict(X)))\nprint(MSE_lm_4)\n\n0.004447386776636628\n\ncoef_dict_lasso = {}\nfor coef, feat in zip(lasso.coef_, X.columns):\n  coef_dict_lasso[feat] = coef\ncoef_dict_lasso\n\n{'l_VT': 0.02647848311704356, 'R1': -0.0, 'R2': 0.01393756455463257, 'R3': 0.30020893054761955, 'R4': -0.054232171831217375, 'R5': -0.0050485376396390445, 'R6': -0.1937096099995072, 'R7': 0.0, 'R8': -0.08910648062930449, 'R9': -0.014437757323950948, 'R10': 0.1838342275547619}\n\n# Gráfica\nlasso = Lasso(random_state=0, max_iter=10000, tol=0.01)\nalphas = np.logspace(-4, 4, 50)\ntuned_parameters = [{'alpha': alphas}]\nn_folds = 3\nclf = GridSearchCV(lasso, tuned_parameters, cv=n_folds, refit=False)\nclf.fit(X, y)\n\nGridSearchCV(cv=3, estimator=Lasso(max_iter=10000, random_state=0, tol=0.01),\n             param_grid=[{'alpha': array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n       4.094915...\n       8.28642773e-01, 1.20679264e+00, 1.75751062e+00, 2.55954792e+00,\n       3.72759372e+00, 5.42867544e+00, 7.90604321e+00, 1.15139540e+01,\n       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n       6.86648845e+03, 1.00000000e+04])}],\n             refit=False)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=3, estimator=Lasso(max_iter=10000, random_state=0, tol=0.01),\n             param_grid=[{'alpha': array([1.00000000e-04, 1.45634848e-04, 2.12095089e-04, 3.08884360e-04,\n       4.49843267e-04, 6.55128557e-04, 9.54095476e-04, 1.38949549e-03,\n       2.02358965e-03, 2.94705170e-03, 4.29193426e-03, 6.25055193e-03,\n       9.10298178e-03, 1.32571137e-02, 1.93069773e-02, 2.81176870e-02,\n       4.094915...\n       8.28642773e-01, 1.20679264e+00, 1.75751062e+00, 2.55954792e+00,\n       3.72759372e+00, 5.42867544e+00, 7.90604321e+00, 1.15139540e+01,\n       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n       6.86648845e+03, 1.00000000e+04])}],\n             refit=False)estimator: LassoLasso(max_iter=10000, random_state=0, tol=0.01)LassoLasso(max_iter=10000, random_state=0, tol=0.01)\n\nscores = clf.cv_results_['mean_test_score']\nscores_std = clf.cv_results_['std_test_score']\nplt.semilogx(alphas, scores)\n# gráfica que muestra los errores (+/- una desviación estándar de las puntuaciones)\nstd_error = scores_std / np.sqrt(n_folds)\nplt.semilogx(alphas, scores + std_error, 'b--')\nplt.semilogx(alphas, scores - std_error, 'b--')\n# alpha=0.2 controla la translucidez del color de relleno\nplt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\nplt.ylabel('CV score +/- std error')\nplt.xlabel('alpha')\nplt.axhline(np.max(scores), linestyle='--', color='.5')\nplt.xlim([alphas[0], alphas[-1]])\n\n(0.0001, 10000.0)\n\nplt.show()"
  },
  {
    "objectID": "p3c2-app11.html#código-r",
    "href": "p3c2-app11.html#código-r",
    "title": "Aplicación 3.11 (Regresores endógenos - El estimador de variables instrumentales: Determinantes de la inflación al nivel internacional",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(ivreg)\n# Para más detalles sobre el método de variables instrumentales \n# (IV o 2SLS en inglés) ver las páginas web: \n# https://cran.r-project.org/web/packages/ivreg/vignettes/ivreg.html \n# https://cran.r-project.org/web/packages/ivreg/vignettes/\n# /Diagnostics-for-2SLS-Regression.html\n#\n# Lectura de datos\nINF_INT &lt;- read_csv(\"data/INF_INTERN.csv\")\nsummary(INF_INT)\n\n      EDUC             INF               INV               RM         \n Min.   :0.1400   Min.   : -0.600   Min.   :0.0868   Min.   :  2.500  \n 1st Qu.:0.6325   1st Qu.:  4.275   1st Qu.:0.1790   1st Qu.:  8.175  \n Median :0.9350   Median :  8.650   Median :0.2278   Median : 16.350  \n Mean   :0.8259   Mean   : 25.354   Mean   :0.2240   Mean   : 29.590  \n 3rd Qu.:1.0600   3rd Qu.: 17.150   3rd Qu.:0.2565   3rd Qu.: 22.400  \n Max.   :1.6400   Max.   :374.300   Max.   :0.4210   Max.   :356.700  \n      RPOB             RY              YPC0       \n Min.   :0.100   Min.   :-0.600   Min.   :0.2370  \n 1st Qu.:1.175   1st Qu.: 1.675   1st Qu.:0.5042  \n Median :2.250   Median : 2.700   Median :0.9190  \n Mean   :2.012   Mean   : 2.997   Mean   :1.7034  \n 3rd Qu.:2.800   3rd Qu.: 4.000   3rd Qu.:2.4505  \n Max.   :3.700   Max.   : 9.600   Max.   :7.3800  \n\n# Estimación MCO\nmodelo_MCO &lt;- lm(INF ~ RM + RY, data=INF_INT)\nsummary(modelo_MCO)\n\n\nCall:\nlm(formula = INF ~ RM + RY, data = INF_INT)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-24.799  -1.235   0.101   1.848   9.076 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.234214   0.979925  -0.239    0.812    \nRM           1.033131   0.009042 114.257  &lt; 2e-16 ***\nRY          -1.662006   0.250566  -6.633 4.95e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.31 on 73 degrees of freedom\nMultiple R-squared:  0.9948,    Adjusted R-squared:  0.9947 \nF-statistic:  6978 on 2 and 73 DF,  p-value: &lt; 2.2e-16\n\n# Estimación VI\nmodelo_IV &lt;- ivreg(INF ~ RM + RY | RM + EDUC + INV + RPOB + YPC0, \n                   data=INF_INT)\nsummary(modelo_IV, diagnostics=TRUE)\n\n\nCall:\nivreg(formula = INF ~ RM + RY | RM + EDUC + INV + RPOB + YPC0, \n    data = INF_INT)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-24.633  -1.487   0.204   1.937   9.498 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.093985   1.858208  -0.589   0.5579    \nRM           1.035059   0.009773 105.914   &lt;2e-16 ***\nRY          -1.394200   0.551503  -2.528   0.0136 *  \n\nDiagnostic tests:\n                 df1 df2 statistic p-value   \nWeak instruments   4  70     4.642 0.00221 **\nWu-Hausman         1  72     0.300 0.58551   \nSargan             3  NA     2.455 0.48344   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.344 on 73 degrees of freedom\nMultiple R-Squared: 0.9947, Adjusted R-squared: 0.9946 \nWald test:  6852 on 2 and 73 DF,  p-value: &lt; 2.2e-16 \n\n# Comparación de modelos\n# car::compareCoefs(modelo_MCO, modelo_IV)\nlibrary(\"modelsummary\")\nmodel_list &lt;- list(MCO = modelo_MCO, IV = modelo_IV)\nmsummary(model_list)\n\n\n\n\n\nMCO\n IV\n\n\n\n\n(Intercept)\n−0.234\n−1.094\n\n\n\n(0.980)\n(1.858)\n\n\nRM\n1.033\n1.035\n\n\n\n(0.009)\n(0.010)\n\n\nRY\n−1.662\n−1.394\n\n\n\n(0.251)\n(0.552)\n\n\nNum.Obs.\n76\n76\n\n\nR2\n0.995\n0.995\n\n\nR2 Adj.\n0.995\n0.995\n\n\nAIC\n442.7\n443.9\n\n\nBIC\n452.0\n453.2\n\n\nLog.Lik.\n−217.340\n\n\n\nF\n6978.325\n\n\n\nRMSE\n4.22\n4.26\n\n\n\n\n\n\nmodelplot(model_list)"
  },
  {
    "objectID": "p3c2-app11.html#código-python",
    "href": "p3c2-app11.html#código-python",
    "title": "Aplicación 3.11 (Regresores endógenos - El estimador de variables instrumentales: Determinantes de la inflación al nivel internacional",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom linearmodels.iv import IV2SLS\n# Lectura de datos\nINF_INT = pd.read_csv('data/INF_INTERN.csv')\nINF_INT.describe()\n\n            EDUC         INF        INV  ...       RPOB         RY       YPC0\ncount  76.000000   76.000000  76.000000  ...  76.000000  76.000000  76.000000\nmean    0.825921   25.353947   0.223951  ...   2.011842   2.997368   1.703421\nstd     0.319229   58.947670   0.066628  ...   1.021759   2.026950   1.765252\nmin     0.140000   -0.600000   0.086800  ...   0.100000  -0.600000   0.237000\n25%     0.632500    4.275000   0.178975  ...   1.175000   1.675000   0.504250\n50%     0.935000    8.650000   0.227850  ...   2.250000   2.700000   0.919000\n75%     1.060000   17.150000   0.256500  ...   2.800000   4.000000   2.450500\nmax     1.640000  374.300000   0.421000  ...   3.700000   9.600000   7.380000\n\n[8 rows x 7 columns]\n\n# Estimación MCO\nINF_INT = sm.add_constant(INF_INT)\nmodelo_MCO = IV2SLS(dependent = INF_INT.INF,\n               exog = INF_INT[['const','RM','RY']], \n               endog = None, \n               instruments = None)\nres_modelo_MCO = modelo_MCO.fit(cov_type='unadjusted')\nprint(res_modelo_MCO)\n\n                            OLS Estimation Summary                            \n==============================================================================\nDep. Variable:                    INF   R-squared:                      0.9948\nEstimator:                        OLS   Adj. R-squared:                 0.9947\nNo. Observations:                  76   F-statistic:                 1.453e+04\nDate:                Wed, Nov 15 2023   P-value (F-stat)                0.0000\nTime:                        09:54:06   Distribution:                  chi2(2)\nCov. Estimator:            unadjusted                                         \n                                                                              \n                             Parameter Estimates                              \n==============================================================================\n            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n------------------------------------------------------------------------------\nconst         -0.2342     0.9604    -0.2439     0.8073     -2.1165      1.6481\nRM             1.0331     0.0089     116.58     0.0000      1.0158      1.0505\nRY            -1.6620     0.2456    -6.7679     0.0000     -2.1433     -1.1807\n==============================================================================\n\n# Estimación IV (2SLS)\nmodelo_IV = IV2SLS(dependent = INF_INT.INF,\n               exog = INF_INT[['const','RM']],\n               endog = INF_INT.RY,\n               instruments = INF_INT[['EDUC','INV','RPOB','YPC0']])\nres_modelo_IV = modelo_IV.fit(cov_type='unadjusted')\nprint(res_modelo_IV)\n\n                          IV-2SLS Estimation Summary                          \n==============================================================================\nDep. Variable:                    INF   R-squared:                      0.9947\nEstimator:                    IV-2SLS   Adj. R-squared:                 0.9946\nNo. Observations:                  76   F-statistic:                 1.427e+04\nDate:                Wed, Nov 15 2023   P-value (F-stat)                0.0000\nTime:                        09:54:06   Distribution:                  chi2(2)\nCov. Estimator:            unadjusted                                         \n                                                                              \n                             Parameter Estimates                              \n==============================================================================\n            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n------------------------------------------------------------------------------\nconst         -1.0940     1.8212    -0.6007     0.5480     -4.6634      2.4754\nRM             1.0351     0.0096     108.07     0.0000      1.0163      1.0538\nRY            -1.3942     0.5405    -2.5794     0.0099     -2.4536     -0.3348\n==============================================================================\n\nEndogenous: RY\nInstruments: EDUC, INV, RPOB, YPC0\nUnadjusted Covariance (Homoskedastic)\nDebiased: False\n\nres_modelo_IV.wu_hausman()\n\nWu-Hausman test of exogeneity\nH0: All endogenous variables are exogenous\nStatistic: 1.1498\nP-value: 0.2872\nDistributed: F(1,72)\nWaldTestStatistic, id: 0x13a9e34f0\n\n# Comparación de resultados\nfrom collections import OrderedDict\nfrom linearmodels.iv.results import compare\nres_modelos = OrderedDict()\nres_modelos[\"MCO\"] = res_modelo_MCO\nres_modelos[\"IV\"] = res_modelo_IV\nprint(compare(res_modelos))\n\n                 Model Comparison                 \n==================================================\n                                MCO             IV\n--------------------------------------------------\nDep. Variable                   INF            INF\nEstimator                       OLS        IV-2SLS\nNo. Observations                 76             76\nCov. Est.                unadjusted     unadjusted\nR-squared                    0.9948         0.9947\nAdj. R-squared               0.9947         0.9946\nF-statistic               1.453e+04      1.427e+04\nP-value (F-stat)             0.0000         0.0000\n==================     ============   ============\nconst                       -0.2342        -1.0940\n                          (-0.2439)      (-0.6007)\nRM                           1.0331         1.0351\n                           (116.58)       (108.07)\nRY                          -1.6620        -1.3942\n                          (-6.7679)      (-2.5794)\n==================== ============== ==============\nInstruments                                   EDUC\n                                               INV\n                                              RPOB\n                                              YPC0\n--------------------------------------------------\n\nT-stats reported in parentheses"
  },
  {
    "objectID": "p3c2-app12.html#variable-dependiente-discreta-modelos-logit-y-probit-préstamos-hipotecarios",
    "href": "p3c2-app12.html#variable-dependiente-discreta-modelos-logit-y-probit-préstamos-hipotecarios",
    "title": "Aplicación 3.12 (Variable dependiente discreta o limitada): Modelos Logit/Probit, Tobit y Heckit",
    "section": "Variable dependiente discreta (modelos Logit y Probit): Préstamos hipotecarios",
    "text": "Variable dependiente discreta (modelos Logit y Probit): Préstamos hipotecarios\nEn un artículo del año 1987, Dhillon y otros autores estudiaron el conjunto de características personales y financieras que determinan la elección por parte de los individuos de un tipo de interés fijo frente a uno variable a la hora de contratar un préstamo hipotecario. El interés de su trabajo radicaba en contrastar las dos posturas que dominan los planteamientos teóricos sobre el tema: la primera de ellas opina que, de acuerdo con la hipótesis de mercados eficientes, las características personales del prestatario no contienen información que no haya sido ya tenida en cuenta por el mercado a la hora de fijar el tipo de interés y, por tanto, sólo las variables de precios y los términos del contrato serían relevantes cuando un individuo elige el tipo de interés que se le aplicará; la segunda escuela de pensamiento supone que existe información asimétrica, es decir, dadas las condiciones del mercado, los prestatarios pueden favorecerse no revelando algunas de sus características personales a la hora de firmar el contrato.\nEl modelo propuesto relaciona la probabilidad de que un individuo elija, dadas sus características personales y las condiciones del mercado, un tipo de interés variable frente a uno fijo para un préstamo hipotecario. Se dispone de una muestra de 78 clientes de un banco hipotecario norteamericano. Del total de observaciones, 46 eligieron un tipo de interés fijo (con vencimiento de 30 años) y 32 un tipo de interés variable (no acotado).\nLas variables disponibles para estimar el modelo son las siguientes:\n\nVariable dependiente: \\(Y\\) toma el valor 1 si el individuo elige un tipo de interés variable y 0 si firma el préstamo a un tipo fijo.\nVariables explicativas del mercado: \\(FI\\) es el tipo de interés fijo que ofertó el banco, \\(MARG\\) el margen del tipo fijo sobre el tipo de interés variable, \\(YLD\\) la diferencia entre el tipo de interés de las letras del tesoro a 10 años y el tipo de las letras a 1 año (esta variable intenta anticipar el cambio futuro en los tipos de interés a corto plazo), \\(PTS\\) la razón entre el tipo de interés fijo y el variable, y \\(MAT\\) la razón entre los vencimientos de los préstamos hipotecarios con tipo fijo y variable.\nVariables explicativas personales: \\(BA\\) es la edad del prestatario, \\(BS\\) los años de escolarización, \\(FTB\\) una variable ficticia que toma el valor 1 si el prestatario compra vivienda por primera vez y 0 en otro caso, \\(CB\\) una ficticia que toma el valor 1 si existe un co-prestatario y 0 en otro caso, \\(MC\\) una ficticia que toma el valor 1 si el prestatario está casado y 0 si no lo está, \\(SE\\) una ficticia que toma el valor 1 si trabaja por cuenta propia y 0 en otro caso, \\(MOB\\) el número de años que el prestatario lleva residiendo en la dirección actual, \\(NW\\) la riqueza neta, \\(LA\\) los activos líquidos, y \\(STL\\) los compromisos económicos del prestatario a corto plazo.\n\nEl modelo econométrico general que se estimará tiene la siguiente expresión:\n\\[Y_{i} = \\beta_1 + \\beta_2 FI_{i} + \\beta_3 MARG_{i} + \\beta_4 YLD_{i} + \\beta_5 PTS_{i} + \\beta_6 MAT_{i} +\\] \\[+ \\beta_7 BA_{i} + \\beta_8 BS_{i} + \\beta_9 FTB_{i} + \\beta_{10} CB_{i} + \\beta_{11} MC_{i} + \\] \\[+ \\beta_{12} SE_{i} + \\beta_{13} MOB_{i} + \\beta_{14} NW_{i} + \\beta_{15} LA_{i} + \\beta_{16} STL_{i} + e_{i}\\]"
  },
  {
    "objectID": "p3c2-app12.html#variable-dependiente-limitada-valores-censurados---modelo-tobit-compra-de-automóviles",
    "href": "p3c2-app12.html#variable-dependiente-limitada-valores-censurados---modelo-tobit-compra-de-automóviles",
    "title": "Aplicación 3.12 (Variable dependiente discreta o limitada): Modelos Logit/Probit, Tobit y Heckit",
    "section": "Variable dependiente limitada (valores censurados -> modelo Tobit): Compra de automóviles",
    "text": "Variable dependiente limitada (valores censurados -&gt; modelo Tobit): Compra de automóviles\nEn un trabajo encargado por una asociación de fabricantes de automóviles, se estimó un modelo microeconométrico en el que se relacionaba el gasto en automóviles realizado por las familias que componían una muestra representativa con algunas características socioeconómicas de las mismas.\nLa ecuación de comportamiento especificada fue la siguiente:\n\\[GAUT_{i} = \\beta_1 + \\beta_2 Y_{i} + \\beta_3 HIJOSM18_{i} + \\beta_4 EDAD_{i} + e_{i}\\]\ndonde \\(GAUT\\) es el gasto familiar efectuado en la adquisición de automóviles en el último año, \\(Y\\) es la renta familiar total del último ejercicio fiscal, \\(HIJOSM18\\) es el número de hijos con edades inferiores a dieciocho años, y \\(EDAD\\) es la edad del cabeza de familia."
  },
  {
    "objectID": "p3c2-app12.html#variable-dependiente-limitada-truncamiento-selectivo---modelo-heckit-de-selección-muestral-salarios-de-las-mujeres-casadas",
    "href": "p3c2-app12.html#variable-dependiente-limitada-truncamiento-selectivo---modelo-heckit-de-selección-muestral-salarios-de-las-mujeres-casadas",
    "title": "Aplicación 3.12 (Variable dependiente discreta o limitada): Modelos Logit/Probit, Tobit y Heckit",
    "section": "Variable dependiente limitada (truncamiento selectivo -> modelo Heckit de selección muestral): Salarios de las mujeres casadas",
    "text": "Variable dependiente limitada (truncamiento selectivo -&gt; modelo Heckit de selección muestral): Salarios de las mujeres casadas\nEn esta aplicación se estima una ecuación Minceriana de salarios para las mujeres casadas basada en una investigación de Thomas A. Mroz del año 1987 para el Reino Uniod. El modelo propuesto es el siguiente:\n\\[log(SALARIO_{i}) = \\beta_1 + \\beta_2 EDUC_{i} + \\beta_3 EXPER_{i} + e_{i}\\]\ndonde \\(SALARIO\\) representa el salario por hora trabajada observado, \\(EDUC\\) es el nivel de educación y \\(EXPER\\) es el nivel de experiencia.\nAl realizar una encuesta a una muestra de N = 753 mujeres casadas, representativa de la población femenina con ese estado civil en UK, preguntándoles entre otras cosas por su salario, muchas de ellas (325 mujeres) respondieron que esa cuestión no era relevante en su caso, ya que eran “amas de casa” (población no activa) y no recibían remuneración alguna por ese trabajo. Solo se observaron datos sobre salarios de mercado para aquellas mujeres (n = 428) que participaban en la fuerza de trabajo."
  },
  {
    "objectID": "p3c2-app13.html#código-r",
    "href": "p3c2-app13.html#código-r",
    "title": "Aplicación 3.13 (Modelos econométricos para datos de panel): Productividad de la industria química en China",
    "section": "Código R",
    "text": "Código R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(stargazer)\nlibrary(plm)\n# Lectura de datos\nQUIM_CHINA &lt;- read_csv(\"data/QUIM_CHINA.csv\")\n# Asignar estructura de panel de datos \nQUIM_CHINA_pdata  &lt;-  pdata.frame(QUIM_CHINA,index=c(\"firm\", \"year\"))\npdim(QUIM_CHINA_pdata)\n\nBalanced Panel: n = 12552, T = 3, N = 37656\n\nsummary(QUIM_CHINA_pdata[c(\"Y\",\"K\",\"L\",\"M\")])\n\n       Y                  K                 L                 M           \n Min.   :      80   Min.   :     10   Min.   :    5.0   Min.   :      13  \n 1st Qu.:   12060   1st Qu.:   2172   1st Qu.:   43.0   1st Qu.:    7281  \n Median :   25744   Median :   5922   Median :   80.0   Median :   15935  \n Mean   :   95061   Mean   :  39923   Mean   :  199.2   Mean   :   60753  \n 3rd Qu.:   65440   3rd Qu.:  19447   3rd Qu.:  178.0   3rd Qu.:   41227  \n Max.   :18801552   Max.   :8483723   Max.   :19194.0   Max.   :12681439  \n\n# Modelos estáticos para datos de panel\n# Modelo plano ('pool MCO`)\nmodelo_plano &lt;- plm(log(Y) ~ log(K) + log(L) + log(M), \n                    data = QUIM_CHINA_pdata, model = \"pooling\")\nsummary(modelo_plano)\n\nPooling Model\n\nCall:\nplm(formula = log(Y) ~ log(K) + log(L) + log(M), data = QUIM_CHINA_pdata, \n    model = \"pooling\")\n\nBalanced Panel: n = 12552, T = 3, N = 37656\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-3.669751 -0.195708 -0.042888  0.138174  5.043532 \n\nCoefficients:\n             Estimate Std. Error t-value  Pr(&gt;|t|)    \n(Intercept) 1.4572295  0.0134731 108.159 &lt; 2.2e-16 ***\nlog(K)      0.0892604  0.0016557  53.910 &lt; 2.2e-16 ***\nlog(L)      0.1267536  0.0024510  51.716 &lt; 2.2e-16 ***\nlog(M)      0.7654859  0.0017867 428.444 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    61241\nResidual Sum of Squares: 4652.8\nR-Squared:      0.92403\nAdj. R-Squared: 0.92402\nF-statistic: 152645 on 3 and 37652 DF, p-value: &lt; 2.22e-16\n\n# Modelo de efectos individuales fijos (EF)\nmodelo_ef &lt;- plm(log(Y) ~ log(K) + log(L) + log(M), \n                 data = QUIM_CHINA_pdata, model = \"within\")\nsummary(modelo_ef)\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = log(Y) ~ log(K) + log(L) + log(M), data = QUIM_CHINA_pdata, \n    model = \"within\")\n\nBalanced Panel: n = 12552, T = 3, N = 37656\n\nResiduals:\n       Min.     1st Qu.      Median     3rd Qu.        Max. \n-3.46366385 -0.08698034  0.00093282  0.08632298  3.00605304 \n\nCoefficients:\n        Estimate Std. Error t-value  Pr(&gt;|t|)    \nlog(K) 0.0701396  0.0037307  18.801 &lt; 2.2e-16 ***\nlog(L) 0.1450594  0.0058192  24.928 &lt; 2.2e-16 ***\nlog(M) 0.6623900  0.0031819 208.173 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    5061.8\nResidual Sum of Squares: 1588.4\nR-Squared:      0.68619\nAdj. R-Squared: 0.52925\nF-statistic: 18295.9 on 3 and 25101 DF, p-value: &lt; 2.22e-16\n\n# Comparación del mdelo plano frente al modelo de efectos fijos\npFtest(modelo_ef, modelo_plano)\n\n\n    F test for individual effects\n\ndata:  log(Y) ~ log(K) + log(L) + log(M)\nF = 3.8581, df1 = 12551, df2 = 25101, p-value &lt; 2.2e-16\nalternative hypothesis: significant effects\n\n# Modelo de efectos individuales y temporales fijos (EF)\nmodelo_ef_it &lt;- plm(log(Y) ~ log(K) + log(L) + log(M), \n                    data = QUIM_CHINA_pdata, \n                    model = \"within\", effect = \"twoways\")\nsummary(modelo_ef_it)\n\nTwoways effects Within Model\n\nCall:\nplm(formula = log(Y) ~ log(K) + log(L) + log(M), data = QUIM_CHINA_pdata, \n    effect = \"twoways\", model = \"within\")\n\nBalanced Panel: n = 12552, T = 3, N = 37656\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-3.3843200 -0.0844505 -0.0012966  0.0838423  2.7736119 \n\nCoefficients:\n        Estimate Std. Error  t-value  Pr(&gt;|t|)    \nlog(K) 0.0365640  0.0036879   9.9146 &lt; 2.2e-16 ***\nlog(L) 0.1454867  0.0056201  25.8871 &lt; 2.2e-16 ***\nlog(M) 0.6125521  0.0032886 186.2647 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    3910.4\nResidual Sum of Squares: 1481.3\nR-Squared:      0.6212\nAdj. R-Squared: 0.4317\nF-statistic: 13720 on 3 and 25099 DF, p-value: &lt; 2.22e-16\n\npFtest(modelo_ef_it, modelo_plano)\n\n\n    F test for twoways effects\n\ndata:  log(Y) ~ log(K) + log(L) + log(M)\nF = 4.2809, df1 = 12553, df2 = 25099, p-value &lt; 2.2e-16\nalternative hypothesis: significant effects\n\n# Significación de efectos individuales\nplmtest(modelo_plano, effect=\"individual\")\n\n\n    Lagrange Multiplier Test - (Honda)\n\ndata:  log(Y) ~ log(K) + log(L) + log(M)\nnormal = 89.816, p-value &lt; 2.2e-16\nalternative hypothesis: significant effects\n\nplmtest(modelo_plano, effect = \"time\" )\n\n\n    Lagrange Multiplier Test - time effects (Honda)\n\ndata:  log(Y) ~ log(K) + log(L) + log(M)\nnormal = 98.672, p-value &lt; 2.2e-16\nalternative hypothesis: significant effects\n\nplmtest(modelo_plano, effect = \"twoways\" )\n\n\n    Lagrange Multiplier Test - two-ways effects (Honda)\n\ndata:  log(Y) ~ log(K) + log(L) + log(M)\nnormal = 133.28, p-value &lt; 2.2e-16\nalternative hypothesis: significant effects\n\n# Modelo de efectos individuales aleatorios (EA)\nmodelo_ea &lt;- plm(log(Y) ~ log(K) + log(L) + log(M), \n                 data = QUIM_CHINA_pdata, model = \"random\")\nsummary(modelo_ea)\n\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = log(Y) ~ log(K) + log(L) + log(M), data = QUIM_CHINA_pdata, \n    model = \"random\")\n\nBalanced Panel: n = 12552, T = 3, N = 37656\n\nEffects:\n                  var std.dev share\nidiosyncratic 0.06328 0.25156 0.522\nindividual    0.05791 0.24065 0.478\ntheta: 0.4833\n\nResiduals:\n     Min.   1st Qu.    Median   3rd Qu.      Max. \n-3.537821 -0.130882 -0.021849  0.101972  4.113790 \n\nCoefficients:\n             Estimate Std. Error z-value  Pr(&gt;|z|)    \n(Intercept) 1.6636911  0.0170805  97.403 &lt; 2.2e-16 ***\nlog(K)      0.0935514  0.0019937  46.923 &lt; 2.2e-16 ***\nlog(L)      0.1396775  0.0030096  46.411 &lt; 2.2e-16 ***\nlog(M)      0.7346752  0.0020847 352.418 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    20061\nResidual Sum of Squares: 2448.6\nR-Squared:      0.87795\nAdj. R-Squared: 0.87794\nChisq: 270834 on 3 DF, p-value: &lt; 2.22e-16\n\n# Contraste del modelo de efectos aleatorios frente al de efectos fijos: \n# Test de Hausman\nphtest(modelo_ef, modelo_ea)\n\n\n    Hausman Test\n\ndata:  log(Y) ~ log(K) + log(L) + log(M)\nchisq = 1061.6, df = 3, p-value &lt; 2.2e-16\nalternative hypothesis: one model is inconsistent\n\n# Comparación de resultados de los tres modelos\nstargazer(modelo_plano, modelo_ef, modelo_ea, type=\"text\")\n\n\n========================================================================================\n                                         Dependent variable:                            \n             ---------------------------------------------------------------------------\n                                               log(Y)                                   \n                          (1)                            (2)                   (3)      \n----------------------------------------------------------------------------------------\nlog(K)                  0.089***                      0.070***               0.094***   \n                        (0.002)                        (0.004)               (0.002)    \n                                                                                        \nlog(L)                  0.127***                      0.145***               0.140***   \n                        (0.002)                        (0.006)               (0.003)    \n                                                                                        \nlog(M)                  0.765***                      0.662***               0.735***   \n                        (0.002)                        (0.003)               (0.002)    \n                                                                                        \nConstant                1.457***                                             1.664***   \n                        (0.013)                                              (0.017)    \n                                                                                        \n----------------------------------------------------------------------------------------\nObservations             37,656                        37,656                 37,656    \nR2                       0.924                          0.686                 0.878     \nAdjusted R2              0.924                          0.529                 0.878     \nF Statistic  152,645.100*** (df = 3; 37652) 18,295.900*** (df = 3; 25101) 270,834.200***\n========================================================================================\nNote:                                                        *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "p3c2-app13.html#código-python",
    "href": "p3c2-app13.html#código-python",
    "title": "Aplicación 3.13 (Modelos econométricos para datos de panel): Productividad de la industria química en China",
    "section": "Código Python",
    "text": "Código Python\n\n# Lectura de librerías \nimport numpy as np\nimport pandas as pd\nfrom linearmodels import PooledOLS, PanelOLS, RandomEffects\n# Lectura de datos\nQUIM_CHINA = pd.read_csv(\"data/QUIM_CHINA.csv\")\n# Estructura de panel de datos\nQUIM_CHINA_pdata = QUIM_CHINA.set_index(['firm','year'])\nQUIM_CHINA[\"Y\"].describe()\n\ncount    3.765600e+04\nmean     9.506150e+04\nstd      3.813742e+05\nmin      8.000003e+01\n25%      1.206001e+04\n50%      2.574357e+04\n75%      6.544007e+04\nmax      1.880155e+07\nName: Y, dtype: float64\n\nQUIM_CHINA[\"K\"].describe()\n\ncount    3.765600e+04\nmean     3.992320e+04\nstd      2.141246e+05\nmin      9.999999e+00\n25%      2.171999e+03\n50%      5.922003e+03\n75%      1.944701e+04\nmax      8.483723e+06\nName: K, dtype: float64\n\nQUIM_CHINA[\"L\"].describe()\n\ncount    37656.000000\nmean       199.237864\nstd        526.069827\nmin          5.000000\n25%         42.999995\n50%         80.000029\n75%        178.000080\nmax      19193.999824\nName: L, dtype: float64\n\nQUIM_CHINA[\"M\"].describe()\n\ncount    3.765600e+04\nmean     6.075306e+04\nstd      2.380030e+05\nmin      1.300000e+01\n25%      7.280747e+03\n50%      1.593550e+04\n75%      4.122654e+04\nmax      1.268144e+07\nName: M, dtype: float64\n\n# Modelos estáticos para datos de panel\n# Modelo plano\nmodelo_plano = PooledOLS.from_formula('np.log(Y) ~ 1 + np.log(K) + np.log(L) + np.log(M)', QUIM_CHINA_pdata)\nres = modelo_plano.fit()\nprint(res)\n\n                          PooledOLS Estimation Summary                          \n================================================================================\nDep. Variable:              np.log(Y)   R-squared:                        0.9240\nEstimator:                  PooledOLS   R-squared (Between):              0.9468\nNo. Observations:               37656   R-squared (Within):               0.6708\nDate:                Tue, Nov 07 2023   R-squared (Overall):              0.9240\nTime:                        07:09:30   Log-likelihood                -1.406e+04\nCov. Estimator:            Unadjusted                                           \n                                        F-statistic:                   1.526e+05\nEntities:                       12552   P-value                           0.0000\nAvg Obs:                       3.0000   Distribution:                 F(3,37652)\nMin Obs:                       3.0000                                           \nMax Obs:                       3.0000   F-statistic (robust):          1.526e+05\n                                        P-value                           0.0000\nTime periods:                       3   Distribution:                 F(3,37652)\nAvg Obs:                    1.255e+04                                           \nMin Obs:                    1.255e+04                                           \nMax Obs:                    1.255e+04                                           \n                                                                                \n                             Parameter Estimates                              \n==============================================================================\n            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n------------------------------------------------------------------------------\nIntercept      1.4572     0.0135     108.16     0.0000      1.4308      1.4836\nnp.log(K)      0.0893     0.0017     53.910     0.0000      0.0860      0.0925\nnp.log(L)      0.1268     0.0025     51.716     0.0000      0.1219      0.1316\nnp.log(M)      0.7655     0.0018     428.44     0.0000      0.7620      0.7690\n==============================================================================\n\n# Modelo de efectos fijos\nmodelo_ef = PanelOLS.from_formula('np.log(Y) ~ 1 + np.log(K) + np.log(L) + np.log(M) + EntityEffects', QUIM_CHINA_pdata)\nres = modelo_ef.fit()\nprint(res)\n\n                          PanelOLS Estimation Summary                           \n================================================================================\nDep. Variable:              np.log(Y)   R-squared:                        0.6862\nEstimator:                   PanelOLS   R-squared (Between):              0.9305\nNo. Observations:               37656   R-squared (Within):               0.6862\nDate:                Tue, Nov 07 2023   R-squared (Overall):              0.9103\nTime:                        07:09:30   Log-likelihood                    6173.0\nCov. Estimator:            Unadjusted                                           \n                                        F-statistic:                    1.83e+04\nEntities:                       12552   P-value                           0.0000\nAvg Obs:                       3.0000   Distribution:                 F(3,25101)\nMin Obs:                       3.0000                                           \nMax Obs:                       3.0000   F-statistic (robust):           1.83e+04\n                                        P-value                           0.0000\nTime periods:                       3   Distribution:                 F(3,25101)\nAvg Obs:                    1.255e+04                                           \nMin Obs:                    1.255e+04                                           \nMax Obs:                    1.255e+04                                           \n                                                                                \n                             Parameter Estimates                              \n==============================================================================\n            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n------------------------------------------------------------------------------\nIntercept      2.5563     0.0420     60.803     0.0000      2.4739      2.6387\nnp.log(K)      0.0701     0.0037     18.801     0.0000      0.0628      0.0775\nnp.log(L)      0.1451     0.0058     24.928     0.0000      0.1337      0.1565\nnp.log(M)      0.6624     0.0032     208.17     0.0000      0.6562      0.6686\n==============================================================================\n\nF-test for Poolability: 3.8581\nP-value: 0.0000\nDistribution: F(12551,25101)\n\nIncluded effects: Entity\n\n# Modelo de efectos aleatorios\nmodelo_ea = RandomEffects.from_formula('np.log(Y) ~ 1 + np.log(K) + np.log(L) + np.log(M)', QUIM_CHINA_pdata)\nres = modelo_ea.fit()\nprint(res)\n\n                        RandomEffects Estimation Summary                        \n================================================================================\nDep. Variable:              np.log(Y)   R-squared:                        0.8779\nEstimator:              RandomEffects   R-squared (Between):              0.9455\nNo. Observations:               37656   R-squared (Within):               0.6777\nDate:                Tue, Nov 07 2023   R-squared (Overall):              0.9234\nTime:                        07:09:31   Log-likelihood                   -1974.9\nCov. Estimator:            Unadjusted                                           \n                                        F-statistic:                   9.028e+04\nEntities:                       12552   P-value                           0.0000\nAvg Obs:                       3.0000   Distribution:                 F(3,37652)\nMin Obs:                       3.0000                                           \nMax Obs:                       3.0000   F-statistic (robust):          9.028e+04\n                                        P-value                           0.0000\nTime periods:                       3   Distribution:                 F(3,37652)\nAvg Obs:                    1.255e+04                                           \nMin Obs:                    1.255e+04                                           \nMax Obs:                    1.255e+04                                           \n                                                                                \n                             Parameter Estimates                              \n==============================================================================\n            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n------------------------------------------------------------------------------\nIntercept      1.6637     0.0171     97.403     0.0000      1.6302      1.6972\nnp.log(K)      0.0936     0.0020     46.923     0.0000      0.0896      0.0975\nnp.log(L)      0.1397     0.0030     46.411     0.0000      0.1338      0.1456\nnp.log(M)      0.7347     0.0021     352.42     0.0000      0.7306      0.7388\n=============================================================================="
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "BIBLIOGRAFÍA",
    "section": "",
    "text": "Akaike H. (1973): “Information Theory and an Extension of the Maximum Likelihood Principle”, en B. Petrov y F. Csake (Eds.), Second International Symposium on Information Theory. Budapest: Akademiai Kiado.\nBreusch T. (1978): “Testing for Autocorrelation in Dynamic Linear Models”, Australian Economic Papers, Vol. 17, págs. 334-335.\nBreusch T. y Pagan A. (1979): “A Simple Test for Heterocedasticity and Random Coefficients Variation”, Econometrica, Vol. 47, págs. 1287-1294.\nChow G. (1960): “Tests of Equality between Sets of Coeffcients in Two Linear Regressions”, Econometrica, Vol. 28, págs. 591-598.\nCobb C. y Douglas P. (1928): “A theory of production”, American Economic Review, Supplement, Vol. 18, págs. 139-165.\nCochrane D. y Orcutt G. (1949): “Application of Least Squares Regressions to Relationships Containing Autocorrelated Error Terms”, Journal of the American Statistical Association, Vol. 44, págs. 32-61.\nCragg J. y Donald S. (1993): “Testing Identifiability and Specification in Instrumental Variable Models”, Econometric Theory, Vol. 9, págs. 222-240.\nDavidson R. y McKinnon J. (1981): “Several Tests for Model Specification in the Presence of Alternative Hypotheses”, Econometrica, Vol. 49, págs. 781-793.\nDavidson R. y McKinnon J. (1982): “Some Non-nested Hypothesis Tests and Relations Among Them”, Review of Economic Studies, Vol. 49, págs. 551-565.\nDurbin J. (1970): “Testing for Serial Correlation in Least Squares Regression when Some of the Regressors are Lagged Dependent Variables”, Econometrica, Vol. 38, págs. 410-421.\nDurbin J. y Watson G. (1950): “Testing for Serial Correlation in Least Squares Regression, I”, Biometrika, Vol. 37, págs. 409-428.\nDurbin J. y Watson G. (1951): “Testing for Serial Correlation in Least Squares Regression, II”, Biometrika, Vol. 38, págs. 159-178.\nDurbin J. y Watson G. (1971): “Testing for Serial Correlation in Least Squares Regression, III”, Biometrika, Vol. 58, págs. 1-42.\nEngle R. (1982): “Autoregressive Conditional Heteroskedasticity with Estimates of the Variance of United Kingdom Inflation”, Econometrica, Vol. 50, págs. 987-1008.\nEngle R. y Granger C. (1987): “Co-integration and Error Correction: Representation, Estimation, and Testing”, Econometrica, Vol. 55, págs. 251-276.\nGodfrey L. (1978): “Testing Against General Autoregressive and Moving Average Models when the Regressors Include Lagged Dependent Variables”, Econometrica, Vol. 46, págs. 1293-1302.\nHannan E. y Quinn B. (1979): “The Determination of the Order of an Autoregression”, Journal of the Royal Statistical Society, Series B, Vol. 41, págs. 190-195.\nHarvey A. (1976): “Estimating Regression Models with Multiplicative Heteroscedasticity”, Econometrica, Vol. 44, págs. 461-465.\nHausman J. (1978): “Specification Tests in Econometrics”, Econometrica, Vol. 46, págs. 1251-1271.\nHeckman J. (1976): “The Common Structure of Statistical Models of Truncation, Sample Selection, and Limited Dependent Variables and a Simple Estimator for Such Models”, Annals of Economic and Social Measurement, Vol. 5, págs. 475–492.\nHeckman J. (1979) “Sample Selection Bias as a Specification Error”, Econometrica, Vol 47, págs. 153–161.\nJarque C. y Bera A. (1987): “A Test for Normality of Observations and Regression Residuals”, International Statistical Review, Vol. 55, págs. 163-172.\nLucas R. (1976): “Econometric policy evaluation: a critique”, en Theory, Policy, Institutions: Papers from the Carnegie-Rochester Conference Series on Public Policy, K. Brunner y A. Meltzer (Eds.), Elsevier Science Publishers B.V. (North-Holland), 1983, págs. 257-284.\nMoran P. (1948): “The interpretation of statistical maps”, Journal of the Royal Statistical Society B, Vol. 10, págs. 243-251.\nNewey W. y West K. (1987): “A Simple Positive Semi-Definite, Heteroscedasticity and Autocorrelation Consistent Covariance Matrix”, Econometrica, Vol. 55, págs. 703-708.\nNewey W. y West K. (1994): “Automatic lag selection in covariance matrix estimation”, Review of Economic Studies, Vol. 61, págs. 631-653.\nPeña E.A. y Slate E.H. (2006): “Global validation of linear model assumptions”, Journal of the American Statistical Association, Vol. 101, págs. 341-354.\nQuandt R. (1960): “Tests of the Hypothesis that a Linear Regression System Obeys Two Different Regimes”, Journal of the American Statistical Association, Vol. 55, págs. 324-330.\nRamsey J. (1969): “Tests for Specification Errors in Classical Linear Least Squares Regression Analysis”, Journal of the Royal Statistical Society, Series B, págs. 350-371. Sargan J.D. (1958): “The Estimation of Economic Relationships Using Instrumental Variables”, Econometrica, Vol 26, págs. 393–415.\nSchwarz G. (1978): “Estimating the Dimension of a Model”, Annals of Statistics, Vol. 6, págs. 461-464.\nStock J. y Yogo M. (2005): “Testing for Weak Instruments in Linear IV Regression”, en D. Andrews y J. Stock (Eds.), Identification and Inference for Econometric Models: Essays in Honor of Thomas Rothenberg. Cambridge: Cambridge University Press.\nTobin J. (1958): “Estimation of Relationships for Limited Dependent Variables”, Econometrica, Vol. 26, págs. 24–36.\nWhite H. (1980): “A Heteroskedasticity Consistent Covariance Matrix Estimator and a Direct Test of Heteroskedasticity”, Econometrica, Vol. 48, págs. 817-838."
  },
  {
    "objectID": "p3c2-app3.html#diferenciación-salarial-por-sexo",
    "href": "p3c2-app3.html#diferenciación-salarial-por-sexo",
    "title": "Aplicación 3.3 (Estabilidad de los parámetros estructurales): Diferenciación salarial por sexo. Exportaciones españolas.",
    "section": "Diferenciación salarial por sexo",
    "text": "Diferenciación salarial por sexo\n\nDe nuevo en este ejemplo se usará como especificación econométrica de partida el siguiente modelo log-lineal, que se corresponde con la ecuación de salarios de Mincer:\n\\[\nlog(SALARIO_{i}) = \\beta_1 + \\beta_2  EDUC_{i} +  \\beta_3  EXPER_{i} + e_{i}\n\\]\ndonde \\(SALARIO\\), \\(EDUC\\) y \\(EXPER\\) representan, respectivamente, el salario percibido, el nivel de educación y el grado de experiencia de cada uno de los 526 indviduos que componen la base muestral.\n\n\nCódigo R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(car)\n# Lectura de datos\nSAL_SEX &lt;- read_csv(\"data/SAL_SEX.csv\")\ndim(SAL_SEX)\n\n[1] 526   4\n\nstr(SAL_SEX)\n\nspc_tbl_ [526 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ EDUC   : num [1:526] 11 12 11 8 12 16 18 12 12 17 ...\n $ EXPER  : num [1:526] 2 22 2 44 7 9 15 5 26 22 ...\n $ MUJER  : num [1:526] 1 1 0 0 0 0 0 1 1 0 ...\n $ SALARIO: num [1:526] 3.1 3.24 3 6 5.3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   EDUC = col_double(),\n  ..   EXPER = col_double(),\n  ..   MUJER = col_double(),\n  ..   SALARIO = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nhead(SAL_SEX)\n\n# A tibble: 6 × 4\n   EDUC EXPER MUJER SALARIO\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1    11     2     1    3.1 \n2    12    22     1    3.24\n3    11     2     0    3   \n4     8    44     0    6   \n5    12     7     0    5.3 \n6    16     9     0    8.75\n\ntail(SAL_SEX)\n\n# A tibble: 6 × 4\n   EDUC EXPER MUJER SALARIO\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1    12     2     0    5.65\n2    16    14     1   15   \n3    10     2     1    2.27\n4    15    13     0    4.67\n5    16     5     0   11.6 \n6    14     5     1    3.5 \n\n# Distribución de la variable dependiente\nBoxplot(~SALARIO, data=SAL_SEX, main=\"\", ylab=\"SALARIO\", id=list(method = \"none\"))\n\n\n\n# Conversión de variable numérica MUJER (0/1) a cualitativa (factor)\nclass(SAL_SEX$MUJER)\n\n[1] \"numeric\"\n\nSEXO &lt;- factor(SAL_SEX$MUJER, labels=c(\"Hombre\", \"Mujer\"))\nsummary(SEXO)\n\nHombre  Mujer \n   274    252 \n\n# Distribución de la variable dependiente por sexo\nBoxplot(SALARIO~SEXO, data=SAL_SEX, ylab=\"SALARIO\", id=list(method = \"none\"))\n\n\n\n# Ecuación de salarios para la muestra total\nsummary(lm_SAL &lt;- lm(log(SALARIO) ~ EDUC + EXPER , data = SAL_SEX))\n\n\nCall:\nlm(formula = log(SALARIO) ~ EDUC + EXPER, data = SAL_SEX)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.05800 -0.30136 -0.04539  0.30601  1.44425 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.216854   0.108595   1.997   0.0464 *  \nEDUC        0.097936   0.007622  12.848  &lt; 2e-16 ***\nEXPER       0.010347   0.001555   6.653 7.24e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4614 on 523 degrees of freedom\nMultiple R-squared:  0.2493,    Adjusted R-squared:  0.2465 \nF-statistic: 86.86 on 2 and 523 DF,  p-value: &lt; 2.2e-16\n\n# Gráficas parciales con diferenciación por sexo\nscatterplot(log(SALARIO) ~ EDUC| SEXO, data=SAL_SEX, smooth=FALSE, \n            boxplots=FALSE, ylab=\"Relación parcial log(Salario)/Educación\")\n\n\n\nscatterplot(log(SALARIO) ~ EXPER| SEXO, data=SAL_SEX, smooth=FALSE, \n            boxplots=FALSE, ylab=\"Relación parcial log(Salario)/Experiencia\")\n\n\n\n# Diferenciación por sexos:\n# ¿existe realmente diferenciación por sexos? (estadísticamente significativa)\n# Hombres\nsummary(lm_SAL_h &lt;- lm(log(SALARIO) ~ EDUC + EXPER , \n                       data = SAL_SEX[which(SAL_SEX$MUJER==0),]))\n\n\nCall:\nlm(formula = log(SALARIO) ~ EDUC + EXPER, data = SAL_SEX[which(SAL_SEX$MUJER == \n    0), ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.20460 -0.29936 -0.01032  0.28558  1.25532 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.249794   0.144264   1.732   0.0845 .  \nEDUC        0.101813   0.009656  10.544  &lt; 2e-16 ***\nEXPER       0.014908   0.002148   6.941 2.87e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4457 on 271 degrees of freedom\nMultiple R-squared:  0.3106,    Adjusted R-squared:  0.3055 \nF-statistic: 61.04 on 2 and 271 DF,  p-value: &lt; 2.2e-16\n\n# Mujeres\nsummary(lm_SAL_m &lt;- lm(log(SALARIO) ~ EDUC + EXPER , \n                       data = SAL_SEX[which(SAL_SEX$MUJER==1),]))\n\n\nCall:\nlm(formula = log(SALARIO) ~ EDUC + EXPER, data = SAL_SEX[which(SAL_SEX$MUJER == \n    1), ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.96983 -0.21953 -0.06965  0.21896  1.22467 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.334836   0.141456   2.367   0.0187 *  \nEDUC        0.082314   0.010458   7.871 1.08e-13 ***\nEXPER       0.004116   0.001894   2.173   0.0307 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.399 on 249 degrees of freedom\nMultiple R-squared:  0.1996,    Adjusted R-squared:  0.1932 \nF-statistic: 31.06 on 2 and 249 DF,  p-value: 9.089e-13\n\n# Comparación de coeficientes estimados\ncompareCoefs(lm_SAL_h, lm_SAL_m)\n\nCalls:\n1: lm(formula = log(SALARIO) ~ EDUC + EXPER, data = \n  SAL_SEX[which(SAL_SEX$MUJER == 0), ])\n2: lm(formula = log(SALARIO) ~ EDUC + EXPER, data = \n  SAL_SEX[which(SAL_SEX$MUJER == 1), ])\n\n            Model 1 Model 2\n(Intercept)   0.250   0.335\nSE            0.144   0.141\n                           \nEDUC        0.10181 0.08231\nSE          0.00966 0.01046\n                           \nEXPER       0.01491 0.00412\nSE          0.00215 0.00189\n                           \n\n# Test de Chow de cambio estructural\nlm_SAL_int &lt;- lm(log(SALARIO) ~ (EDUC + EXPER)*MUJER, data = SAL_SEX)\nanova(lm_SAL, lm_SAL_int)\n\nAnalysis of Variance Table\n\nModel 1: log(SALARIO) ~ EDUC + EXPER\nModel 2: log(SALARIO) ~ (EDUC + EXPER) * MUJER\n  Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    523 111.345                                  \n2    520  93.477  3    17.868 33.133 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Regresión diferenciada por sexos\nsummary(lm_SAL_int)\n\n\nCall:\nlm(formula = log(SALARIO) ~ (EDUC + EXPER) * MUJER, data = SAL_SEX)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.96983 -0.26177 -0.03718  0.25663  1.25532 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.249794   0.137237   1.820 0.069308 .  \nEDUC         0.101813   0.009186  11.084  &lt; 2e-16 ***\nEXPER        0.014908   0.002043   7.296 1.11e-12 ***\nMUJER        0.085042   0.203534   0.418 0.676247    \nEDUC:MUJER  -0.019499   0.014417  -1.352 0.176818    \nEXPER:MUJER -0.010792   0.002868  -3.763 0.000187 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.424 on 520 degrees of freedom\nMultiple R-squared:  0.3698,    Adjusted R-squared:  0.3637 \nF-statistic: 61.03 on 5 and 520 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCódigo Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.stats as smstats\nimport scipy as sp\n# Lectura de datos\nSAL_SEX = pd.read_csv(\"data/SAL_SEX.csv\")\nSAL_SEX.shape\n\n(526, 4)\n\nSAL_SEX.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 526 entries, 0 to 525\nData columns (total 4 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   EDUC     526 non-null    int64  \n 1   EXPER    526 non-null    int64  \n 2   MUJER    526 non-null    int64  \n 3   SALARIO  526 non-null    float64\ndtypes: float64(1), int64(3)\nmemory usage: 16.6 KB\n\nSAL_SEX.head()\n\n   EDUC  EXPER  MUJER  SALARIO\n0    11      2      1     3.10\n1    12     22      1     3.24\n2    11      2      0     3.00\n3     8     44      0     6.00\n4    12      7      0     5.30\n\nSAL_SEX.tail()\n\n     EDUC  EXPER  MUJER  SALARIO\n521    16     14      1    15.00\n522    10      2      1     2.27\n523    15     13      0     4.67\n524    16      5      0    11.56\n525    14      5      1     3.50\n\n# Distribución de la variable dependiente\nplt.figure(1)\nsns.boxplot(x=SAL_SEX[\"SALARIO\"])\nplt.show()\n\n\n\n# Conversión de variable numérica a cualitativa (factor)\nSAL_SEX['SEXO']=SAL_SEX['MUJER'].astype('category')\nSAL_SEX['SEXO']=SAL_SEX['SEXO'].cat.rename_categories(['Hombre', 'Mujer'])\n# Distribución de la variable dependiente por sexo\nplt.figure(2)\nsns.boxplot(x=SAL_SEX[\"SALARIO\"] , y=SAL_SEX[\"SEXO\"])\nplt.show()\n\n\n\n# Ecuación de salarios para la muestra total\nlm_SAL = smf.ols(formula='np.log(SALARIO) ~ EDUC + EXPER', data=SAL_SEX).fit()\nprint(lm_SAL.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        np.log(SALARIO)   R-squared:                       0.249\nModel:                            OLS   Adj. R-squared:                  0.246\nMethod:                 Least Squares   F-statistic:                     86.86\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           2.68e-33\nTime:                        18:42:06   Log-Likelihood:                -338.01\nNo. Observations:                 526   AIC:                             682.0\nDf Residuals:                     523   BIC:                             694.8\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.2169      0.109      1.997      0.046       0.004       0.430\nEDUC           0.0979      0.008     12.848      0.000       0.083       0.113\nEXPER          0.0103      0.002      6.653      0.000       0.007       0.013\n==============================================================================\nOmnibus:                        7.740   Durbin-Watson:                   1.789\nProb(Omnibus):                  0.021   Jarque-Bera (JB):                9.485\nSkew:                           0.165   Prob(JB):                      0.00872\nKurtosis:                       3.569   Cond. No.                         130.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Gráficas parciales con diferenciación por sexo\nSAL_SEX['l_SALARIO']=np.log(SAL_SEX['SALARIO'])\nplt.figure(3)\nsns.lmplot(x=\"EDUC\", y=\"l_SALARIO\", hue=\"SEXO\", data=SAL_SEX);\nplt.show()\n\n\n\nplt.figure(4)\nsns.lmplot(x=\"EXPER\", y=\"l_SALARIO\", hue=\"SEXO\", data=SAL_SEX);\nplt.show()\n\n\n\n# Diferenciación por sexos:\n# ¿existe realmente diferenciación por sexos? (estadísticamente significativa)\n# Hombres\nlm_SAL_h = smf.ols(formula='np.log(SALARIO) ~ EDUC + EXPER', \nsubset=(SAL_SEX['MUJER'] == 0), data=SAL_SEX).fit()\nprint(lm_SAL_h.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        np.log(SALARIO)   R-squared:                       0.311\nModel:                            OLS   Adj. R-squared:                  0.305\nMethod:                 Least Squares   F-statistic:                     61.04\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           1.30e-22\nTime:                        18:42:08   Log-Likelihood:                -165.86\nNo. Observations:                 274   AIC:                             337.7\nDf Residuals:                     271   BIC:                             348.5\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.2498      0.144      1.732      0.084      -0.034       0.534\nEDUC           0.1018      0.010     10.544      0.000       0.083       0.121\nEXPER          0.0149      0.002      6.941      0.000       0.011       0.019\n==============================================================================\nOmnibus:                        0.921   Durbin-Watson:                   1.872\nProb(Omnibus):                  0.631   Jarque-Bera (JB):                0.674\nSkew:                           0.098   Prob(JB):                        0.714\nKurtosis:                       3.143   Cond. No.                         131.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Mujeres\nlm_SAL_m = smf.ols(formula='np.log(SALARIO) ~ EDUC + EXPER', \nsubset=(SAL_SEX['MUJER'] == 1), data=SAL_SEX).fit()\nprint(lm_SAL_m.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        np.log(SALARIO)   R-squared:                       0.200\nModel:                            OLS   Adj. R-squared:                  0.193\nMethod:                 Least Squares   F-statistic:                     31.06\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           9.09e-13\nTime:                        18:42:08   Log-Likelihood:                -124.54\nNo. Observations:                 252   AIC:                             255.1\nDf Residuals:                     249   BIC:                             265.7\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.3348      0.141      2.367      0.019       0.056       0.613\nEDUC           0.0823      0.010      7.871      0.000       0.062       0.103\nEXPER          0.0041      0.002      2.173      0.031       0.000       0.008\n==============================================================================\nOmnibus:                       17.664   Durbin-Watson:                   2.103\nProb(Omnibus):                  0.000   Jarque-Bera (JB):               56.098\nSkew:                           0.007   Prob(JB):                     6.58e-13\nKurtosis:                       5.311   Cond. No.                         133.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Regresión diferenciada por sexos\nlm_SAL_int = smf.ols(formula='np.log(SALARIO) ~ (EDUC + EXPER)*MUJER', \ndata=SAL_SEX).fit()\nprint(lm_SAL_int.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:        np.log(SALARIO)   R-squared:                       0.370\nModel:                            OLS   Adj. R-squared:                  0.364\nMethod:                 Least Squares   F-statistic:                     61.03\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           5.27e-50\nTime:                        18:42:08   Log-Likelihood:                -292.01\nNo. Observations:                 526   AIC:                             596.0\nDf Residuals:                     520   BIC:                             621.6\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n-------------------------------------------------------------------------------\nIntercept       0.2498      0.137      1.820      0.069      -0.020       0.519\nEDUC            0.1018      0.009     11.084      0.000       0.084       0.120\nEXPER           0.0149      0.002      7.296      0.000       0.011       0.019\nMUJER           0.0850      0.204      0.418      0.676      -0.315       0.485\nEDUC:MUJER     -0.0195      0.014     -1.352      0.177      -0.048       0.009\nEXPER:MUJER    -0.0108      0.003     -3.763      0.000      -0.016      -0.005\n==============================================================================\nOmnibus:                       12.139   Durbin-Watson:                   1.802\nProb(Omnibus):                  0.002   Jarque-Bera (JB):               22.040\nSkew:                           0.063   Prob(JB):                     1.64e-05\nKurtosis:                       3.995   Cond. No.                         333.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Test de Chow de cambio estructural\nsm.stats.anova_lm(lm_SAL,lm_SAL_int) \n\n   df_resid         ssr  df_diff    ss_diff          F        Pr(&gt;F)\n0     523.0  111.344709      0.0        NaN        NaN           NaN\n1     520.0   93.476534      3.0  17.868174  33.132916  1.306612e-19"
  },
  {
    "objectID": "p3c2-app3.html#exportaciones-antes-y-después-de-la-entrada-de-españa-en-la-unión-europea",
    "href": "p3c2-app3.html#exportaciones-antes-y-después-de-la-entrada-de-españa-en-la-unión-europea",
    "title": "Aplicación 3.3 (Estabilidad de los parámetros estructurales): Diferenciación salarial por sexo. Exportaciones españolas.",
    "section": "Exportaciones antes y después de la entrada de España en la Unión Europea",
    "text": "Exportaciones antes y después de la entrada de España en la Unión Europea\n\nTanto la teoría económica como la experiencia econométrica internacional nos señalan que las exportaciones de bienes y servicios de un país dependen de dos variables básicas, un indicador de actividad económica mundial y un indicador de precios relativos. Para estimar una ecuación de exportaciones para el caso español, se han tomado series de datos históricos para el período 1970-1997 de las siguientes variables: las exportaciones reales de bienes y servicios, excluido el turismo (\\(XGS\\)); el índice anual del producto interior bruto real mundial (\\(WGDP\\)); y el tipo de cambio efectivo real respecto al conjunto de las diez monedas principales, corregido por la relación de precios de exportación de España respecto a la media ponderada de los precios de exportación de los principales países (\\(REER\\)).\n\nEl modelo de regresión que se usará como soporte del ejemplo es el siguiente:\n\\[\nlog(XGS_{t}) = \\beta_1 + \\beta_2  log(WGDP_{t}) +  \\beta_3  log(REER_{t}) + e_{t}\n\\]\n\nCódigo R\n\n# Lectura de librerías\nlibrary(tidyverse)\nlibrary(car)\n# Lectura de datos\nEXP_ESP &lt;- read_delim(\"data/EXP_ESP_Y.csv\", delim = \";\")\n# División de la muestra entre preUE (1970-1985) y postUE (1986-1997)\nY1986 = match(as.Date(\"1986-01-01\"), EXP_ESP$date)\nY1986\n\n[1] 17\n\n# Variables numérica y cualitativa de subperíodos\nUE &lt;- factor(c(rep(0, 16), rep(1, 12)), labels=c(\"preUE\", \"postUE\"))\nUE\n\n [1] preUE  preUE  preUE  preUE  preUE  preUE  preUE  preUE  preUE  preUE \n[11] preUE  preUE  preUE  preUE  preUE  preUE  postUE postUE postUE postUE\n[21] postUE postUE postUE postUE postUE postUE postUE postUE\nLevels: preUE postUE\n\nclass(UE)\n\n[1] \"factor\"\n\nEXP_ESP$D1986 &lt;- as.numeric(UE)-1\nEXP_ESP$D1986\n\n [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n\nclass(EXP_ESP$D1986)\n\n[1] \"numeric\"\n\n# Formato de series temporales\nEXP_ESP_ts &lt;- ts(EXP_ESP[,2:5], start=c(1970), end = c(1997), frequency = 1)\nplot(EXP_ESP_ts)\n\n\n\n# Ecuación de exportaciones para el período completo (1970-1997)\nlm_X_ESP &lt;- lm(log(XGS) ~ log(WGDP) + log(REER), data = EXP_ESP_ts)\nsummary(lm_X_ESP)\n\n\nCall:\nlm(formula = log(XGS) ~ log(WGDP) + log(REER), data = EXP_ESP_ts)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.08302 -0.04419 -0.02013  0.03883  0.14376 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.24239    0.84432  -0.287    0.776    \nlog(WGDP)    2.04618    0.06235  32.820   &lt;2e-16 ***\nlog(REER)   -0.34878    0.21480  -1.624    0.117    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06663 on 25 degrees of freedom\nMultiple R-squared:  0.9853,    Adjusted R-squared:  0.9841 \nF-statistic: 836.6 on 2 and 25 DF,  p-value: &lt; 2.2e-16\n\n# Gráficas parciales con diferenciación por subperíodos\nscatterplot(log(XGS) ~ log(WGDP)| D1986, data=EXP_ESP_ts, \n            smooth=FALSE, boxplots=FALSE, \n            ylab=\"Relación parcial Exportaciones/PIB mundial (logs)\")\n\n\n\nscatterplot(log(XGS) ~ log(REER)| D1986, data=EXP_ESP_ts, \n            smooth=FALSE, boxplots=FALSE, \n            ylab=\"Relación parcial Exportaciones/Tipo de cambio (logs)\")\n\n\n\n# Diferenciación por subperíodos\n# PreUE\npreUE &lt;- window(EXP_ESP_ts, start=1970, end = 1985)\nlm_X_ESP_preUE &lt;- lm(log(XGS) ~ log(WGDP) + log(REER) , data = preUE)\nsummary(lm_X_ESP_preUE)\n\n\nCall:\nlm(formula = log(XGS) ~ log(WGDP) + log(REER), data = preUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.085980 -0.029433  0.003653  0.027247  0.084831 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   2.5078     1.6493   1.520   0.1523    \nlog(WGDP)     1.8144     0.0846  21.447 1.57e-11 ***\nlog(REER)    -0.6945     0.3187  -2.179   0.0483 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05124 on 13 degrees of freedom\nMultiple R-squared:  0.9763,    Adjusted R-squared:  0.9727 \nF-statistic: 267.8 on 2 and 13 DF,  p-value: 2.725e-11\n\n# PostUE\npostUE &lt;- window(EXP_ESP_ts, start=1986, end = 1997)\nlm_X_ESP_postUE &lt;- lm(log(XGS) ~ log(WGDP) + log(REER) , data = postUE)\nsummary(lm_X_ESP_postUE)\n\n\nCall:\nlm(formula = log(XGS) ~ log(WGDP) + log(REER), data = postUE)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.052680 -0.032117  0.005373  0.029904  0.037074 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -1.6788     0.8889  -1.889  0.09153 .  \nlog(WGDP)     2.6425     0.1032  25.610 1.02e-09 ***\nlog(REER)    -0.7220     0.1933  -3.735  0.00466 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.03661 on 9 degrees of freedom\nMultiple R-squared:  0.9871,    Adjusted R-squared:  0.9842 \nF-statistic: 344.6 on 2 and 9 DF,  p-value: 3.133e-09\n\n# Comparación de coeficientes estimados\ncompareCoefs(lm_X_ESP_preUE,lm_X_ESP_postUE)\n\nCalls:\n1: lm(formula = log(XGS) ~ log(WGDP) + log(REER), data = preUE)\n2: lm(formula = log(XGS) ~ log(WGDP) + log(REER), data = postUE)\n\n            Model 1 Model 2\n(Intercept)   2.508  -1.679\nSE            1.649   0.889\n                           \nlog(WGDP)    1.8144  2.6425\nSE           0.0846  0.1032\n                           \nlog(REER)    -0.694  -0.722\nSE            0.319   0.193\n                           \n\n# ¿Existe diferenciación estadísticamente significativa por períodos?\n# Test de Chow de cambio estructural\n# Método 1 (ANOVA)\nlm_X_EXP_int &lt;- lm(log(XGS) ~ (log(WGDP) + log(REER))*D1986, \n                   data = EXP_ESP_ts)\nsummary(lm_X_EXP_int)\n\n\nCall:\nlm(formula = log(XGS) ~ (log(WGDP) + log(REER)) * D1986, data = EXP_ESP_ts)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.085980 -0.030598  0.004582  0.029904  0.084831 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.50775    1.47498   1.700   0.1032    \nlog(WGDP)        1.81445    0.07566  23.982  &lt; 2e-16 ***\nlog(REER)       -0.69447    0.28504  -2.436   0.0234 *  \nD1986           -4.18659    1.84754  -2.266   0.0336 *  \nlog(WGDP):D1986  0.82803    0.14968   5.532 1.47e-05 ***\nlog(REER):D1986 -0.02750    0.37389  -0.074   0.9420    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04583 on 22 degrees of freedom\nMultiple R-squared:  0.9939,    Adjusted R-squared:  0.9925 \nF-statistic: 713.6 on 5 and 22 DF,  p-value: &lt; 2.2e-16\n\nanova(lm_X_ESP, lm_X_EXP_int)\n\nAnalysis of Variance Table\n\nModel 1: log(XGS) ~ log(WGDP) + log(REER)\nModel 2: log(XGS) ~ (log(WGDP) + log(REER)) * D1986\n  Res.Df      RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     25 0.110991                                  \n2     22 0.046204  3  0.064787 10.283 0.0001978 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Método 2 (librería structchange)\nlibrary(strucchange)\nsctest(log(XGS) ~ log(WGDP) + log(REER), data=EXP_ESP_ts, \n       type = \"Chow\", point = Y1986-1)\n\n\n    Chow test\n\ndata:  log(XGS) ~ log(WGDP) + log(REER)\nF = 10.283, p-value = 0.0001978\n\n# Contrastes tipo Chow basados en estimaciones recursivas\n# [se elimina un % de observaciones en los extremmos]\nsbtest &lt;- Fstats(log(XGS) ~ log(WGDP) + log(REER), data = EXP_ESP_ts, \n                 from = 0.15, to = 0.85)\nsbtest[[\"Fstats\"]]\n\nTime Series:\nStart = 1973 \nEnd = 1992 \nFrequency = 1 \n [1] 26.94858 40.37538 52.72550 53.14715 43.28653 41.27132 51.76225 53.52206\n [9] 43.97098 39.04442 33.07102 30.47271 30.84853 32.31100 37.23453 41.05085\n[17] 41.68393 41.71401 38.20854 33.80421\n\nplot(sbtest, alpha = 0.05)\n\n\n\n# Test de Chow (1960) [versión Chi2]\n# [punto de ruptura conocido: 17 - 4 (15% suprimidos a la izquierda) ]\nChow_F &lt;- sbtest$Fstats[Y1986-4] \nChow_F \n\n[1] 30.84853\n\n# Se puede comprobar que CHOW=Chow_F/K\n# Chow_F tiene una distribución asintótica Chi^2 mientras que\n# CHOW tiene una distribución exacta F_K,T-2*K\npval &lt;-  1-pchisq(Chow_F,sbtest$nreg) \npval\n\n[1] 9.148179e-07\n\n# Contrastes de Andrews (1993) y Andrews y Ploberger (1994): supF, aveF, expF\n# [punto de ruptura desconocido]\nsctest(sbtest, type = \"supF\")\n\n\n    supF test\n\ndata:  sbtest\nsup.F = 53.522, p-value = 2.556e-10\n\nsctest(sbtest, type = \"aveF\")\n\n\n    aveF test\n\ndata:  sbtest\nave.F = 40.323, p-value = 1.043e-13\n\nsctest(sbtest, type = \"expF\")\n\n\n    expF test\n\ndata:  sbtest\nexp.F = 24.845, p-value = 0.0007622\n\n# Test CUSUM (Brown, Durbin y Evans, 1975)\nplot(efp(log(XGS) ~ log(WGDP) + log(REER), data = EXP_ESP_ts))\n\n\n\n# Regresión diferenciada por tramos temporales\nsummary(lm(log(XGS) ~ (log(WGDP) + log(REER))*D1986, data=EXP_ESP_ts))\n\n\nCall:\nlm(formula = log(XGS) ~ (log(WGDP) + log(REER)) * D1986, data = EXP_ESP_ts)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.085980 -0.030598  0.004582  0.029904  0.084831 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.50775    1.47498   1.700   0.1032    \nlog(WGDP)        1.81445    0.07566  23.982  &lt; 2e-16 ***\nlog(REER)       -0.69447    0.28504  -2.436   0.0234 *  \nD1986           -4.18659    1.84754  -2.266   0.0336 *  \nlog(WGDP):D1986  0.82803    0.14968   5.532 1.47e-05 ***\nlog(REER):D1986 -0.02750    0.37389  -0.074   0.9420    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.04583 on 22 degrees of freedom\nMultiple R-squared:  0.9939,    Adjusted R-squared:  0.9925 \nF-statistic: 713.6 on 5 and 22 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nCódigo Python\n\n# Lectura de librerías\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy as sp\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport statsmodels.stats as smstats\n# Lectura de datos\nEXP_ESP = pd.read_csv(\"data/EXP_ESP_Y.csv\", sep=\";\", \nparse_dates=['date'], index_col='date')\ndate = pd.date_range(start = '1970', periods = len(EXP_ESP.index), freq = 'Y')\nEXP_ESP.index = date\nEXP_ESP.index\n\nDatetimeIndex(['1970-12-31', '1971-12-31', '1972-12-31', '1973-12-31',\n               '1974-12-31', '1975-12-31', '1976-12-31', '1977-12-31',\n               '1978-12-31', '1979-12-31', '1980-12-31', '1981-12-31',\n               '1982-12-31', '1983-12-31', '1984-12-31', '1985-12-31',\n               '1986-12-31', '1987-12-31', '1988-12-31', '1989-12-31',\n               '1990-12-31', '1991-12-31', '1992-12-31', '1993-12-31',\n               '1994-12-31', '1995-12-31', '1996-12-31', '1997-12-31'],\n              dtype='datetime64[ns]', freq='A-DEC')\n\nEXP_ESP.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 28 entries, 1970-12-31 to 1997-12-31\nFreq: A-DEC\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   XGS     28 non-null     float64\n 1   REER    28 non-null     float64\n 2   WGDP    28 non-null     float64\ndtypes: float64(3)\nmemory usage: 896.0 bytes\n\nEXP_ESP.head()\n\n                    XGS        REER        WGDP\n1970-12-31  2225.123047  100.495876  104.200000\n1971-12-31  2541.091064  101.909402  109.410000\n1972-12-31  2881.596924  107.146269  115.646370\n1973-12-31  3169.757080  108.713460  123.972908\n1974-12-31  3138.059082  108.003898  127.072231\n\nEXP_ESP.tail()\n\n                  XGS        REER        WGDP\n1993-12-31   9579.586  114.520445  225.825635\n1994-12-31  11181.767  109.674712  235.084486\n1995-12-31  12299.895  116.021269  243.782612\n1996-12-31  13604.854  121.631204  253.777699\n1997-12-31  15611.863  116.142901  264.436363\n\n# Variables numérica y cualitativa de subperíodos\nEXP_ESP['D1986'] = np.where(EXP_ESP.index &gt; '1985-12-31', 1, 0)\nEXP_ESP['UE']=EXP_ESP['D1986'].astype('category')\nEXP_ESP['UE']=EXP_ESP['UE'].cat.rename_categories(['preUE', 'postUE'])\n# Ecuación de exportaciones para el período completo (1970-1997)\nlm_X_ESP = smf.ols(formula='np.log(XGS) ~ np.log(WGDP) + np.log(REER)', \ndata=EXP_ESP).fit()\nprint(lm_X_ESP.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            np.log(XGS)   R-squared:                       0.985\nModel:                            OLS   Adj. R-squared:                  0.984\nMethod:                 Least Squares   F-statistic:                     836.6\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           1.26e-23\nTime:                        18:42:10   Log-Likelihood:                 37.697\nNo. Observations:                  28   AIC:                            -69.39\nDf Residuals:                      25   BIC:                            -65.40\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept       -0.2424      0.844     -0.287      0.776      -1.981       1.497\nnp.log(WGDP)     2.0462      0.062     32.820      0.000       1.918       2.175\nnp.log(REER)    -0.3488      0.215     -1.624      0.117      -0.791       0.094\n==============================================================================\nOmnibus:                        2.960   Durbin-Watson:                   0.290\nProb(Omnibus):                  0.228   Jarque-Bera (JB):                2.618\nSkew:                           0.693   Prob(JB):                        0.270\nKurtosis:                       2.434   Cond. No.                         485.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Gráficas parciales con diferenciación por subperíodos\nEXP_ESP['l_XGS']=np.log(EXP_ESP['XGS'])\nEXP_ESP['l_WGDP']=np.log(EXP_ESP['WGDP'])\nEXP_ESP['l_REER']=np.log(EXP_ESP['REER'])\nplt.figure(5)\nsns.lmplot(x=\"l_WGDP\", y=\"l_XGS\", hue=\"UE\", data=EXP_ESP);\nplt.show()\n\n\n\nplt.figure(6)\nsns.lmplot(x=\"l_REER\", y=\"l_XGS\", hue=\"UE\", data=EXP_ESP);\nplt.show()\n\n\n\n# Diferenciación por subperíodos\n# PreUE\nlm_X_ESP_preUE = smf.ols(formula='np.log(XGS) ~ np.log(WGDP) + np.log(REER)', \nsubset=(EXP_ESP['D1986'] == 0), data=EXP_ESP).fit()\nprint(lm_X_ESP_preUE.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            np.log(XGS)   R-squared:                       0.976\nModel:                            OLS   Adj. R-squared:                  0.973\nMethod:                 Least Squares   F-statistic:                     267.8\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           2.72e-11\nTime:                        18:42:11   Log-Likelihood:                 26.496\nNo. Observations:                  16   AIC:                            -46.99\nDf Residuals:                      13   BIC:                            -44.68\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept        2.5077      1.649      1.520      0.152      -1.055       6.071\nnp.log(WGDP)     1.8144      0.085     21.447      0.000       1.632       1.997\nnp.log(REER)    -0.6945      0.319     -2.179      0.048      -1.383      -0.006\n==============================================================================\nOmnibus:                        0.094   Durbin-Watson:                   0.755\nProb(Omnibus):                  0.954   Jarque-Bera (JB):                0.314\nSkew:                           0.078   Prob(JB):                        0.855\nKurtosis:                       2.331   Cond. No.                         899.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# PostUE\nlm_X_ESP_postUE = smf.ols(formula='np.log(XGS) ~ np.log(WGDP) + np.log(REER)', \nsubset=(EXP_ESP['D1986'] == 1), data=EXP_ESP).fit()\nprint(lm_X_ESP_postUE.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            np.log(XGS)   R-squared:                       0.987\nModel:                            OLS   Adj. R-squared:                  0.984\nMethod:                 Least Squares   F-statistic:                     344.6\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           3.13e-09\nTime:                        18:42:12   Log-Likelihood:                 24.386\nNo. Observations:                  12   AIC:                            -42.77\nDf Residuals:                       9   BIC:                            -41.32\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n================================================================================\n                   coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------\nIntercept       -1.6788      0.889     -1.889      0.092      -3.690       0.332\nnp.log(WGDP)     2.6425      0.103     25.610      0.000       2.409       2.876\nnp.log(REER)    -0.7220      0.193     -3.735      0.005      -1.159      -0.285\n==============================================================================\nOmnibus:                        3.241   Durbin-Watson:                   1.134\nProb(Omnibus):                  0.198   Jarque-Bera (JB):                1.223\nSkew:                          -0.318   Prob(JB):                        0.543\nKurtosis:                       1.572   Cond. No.                         620.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n# Regresión diferenciada por tramos temporales\nlm_X_ESP_int = smf.ols(formula='np.log(XGS) ~ (np.log(WGDP) + np.log(REER))*D1986', \ndata=EXP_ESP).fit()\nprint(lm_X_ESP_int.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:            np.log(XGS)   R-squared:                       0.994\nModel:                            OLS   Adj. R-squared:                  0.992\nMethod:                 Least Squares   F-statistic:                     713.6\nDate:                Wed, 22 Nov 2023   Prob (F-statistic):           1.46e-23\nTime:                        18:42:12   Log-Likelihood:                 49.966\nNo. Observations:                  28   AIC:                            -87.93\nDf Residuals:                      22   BIC:                            -79.94\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n======================================================================================\n                         coef    std err          t      P&gt;|t|      [0.025      0.975]\n--------------------------------------------------------------------------------------\nIntercept              2.5077      1.475      1.700      0.103      -0.551       5.567\nnp.log(WGDP)           1.8144      0.076     23.982      0.000       1.658       1.971\nnp.log(REER)          -0.6945      0.285     -2.436      0.023      -1.286      -0.103\nD1986                 -4.1866      1.848     -2.266      0.034      -8.018      -0.355\nnp.log(WGDP):D1986     0.8280      0.150      5.532      0.000       0.518       1.138\nnp.log(REER):D1986    -0.0275      0.374     -0.074      0.942      -0.803       0.748\n==============================================================================\nOmnibus:                        0.097   Durbin-Watson:                   0.854\nProb(Omnibus):                  0.953   Jarque-Bera (JB):                0.319\nSkew:                           0.000   Prob(JB):                        0.853\nKurtosis:                       2.477   Cond. No.                     2.08e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 2.08e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n# Test de Chow de cambio estructural\nsm.stats.anova_lm(lm_X_ESP,lm_X_ESP_int) \n\n   df_resid       ssr  df_diff   ss_diff          F    Pr(&gt;F)\n0      25.0  0.110991      0.0       NaN        NaN       NaN\n1      22.0  0.046204      3.0  0.064787  10.282842  0.000198"
  }
]